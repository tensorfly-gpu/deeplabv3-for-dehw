{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adbc1c6d-ada5-422a-bd25-ccbbe9dad0e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-20T02:01:07.743241Z",
     "iopub.status.busy": "2022-01-20T02:01:07.742507Z",
     "iopub.status.idle": "2022-01-20T02:01:36.500165Z",
     "shell.execute_reply": "2022-01-20T02:01:36.499373Z",
     "shell.execute_reply.started": "2022-01-20T02:01:07.743201Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting paddlex==2.0.0\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/6b/60/ab6735f0699d002d994fd1ed9383bf5d8ac9423da2b4e3de65581905526b/paddlex-2.0.0-py3-none-any.whl (944kB)\n",
      "\u001b[K     |████████████████████████████████| 952kB 7.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex==2.0.0) (5.1.2)\n",
      "Collecting shapely>=1.7.0 (from paddlex==2.0.0)\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ae/20/33ce377bd24d122a4d54e22ae2c445b9b1be8240edb50040b40add950cd9/Shapely-1.8.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 45.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: chardet in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex==2.0.0) (3.0.4)\n",
      "Collecting lap (from paddlex==2.0.0)\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/bf/64/d9fb6a75b15e783952b2fec6970f033462e67db32dc43dfbb404c14e91c2/lap-0.4.0.tar.gz (1.5MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5MB 24.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex==2.0.0) (1.6.3)\n",
      "Collecting paddleslim==2.1.1 (from paddlex==2.0.0)\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ee/e7/c6b97eb6809d14634ae5cbf287285584045d6f8949d0b436dc64cbefbf7a/paddleslim-2.1.1-py3-none-any.whl (288kB)\n",
      "\u001b[K     |████████████████████████████████| 296kB 45.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex==2.0.0) (4.27.0)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex==2.0.0) (4.1.1.26)\n",
      "Collecting motmetrics (from paddlex==2.0.0)\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/9c/28/9c3bc8e2a87f4c9e7b04ab72856ec7f9895a66681a65973ffaf9562ef879/motmetrics-1.2.0-py3-none-any.whl (151kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 470kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: visualdl>=2.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex==2.0.0) (2.2.0)\n",
      "Collecting scikit-learn==0.23.2 (from paddlex==2.0.0)\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/f4/cb/64623369f348e9bfb29ff898a57ac7c91ed4921f228e9726546614d63ccb/scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8MB)\n",
      "\u001b[K     |████████████████████████████████| 6.8MB 4.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pycocotools (from paddlex==2.0.0)\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/75/5c/ac61ea715d7a89ecc31c090753bde28810238225ca8b71778dfe3e6a68bc/pycocotools-2.0.4.tar.gz (106kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 9.1MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex==2.0.0) (0.4.4)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scipy->paddlex==2.0.0) (1.20.3)\n",
      "Requirement already satisfied: pillow in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleslim==2.1.1->paddlex==2.0.0) (7.1.2)\n",
      "Requirement already satisfied: pyzmq in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleslim==2.1.1->paddlex==2.0.0) (22.3.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleslim==2.1.1->paddlex==2.0.0) (2.2.3)\n",
      "Collecting pytest-benchmark (from motmetrics->paddlex==2.0.0)\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/2c/60/423a63fb190a0483d049786a121bd3dfd7d93bb5ff1bb5b5cd13e5df99a7/pytest_benchmark-3.4.1-py2.py3-none-any.whl (50kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 221kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.23.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from motmetrics->paddlex==2.0.0) (1.1.5)\n",
      "Collecting xmltodict>=0.12.0 (from motmetrics->paddlex==2.0.0)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/28/fd/30d5c1d3ac29ce229f6bdc40bbc20b28f716e8b363140c26eff19122d8a5/xmltodict-0.12.0-py2.py3-none-any.whl\n",
      "Collecting pytest (from motmetrics->paddlex==2.0.0)\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/40/76/86f886e750b81a4357b6ed606b2bcf0ce6d6c27ad3c09ebf63ed674fc86e/pytest-6.2.5-py3-none-any.whl (280kB)\n",
      "\u001b[K     |████████████████████████████████| 286kB 6.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: flake8 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from motmetrics->paddlex==2.0.0) (4.0.1)\n",
      "Collecting flake8-import-order (from motmetrics->paddlex==2.0.0)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ab/52/cf2d6e2c505644ca06de2f6f3546f1e4f2b7be34246c9e0757c6048868f9/flake8_import_order-0.18.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.1->paddlex==2.0.0) (0.8.53)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.1->paddlex==2.0.0) (1.16.0)\n",
      "Requirement already satisfied: pre-commit in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.1->paddlex==2.0.0) (1.21.0)\n",
      "Requirement already satisfied: shellcheck-py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.1->paddlex==2.0.0) (0.7.1.1)\n",
      "Requirement already satisfied: protobuf>=3.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.1->paddlex==2.0.0) (3.14.0)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.1->paddlex==2.0.0) (2.22.0)\n",
      "Requirement already satisfied: flask>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.1->paddlex==2.0.0) (1.1.1)\n",
      "Requirement already satisfied: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.1->paddlex==2.0.0) (1.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn==0.23.2->paddlex==2.0.0) (0.14.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn==0.23.2->paddlex==2.0.0) (2.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddleslim==2.1.1->paddlex==2.0.0) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddleslim==2.1.1->paddlex==2.0.0) (3.0.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddleslim==2.1.1->paddlex==2.0.0) (1.1.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddleslim==2.1.1->paddlex==2.0.0) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddleslim==2.1.1->paddlex==2.0.0) (2.8.2)\n",
      "Collecting py-cpuinfo (from pytest-benchmark->motmetrics->paddlex==2.0.0)\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/e6/ba/77120e44cbe9719152415b97d5bfb29f4053ee987d6cb63f55ce7d50fadc/py-cpuinfo-8.0.0.tar.gz (99kB)\n",
      "\u001b[K     |████████████████████████████████| 102kB 17.5MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: toml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pytest->motmetrics->paddlex==2.0.0) (0.10.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pytest->motmetrics->paddlex==2.0.0) (21.3)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pytest->motmetrics->paddlex==2.0.0) (21.2.0)\n",
      "Collecting iniconfig (from pytest->motmetrics->paddlex==2.0.0)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/9b/dd/b3c12c6d707058fa947864b67f0c4e0c39ef8610988d7baea9578f3c48f3/iniconfig-1.1.1-py2.py3-none-any.whl\n",
      "Collecting py>=1.8.2 (from pytest->motmetrics->paddlex==2.0.0)\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/f6/f0/10642828a8dfb741e5f3fbaac830550a518a775c7fff6f04a007259b0548/py-1.11.0-py2.py3-none-any.whl (98kB)\n",
      "\u001b[K     |████████████████████████████████| 102kB 7.0MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pytest->motmetrics->paddlex==2.0.0) (4.2.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pytest->motmetrics->paddlex==2.0.0) (0.13.1)\n",
      "Requirement already satisfied: pyflakes<2.5.0,>=2.4.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8->motmetrics->paddlex==2.0.0) (2.4.0)\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8->motmetrics->paddlex==2.0.0) (0.6.1)\n",
      "Requirement already satisfied: pycodestyle<2.9.0,>=2.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8->motmetrics->paddlex==2.0.0) (2.8.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8-import-order->motmetrics->paddlex==2.0.0) (56.2.0)\n",
      "Requirement already satisfied: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.1.1->paddlex==2.0.0) (3.9.9)\n",
      "Requirement already satisfied: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.1.1->paddlex==2.0.0) (0.18.0)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.1.1->paddlex==2.0.0) (1.3.4)\n",
      "Requirement already satisfied: identify>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.1.1->paddlex==2.0.0) (1.4.10)\n",
      "Requirement already satisfied: virtualenv>=15.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.1.1->paddlex==2.0.0) (16.7.9)\n",
      "Requirement already satisfied: aspy.yaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.1.1->paddlex==2.0.0) (1.3.0)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.1.1->paddlex==2.0.0) (2.0.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.1.1->paddlex==2.0.0) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.1.1->paddlex==2.0.0) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.1.1->paddlex==2.0.0) (1.25.6)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.1.1->paddlex==2.0.0) (1.1.0)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.1.1->paddlex==2.0.0) (2.11.0)\n",
      "Requirement already satisfied: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.1.1->paddlex==2.0.0) (7.0)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.1.1->paddlex==2.0.0) (0.16.0)\n",
      "Requirement already satisfied: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.1.1->paddlex==2.0.0) (2.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest->motmetrics->paddlex==2.0.0) (4.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest->motmetrics->paddlex==2.0.0) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask>=1.1.1->visualdl>=2.1.1->paddlex==2.0.0) (2.0.1)\n",
      "Building wheels for collected packages: pycocotools\n",
      "  Building wheel for pycocotools (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.4-cp37-cp37m-linux_x86_64.whl size=273758 sha256=31327461fe3a46528b8d5ba92c4cee3a2cd0911d972b5fe703d685f87fbe1ba6\n",
      "  Stored in directory: /home/aistudio/.cache/pip/wheels/d6/61/17/17dc1a5c5902b4ece462574ce618c89f6db0113a69b8f2eee7\n",
      "Successfully built pycocotools\n",
      "Building wheels for collected packages: lap, py-cpuinfo\n",
      "  Building wheel for lap (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lap: filename=lap-0.4.0-cp37-cp37m-linux_x86_64.whl size=1593858 sha256=260bb02ea1389cc04f57605673cc996c75379d5687cf0015f45b5e206ee4f023\n",
      "  Stored in directory: /home/aistudio/.cache/pip/wheels/66/b9/1a/5c513d0b33edd38e4b95052909201336e6526c65226044faff\n",
      "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-cp37-none-any.whl size=22245 sha256=42e3f5ff4547515450224f959ae22a13fab67ab5b086b0815667964c48dd259c\n",
      "  Stored in directory: /home/aistudio/.cache/pip/wheels/6e/ad/c2/8f2580a65eaae741237aede048de6f6c019874e25dbaddfe14\n",
      "Successfully built lap py-cpuinfo\n",
      "\u001b[31mERROR: blackhole 1.0.1 has requirement numpy<=1.19.5, but you'll have numpy 1.20.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: shapely, lap, paddleslim, py-cpuinfo, iniconfig, py, pytest, pytest-benchmark, xmltodict, flake8-import-order, motmetrics, scikit-learn, pycocotools, paddlex\n",
      "  Found existing installation: scikit-learn 0.24.2\n",
      "    Uninstalling scikit-learn-0.24.2:\n",
      "      Successfully uninstalled scikit-learn-0.24.2\n",
      "Successfully installed flake8-import-order-0.18.1 iniconfig-1.1.1 lap-0.4.0 motmetrics-1.2.0 paddleslim-2.1.1 paddlex-2.0.0 py-1.11.0 py-cpuinfo-8.0.0 pycocotools-2.0.4 pytest-6.2.5 pytest-benchmark-3.4.1 scikit-learn-0.23.2 shapely-1.8.0 xmltodict-0.12.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"安装paddlex\"\"\"\n",
    "! pip install paddlex==2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0081beca-7e63-4542-a2f6-c9de3316c292",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-20T11:58:43.317192Z",
     "iopub.status.busy": "2022-01-20T11:58:43.316736Z",
     "iopub.status.idle": "2022-01-20T11:58:47.669997Z",
     "shell.execute_reply": "2022-01-20T11:58:47.669307Z",
     "shell.execute_reply.started": "2022-01-20T11:58:43.317154Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/distributed/parallel.py:136: UserWarning: Currently not a parallel execution environment, `paddle.distributed.init_parallel_env` will not do anything.\n",
      "  \"Currently not a parallel execution environment, `paddle.distributed.init_parallel_env` will not do anything.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01-20 19:58:44 MainThread @utils.py:79] WRN paddlepaddle version: 2.2.1. The dynamic graph version of PARL is under development, not fully tested and supported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/parl/remote/communication.py:38: DeprecationWarning: 'pyarrow.default_serialization_context' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n",
      "  context = pyarrow.default_serialization_context()\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pyarrow/pandas_compat.py:1027: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  'floating': np.float,\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import MutableMapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable, Mapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sized\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/tensor/creation.py:130: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if data.dtype == np.object:\n"
     ]
    }
   ],
   "source": [
    "\"\"\"导入包\"\"\"\n",
    "import paddlex as pdx\n",
    "import random\n",
    "import numpy as np\n",
    "import paddle\n",
    "\n",
    "from paddlex import transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12d324ad-9ea7-43c5-b1ff-4bada81edb42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-20T11:58:56.988106Z",
     "iopub.status.busy": "2022-01-20T11:58:56.987578Z",
     "iopub.status.idle": "2022-01-20T11:58:56.994339Z",
     "shell.execute_reply": "2022-01-20T11:58:56.993679Z",
     "shell.execute_reply.started": "2022-01-20T11:58:56.988066Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"定义数据处理方式\"\"\"\n",
    "train_transforms = T.Compose([\n",
    "    T.Resize(target_size=1024),\n",
    "    T.MixupImage(alpha=1.5, beta=1.5, mixup_epoch=-20),\n",
    "    T.RandomDistort(brightness_range=0.5, brightness_prob=0.5, contrast_range=0.5, contrast_prob=0.5, saturation_range=0.5, saturation_prob=0.5, hue_range=18, hue_prob=0.5, random_apply=True, count=4, shuffle_channel=False),\n",
    "    T.RandomBlur(prob=0.5),\n",
    "    T.Normalize(\n",
    "        mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "eval_transforms = T.Compose([\n",
    "    T.Resize(target_size=1024),\n",
    "    T.Normalize(\n",
    "        mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5fcf5bd-ae07-4933-b760-3bc4b31467e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-20T11:58:59.921755Z",
     "iopub.status.busy": "2022-01-20T11:58:59.920871Z",
     "iopub.status.idle": "2022-01-20T11:58:59.952957Z",
     "shell.execute_reply": "2022-01-20T11:58:59.952446Z",
     "shell.execute_reply.started": "2022-01-20T11:58:59.921717Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-20 19:58:59 [INFO]\t1913 samples in file train_path/all_data.txt\n",
      "2022-01-20 19:58:59 [INFO]\t50 samples in file train_path/val.txt\n"
     ]
    }
   ],
   "source": [
    "\"\"\"直接加载eval_dataset，后面预测就不用传入transfroms了\"\"\"\n",
    "train_dataset = pdx.datasets.SegDataset(\n",
    "    data_dir='',\n",
    "    file_list='train_path/all_data.txt',\n",
    "    label_list='train_path/labels.txt',\n",
    "    transforms=train_transforms,\n",
    "    shuffle=True)\n",
    "\n",
    "eval_dataset = pdx.datasets.SegDataset(\n",
    "    data_dir='',\n",
    "    file_list='train_path/val.txt',\n",
    "    label_list='train_path/labels.txt',\n",
    "    transforms=eval_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0beac06-36bd-43b1-a2d9-54c9f64b2dbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-20T02:01:51.498242Z",
     "iopub.status.busy": "2022-01-20T02:01:51.497317Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0120 10:01:51.502168   504 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W0120 10:01:51.507787   504 device_context.cc:465] device: 0, cuDNN Version: 7.6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-20 10:01:54 [INFO]\tDownloading model.pdparams from https://bj.bcebos.com/paddleseg/dygraph/cityscapes/deeplabv3p_resnet50_os8_cityscapes_1024x512_80k/model.pdparams\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157928/157928 [00:03<00:00, 44124.91KB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-20 10:01:58 [INFO]\tLoading pretrained model from model/deeplab_augument_alldata2/pretrain/model.pdparams\n",
      "2022-01-20 10:01:59 [WARNING]\t[SKIP] Shape of pretrained params head.decoder.conv.weight doesn't match.(Pretrained: [19, 256, 1, 1], Actual: [3, 256, 1, 1])\n",
      "2022-01-20 10:01:59 [WARNING]\t[SKIP] Shape of pretrained params head.decoder.conv.bias doesn't match.(Pretrained: [19], Actual: [3])\n",
      "2022-01-20 10:01:59 [INFO]\tThere are 358/360 variables loaded into DeepLabV3P.\n",
      "2022-01-20 10:02:03 [INFO]\t[TRAIN] Epoch=1/50, Step=2/478, loss=0.425905, lr=0.099997, time_each_step=1.94s, eta=12:54:17\n",
      "2022-01-20 10:02:06 [INFO]\t[TRAIN] Epoch=1/50, Step=4/478, loss=0.496119, lr=0.099990, time_each_step=1.26s, eta=8:20:18\n",
      "2022-01-20 10:02:08 [INFO]\t[TRAIN] Epoch=1/50, Step=6/478, loss=0.562343, lr=0.099983, time_each_step=1.26s, eta=8:20:38\n",
      "2022-01-20 10:02:11 [INFO]\t[TRAIN] Epoch=1/50, Step=8/478, loss=0.230614, lr=0.099977, time_each_step=1.26s, eta=8:20:52\n",
      "2022-01-20 10:02:13 [INFO]\t[TRAIN] Epoch=1/50, Step=10/478, loss=0.279981, lr=0.099970, time_each_step=1.26s, eta=8:20:51\n",
      "2022-01-20 10:02:16 [INFO]\t[TRAIN] Epoch=1/50, Step=12/478, loss=0.232883, lr=0.099963, time_each_step=1.26s, eta=8:22:14\n",
      "2022-01-20 10:02:18 [INFO]\t[TRAIN] Epoch=1/50, Step=14/478, loss=0.204452, lr=0.099956, time_each_step=1.26s, eta=8:22:23\n",
      "2022-01-20 10:02:21 [INFO]\t[TRAIN] Epoch=1/50, Step=16/478, loss=0.246002, lr=0.099950, time_each_step=1.26s, eta=8:22:57\n",
      "2022-01-20 10:02:23 [INFO]\t[TRAIN] Epoch=1/50, Step=18/478, loss=0.190176, lr=0.099943, time_each_step=1.26s, eta=8:21:54\n",
      "2022-01-20 10:02:26 [INFO]\t[TRAIN] Epoch=1/50, Step=20/478, loss=0.196353, lr=0.099936, time_each_step=1.26s, eta=8:22:20\n",
      "2022-01-20 10:02:28 [INFO]\t[TRAIN] Epoch=1/50, Step=22/478, loss=0.173250, lr=0.099930, time_each_step=1.26s, eta=8:22:5\n",
      "2022-01-20 10:02:31 [INFO]\t[TRAIN] Epoch=1/50, Step=24/478, loss=0.227293, lr=0.099923, time_each_step=1.26s, eta=8:22:8\n",
      "2022-01-20 10:02:33 [INFO]\t[TRAIN] Epoch=1/50, Step=26/478, loss=0.208923, lr=0.099916, time_each_step=1.26s, eta=8:23:20\n",
      "2022-01-20 10:02:36 [INFO]\t[TRAIN] Epoch=1/50, Step=28/478, loss=0.214765, lr=0.099910, time_each_step=1.27s, eta=8:24:4\n",
      "2022-01-20 10:02:38 [INFO]\t[TRAIN] Epoch=1/50, Step=30/478, loss=0.193158, lr=0.099903, time_each_step=1.27s, eta=8:24:15\n",
      "2022-01-20 10:02:41 [INFO]\t[TRAIN] Epoch=1/50, Step=32/478, loss=0.139781, lr=0.099896, time_each_step=1.27s, eta=8:23:42\n",
      "2022-01-20 10:02:43 [INFO]\t[TRAIN] Epoch=1/50, Step=34/478, loss=0.172362, lr=0.099890, time_each_step=1.27s, eta=8:24:27\n",
      "2022-01-20 10:02:46 [INFO]\t[TRAIN] Epoch=1/50, Step=36/478, loss=0.179951, lr=0.099883, time_each_step=1.27s, eta=8:24:35\n",
      "2022-01-20 10:02:48 [INFO]\t[TRAIN] Epoch=1/50, Step=38/478, loss=0.173543, lr=0.099876, time_each_step=1.27s, eta=8:23:29\n",
      "2022-01-20 10:02:51 [INFO]\t[TRAIN] Epoch=1/50, Step=40/478, loss=0.162769, lr=0.099869, time_each_step=1.27s, eta=8:24:58\n",
      "2022-01-20 10:02:54 [INFO]\t[TRAIN] Epoch=1/50, Step=42/478, loss=0.171540, lr=0.099863, time_each_step=1.27s, eta=8:24:18\n",
      "2022-01-20 10:02:56 [INFO]\t[TRAIN] Epoch=1/50, Step=44/478, loss=0.169309, lr=0.099856, time_each_step=1.27s, eta=8:23:32\n",
      "2022-01-20 10:02:59 [INFO]\t[TRAIN] Epoch=1/50, Step=46/478, loss=0.250516, lr=0.099849, time_each_step=1.27s, eta=8:25:43\n",
      "2022-01-20 10:03:01 [INFO]\t[TRAIN] Epoch=1/50, Step=48/478, loss=0.124186, lr=0.099843, time_each_step=1.27s, eta=8:24:47\n",
      "2022-01-20 10:03:04 [INFO]\t[TRAIN] Epoch=1/50, Step=50/478, loss=0.212576, lr=0.099836, time_each_step=1.27s, eta=8:24:52\n",
      "2022-01-20 10:03:06 [INFO]\t[TRAIN] Epoch=1/50, Step=52/478, loss=0.142300, lr=0.099829, time_each_step=1.27s, eta=8:24:52\n",
      "2022-01-20 10:03:09 [INFO]\t[TRAIN] Epoch=1/50, Step=54/478, loss=0.158694, lr=0.099823, time_each_step=1.27s, eta=8:26:42\n",
      "2022-01-20 10:03:11 [INFO]\t[TRAIN] Epoch=1/50, Step=56/478, loss=0.125009, lr=0.099816, time_each_step=1.27s, eta=8:25:33\n",
      "2022-01-20 10:03:14 [INFO]\t[TRAIN] Epoch=1/50, Step=58/478, loss=0.156177, lr=0.099809, time_each_step=1.27s, eta=8:24:52\n",
      "2022-01-20 10:03:16 [INFO]\t[TRAIN] Epoch=1/50, Step=60/478, loss=0.181659, lr=0.099802, time_each_step=1.27s, eta=8:25:17\n",
      "2022-01-20 10:03:19 [INFO]\t[TRAIN] Epoch=1/50, Step=62/478, loss=0.185731, lr=0.099796, time_each_step=1.27s, eta=8:26:25\n",
      "2022-01-20 10:03:21 [INFO]\t[TRAIN] Epoch=1/50, Step=64/478, loss=0.230305, lr=0.099789, time_each_step=1.27s, eta=8:26:2\n",
      "2022-01-20 10:03:24 [INFO]\t[TRAIN] Epoch=1/50, Step=66/478, loss=0.113932, lr=0.099782, time_each_step=1.27s, eta=8:25:11\n",
      "2022-01-20 10:03:27 [INFO]\t[TRAIN] Epoch=1/50, Step=68/478, loss=0.163945, lr=0.099776, time_each_step=1.28s, eta=8:28:0\n",
      "2022-01-20 10:03:29 [INFO]\t[TRAIN] Epoch=1/50, Step=70/478, loss=0.184284, lr=0.099769, time_each_step=1.27s, eta=8:25:21\n",
      "2022-01-20 10:03:32 [INFO]\t[TRAIN] Epoch=1/50, Step=72/478, loss=0.130107, lr=0.099762, time_each_step=1.27s, eta=8:25:27\n",
      "2022-01-20 10:03:34 [INFO]\t[TRAIN] Epoch=1/50, Step=74/478, loss=0.127278, lr=0.099756, time_each_step=1.27s, eta=8:25:54\n",
      "2022-01-20 10:03:37 [INFO]\t[TRAIN] Epoch=1/50, Step=76/478, loss=0.129704, lr=0.099749, time_each_step=1.28s, eta=8:26:35\n",
      "2022-01-20 10:03:39 [INFO]\t[TRAIN] Epoch=1/50, Step=78/478, loss=0.130139, lr=0.099742, time_each_step=1.28s, eta=8:27:10\n",
      "2022-01-20 10:03:42 [INFO]\t[TRAIN] Epoch=1/50, Step=80/478, loss=0.105533, lr=0.099735, time_each_step=1.28s, eta=8:26:56\n",
      "2022-01-20 10:03:44 [INFO]\t[TRAIN] Epoch=1/50, Step=82/478, loss=0.131160, lr=0.099729, time_each_step=1.28s, eta=8:26:58\n",
      "2022-01-20 10:03:47 [INFO]\t[TRAIN] Epoch=1/50, Step=84/478, loss=0.155287, lr=0.099722, time_each_step=1.28s, eta=8:28:56\n",
      "2022-01-20 10:03:50 [INFO]\t[TRAIN] Epoch=1/50, Step=86/478, loss=0.137728, lr=0.099715, time_each_step=1.28s, eta=8:27:50\n",
      "2022-01-20 10:03:52 [INFO]\t[TRAIN] Epoch=1/50, Step=88/478, loss=0.206684, lr=0.099709, time_each_step=1.27s, eta=8:26:14\n",
      "2022-01-20 10:03:55 [INFO]\t[TRAIN] Epoch=1/50, Step=90/478, loss=0.211523, lr=0.099702, time_each_step=1.28s, eta=8:27:51\n",
      "2022-01-20 10:03:57 [INFO]\t[TRAIN] Epoch=1/50, Step=92/478, loss=0.130712, lr=0.099695, time_each_step=1.28s, eta=8:27:37\n",
      "2022-01-20 10:04:00 [INFO]\t[TRAIN] Epoch=1/50, Step=94/478, loss=0.159143, lr=0.099689, time_each_step=1.28s, eta=8:29:6\n",
      "2022-01-20 10:04:02 [INFO]\t[TRAIN] Epoch=1/50, Step=96/478, loss=0.118161, lr=0.099682, time_each_step=1.28s, eta=8:26:52\n",
      "2022-01-20 10:04:05 [INFO]\t[TRAIN] Epoch=1/50, Step=98/478, loss=0.140731, lr=0.099675, time_each_step=1.28s, eta=8:28:9\n",
      "2022-01-20 10:04:07 [INFO]\t[TRAIN] Epoch=1/50, Step=100/478, loss=0.166442, lr=0.099668, time_each_step=1.28s, eta=8:27:43\n",
      "2022-01-20 10:04:10 [INFO]\t[TRAIN] Epoch=1/50, Step=102/478, loss=0.128329, lr=0.099662, time_each_step=1.28s, eta=8:27:56\n",
      "2022-01-20 10:04:13 [INFO]\t[TRAIN] Epoch=1/50, Step=104/478, loss=0.166434, lr=0.099655, time_each_step=1.28s, eta=8:26:49\n",
      "2022-01-20 10:04:15 [INFO]\t[TRAIN] Epoch=1/50, Step=106/478, loss=0.120943, lr=0.099648, time_each_step=1.28s, eta=8:27:49\n",
      "2022-01-20 10:04:18 [INFO]\t[TRAIN] Epoch=1/50, Step=108/478, loss=0.109858, lr=0.099642, time_each_step=1.28s, eta=8:28:56\n",
      "2022-01-20 10:04:20 [INFO]\t[TRAIN] Epoch=1/50, Step=110/478, loss=0.156356, lr=0.099635, time_each_step=1.28s, eta=8:28:48\n",
      "2022-01-20 10:04:23 [INFO]\t[TRAIN] Epoch=1/50, Step=112/478, loss=0.106222, lr=0.099628, time_each_step=1.28s, eta=8:27:38\n",
      "2022-01-20 10:04:25 [INFO]\t[TRAIN] Epoch=1/50, Step=114/478, loss=0.146203, lr=0.099622, time_each_step=1.28s, eta=8:27:52\n",
      "2022-01-20 10:04:28 [INFO]\t[TRAIN] Epoch=1/50, Step=116/478, loss=0.090020, lr=0.099615, time_each_step=1.29s, eta=8:30:7\n",
      "2022-01-20 10:04:31 [INFO]\t[TRAIN] Epoch=1/50, Step=118/478, loss=0.177530, lr=0.099608, time_each_step=1.28s, eta=8:27:32\n",
      "2022-01-20 10:04:33 [INFO]\t[TRAIN] Epoch=1/50, Step=120/478, loss=0.125575, lr=0.099601, time_each_step=1.28s, eta=8:28:2\n",
      "2022-01-20 10:04:36 [INFO]\t[TRAIN] Epoch=1/50, Step=122/478, loss=0.125832, lr=0.099595, time_each_step=1.28s, eta=8:26:59\n",
      "2022-01-20 10:04:38 [INFO]\t[TRAIN] Epoch=1/50, Step=124/478, loss=0.123020, lr=0.099588, time_each_step=1.29s, eta=8:29:52\n",
      "2022-01-20 10:04:41 [INFO]\t[TRAIN] Epoch=1/50, Step=126/478, loss=0.105506, lr=0.099581, time_each_step=1.28s, eta=8:26:59\n",
      "2022-01-20 10:04:43 [INFO]\t[TRAIN] Epoch=1/50, Step=128/478, loss=0.131600, lr=0.099575, time_each_step=1.28s, eta=8:27:0\n",
      "2022-01-20 10:04:46 [INFO]\t[TRAIN] Epoch=1/50, Step=130/478, loss=0.078395, lr=0.099568, time_each_step=1.28s, eta=8:28:51\n",
      "2022-01-20 10:04:48 [INFO]\t[TRAIN] Epoch=1/50, Step=132/478, loss=0.141038, lr=0.099561, time_each_step=1.28s, eta=8:28:50\n",
      "2022-01-20 10:04:51 [INFO]\t[TRAIN] Epoch=1/50, Step=134/478, loss=0.101476, lr=0.099555, time_each_step=1.28s, eta=8:28:44\n",
      "2022-01-20 10:04:54 [INFO]\t[TRAIN] Epoch=1/50, Step=136/478, loss=0.109261, lr=0.099548, time_each_step=1.28s, eta=8:27:54\n",
      "2022-01-20 10:04:56 [INFO]\t[TRAIN] Epoch=1/50, Step=138/478, loss=0.142912, lr=0.099541, time_each_step=1.29s, eta=8:29:39\n",
      "2022-01-20 10:04:59 [INFO]\t[TRAIN] Epoch=1/50, Step=140/478, loss=0.109162, lr=0.099534, time_each_step=1.28s, eta=8:27:10\n",
      "2022-01-20 10:05:01 [INFO]\t[TRAIN] Epoch=1/50, Step=142/478, loss=0.154852, lr=0.099528, time_each_step=1.28s, eta=8:26:37\n",
      "2022-01-20 10:05:04 [INFO]\t[TRAIN] Epoch=1/50, Step=144/478, loss=0.106770, lr=0.099521, time_each_step=1.29s, eta=8:29:9\n",
      "2022-01-20 10:05:06 [INFO]\t[TRAIN] Epoch=1/50, Step=146/478, loss=0.125726, lr=0.099514, time_each_step=1.28s, eta=8:26:56\n",
      "2022-01-20 10:05:09 [INFO]\t[TRAIN] Epoch=1/50, Step=148/478, loss=0.203040, lr=0.099508, time_each_step=1.28s, eta=8:27:40\n",
      "2022-01-20 10:05:12 [INFO]\t[TRAIN] Epoch=1/50, Step=150/478, loss=0.182882, lr=0.099501, time_each_step=1.29s, eta=8:29:33\n",
      "2022-01-20 10:05:14 [INFO]\t[TRAIN] Epoch=1/50, Step=152/478, loss=0.141649, lr=0.099494, time_each_step=1.28s, eta=8:28:30\n",
      "2022-01-20 10:05:17 [INFO]\t[TRAIN] Epoch=1/50, Step=154/478, loss=0.156132, lr=0.099488, time_each_step=1.28s, eta=8:28:1\n",
      "2022-01-20 10:05:19 [INFO]\t[TRAIN] Epoch=1/50, Step=156/478, loss=0.128222, lr=0.099481, time_each_step=1.28s, eta=8:27:26\n",
      "2022-01-20 10:05:22 [INFO]\t[TRAIN] Epoch=1/50, Step=158/478, loss=0.127859, lr=0.099474, time_each_step=1.29s, eta=8:30:21\n",
      "2022-01-20 10:05:24 [INFO]\t[TRAIN] Epoch=1/50, Step=160/478, loss=0.184812, lr=0.099467, time_each_step=1.28s, eta=8:27:28\n",
      "2022-01-20 10:05:27 [INFO]\t[TRAIN] Epoch=1/50, Step=162/478, loss=0.119297, lr=0.099461, time_each_step=1.28s, eta=8:27:33\n",
      "2022-01-20 10:05:30 [INFO]\t[TRAIN] Epoch=1/50, Step=164/478, loss=0.138421, lr=0.099454, time_each_step=1.28s, eta=8:27:46\n",
      "2022-01-20 10:05:32 [INFO]\t[TRAIN] Epoch=1/50, Step=166/478, loss=0.119927, lr=0.099447, time_each_step=1.28s, eta=8:27:8\n",
      "2022-01-20 10:05:35 [INFO]\t[TRAIN] Epoch=1/50, Step=168/478, loss=0.115776, lr=0.099441, time_each_step=1.28s, eta=8:28:2\n",
      "2022-01-20 10:05:37 [INFO]\t[TRAIN] Epoch=1/50, Step=170/478, loss=0.139984, lr=0.099434, time_each_step=1.28s, eta=8:26:55\n",
      "2022-01-20 10:05:40 [INFO]\t[TRAIN] Epoch=1/50, Step=172/478, loss=0.129552, lr=0.099427, time_each_step=1.29s, eta=8:31:7\n",
      "2022-01-20 10:05:42 [INFO]\t[TRAIN] Epoch=1/50, Step=174/478, loss=0.101008, lr=0.099421, time_each_step=1.28s, eta=8:27:11\n",
      "2022-01-20 10:05:45 [INFO]\t[TRAIN] Epoch=1/50, Step=176/478, loss=0.180443, lr=0.099414, time_each_step=1.28s, eta=8:27:49\n",
      "2022-01-20 10:05:47 [INFO]\t[TRAIN] Epoch=1/50, Step=178/478, loss=0.121558, lr=0.099407, time_each_step=1.29s, eta=8:29:57\n",
      "2022-01-20 10:05:50 [INFO]\t[TRAIN] Epoch=1/50, Step=180/478, loss=0.093956, lr=0.099400, time_each_step=1.28s, eta=8:26:45\n",
      "2022-01-20 10:05:53 [INFO]\t[TRAIN] Epoch=1/50, Step=182/478, loss=0.089126, lr=0.099394, time_each_step=1.28s, eta=8:27:42\n",
      "2022-01-20 10:05:55 [INFO]\t[TRAIN] Epoch=1/50, Step=184/478, loss=0.123962, lr=0.099387, time_each_step=1.29s, eta=8:28:49\n",
      "2022-01-20 10:05:58 [INFO]\t[TRAIN] Epoch=1/50, Step=186/478, loss=0.161799, lr=0.099380, time_each_step=1.28s, eta=8:26:46\n",
      "2022-01-20 10:06:00 [INFO]\t[TRAIN] Epoch=1/50, Step=188/478, loss=0.165520, lr=0.099374, time_each_step=1.28s, eta=8:27:11\n",
      "2022-01-20 10:06:03 [INFO]\t[TRAIN] Epoch=1/50, Step=190/478, loss=0.135474, lr=0.099367, time_each_step=1.28s, eta=8:27:45\n",
      "2022-01-20 10:06:05 [INFO]\t[TRAIN] Epoch=1/50, Step=192/478, loss=0.170106, lr=0.099360, time_each_step=1.28s, eta=8:26:13\n",
      "2022-01-20 10:06:08 [INFO]\t[TRAIN] Epoch=1/50, Step=194/478, loss=0.157829, lr=0.099353, time_each_step=1.28s, eta=8:27:0\n",
      "2022-01-20 10:06:11 [INFO]\t[TRAIN] Epoch=1/50, Step=196/478, loss=0.128128, lr=0.099347, time_each_step=1.29s, eta=8:28:46\n",
      "2022-01-20 10:06:13 [INFO]\t[TRAIN] Epoch=1/50, Step=198/478, loss=0.124577, lr=0.099340, time_each_step=1.28s, eta=8:27:34\n",
      "2022-01-20 10:06:16 [INFO]\t[TRAIN] Epoch=1/50, Step=200/478, loss=0.117175, lr=0.099333, time_each_step=1.28s, eta=8:27:27\n",
      "2022-01-20 10:06:18 [INFO]\t[TRAIN] Epoch=1/50, Step=202/478, loss=0.111689, lr=0.099327, time_each_step=1.29s, eta=8:27:53\n",
      "2022-01-20 10:06:21 [INFO]\t[TRAIN] Epoch=1/50, Step=204/478, loss=0.130780, lr=0.099320, time_each_step=1.28s, eta=8:27:32\n",
      "2022-01-20 10:06:23 [INFO]\t[TRAIN] Epoch=1/50, Step=206/478, loss=0.103039, lr=0.099313, time_each_step=1.28s, eta=8:25:40\n",
      "2022-01-20 10:06:26 [INFO]\t[TRAIN] Epoch=1/50, Step=208/478, loss=0.118734, lr=0.099307, time_each_step=1.28s, eta=8:26:42\n",
      "2022-01-20 10:06:29 [INFO]\t[TRAIN] Epoch=1/50, Step=210/478, loss=0.112017, lr=0.099300, time_each_step=1.28s, eta=8:26:39\n",
      "2022-01-20 10:06:31 [INFO]\t[TRAIN] Epoch=1/50, Step=212/478, loss=0.092728, lr=0.099293, time_each_step=1.28s, eta=8:25:30\n",
      "2022-01-20 10:06:34 [INFO]\t[TRAIN] Epoch=1/50, Step=214/478, loss=0.139702, lr=0.099286, time_each_step=1.28s, eta=8:26:21\n",
      "2022-01-20 10:06:36 [INFO]\t[TRAIN] Epoch=1/50, Step=216/478, loss=0.129854, lr=0.099280, time_each_step=1.29s, eta=8:27:54\n",
      "2022-01-20 10:06:39 [INFO]\t[TRAIN] Epoch=1/50, Step=218/478, loss=0.122595, lr=0.099273, time_each_step=1.29s, eta=8:27:55\n",
      "2022-01-20 10:06:41 [INFO]\t[TRAIN] Epoch=1/50, Step=220/478, loss=0.121657, lr=0.099266, time_each_step=1.28s, eta=8:26:35\n",
      "2022-01-20 10:06:44 [INFO]\t[TRAIN] Epoch=1/50, Step=222/478, loss=0.128480, lr=0.099260, time_each_step=1.29s, eta=8:27:47\n",
      "2022-01-20 10:06:47 [INFO]\t[TRAIN] Epoch=1/50, Step=224/478, loss=0.168041, lr=0.099253, time_each_step=1.29s, eta=8:28:48\n",
      "2022-01-20 10:06:49 [INFO]\t[TRAIN] Epoch=1/50, Step=226/478, loss=0.112359, lr=0.099246, time_each_step=1.28s, eta=8:25:41\n",
      "2022-01-20 10:06:52 [INFO]\t[TRAIN] Epoch=1/50, Step=228/478, loss=0.125677, lr=0.099239, time_each_step=1.28s, eta=8:26:51\n",
      "2022-01-20 10:06:54 [INFO]\t[TRAIN] Epoch=1/50, Step=230/478, loss=0.097902, lr=0.099233, time_each_step=1.29s, eta=8:28:10\n",
      "2022-01-20 10:06:57 [INFO]\t[TRAIN] Epoch=1/50, Step=232/478, loss=0.131734, lr=0.099226, time_each_step=1.28s, eta=8:25:35\n",
      "2022-01-20 10:06:59 [INFO]\t[TRAIN] Epoch=1/50, Step=234/478, loss=0.151404, lr=0.099219, time_each_step=1.28s, eta=8:24:42\n",
      "2022-01-20 10:07:02 [INFO]\t[TRAIN] Epoch=1/50, Step=236/478, loss=0.115412, lr=0.099213, time_each_step=1.28s, eta=8:26:56\n",
      "2022-01-20 10:07:05 [INFO]\t[TRAIN] Epoch=1/50, Step=238/478, loss=0.138177, lr=0.099206, time_each_step=1.28s, eta=8:26:17\n",
      "2022-01-20 10:07:07 [INFO]\t[TRAIN] Epoch=1/50, Step=240/478, loss=0.104572, lr=0.099199, time_each_step=1.28s, eta=8:26:54\n",
      "2022-01-20 10:07:10 [INFO]\t[TRAIN] Epoch=1/50, Step=242/478, loss=0.095941, lr=0.099192, time_each_step=1.29s, eta=8:27:12\n",
      "2022-01-20 10:07:12 [INFO]\t[TRAIN] Epoch=1/50, Step=244/478, loss=0.139191, lr=0.099186, time_each_step=1.29s, eta=8:27:26\n",
      "2022-01-20 10:07:15 [INFO]\t[TRAIN] Epoch=1/50, Step=246/478, loss=0.121350, lr=0.099179, time_each_step=1.28s, eta=8:24:32\n",
      "2022-01-20 10:07:17 [INFO]\t[TRAIN] Epoch=1/50, Step=248/478, loss=0.163766, lr=0.099172, time_each_step=1.29s, eta=8:27:21\n",
      "2022-01-20 10:07:20 [INFO]\t[TRAIN] Epoch=1/50, Step=250/478, loss=0.179639, lr=0.099166, time_each_step=1.29s, eta=8:27:52\n",
      "2022-01-20 10:07:22 [INFO]\t[TRAIN] Epoch=1/50, Step=252/478, loss=0.163172, lr=0.099159, time_each_step=1.29s, eta=8:27:25\n",
      "2022-01-20 10:07:25 [INFO]\t[TRAIN] Epoch=1/50, Step=254/478, loss=0.101006, lr=0.099152, time_each_step=1.29s, eta=8:27:49\n",
      "2022-01-20 10:07:28 [INFO]\t[TRAIN] Epoch=1/50, Step=256/478, loss=0.115217, lr=0.099146, time_each_step=1.28s, eta=8:26:30\n",
      "2022-01-20 10:07:30 [INFO]\t[TRAIN] Epoch=1/50, Step=258/478, loss=0.145707, lr=0.099139, time_each_step=1.29s, eta=8:26:39\n",
      "2022-01-20 10:07:33 [INFO]\t[TRAIN] Epoch=1/50, Step=260/478, loss=0.125145, lr=0.099132, time_each_step=1.29s, eta=8:26:39\n",
      "2022-01-20 10:07:35 [INFO]\t[TRAIN] Epoch=1/50, Step=262/478, loss=0.076575, lr=0.099125, time_each_step=1.29s, eta=8:27:55\n",
      "2022-01-20 10:07:38 [INFO]\t[TRAIN] Epoch=1/50, Step=264/478, loss=0.168711, lr=0.099119, time_each_step=1.28s, eta=8:26:16\n",
      "2022-01-20 10:07:40 [INFO]\t[TRAIN] Epoch=1/50, Step=266/478, loss=0.083626, lr=0.099112, time_each_step=1.28s, eta=8:26:25\n",
      "2022-01-20 10:07:43 [INFO]\t[TRAIN] Epoch=1/50, Step=268/478, loss=0.137028, lr=0.099105, time_each_step=1.29s, eta=8:27:27\n",
      "2022-01-20 10:07:46 [INFO]\t[TRAIN] Epoch=1/50, Step=270/478, loss=0.117749, lr=0.099099, time_each_step=1.29s, eta=8:26:45\n",
      "2022-01-20 10:07:48 [INFO]\t[TRAIN] Epoch=1/50, Step=272/478, loss=0.081448, lr=0.099092, time_each_step=1.28s, eta=8:26:18\n",
      "2022-01-20 10:07:51 [INFO]\t[TRAIN] Epoch=1/50, Step=274/478, loss=0.141614, lr=0.099085, time_each_step=1.29s, eta=8:26:39\n",
      "2022-01-20 10:07:53 [INFO]\t[TRAIN] Epoch=1/50, Step=276/478, loss=0.149557, lr=0.099078, time_each_step=1.28s, eta=8:25:50\n",
      "2022-01-20 10:07:56 [INFO]\t[TRAIN] Epoch=1/50, Step=278/478, loss=0.115757, lr=0.099072, time_each_step=1.29s, eta=8:27:39\n",
      "2022-01-20 10:07:59 [INFO]\t[TRAIN] Epoch=1/50, Step=280/478, loss=0.105469, lr=0.099065, time_each_step=1.29s, eta=8:27:23\n",
      "2022-01-20 10:08:01 [INFO]\t[TRAIN] Epoch=1/50, Step=282/478, loss=0.085685, lr=0.099058, time_each_step=1.28s, eta=8:24:41\n",
      "2022-01-20 10:08:04 [INFO]\t[TRAIN] Epoch=1/50, Step=284/478, loss=0.139479, lr=0.099052, time_each_step=1.29s, eta=8:27:55\n",
      "2022-01-20 10:08:06 [INFO]\t[TRAIN] Epoch=1/50, Step=286/478, loss=0.123654, lr=0.099045, time_each_step=1.29s, eta=8:27:56\n",
      "2022-01-20 10:08:09 [INFO]\t[TRAIN] Epoch=1/50, Step=288/478, loss=0.097539, lr=0.099038, time_each_step=1.29s, eta=8:26:8\n",
      "2022-01-20 10:08:11 [INFO]\t[TRAIN] Epoch=1/50, Step=290/478, loss=0.099841, lr=0.099031, time_each_step=1.29s, eta=8:26:17\n",
      "2022-01-20 10:08:14 [INFO]\t[TRAIN] Epoch=1/50, Step=292/478, loss=0.116576, lr=0.099025, time_each_step=1.29s, eta=8:26:58\n",
      "2022-01-20 10:08:17 [INFO]\t[TRAIN] Epoch=1/50, Step=294/478, loss=0.129904, lr=0.099018, time_each_step=1.28s, eta=8:25:44\n",
      "2022-01-20 10:08:19 [INFO]\t[TRAIN] Epoch=1/50, Step=296/478, loss=0.168013, lr=0.099011, time_each_step=1.29s, eta=8:26:26\n",
      "2022-01-20 10:08:22 [INFO]\t[TRAIN] Epoch=1/50, Step=298/478, loss=0.079576, lr=0.099005, time_each_step=1.28s, eta=8:25:39\n",
      "2022-01-20 10:08:24 [INFO]\t[TRAIN] Epoch=1/50, Step=300/478, loss=0.121746, lr=0.098998, time_each_step=1.29s, eta=8:26:7\n",
      "2022-01-20 10:08:27 [INFO]\t[TRAIN] Epoch=1/50, Step=302/478, loss=0.126680, lr=0.098991, time_each_step=1.29s, eta=8:27:24\n",
      "2022-01-20 10:08:29 [INFO]\t[TRAIN] Epoch=1/50, Step=304/478, loss=0.160446, lr=0.098984, time_each_step=1.29s, eta=8:26:3\n",
      "2022-01-20 10:08:32 [INFO]\t[TRAIN] Epoch=1/50, Step=306/478, loss=0.149931, lr=0.098978, time_each_step=1.29s, eta=8:25:57\n",
      "2022-01-20 10:08:35 [INFO]\t[TRAIN] Epoch=1/50, Step=308/478, loss=0.122100, lr=0.098971, time_each_step=1.29s, eta=8:26:8\n",
      "2022-01-20 10:08:37 [INFO]\t[TRAIN] Epoch=1/50, Step=310/478, loss=0.127937, lr=0.098964, time_each_step=1.29s, eta=8:26:32\n",
      "2022-01-20 10:08:40 [INFO]\t[TRAIN] Epoch=1/50, Step=312/478, loss=0.166425, lr=0.098958, time_each_step=1.29s, eta=8:26:19\n",
      "2022-01-20 10:08:42 [INFO]\t[TRAIN] Epoch=1/50, Step=314/478, loss=0.114245, lr=0.098951, time_each_step=1.28s, eta=8:25:8\n",
      "2022-01-20 10:08:45 [INFO]\t[TRAIN] Epoch=1/50, Step=316/478, loss=0.162361, lr=0.098944, time_each_step=1.29s, eta=8:25:32\n",
      "2022-01-20 10:08:47 [INFO]\t[TRAIN] Epoch=1/50, Step=318/478, loss=0.139795, lr=0.098937, time_each_step=1.29s, eta=8:25:52\n",
      "2022-01-20 10:08:50 [INFO]\t[TRAIN] Epoch=1/50, Step=320/478, loss=0.108845, lr=0.098931, time_each_step=1.29s, eta=8:26:27\n",
      "2022-01-20 10:08:53 [INFO]\t[TRAIN] Epoch=1/50, Step=322/478, loss=0.164515, lr=0.098924, time_each_step=1.29s, eta=8:25:22\n",
      "2022-01-20 10:08:55 [INFO]\t[TRAIN] Epoch=1/50, Step=324/478, loss=0.095001, lr=0.098917, time_each_step=1.28s, eta=8:24:36\n",
      "2022-01-20 10:08:58 [INFO]\t[TRAIN] Epoch=1/50, Step=326/478, loss=0.126946, lr=0.098911, time_each_step=1.29s, eta=8:25:37\n",
      "2022-01-20 10:09:00 [INFO]\t[TRAIN] Epoch=1/50, Step=328/478, loss=0.158324, lr=0.098904, time_each_step=1.29s, eta=8:26:40\n",
      "2022-01-20 10:09:03 [INFO]\t[TRAIN] Epoch=1/50, Step=330/478, loss=0.094671, lr=0.098897, time_each_step=1.29s, eta=8:26:6\n",
      "2022-01-20 10:09:05 [INFO]\t[TRAIN] Epoch=1/50, Step=332/478, loss=0.122341, lr=0.098891, time_each_step=1.29s, eta=8:26:7\n",
      "2022-01-20 10:09:08 [INFO]\t[TRAIN] Epoch=1/50, Step=334/478, loss=0.117420, lr=0.098884, time_each_step=1.29s, eta=8:25:31\n",
      "2022-01-20 10:09:11 [INFO]\t[TRAIN] Epoch=1/50, Step=336/478, loss=0.089644, lr=0.098877, time_each_step=1.29s, eta=8:25:1\n",
      "2022-01-20 10:09:13 [INFO]\t[TRAIN] Epoch=1/50, Step=338/478, loss=0.118925, lr=0.098870, time_each_step=1.29s, eta=8:25:12\n",
      "2022-01-20 10:09:16 [INFO]\t[TRAIN] Epoch=1/50, Step=340/478, loss=0.139801, lr=0.098864, time_each_step=1.29s, eta=8:24:55\n",
      "2022-01-20 10:09:18 [INFO]\t[TRAIN] Epoch=1/50, Step=342/478, loss=0.124581, lr=0.098857, time_each_step=1.29s, eta=8:25:6\n",
      "2022-01-20 10:09:21 [INFO]\t[TRAIN] Epoch=1/50, Step=344/478, loss=0.111544, lr=0.098850, time_each_step=1.29s, eta=8:25:35\n",
      "2022-01-20 10:09:23 [INFO]\t[TRAIN] Epoch=1/50, Step=346/478, loss=0.125457, lr=0.098844, time_each_step=1.28s, eta=8:24:31\n",
      "2022-01-20 10:09:26 [INFO]\t[TRAIN] Epoch=1/50, Step=348/478, loss=0.104154, lr=0.098837, time_each_step=1.29s, eta=8:25:8\n",
      "2022-01-20 10:09:29 [INFO]\t[TRAIN] Epoch=1/50, Step=350/478, loss=0.119011, lr=0.098830, time_each_step=1.29s, eta=8:26:7\n",
      "2022-01-20 10:09:31 [INFO]\t[TRAIN] Epoch=1/50, Step=352/478, loss=0.092964, lr=0.098823, time_each_step=1.29s, eta=8:25:1\n",
      "2022-01-20 10:09:34 [INFO]\t[TRAIN] Epoch=1/50, Step=354/478, loss=0.111213, lr=0.098817, time_each_step=1.29s, eta=8:24:37\n",
      "2022-01-20 10:09:36 [INFO]\t[TRAIN] Epoch=1/50, Step=356/478, loss=0.118368, lr=0.098810, time_each_step=1.29s, eta=8:25:16\n",
      "2022-01-20 10:09:39 [INFO]\t[TRAIN] Epoch=1/50, Step=358/478, loss=0.137842, lr=0.098803, time_each_step=1.29s, eta=8:24:32\n",
      "2022-01-20 10:09:41 [INFO]\t[TRAIN] Epoch=1/50, Step=360/478, loss=0.097074, lr=0.098797, time_each_step=1.29s, eta=8:25:1\n",
      "2022-01-20 10:09:44 [INFO]\t[TRAIN] Epoch=1/50, Step=362/478, loss=0.111639, lr=0.098790, time_each_step=1.29s, eta=8:24:58\n",
      "2022-01-20 10:09:47 [INFO]\t[TRAIN] Epoch=1/50, Step=364/478, loss=0.103481, lr=0.098783, time_each_step=1.29s, eta=8:24:45\n",
      "2022-01-20 10:09:49 [INFO]\t[TRAIN] Epoch=1/50, Step=366/478, loss=0.163242, lr=0.098776, time_each_step=1.28s, eta=8:24:14\n",
      "2022-01-20 10:09:52 [INFO]\t[TRAIN] Epoch=1/50, Step=368/478, loss=0.118947, lr=0.098770, time_each_step=1.29s, eta=8:25:48\n",
      "2022-01-20 10:09:54 [INFO]\t[TRAIN] Epoch=1/50, Step=370/478, loss=0.097370, lr=0.098763, time_each_step=1.29s, eta=8:24:22\n",
      "2022-01-20 10:09:57 [INFO]\t[TRAIN] Epoch=1/50, Step=372/478, loss=0.097062, lr=0.098756, time_each_step=1.28s, eta=8:24:9\n",
      "2022-01-20 10:09:59 [INFO]\t[TRAIN] Epoch=1/50, Step=374/478, loss=0.099110, lr=0.098750, time_each_step=1.29s, eta=8:25:3\n",
      "2022-01-20 10:10:02 [INFO]\t[TRAIN] Epoch=1/50, Step=376/478, loss=0.075788, lr=0.098743, time_each_step=1.29s, eta=8:24:56\n",
      "2022-01-20 10:10:05 [INFO]\t[TRAIN] Epoch=1/50, Step=378/478, loss=0.109833, lr=0.098736, time_each_step=1.28s, eta=8:23:58\n",
      "2022-01-20 10:10:07 [INFO]\t[TRAIN] Epoch=1/50, Step=380/478, loss=0.099562, lr=0.098729, time_each_step=1.29s, eta=8:24:26\n",
      "2022-01-20 10:10:10 [INFO]\t[TRAIN] Epoch=1/50, Step=382/478, loss=0.123819, lr=0.098723, time_each_step=1.28s, eta=8:23:52\n",
      "2022-01-20 10:10:12 [INFO]\t[TRAIN] Epoch=1/50, Step=384/478, loss=0.109047, lr=0.098716, time_each_step=1.29s, eta=8:24:10\n",
      "2022-01-20 10:10:15 [INFO]\t[TRAIN] Epoch=1/50, Step=386/478, loss=0.188796, lr=0.098709, time_each_step=1.29s, eta=8:25:19\n",
      "2022-01-20 10:10:17 [INFO]\t[TRAIN] Epoch=1/50, Step=388/478, loss=0.116512, lr=0.098702, time_each_step=1.28s, eta=8:23:44\n",
      "2022-01-20 10:10:20 [INFO]\t[TRAIN] Epoch=1/50, Step=390/478, loss=0.102838, lr=0.098696, time_each_step=1.29s, eta=8:23:58\n",
      "2022-01-20 10:10:23 [INFO]\t[TRAIN] Epoch=1/50, Step=392/478, loss=0.114249, lr=0.098689, time_each_step=1.29s, eta=8:24:37\n",
      "2022-01-20 10:10:25 [INFO]\t[TRAIN] Epoch=1/50, Step=394/478, loss=0.102859, lr=0.098682, time_each_step=1.29s, eta=8:24:15\n",
      "2022-01-20 10:10:28 [INFO]\t[TRAIN] Epoch=1/50, Step=396/478, loss=0.118732, lr=0.098676, time_each_step=1.28s, eta=8:23:35\n",
      "2022-01-20 10:10:30 [INFO]\t[TRAIN] Epoch=1/50, Step=398/478, loss=0.098004, lr=0.098669, time_each_step=1.29s, eta=8:24:54\n",
      "2022-01-20 10:10:33 [INFO]\t[TRAIN] Epoch=1/50, Step=400/478, loss=0.109931, lr=0.098662, time_each_step=1.29s, eta=8:23:54\n",
      "2022-01-20 10:10:35 [INFO]\t[TRAIN] Epoch=1/50, Step=402/478, loss=0.093992, lr=0.098655, time_each_step=1.29s, eta=8:24:12\n",
      "2022-01-20 10:10:38 [INFO]\t[TRAIN] Epoch=1/50, Step=404/478, loss=0.085799, lr=0.098649, time_each_step=1.29s, eta=8:24:0\n",
      "2022-01-20 10:10:41 [INFO]\t[TRAIN] Epoch=1/50, Step=406/478, loss=0.118413, lr=0.098642, time_each_step=1.29s, eta=8:24:19\n",
      "2022-01-20 10:10:43 [INFO]\t[TRAIN] Epoch=1/50, Step=408/478, loss=0.081091, lr=0.098635, time_each_step=1.29s, eta=8:23:43\n",
      "2022-01-20 10:10:46 [INFO]\t[TRAIN] Epoch=1/50, Step=410/478, loss=0.094394, lr=0.098629, time_each_step=1.29s, eta=8:24:44\n",
      "2022-01-20 10:10:48 [INFO]\t[TRAIN] Epoch=1/50, Step=412/478, loss=0.079450, lr=0.098622, time_each_step=1.28s, eta=8:22:39\n",
      "2022-01-20 10:10:51 [INFO]\t[TRAIN] Epoch=1/50, Step=414/478, loss=0.120694, lr=0.098615, time_each_step=1.28s, eta=8:23:6\n",
      "2022-01-20 10:10:53 [INFO]\t[TRAIN] Epoch=1/50, Step=416/478, loss=0.114099, lr=0.098608, time_each_step=1.29s, eta=8:24:12\n",
      "2022-01-20 10:10:56 [INFO]\t[TRAIN] Epoch=1/50, Step=418/478, loss=0.091388, lr=0.098602, time_each_step=1.29s, eta=8:24:20\n",
      "2022-01-20 10:10:59 [INFO]\t[TRAIN] Epoch=1/50, Step=420/478, loss=0.103927, lr=0.098595, time_each_step=1.29s, eta=8:23:15\n",
      "2022-01-20 10:11:01 [INFO]\t[TRAIN] Epoch=1/50, Step=422/478, loss=0.099345, lr=0.098588, time_each_step=1.29s, eta=8:23:39\n",
      "2022-01-20 10:11:04 [INFO]\t[TRAIN] Epoch=1/50, Step=424/478, loss=0.159909, lr=0.098582, time_each_step=1.28s, eta=8:22:45\n",
      "2022-01-20 10:11:06 [INFO]\t[TRAIN] Epoch=1/50, Step=426/478, loss=0.093269, lr=0.098575, time_each_step=1.29s, eta=8:23:26\n",
      "2022-01-20 10:11:09 [INFO]\t[TRAIN] Epoch=1/50, Step=428/478, loss=0.098537, lr=0.098568, time_each_step=1.29s, eta=8:23:52\n",
      "2022-01-20 10:11:11 [INFO]\t[TRAIN] Epoch=1/50, Step=430/478, loss=0.111816, lr=0.098561, time_each_step=1.29s, eta=8:24:19\n",
      "2022-01-20 10:11:14 [INFO]\t[TRAIN] Epoch=1/50, Step=432/478, loss=0.101246, lr=0.098555, time_each_step=1.29s, eta=8:23:20\n",
      "2022-01-20 10:11:17 [INFO]\t[TRAIN] Epoch=1/50, Step=434/478, loss=0.072012, lr=0.098548, time_each_step=1.29s, eta=8:22:56\n",
      "2022-01-20 10:11:19 [INFO]\t[TRAIN] Epoch=1/50, Step=436/478, loss=0.078697, lr=0.098541, time_each_step=1.29s, eta=8:24:5\n",
      "2022-01-20 10:11:22 [INFO]\t[TRAIN] Epoch=1/50, Step=438/478, loss=0.089285, lr=0.098535, time_each_step=1.28s, eta=8:22:44\n",
      "2022-01-20 10:11:24 [INFO]\t[TRAIN] Epoch=1/50, Step=440/478, loss=0.077236, lr=0.098528, time_each_step=1.29s, eta=8:23:53\n",
      "2022-01-20 10:11:27 [INFO]\t[TRAIN] Epoch=1/50, Step=442/478, loss=0.095338, lr=0.098521, time_each_step=1.29s, eta=8:23:9\n",
      "2022-01-20 10:11:29 [INFO]\t[TRAIN] Epoch=1/50, Step=444/478, loss=0.087888, lr=0.098514, time_each_step=1.29s, eta=8:22:52\n",
      "2022-01-20 10:11:32 [INFO]\t[TRAIN] Epoch=1/50, Step=446/478, loss=0.108951, lr=0.098508, time_each_step=1.29s, eta=8:23:38\n",
      "2022-01-20 10:11:35 [INFO]\t[TRAIN] Epoch=1/50, Step=448/478, loss=0.107726, lr=0.098501, time_each_step=1.29s, eta=8:22:49\n",
      "2022-01-20 10:11:37 [INFO]\t[TRAIN] Epoch=1/50, Step=450/478, loss=0.118351, lr=0.098494, time_each_step=1.29s, eta=8:22:39\n",
      "2022-01-20 10:11:40 [INFO]\t[TRAIN] Epoch=1/50, Step=452/478, loss=0.080163, lr=0.098488, time_each_step=1.29s, eta=8:22:46\n",
      "2022-01-20 10:11:42 [INFO]\t[TRAIN] Epoch=1/50, Step=454/478, loss=0.101087, lr=0.098481, time_each_step=1.28s, eta=8:22:24\n",
      "2022-01-20 10:11:45 [INFO]\t[TRAIN] Epoch=1/50, Step=456/478, loss=0.140945, lr=0.098474, time_each_step=1.28s, eta=8:21:45\n",
      "2022-01-20 10:11:47 [INFO]\t[TRAIN] Epoch=1/50, Step=458/478, loss=0.117084, lr=0.098467, time_each_step=1.29s, eta=8:23:8\n",
      "2022-01-20 10:11:50 [INFO]\t[TRAIN] Epoch=1/50, Step=460/478, loss=0.108782, lr=0.098461, time_each_step=1.29s, eta=8:22:35\n",
      "2022-01-20 10:11:53 [INFO]\t[TRAIN] Epoch=1/50, Step=462/478, loss=0.132855, lr=0.098454, time_each_step=1.28s, eta=8:22:4\n",
      "2022-01-20 10:11:55 [INFO]\t[TRAIN] Epoch=1/50, Step=464/478, loss=0.070455, lr=0.098447, time_each_step=1.29s, eta=8:23:30\n",
      "2022-01-20 10:11:58 [INFO]\t[TRAIN] Epoch=1/50, Step=466/478, loss=0.179667, lr=0.098440, time_each_step=1.29s, eta=8:22:23\n",
      "2022-01-20 10:12:00 [INFO]\t[TRAIN] Epoch=1/50, Step=468/478, loss=0.120403, lr=0.098434, time_each_step=1.28s, eta=8:22:5\n",
      "2022-01-20 10:12:03 [INFO]\t[TRAIN] Epoch=1/50, Step=470/478, loss=0.110084, lr=0.098427, time_each_step=1.29s, eta=8:23:3\n",
      "2022-01-20 10:12:05 [INFO]\t[TRAIN] Epoch=1/50, Step=472/478, loss=0.127687, lr=0.098420, time_each_step=1.28s, eta=8:21:55\n",
      "2022-01-20 10:12:08 [INFO]\t[TRAIN] Epoch=1/50, Step=474/478, loss=0.078400, lr=0.098414, time_each_step=1.29s, eta=8:22:11\n",
      "2022-01-20 10:12:11 [INFO]\t[TRAIN] Epoch=1/50, Step=476/478, loss=0.079287, lr=0.098407, time_each_step=1.29s, eta=8:22:10\n",
      "2022-01-20 10:12:13 [INFO]\t[TRAIN] Epoch=1/50, Step=478/478, loss=0.113682, lr=0.098400, time_each_step=1.28s, eta=8:21:53\n",
      "2022-01-20 10:12:13 [INFO]\t[TRAIN] Epoch 1 finished, loss=0.13847601 .\n",
      "2022-01-20 10:12:13 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-01-20 10:12:14 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/math_op_patch.py:253: UserWarning: The dtype of left and right variables are not the same, left dtype is paddle.int32, but right dtype is paddle.bool, the right dtype will convert to paddle.int32\n",
      "  format(lhs_dtype, rhs_dtype, lhs_dtype))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/math_op_patch.py:253: UserWarning: The dtype of left and right variables are not the same, left dtype is paddle.int64, but right dtype is paddle.bool, the right dtype will convert to paddle.int64\n",
      "  format(lhs_dtype, rhs_dtype, lhs_dtype))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/math_op_patch.py:253: UserWarning: The dtype of left and right variables are not the same, left dtype is paddle.int64, but right dtype is paddle.int32, the right dtype will convert to paddle.int64\n",
      "  format(lhs_dtype, rhs_dtype, lhs_dtype))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-20 10:12:20 [INFO]\t[EVAL] Finished, Epoch=1, miou=0.790595, category_iou=[0.96693116 0.6539901  0.7508646 ], oacc=0.967731, category_acc=[0.9819752  0.85272247 0.8535073 ], kappa=0.840675, category_F1-score=[0.98318761 0.79080294 0.85770729] .\n",
      "2022-01-20 10:12:20 [INFO]\tModel saved in model/deeplab_augument_alldata2/best_model.\n",
      "2022-01-20 10:12:20 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_1, miou=0.790595293045044\n",
      "2022-01-20 10:12:21 [INFO]\tModel saved in model/deeplab_augument_alldata2/epoch_1.\n",
      "2022-01-20 10:12:24 [INFO]\t[TRAIN] Epoch=2/50, Step=2/478, loss=0.119015, lr=0.098393, time_each_step=1.8s, eta=11:49:10\n",
      "2022-01-20 10:12:27 [INFO]\t[TRAIN] Epoch=2/50, Step=4/478, loss=0.086192, lr=0.098387, time_each_step=1.29s, eta=8:27:20\n",
      "2022-01-20 10:12:29 [INFO]\t[TRAIN] Epoch=2/50, Step=6/478, loss=0.089094, lr=0.098380, time_each_step=1.29s, eta=8:27:9\n",
      "2022-01-20 10:12:32 [INFO]\t[TRAIN] Epoch=2/50, Step=8/478, loss=0.079278, lr=0.098373, time_each_step=1.28s, eta=8:26:3\n",
      "2022-01-20 10:12:35 [INFO]\t[TRAIN] Epoch=2/50, Step=10/478, loss=0.104194, lr=0.098367, time_each_step=1.29s, eta=8:27:40\n",
      "2022-01-20 10:12:37 [INFO]\t[TRAIN] Epoch=2/50, Step=12/478, loss=0.084648, lr=0.098360, time_each_step=1.29s, eta=8:27:8\n",
      "2022-01-20 10:12:40 [INFO]\t[TRAIN] Epoch=2/50, Step=14/478, loss=0.112425, lr=0.098353, time_each_step=1.28s, eta=8:26:12\n",
      "2022-01-20 10:12:42 [INFO]\t[TRAIN] Epoch=2/50, Step=16/478, loss=0.118359, lr=0.098346, time_each_step=1.28s, eta=8:26:11\n",
      "2022-01-20 10:12:45 [INFO]\t[TRAIN] Epoch=2/50, Step=18/478, loss=0.122939, lr=0.098340, time_each_step=1.29s, eta=8:27:20\n",
      "2022-01-20 10:12:47 [INFO]\t[TRAIN] Epoch=2/50, Step=20/478, loss=0.083498, lr=0.098333, time_each_step=1.28s, eta=8:25:48\n",
      "2022-01-20 10:12:50 [INFO]\t[TRAIN] Epoch=2/50, Step=22/478, loss=0.070137, lr=0.098326, time_each_step=1.29s, eta=8:26:49\n",
      "2022-01-20 10:12:53 [INFO]\t[TRAIN] Epoch=2/50, Step=24/478, loss=0.073953, lr=0.098319, time_each_step=1.29s, eta=8:27:39\n",
      "2022-01-20 10:12:55 [INFO]\t[TRAIN] Epoch=2/50, Step=26/478, loss=0.097739, lr=0.098313, time_each_step=1.28s, eta=8:25:46\n",
      "2022-01-20 10:12:58 [INFO]\t[TRAIN] Epoch=2/50, Step=28/478, loss=0.085674, lr=0.098306, time_each_step=1.28s, eta=8:26:12\n",
      "2022-01-20 10:13:00 [INFO]\t[TRAIN] Epoch=2/50, Step=30/478, loss=0.115800, lr=0.098299, time_each_step=1.29s, eta=8:27:21\n",
      "2022-01-20 10:13:03 [INFO]\t[TRAIN] Epoch=2/50, Step=32/478, loss=0.094905, lr=0.098293, time_each_step=1.28s, eta=8:25:2\n",
      "2022-01-20 10:13:05 [INFO]\t[TRAIN] Epoch=2/50, Step=34/478, loss=0.094482, lr=0.098286, time_each_step=1.28s, eta=8:26:20\n",
      "2022-01-20 10:13:08 [INFO]\t[TRAIN] Epoch=2/50, Step=36/478, loss=0.106589, lr=0.098279, time_each_step=1.28s, eta=8:25:51\n",
      "2022-01-20 10:13:11 [INFO]\t[TRAIN] Epoch=2/50, Step=38/478, loss=0.126912, lr=0.098272, time_each_step=1.29s, eta=8:26:38\n",
      "2022-01-20 10:13:13 [INFO]\t[TRAIN] Epoch=2/50, Step=40/478, loss=0.073721, lr=0.098266, time_each_step=1.28s, eta=8:25:9\n",
      "2022-01-20 10:13:16 [INFO]\t[TRAIN] Epoch=2/50, Step=42/478, loss=0.137164, lr=0.098259, time_each_step=1.29s, eta=8:26:43\n",
      "2022-01-20 10:13:18 [INFO]\t[TRAIN] Epoch=2/50, Step=44/478, loss=0.067921, lr=0.098252, time_each_step=1.29s, eta=8:26:43\n",
      "2022-01-20 10:13:21 [INFO]\t[TRAIN] Epoch=2/50, Step=46/478, loss=0.070579, lr=0.098246, time_each_step=1.29s, eta=8:28:8\n",
      "2022-01-20 10:13:23 [INFO]\t[TRAIN] Epoch=2/50, Step=48/478, loss=0.114740, lr=0.098239, time_each_step=1.29s, eta=8:28:32\n",
      "2022-01-20 10:13:26 [INFO]\t[TRAIN] Epoch=2/50, Step=50/478, loss=0.102359, lr=0.098232, time_each_step=1.28s, eta=8:25:45\n",
      "2022-01-20 10:13:29 [INFO]\t[TRAIN] Epoch=2/50, Step=52/478, loss=0.123546, lr=0.098225, time_each_step=1.29s, eta=8:26:23\n",
      "2022-01-20 10:13:31 [INFO]\t[TRAIN] Epoch=2/50, Step=54/478, loss=0.073607, lr=0.098219, time_each_step=1.29s, eta=8:26:15\n",
      "2022-01-20 10:13:34 [INFO]\t[TRAIN] Epoch=2/50, Step=56/478, loss=0.093051, lr=0.098212, time_each_step=1.29s, eta=8:25:58\n",
      "2022-01-20 10:13:36 [INFO]\t[TRAIN] Epoch=2/50, Step=58/478, loss=0.148891, lr=0.098205, time_each_step=1.28s, eta=8:25:25\n",
      "2022-01-20 10:13:39 [INFO]\t[TRAIN] Epoch=2/50, Step=60/478, loss=0.122522, lr=0.098198, time_each_step=1.29s, eta=8:26:42\n",
      "2022-01-20 10:13:41 [INFO]\t[TRAIN] Epoch=2/50, Step=62/478, loss=0.110173, lr=0.098192, time_each_step=1.28s, eta=8:25:5\n",
      "2022-01-20 10:13:44 [INFO]\t[TRAIN] Epoch=2/50, Step=64/478, loss=0.098612, lr=0.098185, time_each_step=1.29s, eta=8:26:29\n",
      "2022-01-20 10:13:47 [INFO]\t[TRAIN] Epoch=2/50, Step=66/478, loss=0.093821, lr=0.098178, time_each_step=1.29s, eta=8:27:33\n",
      "2022-01-20 10:13:49 [INFO]\t[TRAIN] Epoch=2/50, Step=68/478, loss=0.141839, lr=0.098172, time_each_step=1.28s, eta=8:25:29\n",
      "2022-01-20 10:13:52 [INFO]\t[TRAIN] Epoch=2/50, Step=70/478, loss=0.099994, lr=0.098165, time_each_step=1.29s, eta=8:25:50\n",
      "2022-01-20 10:13:54 [INFO]\t[TRAIN] Epoch=2/50, Step=72/478, loss=0.102492, lr=0.098158, time_each_step=1.29s, eta=8:27:7\n",
      "2022-01-20 10:13:57 [INFO]\t[TRAIN] Epoch=2/50, Step=74/478, loss=0.107972, lr=0.098151, time_each_step=1.28s, eta=8:25:16\n",
      "2022-01-20 10:13:59 [INFO]\t[TRAIN] Epoch=2/50, Step=76/478, loss=0.107356, lr=0.098145, time_each_step=1.29s, eta=8:25:44\n",
      "2022-01-20 10:14:02 [INFO]\t[TRAIN] Epoch=2/50, Step=78/478, loss=0.114638, lr=0.098138, time_each_step=1.29s, eta=8:26:13\n",
      "2022-01-20 10:14:05 [INFO]\t[TRAIN] Epoch=2/50, Step=80/478, loss=0.103490, lr=0.098131, time_each_step=1.28s, eta=8:25:9\n",
      "2022-01-20 10:14:07 [INFO]\t[TRAIN] Epoch=2/50, Step=82/478, loss=0.101485, lr=0.098124, time_each_step=1.29s, eta=8:25:50\n",
      "2022-01-20 10:14:10 [INFO]\t[TRAIN] Epoch=2/50, Step=84/478, loss=0.099306, lr=0.098118, time_each_step=1.29s, eta=8:25:46\n",
      "2022-01-20 10:14:12 [INFO]\t[TRAIN] Epoch=2/50, Step=86/478, loss=0.073367, lr=0.098111, time_each_step=1.29s, eta=8:26:33\n",
      "2022-01-20 10:14:15 [INFO]\t[TRAIN] Epoch=2/50, Step=88/478, loss=0.119282, lr=0.098104, time_each_step=1.29s, eta=8:25:56\n",
      "2022-01-20 10:14:17 [INFO]\t[TRAIN] Epoch=2/50, Step=90/478, loss=0.091374, lr=0.098098, time_each_step=1.29s, eta=8:26:34\n",
      "2022-01-20 10:14:20 [INFO]\t[TRAIN] Epoch=2/50, Step=92/478, loss=0.121930, lr=0.098091, time_each_step=1.28s, eta=8:24:32\n",
      "2022-01-20 10:14:23 [INFO]\t[TRAIN] Epoch=2/50, Step=94/478, loss=0.110004, lr=0.098084, time_each_step=1.29s, eta=8:25:35\n",
      "2022-01-20 10:14:25 [INFO]\t[TRAIN] Epoch=2/50, Step=96/478, loss=0.128997, lr=0.098077, time_each_step=1.29s, eta=8:26:49\n",
      "2022-01-20 10:14:28 [INFO]\t[TRAIN] Epoch=2/50, Step=98/478, loss=0.096853, lr=0.098071, time_each_step=1.29s, eta=8:26:11\n",
      "2022-01-20 10:14:30 [INFO]\t[TRAIN] Epoch=2/50, Step=100/478, loss=0.117373, lr=0.098064, time_each_step=1.28s, eta=8:23:57\n",
      "2022-01-20 10:14:33 [INFO]\t[TRAIN] Epoch=2/50, Step=102/478, loss=0.096319, lr=0.098057, time_each_step=1.29s, eta=8:25:36\n",
      "2022-01-20 10:14:35 [INFO]\t[TRAIN] Epoch=2/50, Step=104/478, loss=0.148180, lr=0.098050, time_each_step=1.29s, eta=8:25:43\n",
      "2022-01-20 10:14:38 [INFO]\t[TRAIN] Epoch=2/50, Step=106/478, loss=0.096025, lr=0.098044, time_each_step=1.29s, eta=8:24:59\n",
      "2022-01-20 10:14:41 [INFO]\t[TRAIN] Epoch=2/50, Step=108/478, loss=0.134385, lr=0.098037, time_each_step=1.29s, eta=8:25:57\n",
      "2022-01-20 10:14:43 [INFO]\t[TRAIN] Epoch=2/50, Step=110/478, loss=0.085695, lr=0.098030, time_each_step=1.29s, eta=8:25:48\n",
      "2022-01-20 10:14:46 [INFO]\t[TRAIN] Epoch=2/50, Step=112/478, loss=0.074350, lr=0.098024, time_each_step=1.29s, eta=8:24:56\n",
      "2022-01-20 10:14:48 [INFO]\t[TRAIN] Epoch=2/50, Step=114/478, loss=0.074069, lr=0.098017, time_each_step=1.29s, eta=8:26:0\n",
      "2022-01-20 10:14:51 [INFO]\t[TRAIN] Epoch=2/50, Step=116/478, loss=0.103722, lr=0.098010, time_each_step=1.29s, eta=8:25:1\n",
      "2022-01-20 10:14:53 [INFO]\t[TRAIN] Epoch=2/50, Step=118/478, loss=0.132107, lr=0.098003, time_each_step=1.28s, eta=8:24:24\n",
      "2022-01-20 10:14:56 [INFO]\t[TRAIN] Epoch=2/50, Step=120/478, loss=0.122271, lr=0.097997, time_each_step=1.28s, eta=8:24:22\n",
      "2022-01-20 10:14:59 [INFO]\t[TRAIN] Epoch=2/50, Step=122/478, loss=0.110996, lr=0.097990, time_each_step=1.29s, eta=8:25:40\n",
      "2022-01-20 10:15:01 [INFO]\t[TRAIN] Epoch=2/50, Step=124/478, loss=0.106176, lr=0.097983, time_each_step=1.28s, eta=8:24:24\n",
      "2022-01-20 10:15:04 [INFO]\t[TRAIN] Epoch=2/50, Step=126/478, loss=0.147162, lr=0.097976, time_each_step=1.29s, eta=8:26:13\n",
      "2022-01-20 10:15:06 [INFO]\t[TRAIN] Epoch=2/50, Step=128/478, loss=0.071461, lr=0.097970, time_each_step=1.29s, eta=8:24:29\n",
      "2022-01-20 10:15:09 [INFO]\t[TRAIN] Epoch=2/50, Step=130/478, loss=0.106523, lr=0.097963, time_each_step=1.28s, eta=8:24:13\n",
      "2022-01-20 10:15:11 [INFO]\t[TRAIN] Epoch=2/50, Step=132/478, loss=0.087133, lr=0.097956, time_each_step=1.29s, eta=8:25:6\n",
      "2022-01-20 10:15:14 [INFO]\t[TRAIN] Epoch=2/50, Step=134/478, loss=0.116922, lr=0.097950, time_each_step=1.29s, eta=8:24:17\n",
      "2022-01-20 10:15:17 [INFO]\t[TRAIN] Epoch=2/50, Step=136/478, loss=0.094819, lr=0.097943, time_each_step=1.28s, eta=8:24:2\n",
      "2022-01-20 10:15:19 [INFO]\t[TRAIN] Epoch=2/50, Step=138/478, loss=0.093291, lr=0.097936, time_each_step=1.29s, eta=8:24:40\n",
      "2022-01-20 10:15:22 [INFO]\t[TRAIN] Epoch=2/50, Step=140/478, loss=0.126038, lr=0.097929, time_each_step=1.29s, eta=8:24:54\n",
      "2022-01-20 10:15:24 [INFO]\t[TRAIN] Epoch=2/50, Step=142/478, loss=0.103267, lr=0.097923, time_each_step=1.28s, eta=8:23:30\n",
      "2022-01-20 10:15:27 [INFO]\t[TRAIN] Epoch=2/50, Step=144/478, loss=0.170477, lr=0.097916, time_each_step=1.29s, eta=8:24:58\n",
      "2022-01-20 10:15:29 [INFO]\t[TRAIN] Epoch=2/50, Step=146/478, loss=0.110249, lr=0.097909, time_each_step=1.29s, eta=8:24:39\n",
      "2022-01-20 10:15:32 [INFO]\t[TRAIN] Epoch=2/50, Step=148/478, loss=0.095807, lr=0.097902, time_each_step=1.29s, eta=8:24:31\n",
      "2022-01-20 10:15:35 [INFO]\t[TRAIN] Epoch=2/50, Step=150/478, loss=0.097048, lr=0.097896, time_each_step=1.29s, eta=8:24:42\n",
      "2022-01-20 10:15:37 [INFO]\t[TRAIN] Epoch=2/50, Step=152/478, loss=0.099004, lr=0.097889, time_each_step=1.29s, eta=8:24:56\n",
      "2022-01-20 10:15:40 [INFO]\t[TRAIN] Epoch=2/50, Step=154/478, loss=0.121131, lr=0.097882, time_each_step=1.28s, eta=8:23:15\n",
      "2022-01-20 10:15:42 [INFO]\t[TRAIN] Epoch=2/50, Step=156/478, loss=0.084155, lr=0.097875, time_each_step=1.29s, eta=8:25:15\n",
      "2022-01-20 10:15:45 [INFO]\t[TRAIN] Epoch=2/50, Step=158/478, loss=0.091082, lr=0.097869, time_each_step=1.28s, eta=8:23:38\n",
      "2022-01-20 10:15:47 [INFO]\t[TRAIN] Epoch=2/50, Step=160/478, loss=0.107650, lr=0.097862, time_each_step=1.29s, eta=8:23:57\n",
      "2022-01-20 10:15:50 [INFO]\t[TRAIN] Epoch=2/50, Step=162/478, loss=0.076011, lr=0.097855, time_each_step=1.29s, eta=8:25:39\n",
      "2022-01-20 10:15:53 [INFO]\t[TRAIN] Epoch=2/50, Step=164/478, loss=0.094277, lr=0.097849, time_each_step=1.28s, eta=8:23:29\n",
      "2022-01-20 10:15:55 [INFO]\t[TRAIN] Epoch=2/50, Step=166/478, loss=0.095422, lr=0.097842, time_each_step=1.29s, eta=8:23:36\n",
      "2022-01-20 10:15:58 [INFO]\t[TRAIN] Epoch=2/50, Step=168/478, loss=0.083435, lr=0.097835, time_each_step=1.29s, eta=8:25:2\n",
      "2022-01-20 10:16:00 [INFO]\t[TRAIN] Epoch=2/50, Step=170/478, loss=0.172363, lr=0.097828, time_each_step=1.29s, eta=8:24:11\n",
      "2022-01-20 10:16:03 [INFO]\t[TRAIN] Epoch=2/50, Step=172/478, loss=0.100776, lr=0.097822, time_each_step=1.29s, eta=8:23:32\n",
      "2022-01-20 10:16:05 [INFO]\t[TRAIN] Epoch=2/50, Step=174/478, loss=0.116853, lr=0.097815, time_each_step=1.29s, eta=8:23:58\n",
      "2022-01-20 10:16:08 [INFO]\t[TRAIN] Epoch=2/50, Step=176/478, loss=0.096341, lr=0.097808, time_each_step=1.29s, eta=8:23:30\n",
      "2022-01-20 10:16:11 [INFO]\t[TRAIN] Epoch=2/50, Step=178/478, loss=0.112645, lr=0.097801, time_each_step=1.29s, eta=8:23:23\n",
      "2022-01-20 10:16:13 [INFO]\t[TRAIN] Epoch=2/50, Step=180/478, loss=0.100071, lr=0.097795, time_each_step=1.29s, eta=8:24:48\n",
      "2022-01-20 10:16:16 [INFO]\t[TRAIN] Epoch=2/50, Step=182/478, loss=0.093853, lr=0.097788, time_each_step=1.29s, eta=8:23:35\n",
      "2022-01-20 10:16:18 [INFO]\t[TRAIN] Epoch=2/50, Step=184/478, loss=0.070656, lr=0.097781, time_each_step=1.28s, eta=8:23:7\n",
      "2022-01-20 10:16:21 [INFO]\t[TRAIN] Epoch=2/50, Step=186/478, loss=0.130524, lr=0.097775, time_each_step=1.29s, eta=8:23:56\n",
      "2022-01-20 10:16:24 [INFO]\t[TRAIN] Epoch=2/50, Step=188/478, loss=0.154397, lr=0.097768, time_each_step=1.29s, eta=8:23:34\n",
      "2022-01-20 10:16:26 [INFO]\t[TRAIN] Epoch=2/50, Step=190/478, loss=0.115933, lr=0.097761, time_each_step=1.29s, eta=8:23:38\n",
      "2022-01-20 10:16:29 [INFO]\t[TRAIN] Epoch=2/50, Step=192/478, loss=0.122336, lr=0.097754, time_each_step=1.29s, eta=8:23:32\n",
      "2022-01-20 10:16:31 [INFO]\t[TRAIN] Epoch=2/50, Step=194/478, loss=0.132932, lr=0.097748, time_each_step=1.28s, eta=8:21:55\n",
      "2022-01-20 10:16:34 [INFO]\t[TRAIN] Epoch=2/50, Step=196/478, loss=0.106289, lr=0.097741, time_each_step=1.29s, eta=8:23:27\n",
      "2022-01-20 10:16:36 [INFO]\t[TRAIN] Epoch=2/50, Step=198/478, loss=0.093659, lr=0.097734, time_each_step=1.29s, eta=8:23:3\n",
      "2022-01-20 10:16:39 [INFO]\t[TRAIN] Epoch=2/50, Step=200/478, loss=0.132577, lr=0.097727, time_each_step=1.29s, eta=8:23:27\n",
      "2022-01-20 10:16:42 [INFO]\t[TRAIN] Epoch=2/50, Step=202/478, loss=0.115283, lr=0.097721, time_each_step=1.28s, eta=8:22:37\n",
      "2022-01-20 10:16:44 [INFO]\t[TRAIN] Epoch=2/50, Step=204/478, loss=0.090322, lr=0.097714, time_each_step=1.28s, eta=8:22:22\n",
      "2022-01-20 10:16:47 [INFO]\t[TRAIN] Epoch=2/50, Step=206/478, loss=0.099915, lr=0.097707, time_each_step=1.29s, eta=8:24:15\n",
      "2022-01-20 10:16:49 [INFO]\t[TRAIN] Epoch=2/50, Step=208/478, loss=0.101558, lr=0.097700, time_each_step=1.28s, eta=8:22:33\n",
      "2022-01-20 10:16:52 [INFO]\t[TRAIN] Epoch=2/50, Step=210/478, loss=0.071199, lr=0.097694, time_each_step=1.29s, eta=8:22:47\n",
      "2022-01-20 10:16:54 [INFO]\t[TRAIN] Epoch=2/50, Step=212/478, loss=0.122804, lr=0.097687, time_each_step=1.29s, eta=8:24:45\n",
      "2022-01-20 10:16:57 [INFO]\t[TRAIN] Epoch=2/50, Step=214/478, loss=0.070312, lr=0.097680, time_each_step=1.28s, eta=8:22:1\n",
      "2022-01-20 10:17:00 [INFO]\t[TRAIN] Epoch=2/50, Step=216/478, loss=0.097616, lr=0.097674, time_each_step=1.29s, eta=8:24:23\n",
      "2022-01-20 10:17:02 [INFO]\t[TRAIN] Epoch=2/50, Step=218/478, loss=0.101722, lr=0.097667, time_each_step=1.29s, eta=8:23:11\n",
      "2022-01-20 10:17:05 [INFO]\t[TRAIN] Epoch=2/50, Step=220/478, loss=0.056800, lr=0.097660, time_each_step=1.28s, eta=8:22:23\n",
      "2022-01-20 10:17:07 [INFO]\t[TRAIN] Epoch=2/50, Step=222/478, loss=0.097456, lr=0.097653, time_each_step=1.29s, eta=8:22:49\n",
      "2022-01-20 10:17:10 [INFO]\t[TRAIN] Epoch=2/50, Step=224/478, loss=0.078996, lr=0.097647, time_each_step=1.29s, eta=8:22:46\n",
      "2022-01-20 10:17:12 [INFO]\t[TRAIN] Epoch=2/50, Step=226/478, loss=0.094981, lr=0.097640, time_each_step=1.29s, eta=8:22:41\n",
      "2022-01-20 10:17:15 [INFO]\t[TRAIN] Epoch=2/50, Step=228/478, loss=0.112983, lr=0.097633, time_each_step=1.29s, eta=8:24:27\n",
      "2022-01-20 10:17:18 [INFO]\t[TRAIN] Epoch=2/50, Step=230/478, loss=0.117631, lr=0.097626, time_each_step=1.29s, eta=8:22:33\n",
      "2022-01-20 10:17:20 [INFO]\t[TRAIN] Epoch=2/50, Step=232/478, loss=0.129719, lr=0.097620, time_each_step=1.29s, eta=8:22:34\n",
      "2022-01-20 10:17:23 [INFO]\t[TRAIN] Epoch=2/50, Step=234/478, loss=0.089444, lr=0.097613, time_each_step=1.29s, eta=8:23:46\n",
      "2022-01-20 10:17:25 [INFO]\t[TRAIN] Epoch=2/50, Step=236/478, loss=0.109246, lr=0.097606, time_each_step=1.28s, eta=8:21:56\n",
      "2022-01-20 10:17:28 [INFO]\t[TRAIN] Epoch=2/50, Step=238/478, loss=0.142975, lr=0.097599, time_each_step=1.29s, eta=8:22:30\n",
      "2022-01-20 10:17:30 [INFO]\t[TRAIN] Epoch=2/50, Step=240/478, loss=0.083438, lr=0.097593, time_each_step=1.29s, eta=8:23:16\n",
      "2022-01-20 10:17:33 [INFO]\t[TRAIN] Epoch=2/50, Step=242/478, loss=0.098333, lr=0.097586, time_each_step=1.28s, eta=8:21:51\n",
      "2022-01-20 10:17:36 [INFO]\t[TRAIN] Epoch=2/50, Step=244/478, loss=0.103659, lr=0.097579, time_each_step=1.28s, eta=8:21:35\n",
      "2022-01-20 10:17:38 [INFO]\t[TRAIN] Epoch=2/50, Step=246/478, loss=0.069825, lr=0.097573, time_each_step=1.29s, eta=8:23:44\n",
      "2022-01-20 10:17:41 [INFO]\t[TRAIN] Epoch=2/50, Step=248/478, loss=0.102981, lr=0.097566, time_each_step=1.29s, eta=8:22:6\n",
      "2022-01-20 10:17:43 [INFO]\t[TRAIN] Epoch=2/50, Step=250/478, loss=0.101774, lr=0.097559, time_each_step=1.29s, eta=8:22:12\n",
      "2022-01-20 10:17:46 [INFO]\t[TRAIN] Epoch=2/50, Step=252/478, loss=0.098103, lr=0.097552, time_each_step=1.29s, eta=8:23:40\n",
      "2022-01-20 10:17:48 [INFO]\t[TRAIN] Epoch=2/50, Step=254/478, loss=0.069513, lr=0.097546, time_each_step=1.28s, eta=8:21:13\n",
      "2022-01-20 10:17:51 [INFO]\t[TRAIN] Epoch=2/50, Step=256/478, loss=0.115826, lr=0.097539, time_each_step=1.29s, eta=8:22:15\n",
      "2022-01-20 10:17:54 [INFO]\t[TRAIN] Epoch=2/50, Step=258/478, loss=0.140671, lr=0.097532, time_each_step=1.29s, eta=8:23:22\n",
      "2022-01-20 10:17:56 [INFO]\t[TRAIN] Epoch=2/50, Step=260/478, loss=0.105603, lr=0.097525, time_each_step=1.29s, eta=8:22:9\n",
      "2022-01-20 10:17:59 [INFO]\t[TRAIN] Epoch=2/50, Step=262/478, loss=0.106418, lr=0.097519, time_each_step=1.29s, eta=8:22:11\n",
      "2022-01-20 10:18:01 [INFO]\t[TRAIN] Epoch=2/50, Step=264/478, loss=0.100857, lr=0.097512, time_each_step=1.29s, eta=8:22:3\n",
      "2022-01-20 10:18:04 [INFO]\t[TRAIN] Epoch=2/50, Step=266/478, loss=0.077945, lr=0.097505, time_each_step=1.29s, eta=8:22:1\n",
      "2022-01-20 10:18:06 [INFO]\t[TRAIN] Epoch=2/50, Step=268/478, loss=0.078580, lr=0.097498, time_each_step=1.28s, eta=8:21:11\n",
      "2022-01-20 10:18:09 [INFO]\t[TRAIN] Epoch=2/50, Step=270/478, loss=0.109961, lr=0.097492, time_each_step=1.29s, eta=8:22:42\n",
      "2022-01-20 10:18:12 [INFO]\t[TRAIN] Epoch=2/50, Step=272/478, loss=0.087280, lr=0.097485, time_each_step=1.29s, eta=8:22:5\n",
      "2022-01-20 10:18:14 [INFO]\t[TRAIN] Epoch=2/50, Step=274/478, loss=0.084594, lr=0.097478, time_each_step=1.28s, eta=8:20:33\n",
      "2022-01-20 10:18:17 [INFO]\t[TRAIN] Epoch=2/50, Step=276/478, loss=0.104114, lr=0.097471, time_each_step=1.29s, eta=8:22:25\n",
      "2022-01-20 10:18:19 [INFO]\t[TRAIN] Epoch=2/50, Step=278/478, loss=0.119996, lr=0.097465, time_each_step=1.28s, eta=8:21:4\n",
      "2022-01-20 10:18:22 [INFO]\t[TRAIN] Epoch=2/50, Step=280/478, loss=0.121158, lr=0.097458, time_each_step=1.29s, eta=8:21:32\n",
      "2022-01-20 10:18:24 [INFO]\t[TRAIN] Epoch=2/50, Step=282/478, loss=0.084034, lr=0.097451, time_each_step=1.29s, eta=8:22:8\n",
      "2022-01-20 10:18:27 [INFO]\t[TRAIN] Epoch=2/50, Step=284/478, loss=0.121875, lr=0.097445, time_each_step=1.28s, eta=8:20:48\n",
      "2022-01-20 10:18:30 [INFO]\t[TRAIN] Epoch=2/50, Step=286/478, loss=0.091551, lr=0.097438, time_each_step=1.28s, eta=8:20:0\n",
      "2022-01-20 10:18:32 [INFO]\t[TRAIN] Epoch=2/50, Step=288/478, loss=0.091183, lr=0.097431, time_each_step=1.29s, eta=8:21:23\n",
      "2022-01-20 10:18:35 [INFO]\t[TRAIN] Epoch=2/50, Step=290/478, loss=0.099784, lr=0.097424, time_each_step=1.29s, eta=8:21:47\n",
      "2022-01-20 10:18:37 [INFO]\t[TRAIN] Epoch=2/50, Step=292/478, loss=0.122094, lr=0.097418, time_each_step=1.29s, eta=8:21:17\n",
      "2022-01-20 10:18:40 [INFO]\t[TRAIN] Epoch=2/50, Step=294/478, loss=0.107308, lr=0.097411, time_each_step=1.29s, eta=8:21:23\n",
      "2022-01-20 10:18:42 [INFO]\t[TRAIN] Epoch=2/50, Step=296/478, loss=0.140590, lr=0.097404, time_each_step=1.29s, eta=8:21:54\n",
      "2022-01-20 10:18:45 [INFO]\t[TRAIN] Epoch=2/50, Step=298/478, loss=0.083223, lr=0.097397, time_each_step=1.28s, eta=8:20:17\n",
      "2022-01-20 10:18:48 [INFO]\t[TRAIN] Epoch=2/50, Step=300/478, loss=0.075486, lr=0.097391, time_each_step=1.29s, eta=8:22:8\n",
      "2022-01-20 10:18:50 [INFO]\t[TRAIN] Epoch=2/50, Step=302/478, loss=0.098611, lr=0.097384, time_each_step=1.29s, eta=8:21:40\n",
      "2022-01-20 10:18:53 [INFO]\t[TRAIN] Epoch=2/50, Step=304/478, loss=0.098620, lr=0.097377, time_each_step=1.28s, eta=8:19:59\n",
      "2022-01-20 10:18:55 [INFO]\t[TRAIN] Epoch=2/50, Step=306/478, loss=0.064665, lr=0.097370, time_each_step=1.29s, eta=8:22:50\n",
      "2022-01-20 10:18:58 [INFO]\t[TRAIN] Epoch=2/50, Step=308/478, loss=0.089671, lr=0.097364, time_each_step=1.29s, eta=8:21:32\n",
      "2022-01-20 10:19:00 [INFO]\t[TRAIN] Epoch=2/50, Step=310/478, loss=0.068699, lr=0.097357, time_each_step=1.29s, eta=8:21:56\n",
      "2022-01-20 10:19:03 [INFO]\t[TRAIN] Epoch=2/50, Step=312/478, loss=0.087402, lr=0.097350, time_each_step=1.29s, eta=8:21:2\n",
      "2022-01-20 10:19:06 [INFO]\t[TRAIN] Epoch=2/50, Step=314/478, loss=0.113211, lr=0.097343, time_each_step=1.29s, eta=8:20:39\n",
      "2022-01-20 10:19:08 [INFO]\t[TRAIN] Epoch=2/50, Step=316/478, loss=0.111501, lr=0.097337, time_each_step=1.28s, eta=8:20:1\n",
      "2022-01-20 10:19:11 [INFO]\t[TRAIN] Epoch=2/50, Step=318/478, loss=0.118885, lr=0.097330, time_each_step=1.29s, eta=8:20:47\n",
      "2022-01-20 10:19:13 [INFO]\t[TRAIN] Epoch=2/50, Step=320/478, loss=0.077592, lr=0.097323, time_each_step=1.28s, eta=8:19:52\n",
      "2022-01-20 10:19:16 [INFO]\t[TRAIN] Epoch=2/50, Step=322/478, loss=0.126140, lr=0.097316, time_each_step=1.29s, eta=8:20:51\n",
      "2022-01-20 10:19:18 [INFO]\t[TRAIN] Epoch=2/50, Step=324/478, loss=0.100048, lr=0.097310, time_each_step=1.29s, eta=8:21:44\n",
      "2022-01-20 10:19:21 [INFO]\t[TRAIN] Epoch=2/50, Step=326/478, loss=0.155197, lr=0.097303, time_each_step=1.28s, eta=8:19:23\n",
      "2022-01-20 10:19:24 [INFO]\t[TRAIN] Epoch=2/50, Step=328/478, loss=0.070257, lr=0.097296, time_each_step=1.28s, eta=8:19:33\n",
      "2022-01-20 10:19:26 [INFO]\t[TRAIN] Epoch=2/50, Step=330/478, loss=0.098601, lr=0.097289, time_each_step=1.29s, eta=8:21:31\n",
      "2022-01-20 10:19:29 [INFO]\t[TRAIN] Epoch=2/50, Step=332/478, loss=0.071796, lr=0.097283, time_each_step=1.28s, eta=8:19:42\n",
      "2022-01-20 10:19:31 [INFO]\t[TRAIN] Epoch=2/50, Step=334/478, loss=0.144812, lr=0.097276, time_each_step=1.28s, eta=8:19:50\n",
      "2022-01-20 10:19:34 [INFO]\t[TRAIN] Epoch=2/50, Step=336/478, loss=0.098280, lr=0.097269, time_each_step=1.29s, eta=8:21:55\n",
      "2022-01-20 10:19:36 [INFO]\t[TRAIN] Epoch=2/50, Step=338/478, loss=0.085765, lr=0.097263, time_each_step=1.29s, eta=8:20:18\n",
      "2022-01-20 10:19:39 [INFO]\t[TRAIN] Epoch=2/50, Step=340/478, loss=0.082249, lr=0.097256, time_each_step=1.28s, eta=8:19:39\n",
      "2022-01-20 10:19:42 [INFO]\t[TRAIN] Epoch=2/50, Step=342/478, loss=0.084859, lr=0.097249, time_each_step=1.29s, eta=8:21:28\n",
      "2022-01-20 10:19:44 [INFO]\t[TRAIN] Epoch=2/50, Step=344/478, loss=0.128772, lr=0.097242, time_each_step=1.28s, eta=8:19:7\n",
      "2022-01-20 10:19:47 [INFO]\t[TRAIN] Epoch=2/50, Step=346/478, loss=0.090763, lr=0.097236, time_each_step=1.29s, eta=8:19:59\n",
      "2022-01-20 10:19:49 [INFO]\t[TRAIN] Epoch=2/50, Step=348/478, loss=0.148588, lr=0.097229, time_each_step=1.29s, eta=8:20:57\n",
      "2022-01-20 10:19:52 [INFO]\t[TRAIN] Epoch=2/50, Step=350/478, loss=0.133432, lr=0.097222, time_each_step=1.28s, eta=8:19:25\n",
      "2022-01-20 10:19:54 [INFO]\t[TRAIN] Epoch=2/50, Step=352/478, loss=0.097232, lr=0.097215, time_each_step=1.29s, eta=8:19:43\n",
      "2022-01-20 10:19:57 [INFO]\t[TRAIN] Epoch=2/50, Step=354/478, loss=0.139149, lr=0.097209, time_each_step=1.29s, eta=8:19:37\n",
      "2022-01-20 10:20:00 [INFO]\t[TRAIN] Epoch=2/50, Step=356/478, loss=0.114696, lr=0.097202, time_each_step=1.28s, eta=8:19:15\n",
      "2022-01-20 10:20:02 [INFO]\t[TRAIN] Epoch=2/50, Step=358/478, loss=0.068647, lr=0.097195, time_each_step=1.29s, eta=8:19:30\n",
      "2022-01-20 10:20:05 [INFO]\t[TRAIN] Epoch=2/50, Step=360/478, loss=0.101586, lr=0.097188, time_each_step=1.29s, eta=8:20:44\n",
      "2022-01-20 10:20:07 [INFO]\t[TRAIN] Epoch=2/50, Step=362/478, loss=0.101330, lr=0.097182, time_each_step=1.29s, eta=8:19:54\n",
      "2022-01-20 10:20:10 [INFO]\t[TRAIN] Epoch=2/50, Step=364/478, loss=0.086295, lr=0.097175, time_each_step=1.29s, eta=8:19:57\n",
      "2022-01-20 10:20:12 [INFO]\t[TRAIN] Epoch=2/50, Step=366/478, loss=0.085619, lr=0.097168, time_each_step=1.29s, eta=8:20:14\n",
      "2022-01-20 10:20:15 [INFO]\t[TRAIN] Epoch=2/50, Step=368/478, loss=0.091203, lr=0.097161, time_each_step=1.29s, eta=8:19:32\n",
      "2022-01-20 10:20:18 [INFO]\t[TRAIN] Epoch=2/50, Step=370/478, loss=0.118302, lr=0.097155, time_each_step=1.28s, eta=8:19:2\n",
      "2022-01-20 10:20:20 [INFO]\t[TRAIN] Epoch=2/50, Step=372/478, loss=0.089320, lr=0.097148, time_each_step=1.29s, eta=8:19:35\n",
      "2022-01-20 10:20:23 [INFO]\t[TRAIN] Epoch=2/50, Step=374/478, loss=0.092313, lr=0.097141, time_each_step=1.29s, eta=8:19:49\n",
      "2022-01-20 10:20:25 [INFO]\t[TRAIN] Epoch=2/50, Step=376/478, loss=0.104052, lr=0.097134, time_each_step=1.29s, eta=8:20:3\n",
      "2022-01-20 10:20:28 [INFO]\t[TRAIN] Epoch=2/50, Step=378/478, loss=0.074849, lr=0.097128, time_each_step=1.29s, eta=8:19:52\n",
      "2022-01-20 10:20:30 [INFO]\t[TRAIN] Epoch=2/50, Step=380/478, loss=0.094122, lr=0.097121, time_each_step=1.29s, eta=8:19:56\n",
      "2022-01-20 10:20:33 [INFO]\t[TRAIN] Epoch=2/50, Step=382/478, loss=0.127936, lr=0.097114, time_each_step=1.29s, eta=8:19:20\n",
      "2022-01-20 10:20:36 [INFO]\t[TRAIN] Epoch=2/50, Step=384/478, loss=0.096705, lr=0.097107, time_each_step=1.29s, eta=8:19:54\n",
      "2022-01-20 10:20:38 [INFO]\t[TRAIN] Epoch=2/50, Step=386/478, loss=0.104153, lr=0.097101, time_each_step=1.28s, eta=8:18:42\n",
      "2022-01-20 10:20:41 [INFO]\t[TRAIN] Epoch=2/50, Step=388/478, loss=0.079903, lr=0.097094, time_each_step=1.29s, eta=8:18:49\n",
      "2022-01-20 10:20:43 [INFO]\t[TRAIN] Epoch=2/50, Step=390/478, loss=0.065227, lr=0.097087, time_each_step=1.28s, eta=8:18:31\n",
      "2022-01-20 10:20:46 [INFO]\t[TRAIN] Epoch=2/50, Step=392/478, loss=0.089713, lr=0.097080, time_each_step=1.29s, eta=8:18:54\n",
      "2022-01-20 10:20:48 [INFO]\t[TRAIN] Epoch=2/50, Step=394/478, loss=0.120870, lr=0.097074, time_each_step=1.28s, eta=8:18:11\n",
      "2022-01-20 10:20:51 [INFO]\t[TRAIN] Epoch=2/50, Step=396/478, loss=0.062679, lr=0.097067, time_each_step=1.29s, eta=8:19:4\n",
      "2022-01-20 10:20:54 [INFO]\t[TRAIN] Epoch=2/50, Step=398/478, loss=0.137961, lr=0.097060, time_each_step=1.29s, eta=8:18:36\n",
      "2022-01-20 10:20:56 [INFO]\t[TRAIN] Epoch=2/50, Step=400/478, loss=0.082755, lr=0.097054, time_each_step=1.29s, eta=8:18:44\n",
      "2022-01-20 10:20:59 [INFO]\t[TRAIN] Epoch=2/50, Step=402/478, loss=0.077232, lr=0.097047, time_each_step=1.29s, eta=8:19:13\n",
      "2022-01-20 10:21:01 [INFO]\t[TRAIN] Epoch=2/50, Step=404/478, loss=0.119807, lr=0.097040, time_each_step=1.29s, eta=8:18:53\n",
      "2022-01-20 10:21:04 [INFO]\t[TRAIN] Epoch=2/50, Step=406/478, loss=0.077527, lr=0.097033, time_each_step=1.29s, eta=8:19:22\n",
      "2022-01-20 10:21:06 [INFO]\t[TRAIN] Epoch=2/50, Step=408/478, loss=0.092229, lr=0.097027, time_each_step=1.29s, eta=8:19:54\n",
      "2022-01-20 10:21:09 [INFO]\t[TRAIN] Epoch=2/50, Step=410/478, loss=0.094527, lr=0.097020, time_each_step=1.29s, eta=8:18:39\n",
      "2022-01-20 10:21:12 [INFO]\t[TRAIN] Epoch=2/50, Step=412/478, loss=0.064453, lr=0.097013, time_each_step=1.29s, eta=8:19:27\n",
      "2022-01-20 10:21:14 [INFO]\t[TRAIN] Epoch=2/50, Step=414/478, loss=0.059193, lr=0.097006, time_each_step=1.29s, eta=8:20:11\n",
      "2022-01-20 10:21:17 [INFO]\t[TRAIN] Epoch=2/50, Step=416/478, loss=0.074652, lr=0.097000, time_each_step=1.28s, eta=8:17:26\n",
      "2022-01-20 10:21:19 [INFO]\t[TRAIN] Epoch=2/50, Step=418/478, loss=0.112293, lr=0.096993, time_each_step=1.28s, eta=8:18:0\n",
      "2022-01-20 10:21:22 [INFO]\t[TRAIN] Epoch=2/50, Step=420/478, loss=0.093070, lr=0.096986, time_each_step=1.29s, eta=8:19:31\n",
      "2022-01-20 10:21:25 [INFO]\t[TRAIN] Epoch=2/50, Step=422/478, loss=0.092949, lr=0.096979, time_each_step=1.29s, eta=8:18:44\n",
      "2022-01-20 10:21:27 [INFO]\t[TRAIN] Epoch=2/50, Step=424/478, loss=0.084301, lr=0.096973, time_each_step=1.28s, eta=8:18:1\n",
      "2022-01-20 10:21:30 [INFO]\t[TRAIN] Epoch=2/50, Step=426/478, loss=0.102391, lr=0.096966, time_each_step=1.29s, eta=8:19:41\n",
      "2022-01-20 10:21:32 [INFO]\t[TRAIN] Epoch=2/50, Step=428/478, loss=0.072279, lr=0.096959, time_each_step=1.28s, eta=8:17:11\n",
      "2022-01-20 10:21:35 [INFO]\t[TRAIN] Epoch=2/50, Step=430/478, loss=0.096879, lr=0.096952, time_each_step=1.29s, eta=8:18:41\n",
      "2022-01-20 10:21:37 [INFO]\t[TRAIN] Epoch=2/50, Step=432/478, loss=0.097544, lr=0.096946, time_each_step=1.29s, eta=8:19:2\n",
      "2022-01-20 10:21:40 [INFO]\t[TRAIN] Epoch=2/50, Step=434/478, loss=0.127652, lr=0.096939, time_each_step=1.28s, eta=8:17:44\n",
      "2022-01-20 10:21:43 [INFO]\t[TRAIN] Epoch=2/50, Step=436/478, loss=0.089490, lr=0.096932, time_each_step=1.28s, eta=8:17:13\n",
      "2022-01-20 10:21:45 [INFO]\t[TRAIN] Epoch=2/50, Step=438/478, loss=0.102807, lr=0.096925, time_each_step=1.29s, eta=8:17:55\n",
      "2022-01-20 10:21:48 [INFO]\t[TRAIN] Epoch=2/50, Step=440/478, loss=0.098344, lr=0.096919, time_each_step=1.28s, eta=8:17:21\n",
      "2022-01-20 10:21:50 [INFO]\t[TRAIN] Epoch=2/50, Step=442/478, loss=0.085490, lr=0.096912, time_each_step=1.29s, eta=8:18:0\n",
      "2022-01-20 10:21:53 [INFO]\t[TRAIN] Epoch=2/50, Step=444/478, loss=0.118139, lr=0.096905, time_each_step=1.29s, eta=8:19:7\n",
      "2022-01-20 10:21:55 [INFO]\t[TRAIN] Epoch=2/50, Step=446/478, loss=0.107766, lr=0.096898, time_each_step=1.29s, eta=8:17:41\n",
      "2022-01-20 10:21:58 [INFO]\t[TRAIN] Epoch=2/50, Step=448/478, loss=0.091867, lr=0.096892, time_each_step=1.28s, eta=8:17:24\n",
      "2022-01-20 10:22:01 [INFO]\t[TRAIN] Epoch=2/50, Step=450/478, loss=0.099104, lr=0.096885, time_each_step=1.29s, eta=8:18:39\n",
      "2022-01-20 10:22:03 [INFO]\t[TRAIN] Epoch=2/50, Step=452/478, loss=0.077264, lr=0.096878, time_each_step=1.28s, eta=8:16:51\n",
      "2022-01-20 10:22:06 [INFO]\t[TRAIN] Epoch=2/50, Step=454/478, loss=0.125593, lr=0.096871, time_each_step=1.28s, eta=8:16:45\n",
      "2022-01-20 10:22:08 [INFO]\t[TRAIN] Epoch=2/50, Step=456/478, loss=0.087086, lr=0.096865, time_each_step=1.29s, eta=8:17:27\n",
      "2022-01-20 10:22:11 [INFO]\t[TRAIN] Epoch=2/50, Step=458/478, loss=0.089780, lr=0.096858, time_each_step=1.29s, eta=8:18:24\n",
      "2022-01-20 10:22:13 [INFO]\t[TRAIN] Epoch=2/50, Step=460/478, loss=0.081273, lr=0.096851, time_each_step=1.29s, eta=8:18:4\n",
      "2022-01-20 10:22:16 [INFO]\t[TRAIN] Epoch=2/50, Step=462/478, loss=0.111325, lr=0.096844, time_each_step=1.29s, eta=8:17:39\n",
      "2022-01-20 10:22:19 [INFO]\t[TRAIN] Epoch=2/50, Step=464/478, loss=0.074606, lr=0.096838, time_each_step=1.29s, eta=8:18:52\n",
      "2022-01-20 10:22:21 [INFO]\t[TRAIN] Epoch=2/50, Step=466/478, loss=0.107814, lr=0.096831, time_each_step=1.29s, eta=8:17:53\n",
      "2022-01-20 10:22:24 [INFO]\t[TRAIN] Epoch=2/50, Step=468/478, loss=0.073222, lr=0.096824, time_each_step=1.29s, eta=8:17:33\n",
      "2022-01-20 10:22:26 [INFO]\t[TRAIN] Epoch=2/50, Step=470/478, loss=0.114562, lr=0.096817, time_each_step=1.29s, eta=8:17:48\n",
      "2022-01-20 10:22:29 [INFO]\t[TRAIN] Epoch=2/50, Step=472/478, loss=0.101141, lr=0.096811, time_each_step=1.29s, eta=8:17:32\n",
      "2022-01-20 10:22:31 [INFO]\t[TRAIN] Epoch=2/50, Step=474/478, loss=0.124350, lr=0.096804, time_each_step=1.29s, eta=8:17:16\n",
      "2022-01-20 10:22:34 [INFO]\t[TRAIN] Epoch=2/50, Step=476/478, loss=0.065247, lr=0.096797, time_each_step=1.28s, eta=8:16:36\n",
      "2022-01-20 10:22:37 [INFO]\t[TRAIN] Epoch=2/50, Step=478/478, loss=0.131317, lr=0.096790, time_each_step=1.28s, eta=8:16:12\n",
      "2022-01-20 10:22:37 [INFO]\t[TRAIN] Epoch 2 finished, loss=0.10126993 .\n",
      "2022-01-20 10:22:37 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-01-20 10:22:37 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-01-20 10:22:43 [INFO]\t[EVAL] Finished, Epoch=2, miou=0.804105, category_iou=[0.9647533  0.6931838  0.75437766], oacc=0.966427, category_acc=[0.99033964 0.81039816 0.8013777 ], kappa=0.844746, category_F1-score=[0.98206052 0.81879334 0.85999461] .\n",
      "2022-01-20 10:22:44 [INFO]\tModel saved in model/deeplab_augument_alldata2/best_model.\n",
      "2022-01-20 10:22:44 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_2, miou=0.8041048645973206\n",
      "2022-01-20 10:22:44 [INFO]\tModel saved in model/deeplab_augument_alldata2/epoch_2.\n",
      "2022-01-20 10:22:48 [INFO]\t[TRAIN] Epoch=3/50, Step=2/478, loss=0.092351, lr=0.096784, time_each_step=1.91s, eta=12:16:26\n",
      "2022-01-20 10:22:51 [INFO]\t[TRAIN] Epoch=3/50, Step=4/478, loss=0.061116, lr=0.096777, time_each_step=1.28s, eta=8:16:40\n",
      "2022-01-20 10:22:53 [INFO]\t[TRAIN] Epoch=3/50, Step=6/478, loss=0.146544, lr=0.096770, time_each_step=1.28s, eta=8:16:7\n",
      "2022-01-20 10:22:56 [INFO]\t[TRAIN] Epoch=3/50, Step=8/478, loss=0.088821, lr=0.096763, time_each_step=1.28s, eta=8:15:56\n",
      "2022-01-20 10:22:58 [INFO]\t[TRAIN] Epoch=3/50, Step=10/478, loss=0.083154, lr=0.096757, time_each_step=1.29s, eta=8:17:3\n",
      "2022-01-20 10:23:01 [INFO]\t[TRAIN] Epoch=3/50, Step=12/478, loss=0.088702, lr=0.096750, time_each_step=1.28s, eta=8:15:21\n",
      "2022-01-20 10:23:03 [INFO]\t[TRAIN] Epoch=3/50, Step=14/478, loss=0.067935, lr=0.096743, time_each_step=1.29s, eta=8:17:33\n",
      "2022-01-20 10:23:06 [INFO]\t[TRAIN] Epoch=3/50, Step=16/478, loss=0.071741, lr=0.096736, time_each_step=1.29s, eta=8:17:6\n",
      "2022-01-20 10:23:09 [INFO]\t[TRAIN] Epoch=3/50, Step=18/478, loss=0.097256, lr=0.096730, time_each_step=1.28s, eta=8:16:21\n",
      "2022-01-20 10:23:11 [INFO]\t[TRAIN] Epoch=3/50, Step=20/478, loss=0.085100, lr=0.096723, time_each_step=1.29s, eta=8:16:34\n",
      "2022-01-20 10:23:14 [INFO]\t[TRAIN] Epoch=3/50, Step=22/478, loss=0.085939, lr=0.096716, time_each_step=1.29s, eta=8:18:7\n",
      "2022-01-20 10:23:16 [INFO]\t[TRAIN] Epoch=3/50, Step=24/478, loss=0.081794, lr=0.096709, time_each_step=1.29s, eta=8:16:47\n",
      "2022-01-20 10:23:19 [INFO]\t[TRAIN] Epoch=3/50, Step=26/478, loss=0.077792, lr=0.096703, time_each_step=1.29s, eta=8:16:46\n",
      "2022-01-20 10:23:21 [INFO]\t[TRAIN] Epoch=3/50, Step=28/478, loss=0.092157, lr=0.096696, time_each_step=1.29s, eta=8:17:46\n",
      "2022-01-20 10:23:24 [INFO]\t[TRAIN] Epoch=3/50, Step=30/478, loss=0.102679, lr=0.096689, time_each_step=1.29s, eta=8:16:38\n",
      "2022-01-20 10:23:27 [INFO]\t[TRAIN] Epoch=3/50, Step=32/478, loss=0.095477, lr=0.096682, time_each_step=1.28s, eta=8:16:5\n",
      "2022-01-20 10:23:29 [INFO]\t[TRAIN] Epoch=3/50, Step=34/478, loss=0.110527, lr=0.096676, time_each_step=1.29s, eta=8:17:16\n",
      "2022-01-20 10:23:32 [INFO]\t[TRAIN] Epoch=3/50, Step=36/478, loss=0.114459, lr=0.096669, time_each_step=1.28s, eta=8:16:1\n",
      "2022-01-20 10:23:34 [INFO]\t[TRAIN] Epoch=3/50, Step=38/478, loss=0.097824, lr=0.096662, time_each_step=1.29s, eta=8:16:33\n",
      "2022-01-20 10:23:37 [INFO]\t[TRAIN] Epoch=3/50, Step=40/478, loss=0.145832, lr=0.096655, time_each_step=1.29s, eta=8:17:28\n",
      "2022-01-20 10:23:39 [INFO]\t[TRAIN] Epoch=3/50, Step=42/478, loss=0.125229, lr=0.096649, time_each_step=1.28s, eta=8:15:44\n",
      "2022-01-20 10:23:42 [INFO]\t[TRAIN] Epoch=3/50, Step=44/478, loss=0.086314, lr=0.096642, time_each_step=1.29s, eta=8:17:16\n",
      "2022-01-20 10:23:45 [INFO]\t[TRAIN] Epoch=3/50, Step=46/478, loss=0.120115, lr=0.096635, time_each_step=1.29s, eta=8:17:13\n",
      "2022-01-20 10:23:47 [INFO]\t[TRAIN] Epoch=3/50, Step=48/478, loss=0.093052, lr=0.096628, time_each_step=1.29s, eta=8:16:16\n",
      "2022-01-20 10:23:50 [INFO]\t[TRAIN] Epoch=3/50, Step=50/478, loss=0.109955, lr=0.096622, time_each_step=1.29s, eta=8:16:20\n",
      "2022-01-20 10:23:52 [INFO]\t[TRAIN] Epoch=3/50, Step=52/478, loss=0.089146, lr=0.096615, time_each_step=1.29s, eta=8:16:23\n",
      "2022-01-20 10:23:55 [INFO]\t[TRAIN] Epoch=3/50, Step=54/478, loss=0.091634, lr=0.096608, time_each_step=1.28s, eta=8:15:35\n",
      "2022-01-20 10:23:57 [INFO]\t[TRAIN] Epoch=3/50, Step=56/478, loss=0.092005, lr=0.096601, time_each_step=1.29s, eta=8:16:19\n",
      "2022-01-20 10:24:00 [INFO]\t[TRAIN] Epoch=3/50, Step=58/478, loss=0.077248, lr=0.096595, time_each_step=1.29s, eta=8:16:29\n",
      "2022-01-20 10:24:03 [INFO]\t[TRAIN] Epoch=3/50, Step=60/478, loss=0.135882, lr=0.096588, time_each_step=1.29s, eta=8:16:14\n",
      "2022-01-20 10:24:05 [INFO]\t[TRAIN] Epoch=3/50, Step=62/478, loss=0.068480, lr=0.096581, time_each_step=1.29s, eta=8:16:16\n",
      "2022-01-20 10:24:08 [INFO]\t[TRAIN] Epoch=3/50, Step=64/478, loss=0.084396, lr=0.096574, time_each_step=1.29s, eta=8:16:7\n",
      "2022-01-20 10:24:10 [INFO]\t[TRAIN] Epoch=3/50, Step=66/478, loss=0.121807, lr=0.096568, time_each_step=1.29s, eta=8:16:11\n",
      "2022-01-20 10:24:13 [INFO]\t[TRAIN] Epoch=3/50, Step=68/478, loss=0.104988, lr=0.096561, time_each_step=1.29s, eta=8:16:28\n",
      "2022-01-20 10:24:15 [INFO]\t[TRAIN] Epoch=3/50, Step=70/478, loss=0.094911, lr=0.096554, time_each_step=1.29s, eta=8:16:0\n",
      "2022-01-20 10:24:18 [INFO]\t[TRAIN] Epoch=3/50, Step=72/478, loss=0.100138, lr=0.096547, time_each_step=1.28s, eta=8:15:1\n",
      "2022-01-20 10:24:21 [INFO]\t[TRAIN] Epoch=3/50, Step=74/478, loss=0.113450, lr=0.096541, time_each_step=1.29s, eta=8:16:37\n",
      "2022-01-20 10:24:23 [INFO]\t[TRAIN] Epoch=3/50, Step=76/478, loss=0.118877, lr=0.096534, time_each_step=1.29s, eta=8:15:36\n",
      "2022-01-20 10:24:26 [INFO]\t[TRAIN] Epoch=3/50, Step=78/478, loss=0.088680, lr=0.096527, time_each_step=1.29s, eta=8:15:14\n",
      "2022-01-20 10:24:28 [INFO]\t[TRAIN] Epoch=3/50, Step=80/478, loss=0.091860, lr=0.096520, time_each_step=1.29s, eta=8:16:13\n",
      "2022-01-20 10:24:31 [INFO]\t[TRAIN] Epoch=3/50, Step=82/478, loss=0.080239, lr=0.096514, time_each_step=1.29s, eta=8:15:45\n",
      "2022-01-20 10:24:33 [INFO]\t[TRAIN] Epoch=3/50, Step=84/478, loss=0.081446, lr=0.096507, time_each_step=1.29s, eta=8:16:15\n",
      "2022-01-20 10:24:36 [INFO]\t[TRAIN] Epoch=3/50, Step=86/478, loss=0.109971, lr=0.096500, time_each_step=1.29s, eta=8:16:40\n",
      "2022-01-20 10:24:39 [INFO]\t[TRAIN] Epoch=3/50, Step=88/478, loss=0.068533, lr=0.096493, time_each_step=1.29s, eta=8:15:54\n",
      "2022-01-20 10:24:41 [INFO]\t[TRAIN] Epoch=3/50, Step=90/478, loss=0.106506, lr=0.096487, time_each_step=1.28s, eta=8:14:39\n",
      "2022-01-20 10:24:44 [INFO]\t[TRAIN] Epoch=3/50, Step=92/478, loss=0.100794, lr=0.096480, time_each_step=1.29s, eta=8:15:30\n",
      "2022-01-20 10:24:46 [INFO]\t[TRAIN] Epoch=3/50, Step=94/478, loss=0.090291, lr=0.096473, time_each_step=1.28s, eta=8:14:46\n",
      "2022-01-20 10:24:49 [INFO]\t[TRAIN] Epoch=3/50, Step=96/478, loss=0.109099, lr=0.096466, time_each_step=1.29s, eta=8:15:11\n",
      "2022-01-20 10:24:51 [INFO]\t[TRAIN] Epoch=3/50, Step=98/478, loss=0.062825, lr=0.096460, time_each_step=1.28s, eta=8:14:44\n",
      "2022-01-20 10:24:54 [INFO]\t[TRAIN] Epoch=3/50, Step=100/478, loss=0.088595, lr=0.096453, time_each_step=1.28s, eta=8:14:36\n",
      "2022-01-20 10:24:57 [INFO]\t[TRAIN] Epoch=3/50, Step=102/478, loss=0.071998, lr=0.096446, time_each_step=1.29s, eta=8:14:47\n",
      "2022-01-20 10:24:59 [INFO]\t[TRAIN] Epoch=3/50, Step=104/478, loss=0.091191, lr=0.096439, time_each_step=1.29s, eta=8:15:32\n",
      "2022-01-20 10:25:02 [INFO]\t[TRAIN] Epoch=3/50, Step=106/478, loss=0.071731, lr=0.096432, time_each_step=1.29s, eta=8:15:56\n",
      "2022-01-20 10:25:04 [INFO]\t[TRAIN] Epoch=3/50, Step=108/478, loss=0.067021, lr=0.096426, time_each_step=1.29s, eta=8:14:53\n",
      "2022-01-20 10:25:07 [INFO]\t[TRAIN] Epoch=3/50, Step=110/478, loss=0.077857, lr=0.096419, time_each_step=1.29s, eta=8:14:57\n",
      "2022-01-20 10:25:09 [INFO]\t[TRAIN] Epoch=3/50, Step=112/478, loss=0.107959, lr=0.096412, time_each_step=1.29s, eta=8:14:44\n",
      "2022-01-20 10:25:12 [INFO]\t[TRAIN] Epoch=3/50, Step=114/478, loss=0.068520, lr=0.096405, time_each_step=1.29s, eta=8:14:33\n",
      "2022-01-20 10:25:15 [INFO]\t[TRAIN] Epoch=3/50, Step=116/478, loss=0.083881, lr=0.096399, time_each_step=1.29s, eta=8:15:21\n",
      "2022-01-20 10:25:17 [INFO]\t[TRAIN] Epoch=3/50, Step=118/478, loss=0.110318, lr=0.096392, time_each_step=1.28s, eta=8:13:49\n",
      "2022-01-20 10:25:20 [INFO]\t[TRAIN] Epoch=3/50, Step=120/478, loss=0.077074, lr=0.096385, time_each_step=1.29s, eta=8:14:30\n",
      "2022-01-20 10:25:22 [INFO]\t[TRAIN] Epoch=3/50, Step=122/478, loss=0.064451, lr=0.096378, time_each_step=1.29s, eta=8:15:8\n",
      "2022-01-20 10:25:25 [INFO]\t[TRAIN] Epoch=3/50, Step=124/478, loss=0.087831, lr=0.096372, time_each_step=1.28s, eta=8:14:3\n",
      "2022-01-20 10:25:27 [INFO]\t[TRAIN] Epoch=3/50, Step=126/478, loss=0.061616, lr=0.096365, time_each_step=1.28s, eta=8:14:5\n",
      "2022-01-20 10:25:30 [INFO]\t[TRAIN] Epoch=3/50, Step=128/478, loss=0.154711, lr=0.096358, time_each_step=1.29s, eta=8:15:19\n",
      "2022-01-20 10:25:33 [INFO]\t[TRAIN] Epoch=3/50, Step=130/478, loss=0.072597, lr=0.096351, time_each_step=1.29s, eta=8:14:34\n",
      "2022-01-20 10:25:35 [INFO]\t[TRAIN] Epoch=3/50, Step=132/478, loss=0.087557, lr=0.096345, time_each_step=1.29s, eta=8:14:18\n",
      "2022-01-20 10:25:38 [INFO]\t[TRAIN] Epoch=3/50, Step=134/478, loss=0.089564, lr=0.096338, time_each_step=1.29s, eta=8:14:18\n",
      "2022-01-20 10:25:40 [INFO]\t[TRAIN] Epoch=3/50, Step=136/478, loss=0.080072, lr=0.096331, time_each_step=1.29s, eta=8:14:3\n",
      "2022-01-20 10:25:43 [INFO]\t[TRAIN] Epoch=3/50, Step=138/478, loss=0.087123, lr=0.096324, time_each_step=1.29s, eta=8:13:59\n",
      "2022-01-20 10:25:45 [INFO]\t[TRAIN] Epoch=3/50, Step=140/478, loss=0.066263, lr=0.096318, time_each_step=1.29s, eta=8:14:45\n",
      "2022-01-20 10:25:48 [INFO]\t[TRAIN] Epoch=3/50, Step=142/478, loss=0.083790, lr=0.096311, time_each_step=1.28s, eta=8:13:34\n",
      "2022-01-20 10:25:51 [INFO]\t[TRAIN] Epoch=3/50, Step=144/478, loss=0.077064, lr=0.096304, time_each_step=1.29s, eta=8:13:47\n",
      "2022-01-20 10:25:53 [INFO]\t[TRAIN] Epoch=3/50, Step=146/478, loss=0.091473, lr=0.096297, time_each_step=1.29s, eta=8:15:2\n",
      "2022-01-20 10:25:56 [INFO]\t[TRAIN] Epoch=3/50, Step=148/478, loss=0.122604, lr=0.096291, time_each_step=1.29s, eta=8:14:43\n",
      "2022-01-20 10:25:58 [INFO]\t[TRAIN] Epoch=3/50, Step=150/478, loss=0.092612, lr=0.096284, time_each_step=1.29s, eta=8:14:29\n",
      "2022-01-20 10:26:01 [INFO]\t[TRAIN] Epoch=3/50, Step=152/478, loss=0.100582, lr=0.096277, time_each_step=1.29s, eta=8:14:24\n",
      "2022-01-20 10:26:03 [INFO]\t[TRAIN] Epoch=3/50, Step=154/478, loss=0.129653, lr=0.096270, time_each_step=1.28s, eta=8:13:20\n",
      "2022-01-20 10:26:06 [INFO]\t[TRAIN] Epoch=3/50, Step=156/478, loss=0.090273, lr=0.096264, time_each_step=1.29s, eta=8:14:15\n",
      "2022-01-20 10:26:09 [INFO]\t[TRAIN] Epoch=3/50, Step=158/478, loss=0.092193, lr=0.096257, time_each_step=1.29s, eta=8:14:45\n",
      "2022-01-20 10:26:11 [INFO]\t[TRAIN] Epoch=3/50, Step=160/478, loss=0.124188, lr=0.096250, time_each_step=1.28s, eta=8:13:15\n",
      "2022-01-20 10:26:14 [INFO]\t[TRAIN] Epoch=3/50, Step=162/478, loss=0.103136, lr=0.096243, time_each_step=1.29s, eta=8:13:50\n",
      "2022-01-20 10:26:16 [INFO]\t[TRAIN] Epoch=3/50, Step=164/478, loss=0.072110, lr=0.096237, time_each_step=1.29s, eta=8:14:18\n",
      "2022-01-20 10:26:19 [INFO]\t[TRAIN] Epoch=3/50, Step=166/478, loss=0.128061, lr=0.096230, time_each_step=1.29s, eta=8:14:27\n",
      "2022-01-20 10:26:21 [INFO]\t[TRAIN] Epoch=3/50, Step=168/478, loss=0.111612, lr=0.096223, time_each_step=1.28s, eta=8:12:33\n",
      "2022-01-20 10:26:24 [INFO]\t[TRAIN] Epoch=3/50, Step=170/478, loss=0.087537, lr=0.096216, time_each_step=1.29s, eta=8:14:8\n",
      "2022-01-20 10:26:27 [INFO]\t[TRAIN] Epoch=3/50, Step=172/478, loss=0.080500, lr=0.096209, time_each_step=1.29s, eta=8:13:42\n",
      "2022-01-20 10:26:29 [INFO]\t[TRAIN] Epoch=3/50, Step=174/478, loss=0.090141, lr=0.096203, time_each_step=1.29s, eta=8:13:38\n",
      "2022-01-20 10:26:32 [INFO]\t[TRAIN] Epoch=3/50, Step=176/478, loss=0.073964, lr=0.096196, time_each_step=1.29s, eta=8:14:25\n",
      "2022-01-20 10:26:34 [INFO]\t[TRAIN] Epoch=3/50, Step=178/478, loss=0.079459, lr=0.096189, time_each_step=1.29s, eta=8:13:11\n",
      "2022-01-20 10:26:37 [INFO]\t[TRAIN] Epoch=3/50, Step=180/478, loss=0.080521, lr=0.096182, time_each_step=1.28s, eta=8:12:45\n",
      "2022-01-20 10:26:39 [INFO]\t[TRAIN] Epoch=3/50, Step=182/478, loss=0.077167, lr=0.096176, time_each_step=1.28s, eta=8:12:51\n",
      "2022-01-20 10:26:42 [INFO]\t[TRAIN] Epoch=3/50, Step=184/478, loss=0.125034, lr=0.096169, time_each_step=1.29s, eta=8:14:0\n",
      "2022-01-20 10:26:45 [INFO]\t[TRAIN] Epoch=3/50, Step=186/478, loss=0.144760, lr=0.096162, time_each_step=1.29s, eta=8:13:18\n",
      "2022-01-20 10:26:47 [INFO]\t[TRAIN] Epoch=3/50, Step=188/478, loss=0.082505, lr=0.096155, time_each_step=1.29s, eta=8:13:14\n",
      "2022-01-20 10:26:50 [INFO]\t[TRAIN] Epoch=3/50, Step=190/478, loss=0.070572, lr=0.096149, time_each_step=1.29s, eta=8:14:37\n",
      "2022-01-20 10:26:52 [INFO]\t[TRAIN] Epoch=3/50, Step=192/478, loss=0.107216, lr=0.096142, time_each_step=1.28s, eta=8:12:0\n",
      "2022-01-20 10:26:55 [INFO]\t[TRAIN] Epoch=3/50, Step=194/478, loss=0.070185, lr=0.096135, time_each_step=1.29s, eta=8:13:4\n",
      "2022-01-20 10:26:58 [INFO]\t[TRAIN] Epoch=3/50, Step=196/478, loss=0.124191, lr=0.096128, time_each_step=1.29s, eta=8:15:15\n",
      "2022-01-20 10:27:00 [INFO]\t[TRAIN] Epoch=3/50, Step=198/478, loss=0.090468, lr=0.096122, time_each_step=1.28s, eta=8:12:29\n",
      "2022-01-20 10:27:03 [INFO]\t[TRAIN] Epoch=3/50, Step=200/478, loss=0.079385, lr=0.096115, time_each_step=1.29s, eta=8:15:17\n",
      "2022-01-20 10:27:05 [INFO]\t[TRAIN] Epoch=3/50, Step=202/478, loss=0.104757, lr=0.096108, time_each_step=1.28s, eta=8:12:23\n",
      "2022-01-20 10:27:08 [INFO]\t[TRAIN] Epoch=3/50, Step=204/478, loss=0.094528, lr=0.096101, time_each_step=1.29s, eta=8:12:55\n",
      "2022-01-20 10:27:10 [INFO]\t[TRAIN] Epoch=3/50, Step=206/478, loss=0.081330, lr=0.096095, time_each_step=1.29s, eta=8:12:49\n",
      "2022-01-20 10:27:13 [INFO]\t[TRAIN] Epoch=3/50, Step=208/478, loss=0.110930, lr=0.096088, time_each_step=1.28s, eta=8:12:4\n",
      "2022-01-20 10:27:16 [INFO]\t[TRAIN] Epoch=3/50, Step=210/478, loss=0.084080, lr=0.096081, time_each_step=1.28s, eta=8:12:13\n",
      "2022-01-20 10:27:18 [INFO]\t[TRAIN] Epoch=3/50, Step=212/478, loss=0.084062, lr=0.096074, time_each_step=1.29s, eta=8:13:9\n",
      "2022-01-20 10:27:21 [INFO]\t[TRAIN] Epoch=3/50, Step=214/478, loss=0.096898, lr=0.096068, time_each_step=1.29s, eta=8:12:26\n",
      "2022-01-20 10:27:23 [INFO]\t[TRAIN] Epoch=3/50, Step=216/478, loss=0.093442, lr=0.096061, time_each_step=1.28s, eta=8:11:53\n",
      "2022-01-20 10:27:26 [INFO]\t[TRAIN] Epoch=3/50, Step=218/478, loss=0.087490, lr=0.096054, time_each_step=1.29s, eta=8:12:41\n",
      "2022-01-20 10:27:28 [INFO]\t[TRAIN] Epoch=3/50, Step=220/478, loss=0.108299, lr=0.096047, time_each_step=1.29s, eta=8:12:10\n",
      "2022-01-20 10:27:31 [INFO]\t[TRAIN] Epoch=3/50, Step=222/478, loss=0.069151, lr=0.096040, time_each_step=1.28s, eta=8:11:50\n",
      "2022-01-20 10:27:34 [INFO]\t[TRAIN] Epoch=3/50, Step=224/478, loss=0.099528, lr=0.096034, time_each_step=1.29s, eta=8:13:47\n",
      "2022-01-20 10:27:36 [INFO]\t[TRAIN] Epoch=3/50, Step=226/478, loss=0.113596, lr=0.096027, time_each_step=1.28s, eta=8:11:31\n",
      "2022-01-20 10:27:39 [INFO]\t[TRAIN] Epoch=3/50, Step=228/478, loss=0.080546, lr=0.096020, time_each_step=1.29s, eta=8:12:13\n",
      "2022-01-20 10:27:41 [INFO]\t[TRAIN] Epoch=3/50, Step=230/478, loss=0.077633, lr=0.096013, time_each_step=1.29s, eta=8:12:51\n",
      "2022-01-20 10:27:44 [INFO]\t[TRAIN] Epoch=3/50, Step=232/478, loss=0.077368, lr=0.096007, time_each_step=1.28s, eta=8:11:48\n",
      "2022-01-20 10:27:46 [INFO]\t[TRAIN] Epoch=3/50, Step=234/478, loss=0.090340, lr=0.096000, time_each_step=1.29s, eta=8:12:27\n",
      "2022-01-20 10:27:49 [INFO]\t[TRAIN] Epoch=3/50, Step=236/478, loss=0.081499, lr=0.095993, time_each_step=1.29s, eta=8:12:56\n",
      "2022-01-20 10:27:52 [INFO]\t[TRAIN] Epoch=3/50, Step=238/478, loss=0.095697, lr=0.095986, time_each_step=1.28s, eta=8:11:35\n",
      "2022-01-20 10:27:54 [INFO]\t[TRAIN] Epoch=3/50, Step=240/478, loss=0.127512, lr=0.095980, time_each_step=1.29s, eta=8:13:20\n",
      "2022-01-20 10:27:57 [INFO]\t[TRAIN] Epoch=3/50, Step=242/478, loss=0.109335, lr=0.095973, time_each_step=1.29s, eta=8:13:2\n",
      "2022-01-20 10:27:59 [INFO]\t[TRAIN] Epoch=3/50, Step=244/478, loss=0.095428, lr=0.095966, time_each_step=1.29s, eta=8:12:12\n",
      "2022-01-20 10:28:02 [INFO]\t[TRAIN] Epoch=3/50, Step=246/478, loss=0.111184, lr=0.095959, time_each_step=1.28s, eta=8:11:1\n",
      "2022-01-20 10:28:04 [INFO]\t[TRAIN] Epoch=3/50, Step=248/478, loss=0.132014, lr=0.095953, time_each_step=1.29s, eta=8:12:56\n",
      "2022-01-20 10:28:07 [INFO]\t[TRAIN] Epoch=3/50, Step=250/478, loss=0.076317, lr=0.095946, time_each_step=1.29s, eta=8:12:13\n",
      "2022-01-20 10:28:10 [INFO]\t[TRAIN] Epoch=3/50, Step=252/478, loss=0.086909, lr=0.095939, time_each_step=1.28s, eta=8:10:49\n",
      "2022-01-20 10:28:12 [INFO]\t[TRAIN] Epoch=3/50, Step=254/478, loss=0.097887, lr=0.095932, time_each_step=1.29s, eta=8:11:56\n",
      "2022-01-20 10:28:15 [INFO]\t[TRAIN] Epoch=3/50, Step=256/478, loss=0.084546, lr=0.095925, time_each_step=1.29s, eta=8:12:16\n",
      "2022-01-20 10:28:17 [INFO]\t[TRAIN] Epoch=3/50, Step=258/478, loss=0.082856, lr=0.095919, time_each_step=1.29s, eta=8:11:26\n",
      "2022-01-20 10:28:20 [INFO]\t[TRAIN] Epoch=3/50, Step=260/478, loss=0.094807, lr=0.095912, time_each_step=1.29s, eta=8:12:59\n",
      "2022-01-20 10:28:22 [INFO]\t[TRAIN] Epoch=3/50, Step=262/478, loss=0.117344, lr=0.095905, time_each_step=1.29s, eta=8:11:30\n",
      "2022-01-20 10:28:25 [INFO]\t[TRAIN] Epoch=3/50, Step=264/478, loss=0.076928, lr=0.095898, time_each_step=1.28s, eta=8:11:0\n",
      "2022-01-20 10:28:28 [INFO]\t[TRAIN] Epoch=3/50, Step=266/478, loss=0.106030, lr=0.095892, time_each_step=1.29s, eta=8:12:10\n",
      "2022-01-20 10:28:30 [INFO]\t[TRAIN] Epoch=3/50, Step=268/478, loss=0.076487, lr=0.095885, time_each_step=1.28s, eta=8:10:32\n",
      "2022-01-20 10:28:33 [INFO]\t[TRAIN] Epoch=3/50, Step=270/478, loss=0.079661, lr=0.095878, time_each_step=1.28s, eta=8:11:3\n",
      "2022-01-20 10:28:35 [INFO]\t[TRAIN] Epoch=3/50, Step=272/478, loss=0.077091, lr=0.095871, time_each_step=1.28s, eta=8:10:45\n",
      "2022-01-20 10:28:38 [INFO]\t[TRAIN] Epoch=3/50, Step=274/478, loss=0.053127, lr=0.095865, time_each_step=1.29s, eta=8:11:20\n",
      "2022-01-20 10:28:40 [INFO]\t[TRAIN] Epoch=3/50, Step=276/478, loss=0.073054, lr=0.095858, time_each_step=1.29s, eta=8:11:0\n",
      "2022-01-20 10:28:43 [INFO]\t[TRAIN] Epoch=3/50, Step=278/478, loss=0.075086, lr=0.095851, time_each_step=1.29s, eta=8:11:23\n",
      "2022-01-20 10:28:46 [INFO]\t[TRAIN] Epoch=3/50, Step=280/478, loss=0.104028, lr=0.095844, time_each_step=1.28s, eta=8:10:44\n",
      "2022-01-20 10:28:48 [INFO]\t[TRAIN] Epoch=3/50, Step=282/478, loss=0.111024, lr=0.095838, time_each_step=1.29s, eta=8:11:13\n",
      "2022-01-20 10:28:51 [INFO]\t[TRAIN] Epoch=3/50, Step=284/478, loss=0.082846, lr=0.095831, time_each_step=1.29s, eta=8:12:37\n",
      "2022-01-20 10:28:53 [INFO]\t[TRAIN] Epoch=3/50, Step=286/478, loss=0.066499, lr=0.095824, time_each_step=1.29s, eta=8:11:46\n",
      "2022-01-20 10:28:56 [INFO]\t[TRAIN] Epoch=3/50, Step=288/478, loss=0.139785, lr=0.095817, time_each_step=1.28s, eta=8:10:39\n",
      "2022-01-20 10:28:58 [INFO]\t[TRAIN] Epoch=3/50, Step=290/478, loss=0.099785, lr=0.095810, time_each_step=1.29s, eta=8:12:10\n",
      "2022-01-20 10:29:01 [INFO]\t[TRAIN] Epoch=3/50, Step=292/478, loss=0.069535, lr=0.095804, time_each_step=1.28s, eta=8:10:25\n",
      "2022-01-20 10:29:04 [INFO]\t[TRAIN] Epoch=3/50, Step=294/478, loss=0.082433, lr=0.095797, time_each_step=1.29s, eta=8:11:51\n",
      "2022-01-20 10:29:06 [INFO]\t[TRAIN] Epoch=3/50, Step=296/478, loss=0.086587, lr=0.095790, time_each_step=1.29s, eta=8:11:22\n",
      "2022-01-20 10:29:09 [INFO]\t[TRAIN] Epoch=3/50, Step=298/478, loss=0.094115, lr=0.095783, time_each_step=1.29s, eta=8:10:44\n",
      "2022-01-20 10:29:11 [INFO]\t[TRAIN] Epoch=3/50, Step=300/478, loss=0.083324, lr=0.095777, time_each_step=1.28s, eta=8:9:50\n",
      "2022-01-20 10:29:14 [INFO]\t[TRAIN] Epoch=3/50, Step=302/478, loss=0.077652, lr=0.095770, time_each_step=1.29s, eta=8:11:11\n",
      "2022-01-20 10:29:16 [INFO]\t[TRAIN] Epoch=3/50, Step=304/478, loss=0.082473, lr=0.095763, time_each_step=1.29s, eta=8:10:57\n",
      "2022-01-20 10:29:19 [INFO]\t[TRAIN] Epoch=3/50, Step=306/478, loss=0.100878, lr=0.095756, time_each_step=1.28s, eta=8:9:28\n",
      "2022-01-20 10:29:22 [INFO]\t[TRAIN] Epoch=3/50, Step=308/478, loss=0.103977, lr=0.095750, time_each_step=1.29s, eta=8:11:25\n",
      "2022-01-20 10:29:24 [INFO]\t[TRAIN] Epoch=3/50, Step=310/478, loss=0.066385, lr=0.095743, time_each_step=1.29s, eta=8:10:46\n",
      "2022-01-20 10:29:27 [INFO]\t[TRAIN] Epoch=3/50, Step=312/478, loss=0.068589, lr=0.095736, time_each_step=1.29s, eta=8:10:32\n",
      "2022-01-20 10:29:29 [INFO]\t[TRAIN] Epoch=3/50, Step=314/478, loss=0.079798, lr=0.095729, time_each_step=1.29s, eta=8:10:40\n",
      "2022-01-20 10:29:32 [INFO]\t[TRAIN] Epoch=3/50, Step=316/478, loss=0.103365, lr=0.095722, time_each_step=1.29s, eta=8:10:15\n",
      "2022-01-20 10:29:34 [INFO]\t[TRAIN] Epoch=3/50, Step=318/478, loss=0.108868, lr=0.095716, time_each_step=1.29s, eta=8:10:40\n",
      "2022-01-20 10:29:37 [INFO]\t[TRAIN] Epoch=3/50, Step=320/478, loss=0.081817, lr=0.095709, time_each_step=1.29s, eta=8:10:30\n",
      "2022-01-20 10:29:40 [INFO]\t[TRAIN] Epoch=3/50, Step=322/478, loss=0.098443, lr=0.095702, time_each_step=1.29s, eta=8:9:59\n",
      "2022-01-20 10:29:42 [INFO]\t[TRAIN] Epoch=3/50, Step=324/478, loss=0.057945, lr=0.095695, time_each_step=1.29s, eta=8:10:25\n",
      "2022-01-20 10:29:45 [INFO]\t[TRAIN] Epoch=3/50, Step=326/478, loss=0.085016, lr=0.095689, time_each_step=1.29s, eta=8:11:41\n",
      "2022-01-20 10:29:47 [INFO]\t[TRAIN] Epoch=3/50, Step=328/478, loss=0.090353, lr=0.095682, time_each_step=1.29s, eta=8:10:6\n",
      "2022-01-20 10:29:50 [INFO]\t[TRAIN] Epoch=3/50, Step=330/478, loss=0.087594, lr=0.095675, time_each_step=1.28s, eta=8:9:28\n",
      "2022-01-20 10:29:52 [INFO]\t[TRAIN] Epoch=3/50, Step=332/478, loss=0.153569, lr=0.095668, time_each_step=1.29s, eta=8:10:51\n",
      "2022-01-20 10:29:55 [INFO]\t[TRAIN] Epoch=3/50, Step=334/478, loss=0.078859, lr=0.095662, time_each_step=1.28s, eta=8:9:39\n",
      "2022-01-20 10:29:58 [INFO]\t[TRAIN] Epoch=3/50, Step=336/478, loss=0.058707, lr=0.095655, time_each_step=1.29s, eta=8:9:55\n",
      "2022-01-20 10:30:00 [INFO]\t[TRAIN] Epoch=3/50, Step=338/478, loss=0.134534, lr=0.095648, time_each_step=1.29s, eta=8:10:34\n",
      "2022-01-20 10:30:03 [INFO]\t[TRAIN] Epoch=3/50, Step=340/478, loss=0.085600, lr=0.095641, time_each_step=1.29s, eta=8:10:16\n",
      "2022-01-20 10:30:05 [INFO]\t[TRAIN] Epoch=3/50, Step=342/478, loss=0.077002, lr=0.095634, time_each_step=1.29s, eta=8:10:4\n",
      "2022-01-20 10:30:08 [INFO]\t[TRAIN] Epoch=3/50, Step=344/478, loss=0.098536, lr=0.095628, time_each_step=1.29s, eta=8:10:32\n",
      "2022-01-20 10:30:10 [INFO]\t[TRAIN] Epoch=3/50, Step=346/478, loss=0.088434, lr=0.095621, time_each_step=1.29s, eta=8:10:27\n",
      "2022-01-20 10:30:13 [INFO]\t[TRAIN] Epoch=3/50, Step=348/478, loss=0.071490, lr=0.095614, time_each_step=1.28s, eta=8:8:50\n",
      "2022-01-20 10:30:16 [INFO]\t[TRAIN] Epoch=3/50, Step=350/478, loss=0.097873, lr=0.095607, time_each_step=1.29s, eta=8:10:42\n",
      "2022-01-20 10:30:18 [INFO]\t[TRAIN] Epoch=3/50, Step=352/478, loss=0.109127, lr=0.095601, time_each_step=1.29s, eta=8:9:28\n",
      "2022-01-20 10:30:21 [INFO]\t[TRAIN] Epoch=3/50, Step=354/478, loss=0.102891, lr=0.095594, time_each_step=1.29s, eta=8:9:19\n",
      "2022-01-20 10:30:23 [INFO]\t[TRAIN] Epoch=3/50, Step=356/478, loss=0.060261, lr=0.095587, time_each_step=1.29s, eta=8:9:47\n",
      "2022-01-20 10:30:26 [INFO]\t[TRAIN] Epoch=3/50, Step=358/478, loss=0.091667, lr=0.095580, time_each_step=1.28s, eta=8:8:30\n",
      "2022-01-20 10:30:28 [INFO]\t[TRAIN] Epoch=3/50, Step=360/478, loss=0.074130, lr=0.095574, time_each_step=1.28s, eta=8:8:50\n",
      "2022-01-20 10:30:31 [INFO]\t[TRAIN] Epoch=3/50, Step=362/478, loss=0.077747, lr=0.095567, time_each_step=1.29s, eta=8:11:32\n",
      "2022-01-20 10:30:34 [INFO]\t[TRAIN] Epoch=3/50, Step=364/478, loss=0.098137, lr=0.095560, time_each_step=1.28s, eta=8:8:49\n",
      "2022-01-20 10:30:36 [INFO]\t[TRAIN] Epoch=3/50, Step=366/478, loss=0.066856, lr=0.095553, time_each_step=1.28s, eta=8:8:56\n",
      "2022-01-20 10:30:39 [INFO]\t[TRAIN] Epoch=3/50, Step=368/478, loss=0.083668, lr=0.095546, time_each_step=1.29s, eta=8:9:16\n",
      "2022-01-20 10:30:41 [INFO]\t[TRAIN] Epoch=3/50, Step=370/478, loss=0.077911, lr=0.095540, time_each_step=1.29s, eta=8:8:58\n",
      "2022-01-20 10:30:44 [INFO]\t[TRAIN] Epoch=3/50, Step=372/478, loss=0.077180, lr=0.095533, time_each_step=1.29s, eta=8:9:21\n",
      "2022-01-20 10:30:46 [INFO]\t[TRAIN] Epoch=3/50, Step=374/478, loss=0.081420, lr=0.095526, time_each_step=1.29s, eta=8:9:44\n",
      "2022-01-20 10:30:49 [INFO]\t[TRAIN] Epoch=3/50, Step=376/478, loss=0.091609, lr=0.095519, time_each_step=1.29s, eta=8:9:7\n",
      "2022-01-20 10:30:52 [INFO]\t[TRAIN] Epoch=3/50, Step=378/478, loss=0.055974, lr=0.095513, time_each_step=1.29s, eta=8:9:1\n",
      "2022-01-20 10:30:54 [INFO]\t[TRAIN] Epoch=3/50, Step=380/478, loss=0.109634, lr=0.095506, time_each_step=1.29s, eta=8:9:50\n",
      "2022-01-20 10:30:57 [INFO]\t[TRAIN] Epoch=3/50, Step=382/478, loss=0.083047, lr=0.095499, time_each_step=1.28s, eta=8:8:30\n",
      "2022-01-20 10:30:59 [INFO]\t[TRAIN] Epoch=3/50, Step=384/478, loss=0.075473, lr=0.095492, time_each_step=1.28s, eta=8:7:50\n",
      "2022-01-20 10:31:02 [INFO]\t[TRAIN] Epoch=3/50, Step=386/478, loss=0.085430, lr=0.095486, time_each_step=1.29s, eta=8:10:9\n",
      "2022-01-20 10:31:04 [INFO]\t[TRAIN] Epoch=3/50, Step=388/478, loss=0.084629, lr=0.095479, time_each_step=1.29s, eta=8:8:43\n",
      "2022-01-20 10:31:07 [INFO]\t[TRAIN] Epoch=3/50, Step=390/478, loss=0.064149, lr=0.095472, time_each_step=1.29s, eta=8:8:47\n",
      "2022-01-20 10:31:10 [INFO]\t[TRAIN] Epoch=3/50, Step=392/478, loss=0.088596, lr=0.095465, time_each_step=1.29s, eta=8:9:18\n",
      "2022-01-20 10:31:12 [INFO]\t[TRAIN] Epoch=3/50, Step=394/478, loss=0.074397, lr=0.095458, time_each_step=1.29s, eta=8:8:51\n",
      "2022-01-20 10:31:15 [INFO]\t[TRAIN] Epoch=3/50, Step=396/478, loss=0.045374, lr=0.095452, time_each_step=1.29s, eta=8:9:24\n",
      "2022-01-20 10:31:17 [INFO]\t[TRAIN] Epoch=3/50, Step=398/478, loss=0.079761, lr=0.095445, time_each_step=1.29s, eta=8:9:16\n",
      "2022-01-20 10:31:20 [INFO]\t[TRAIN] Epoch=3/50, Step=400/478, loss=0.087625, lr=0.095438, time_each_step=1.29s, eta=8:8:58\n",
      "2022-01-20 10:31:22 [INFO]\t[TRAIN] Epoch=3/50, Step=402/478, loss=0.088840, lr=0.095431, time_each_step=1.29s, eta=8:8:52\n",
      "2022-01-20 10:31:25 [INFO]\t[TRAIN] Epoch=3/50, Step=404/478, loss=0.102200, lr=0.095425, time_each_step=1.29s, eta=8:8:56\n",
      "2022-01-20 10:31:28 [INFO]\t[TRAIN] Epoch=3/50, Step=406/478, loss=0.069349, lr=0.095418, time_each_step=1.29s, eta=8:8:9\n",
      "2022-01-20 10:31:30 [INFO]\t[TRAIN] Epoch=3/50, Step=408/478, loss=0.072572, lr=0.095411, time_each_step=1.28s, eta=8:7:47\n",
      "2022-01-20 10:31:33 [INFO]\t[TRAIN] Epoch=3/50, Step=410/478, loss=0.101455, lr=0.095404, time_each_step=1.29s, eta=8:8:59\n",
      "2022-01-20 10:31:35 [INFO]\t[TRAIN] Epoch=3/50, Step=412/478, loss=0.100764, lr=0.095397, time_each_step=1.28s, eta=8:7:37\n",
      "2022-01-20 10:31:38 [INFO]\t[TRAIN] Epoch=3/50, Step=414/478, loss=0.101622, lr=0.095391, time_each_step=1.29s, eta=8:8:15\n",
      "2022-01-20 10:31:40 [INFO]\t[TRAIN] Epoch=3/50, Step=416/478, loss=0.106247, lr=0.095384, time_each_step=1.29s, eta=8:9:31\n",
      "2022-01-20 10:31:43 [INFO]\t[TRAIN] Epoch=3/50, Step=418/478, loss=0.099163, lr=0.095377, time_each_step=1.28s, eta=8:7:29\n",
      "2022-01-20 10:31:46 [INFO]\t[TRAIN] Epoch=3/50, Step=420/478, loss=0.073204, lr=0.095370, time_each_step=1.29s, eta=8:8:26\n",
      "2022-01-20 10:31:48 [INFO]\t[TRAIN] Epoch=3/50, Step=422/478, loss=0.067912, lr=0.095364, time_each_step=1.29s, eta=8:8:36\n",
      "2022-01-20 10:31:51 [INFO]\t[TRAIN] Epoch=3/50, Step=424/478, loss=0.086878, lr=0.095357, time_each_step=1.29s, eta=8:7:55\n",
      "2022-01-20 10:31:53 [INFO]\t[TRAIN] Epoch=3/50, Step=426/478, loss=0.094650, lr=0.095350, time_each_step=1.28s, eta=8:7:32\n",
      "2022-01-20 10:31:56 [INFO]\t[TRAIN] Epoch=3/50, Step=428/478, loss=0.099178, lr=0.095343, time_each_step=1.29s, eta=8:8:27\n",
      "2022-01-20 10:31:58 [INFO]\t[TRAIN] Epoch=3/50, Step=430/478, loss=0.084989, lr=0.095337, time_each_step=1.28s, eta=8:7:35\n",
      "2022-01-20 10:32:01 [INFO]\t[TRAIN] Epoch=3/50, Step=432/478, loss=0.092181, lr=0.095330, time_each_step=1.29s, eta=8:7:55\n",
      "2022-01-20 10:32:04 [INFO]\t[TRAIN] Epoch=3/50, Step=434/478, loss=0.116762, lr=0.095323, time_each_step=1.29s, eta=8:9:5\n",
      "2022-01-20 10:32:06 [INFO]\t[TRAIN] Epoch=3/50, Step=436/478, loss=0.069782, lr=0.095316, time_each_step=1.28s, eta=8:7:3\n",
      "2022-01-20 10:32:09 [INFO]\t[TRAIN] Epoch=3/50, Step=438/478, loss=0.055050, lr=0.095309, time_each_step=1.28s, eta=8:7:18\n",
      "2022-01-20 10:32:11 [INFO]\t[TRAIN] Epoch=3/50, Step=440/478, loss=0.102283, lr=0.095303, time_each_step=1.29s, eta=8:8:50\n",
      "2022-01-20 10:32:14 [INFO]\t[TRAIN] Epoch=3/50, Step=442/478, loss=0.090222, lr=0.095296, time_each_step=1.28s, eta=8:7:15\n",
      "2022-01-20 10:32:16 [INFO]\t[TRAIN] Epoch=3/50, Step=444/478, loss=0.083470, lr=0.095289, time_each_step=1.29s, eta=8:7:24\n",
      "2022-01-20 10:32:19 [INFO]\t[TRAIN] Epoch=3/50, Step=446/478, loss=0.095402, lr=0.095282, time_each_step=1.29s, eta=8:9:45\n",
      "2022-01-20 10:32:22 [INFO]\t[TRAIN] Epoch=3/50, Step=448/478, loss=0.073014, lr=0.095276, time_each_step=1.28s, eta=8:6:29\n",
      "2022-01-20 10:32:24 [INFO]\t[TRAIN] Epoch=3/50, Step=450/478, loss=0.071885, lr=0.095269, time_each_step=1.29s, eta=8:7:24\n",
      "2022-01-20 10:32:27 [INFO]\t[TRAIN] Epoch=3/50, Step=452/478, loss=0.104134, lr=0.095262, time_each_step=1.29s, eta=8:8:43\n",
      "2022-01-20 10:32:29 [INFO]\t[TRAIN] Epoch=3/50, Step=454/478, loss=0.075479, lr=0.095255, time_each_step=1.28s, eta=8:6:32\n",
      "2022-01-20 10:32:32 [INFO]\t[TRAIN] Epoch=3/50, Step=456/478, loss=0.054863, lr=0.095248, time_each_step=1.28s, eta=8:6:52\n",
      "2022-01-20 10:32:35 [INFO]\t[TRAIN] Epoch=3/50, Step=458/478, loss=0.091432, lr=0.095242, time_each_step=1.29s, eta=8:8:5\n",
      "2022-01-20 10:32:37 [INFO]\t[TRAIN] Epoch=3/50, Step=460/478, loss=0.091238, lr=0.095235, time_each_step=1.29s, eta=8:7:11\n",
      "2022-01-20 10:32:40 [INFO]\t[TRAIN] Epoch=3/50, Step=462/478, loss=0.089864, lr=0.095228, time_each_step=1.29s, eta=8:7:22\n",
      "2022-01-20 10:32:42 [INFO]\t[TRAIN] Epoch=3/50, Step=464/478, loss=0.077492, lr=0.095221, time_each_step=1.29s, eta=8:7:39\n",
      "2022-01-20 10:32:45 [INFO]\t[TRAIN] Epoch=3/50, Step=466/478, loss=0.079154, lr=0.095215, time_each_step=1.29s, eta=8:7:15\n",
      "2022-01-20 10:32:47 [INFO]\t[TRAIN] Epoch=3/50, Step=468/478, loss=0.081113, lr=0.095208, time_each_step=1.29s, eta=8:6:55\n",
      "2022-01-20 10:32:50 [INFO]\t[TRAIN] Epoch=3/50, Step=470/478, loss=0.075308, lr=0.095201, time_each_step=1.29s, eta=8:7:0\n",
      "2022-01-20 10:32:53 [INFO]\t[TRAIN] Epoch=3/50, Step=472/478, loss=0.062341, lr=0.095194, time_each_step=1.29s, eta=8:7:11\n",
      "2022-01-20 10:32:55 [INFO]\t[TRAIN] Epoch=3/50, Step=474/478, loss=0.102667, lr=0.095187, time_each_step=1.29s, eta=8:6:45\n",
      "2022-01-20 10:32:58 [INFO]\t[TRAIN] Epoch=3/50, Step=476/478, loss=0.160139, lr=0.095181, time_each_step=1.29s, eta=8:6:49\n",
      "2022-01-20 10:33:00 [INFO]\t[TRAIN] Epoch=3/50, Step=478/478, loss=0.074211, lr=0.095174, time_each_step=1.28s, eta=8:6:21\n",
      "2022-01-20 10:33:00 [INFO]\t[TRAIN] Epoch 3 finished, loss=0.09028681 .\n",
      "2022-01-20 10:33:00 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-01-20 10:33:01 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-01-20 10:33:07 [INFO]\t[EVAL] Finished, Epoch=3, miou=0.812051, category_iou=[0.9669602  0.7012216  0.76797074], oacc=0.968619, category_acc=[0.9892645 0.803335  0.827042 ], kappa=0.852802, category_F1-score=[0.98320261 0.82437419 0.86875952] .\n",
      "2022-01-20 10:33:07 [INFO]\tModel saved in model/deeplab_augument_alldata2/best_model.\n",
      "2022-01-20 10:33:07 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_3, miou=0.8120508193969727\n",
      "2022-01-20 10:33:08 [INFO]\tModel saved in model/deeplab_augument_alldata2/epoch_3.\n",
      "2022-01-20 10:33:12 [INFO]\t[TRAIN] Epoch=4/50, Step=2/478, loss=0.102572, lr=0.095167, time_each_step=1.91s, eta=12:1:10\n",
      "2022-01-20 10:33:14 [INFO]\t[TRAIN] Epoch=4/50, Step=4/478, loss=0.096024, lr=0.095160, time_each_step=1.28s, eta=8:5:50\n",
      "2022-01-20 10:33:17 [INFO]\t[TRAIN] Epoch=4/50, Step=6/478, loss=0.104389, lr=0.095154, time_each_step=1.29s, eta=8:7:11\n",
      "2022-01-20 10:33:19 [INFO]\t[TRAIN] Epoch=4/50, Step=8/478, loss=0.075651, lr=0.095147, time_each_step=1.29s, eta=8:7:31\n",
      "2022-01-20 10:33:22 [INFO]\t[TRAIN] Epoch=4/50, Step=10/478, loss=0.122468, lr=0.095140, time_each_step=1.28s, eta=8:5:33\n",
      "2022-01-20 10:33:25 [INFO]\t[TRAIN] Epoch=4/50, Step=12/478, loss=0.066557, lr=0.095133, time_each_step=1.29s, eta=8:7:3\n",
      "2022-01-20 10:33:27 [INFO]\t[TRAIN] Epoch=4/50, Step=14/478, loss=0.095826, lr=0.095126, time_each_step=1.29s, eta=8:6:51\n",
      "2022-01-20 10:33:30 [INFO]\t[TRAIN] Epoch=4/50, Step=16/478, loss=0.126490, lr=0.095120, time_each_step=1.29s, eta=8:7:9\n",
      "2022-01-20 10:33:32 [INFO]\t[TRAIN] Epoch=4/50, Step=18/478, loss=0.091292, lr=0.095113, time_each_step=1.28s, eta=8:5:3\n",
      "2022-01-20 10:33:35 [INFO]\t[TRAIN] Epoch=4/50, Step=20/478, loss=0.118897, lr=0.095106, time_each_step=1.29s, eta=8:7:17\n",
      "2022-01-20 10:33:37 [INFO]\t[TRAIN] Epoch=4/50, Step=22/478, loss=0.093918, lr=0.095099, time_each_step=1.29s, eta=8:7:1\n",
      "2022-01-20 10:33:40 [INFO]\t[TRAIN] Epoch=4/50, Step=24/478, loss=0.083264, lr=0.095093, time_each_step=1.29s, eta=8:6:11\n",
      "2022-01-20 10:33:43 [INFO]\t[TRAIN] Epoch=4/50, Step=26/478, loss=0.137382, lr=0.095086, time_each_step=1.29s, eta=8:6:13\n",
      "2022-01-20 10:33:45 [INFO]\t[TRAIN] Epoch=4/50, Step=28/478, loss=0.099696, lr=0.095079, time_each_step=1.29s, eta=8:7:17\n",
      "2022-01-20 10:33:48 [INFO]\t[TRAIN] Epoch=4/50, Step=30/478, loss=0.071165, lr=0.095072, time_each_step=1.29s, eta=8:6:37\n",
      "2022-01-20 10:33:50 [INFO]\t[TRAIN] Epoch=4/50, Step=32/478, loss=0.078474, lr=0.095065, time_each_step=1.29s, eta=8:7:33\n",
      "2022-01-20 10:33:53 [INFO]\t[TRAIN] Epoch=4/50, Step=34/478, loss=0.064478, lr=0.095059, time_each_step=1.29s, eta=8:6:1\n",
      "2022-01-20 10:33:55 [INFO]\t[TRAIN] Epoch=4/50, Step=36/478, loss=0.073517, lr=0.095052, time_each_step=1.28s, eta=8:5:39\n",
      "2022-01-20 10:33:58 [INFO]\t[TRAIN] Epoch=4/50, Step=38/478, loss=0.089549, lr=0.095045, time_each_step=1.29s, eta=8:7:5\n",
      "2022-01-20 10:34:01 [INFO]\t[TRAIN] Epoch=4/50, Step=40/478, loss=0.106563, lr=0.095038, time_each_step=1.29s, eta=8:6:3\n",
      "2022-01-20 10:34:03 [INFO]\t[TRAIN] Epoch=4/50, Step=42/478, loss=0.086862, lr=0.095032, time_each_step=1.29s, eta=8:6:0\n",
      "2022-01-20 10:34:06 [INFO]\t[TRAIN] Epoch=4/50, Step=44/478, loss=0.070894, lr=0.095025, time_each_step=1.29s, eta=8:6:8\n",
      "2022-01-20 10:34:08 [INFO]\t[TRAIN] Epoch=4/50, Step=46/478, loss=0.064080, lr=0.095018, time_each_step=1.29s, eta=8:6:17\n",
      "2022-01-20 10:34:11 [INFO]\t[TRAIN] Epoch=4/50, Step=48/478, loss=0.090878, lr=0.095011, time_each_step=1.28s, eta=8:5:19\n",
      "2022-01-20 10:34:13 [INFO]\t[TRAIN] Epoch=4/50, Step=50/478, loss=0.061842, lr=0.095004, time_each_step=1.29s, eta=8:7:23\n",
      "2022-01-20 10:34:16 [INFO]\t[TRAIN] Epoch=4/50, Step=52/478, loss=0.083091, lr=0.094998, time_each_step=1.29s, eta=8:6:12\n",
      "2022-01-20 10:34:19 [INFO]\t[TRAIN] Epoch=4/50, Step=54/478, loss=0.085677, lr=0.094991, time_each_step=1.29s, eta=8:5:47\n",
      "2022-01-20 10:34:21 [INFO]\t[TRAIN] Epoch=4/50, Step=56/478, loss=0.083895, lr=0.094984, time_each_step=1.29s, eta=8:6:20\n",
      "2022-01-20 10:34:24 [INFO]\t[TRAIN] Epoch=4/50, Step=58/478, loss=0.080544, lr=0.094977, time_each_step=1.28s, eta=8:4:55\n",
      "2022-01-20 10:34:26 [INFO]\t[TRAIN] Epoch=4/50, Step=60/478, loss=0.081606, lr=0.094970, time_each_step=1.29s, eta=8:5:55\n",
      "2022-01-20 10:34:29 [INFO]\t[TRAIN] Epoch=4/50, Step=62/478, loss=0.082231, lr=0.094964, time_each_step=1.29s, eta=8:5:41\n",
      "2022-01-20 10:34:31 [INFO]\t[TRAIN] Epoch=4/50, Step=64/478, loss=0.071721, lr=0.094957, time_each_step=1.29s, eta=8:5:29\n",
      "2022-01-20 10:34:34 [INFO]\t[TRAIN] Epoch=4/50, Step=66/478, loss=0.068977, lr=0.094950, time_each_step=1.28s, eta=8:4:46\n",
      "2022-01-20 10:34:37 [INFO]\t[TRAIN] Epoch=4/50, Step=68/478, loss=0.098804, lr=0.094943, time_each_step=1.29s, eta=8:5:34\n",
      "2022-01-20 10:34:39 [INFO]\t[TRAIN] Epoch=4/50, Step=70/478, loss=0.080454, lr=0.094937, time_each_step=1.29s, eta=8:5:5\n",
      "2022-01-20 10:34:42 [INFO]\t[TRAIN] Epoch=4/50, Step=72/478, loss=0.115508, lr=0.094930, time_each_step=1.28s, eta=8:4:14\n",
      "2022-01-20 10:34:44 [INFO]\t[TRAIN] Epoch=4/50, Step=74/478, loss=0.106966, lr=0.094923, time_each_step=1.28s, eta=8:4:7\n",
      "2022-01-20 10:34:47 [INFO]\t[TRAIN] Epoch=4/50, Step=76/478, loss=0.093933, lr=0.094916, time_each_step=1.29s, eta=8:8:3\n",
      "2022-01-20 10:34:49 [INFO]\t[TRAIN] Epoch=4/50, Step=78/478, loss=0.063902, lr=0.094909, time_each_step=1.29s, eta=8:4:55\n",
      "2022-01-20 10:34:52 [INFO]\t[TRAIN] Epoch=4/50, Step=80/478, loss=0.107483, lr=0.094903, time_each_step=1.29s, eta=8:5:14\n",
      "2022-01-20 10:34:55 [INFO]\t[TRAIN] Epoch=4/50, Step=82/478, loss=0.090060, lr=0.094896, time_each_step=1.29s, eta=8:6:50\n",
      "2022-01-20 10:34:57 [INFO]\t[TRAIN] Epoch=4/50, Step=84/478, loss=0.060756, lr=0.094889, time_each_step=1.29s, eta=8:5:5\n",
      "2022-01-20 10:35:00 [INFO]\t[TRAIN] Epoch=4/50, Step=86/478, loss=0.132799, lr=0.094882, time_each_step=1.29s, eta=8:7:11\n",
      "2022-01-20 10:35:02 [INFO]\t[TRAIN] Epoch=4/50, Step=88/478, loss=0.137157, lr=0.094876, time_each_step=1.28s, eta=8:4:17\n",
      "2022-01-20 10:35:05 [INFO]\t[TRAIN] Epoch=4/50, Step=90/478, loss=0.083080, lr=0.094869, time_each_step=1.28s, eta=8:4:31\n",
      "2022-01-20 10:35:07 [INFO]\t[TRAIN] Epoch=4/50, Step=92/478, loss=0.095271, lr=0.094862, time_each_step=1.29s, eta=8:5:30\n",
      "2022-01-20 10:35:10 [INFO]\t[TRAIN] Epoch=4/50, Step=94/478, loss=0.057855, lr=0.094855, time_each_step=1.28s, eta=8:4:16\n",
      "2022-01-20 10:35:13 [INFO]\t[TRAIN] Epoch=4/50, Step=96/478, loss=0.152210, lr=0.094848, time_each_step=1.28s, eta=8:4:8\n",
      "2022-01-20 10:35:15 [INFO]\t[TRAIN] Epoch=4/50, Step=98/478, loss=0.070160, lr=0.094842, time_each_step=1.29s, eta=8:5:15\n",
      "2022-01-20 10:35:18 [INFO]\t[TRAIN] Epoch=4/50, Step=100/478, loss=0.107100, lr=0.094835, time_each_step=1.29s, eta=8:4:34\n",
      "2022-01-20 10:35:20 [INFO]\t[TRAIN] Epoch=4/50, Step=102/478, loss=0.094854, lr=0.094828, time_each_step=1.29s, eta=8:4:38\n",
      "2022-01-20 10:35:23 [INFO]\t[TRAIN] Epoch=4/50, Step=104/478, loss=0.112832, lr=0.094821, time_each_step=1.29s, eta=8:5:54\n",
      "2022-01-20 10:35:25 [INFO]\t[TRAIN] Epoch=4/50, Step=106/478, loss=0.097877, lr=0.094814, time_each_step=1.28s, eta=8:4:6\n",
      "2022-01-20 10:35:28 [INFO]\t[TRAIN] Epoch=4/50, Step=108/478, loss=0.115636, lr=0.094808, time_each_step=1.29s, eta=8:4:23\n",
      "2022-01-20 10:35:31 [INFO]\t[TRAIN] Epoch=4/50, Step=110/478, loss=0.121254, lr=0.094801, time_each_step=1.29s, eta=8:5:30\n",
      "2022-01-20 10:35:33 [INFO]\t[TRAIN] Epoch=4/50, Step=112/478, loss=0.084294, lr=0.094794, time_each_step=1.28s, eta=8:3:24\n",
      "2022-01-20 10:35:36 [INFO]\t[TRAIN] Epoch=4/50, Step=114/478, loss=0.093606, lr=0.094787, time_each_step=1.29s, eta=8:4:24\n",
      "2022-01-20 10:35:38 [INFO]\t[TRAIN] Epoch=4/50, Step=116/478, loss=0.095853, lr=0.094781, time_each_step=1.29s, eta=8:6:31\n",
      "2022-01-20 10:35:41 [INFO]\t[TRAIN] Epoch=4/50, Step=118/478, loss=0.073078, lr=0.094774, time_each_step=1.29s, eta=8:4:19\n",
      "2022-01-20 10:35:44 [INFO]\t[TRAIN] Epoch=4/50, Step=120/478, loss=0.085257, lr=0.094767, time_each_step=1.29s, eta=8:4:40\n",
      "2022-01-20 10:35:46 [INFO]\t[TRAIN] Epoch=4/50, Step=122/478, loss=0.084638, lr=0.094760, time_each_step=1.29s, eta=8:6:27\n",
      "2022-01-20 10:35:49 [INFO]\t[TRAIN] Epoch=4/50, Step=124/478, loss=0.108884, lr=0.094753, time_each_step=1.29s, eta=8:5:20\n",
      "2022-01-20 10:35:51 [INFO]\t[TRAIN] Epoch=4/50, Step=126/478, loss=0.058432, lr=0.094747, time_each_step=1.29s, eta=8:4:19\n",
      "2022-01-20 10:35:54 [INFO]\t[TRAIN] Epoch=4/50, Step=128/478, loss=0.074140, lr=0.094740, time_each_step=1.29s, eta=8:6:13\n",
      "2022-01-20 10:35:56 [INFO]\t[TRAIN] Epoch=4/50, Step=130/478, loss=0.072870, lr=0.094733, time_each_step=1.28s, eta=8:3:10\n",
      "2022-01-20 10:35:59 [INFO]\t[TRAIN] Epoch=4/50, Step=132/478, loss=0.068871, lr=0.094726, time_each_step=1.29s, eta=8:4:53\n",
      "2022-01-20 10:36:02 [INFO]\t[TRAIN] Epoch=4/50, Step=134/478, loss=0.089905, lr=0.094719, time_each_step=1.29s, eta=8:5:50\n",
      "2022-01-20 10:36:04 [INFO]\t[TRAIN] Epoch=4/50, Step=136/478, loss=0.093457, lr=0.094713, time_each_step=1.29s, eta=8:4:29\n",
      "2022-01-20 10:36:07 [INFO]\t[TRAIN] Epoch=4/50, Step=138/478, loss=0.123902, lr=0.094706, time_each_step=1.29s, eta=8:5:58\n",
      "2022-01-20 10:36:09 [INFO]\t[TRAIN] Epoch=4/50, Step=140/478, loss=0.088336, lr=0.094699, time_each_step=1.29s, eta=8:5:17\n",
      "2022-01-20 10:36:12 [INFO]\t[TRAIN] Epoch=4/50, Step=142/478, loss=0.093766, lr=0.094692, time_each_step=1.29s, eta=8:5:27\n",
      "2022-01-20 10:36:14 [INFO]\t[TRAIN] Epoch=4/50, Step=144/478, loss=0.057300, lr=0.094686, time_each_step=1.29s, eta=8:4:42\n",
      "2022-01-20 10:36:17 [INFO]\t[TRAIN] Epoch=4/50, Step=146/478, loss=0.117212, lr=0.094679, time_each_step=1.29s, eta=8:4:54\n",
      "2022-01-20 10:36:20 [INFO]\t[TRAIN] Epoch=4/50, Step=148/478, loss=0.072076, lr=0.094672, time_each_step=1.29s, eta=8:4:44\n",
      "2022-01-20 10:36:22 [INFO]\t[TRAIN] Epoch=4/50, Step=150/478, loss=0.114926, lr=0.094665, time_each_step=1.3s, eta=8:8:0\n",
      "2022-01-20 10:36:25 [INFO]\t[TRAIN] Epoch=4/50, Step=152/478, loss=0.089021, lr=0.094658, time_each_step=1.29s, eta=8:4:51\n",
      "2022-01-20 10:36:27 [INFO]\t[TRAIN] Epoch=4/50, Step=154/478, loss=0.086323, lr=0.094652, time_each_step=1.29s, eta=8:6:48\n",
      "2022-01-20 10:36:30 [INFO]\t[TRAIN] Epoch=4/50, Step=156/478, loss=0.091987, lr=0.094645, time_each_step=1.3s, eta=8:6:57\n",
      "2022-01-20 10:36:33 [INFO]\t[TRAIN] Epoch=4/50, Step=158/478, loss=0.082641, lr=0.094638, time_each_step=1.3s, eta=8:7:10\n",
      "2022-01-20 10:36:35 [INFO]\t[TRAIN] Epoch=4/50, Step=160/478, loss=0.073712, lr=0.094631, time_each_step=1.29s, eta=8:5:16\n",
      "2022-01-20 10:36:38 [INFO]\t[TRAIN] Epoch=4/50, Step=162/478, loss=0.101332, lr=0.094624, time_each_step=1.29s, eta=8:3:58\n",
      "2022-01-20 10:36:40 [INFO]\t[TRAIN] Epoch=4/50, Step=164/478, loss=0.093981, lr=0.094618, time_each_step=1.29s, eta=8:5:57\n",
      "2022-01-20 10:36:43 [INFO]\t[TRAIN] Epoch=4/50, Step=166/478, loss=0.073566, lr=0.094611, time_each_step=1.29s, eta=8:3:43\n",
      "2022-01-20 10:36:45 [INFO]\t[TRAIN] Epoch=4/50, Step=168/478, loss=0.100673, lr=0.094604, time_each_step=1.29s, eta=8:3:47\n",
      "2022-01-20 10:36:48 [INFO]\t[TRAIN] Epoch=4/50, Step=170/478, loss=0.110177, lr=0.094597, time_each_step=1.3s, eta=8:7:5\n",
      "2022-01-20 10:36:51 [INFO]\t[TRAIN] Epoch=4/50, Step=172/478, loss=0.084279, lr=0.094591, time_each_step=1.29s, eta=8:3:43\n",
      "2022-01-20 10:36:53 [INFO]\t[TRAIN] Epoch=4/50, Step=174/478, loss=0.117524, lr=0.094584, time_each_step=1.29s, eta=8:5:0\n",
      "2022-01-20 10:36:56 [INFO]\t[TRAIN] Epoch=4/50, Step=176/478, loss=0.128125, lr=0.094577, time_each_step=1.29s, eta=8:6:26\n",
      "2022-01-20 10:36:58 [INFO]\t[TRAIN] Epoch=4/50, Step=178/478, loss=0.092464, lr=0.094570, time_each_step=1.29s, eta=8:4:13\n",
      "2022-01-20 10:37:01 [INFO]\t[TRAIN] Epoch=4/50, Step=180/478, loss=0.081837, lr=0.094563, time_each_step=1.29s, eta=8:4:48\n",
      "2022-01-20 10:37:04 [INFO]\t[TRAIN] Epoch=4/50, Step=182/478, loss=0.083161, lr=0.094557, time_each_step=1.29s, eta=8:3:46\n",
      "2022-01-20 10:37:06 [INFO]\t[TRAIN] Epoch=4/50, Step=184/478, loss=0.079887, lr=0.094550, time_each_step=1.29s, eta=8:3:29\n",
      "2022-01-20 10:37:09 [INFO]\t[TRAIN] Epoch=4/50, Step=186/478, loss=0.119741, lr=0.094543, time_each_step=1.29s, eta=8:4:29\n",
      "2022-01-20 10:37:11 [INFO]\t[TRAIN] Epoch=4/50, Step=188/478, loss=0.069727, lr=0.094536, time_each_step=1.29s, eta=8:3:58\n",
      "2022-01-20 10:37:14 [INFO]\t[TRAIN] Epoch=4/50, Step=190/478, loss=0.083945, lr=0.094529, time_each_step=1.29s, eta=8:5:35\n",
      "2022-01-20 10:37:16 [INFO]\t[TRAIN] Epoch=4/50, Step=192/478, loss=0.077986, lr=0.094523, time_each_step=1.29s, eta=8:4:18\n",
      "2022-01-20 10:37:19 [INFO]\t[TRAIN] Epoch=4/50, Step=194/478, loss=0.087050, lr=0.094516, time_each_step=1.29s, eta=8:4:15\n",
      "2022-01-20 10:37:22 [INFO]\t[TRAIN] Epoch=4/50, Step=196/478, loss=0.083501, lr=0.094509, time_each_step=1.29s, eta=8:5:1\n",
      "2022-01-20 10:37:24 [INFO]\t[TRAIN] Epoch=4/50, Step=198/478, loss=0.083911, lr=0.094502, time_each_step=1.28s, eta=8:2:15\n",
      "2022-01-20 10:37:27 [INFO]\t[TRAIN] Epoch=4/50, Step=200/478, loss=0.064254, lr=0.094495, time_each_step=1.29s, eta=8:3:21\n",
      "2022-01-20 10:37:29 [INFO]\t[TRAIN] Epoch=4/50, Step=202/478, loss=0.102115, lr=0.094489, time_each_step=1.29s, eta=8:4:19\n",
      "2022-01-20 10:37:32 [INFO]\t[TRAIN] Epoch=4/50, Step=204/478, loss=0.080141, lr=0.094482, time_each_step=1.29s, eta=8:2:47\n",
      "2022-01-20 10:37:34 [INFO]\t[TRAIN] Epoch=4/50, Step=206/478, loss=0.097769, lr=0.094475, time_each_step=1.29s, eta=8:3:54\n",
      "2022-01-20 10:37:37 [INFO]\t[TRAIN] Epoch=4/50, Step=208/478, loss=0.071428, lr=0.094468, time_each_step=1.29s, eta=8:5:18\n",
      "2022-01-20 10:37:40 [INFO]\t[TRAIN] Epoch=4/50, Step=210/478, loss=0.093881, lr=0.094462, time_each_step=1.29s, eta=8:4:16\n",
      "2022-01-20 10:37:42 [INFO]\t[TRAIN] Epoch=4/50, Step=212/478, loss=0.089118, lr=0.094455, time_each_step=1.29s, eta=8:3:10\n",
      "2022-01-20 10:37:45 [INFO]\t[TRAIN] Epoch=4/50, Step=214/478, loss=0.118043, lr=0.094448, time_each_step=1.29s, eta=8:2:15\n",
      "2022-01-20 10:37:47 [INFO]\t[TRAIN] Epoch=4/50, Step=216/478, loss=0.081073, lr=0.094441, time_each_step=1.29s, eta=8:3:47\n",
      "2022-01-20 10:37:50 [INFO]\t[TRAIN] Epoch=4/50, Step=218/478, loss=0.103247, lr=0.094434, time_each_step=1.29s, eta=8:5:2\n",
      "2022-01-20 10:37:53 [INFO]\t[TRAIN] Epoch=4/50, Step=220/478, loss=0.110340, lr=0.094428, time_each_step=1.29s, eta=8:2:6\n",
      "2022-01-20 10:37:55 [INFO]\t[TRAIN] Epoch=4/50, Step=222/478, loss=0.067338, lr=0.094421, time_each_step=1.29s, eta=8:4:3\n",
      "2022-01-20 10:37:58 [INFO]\t[TRAIN] Epoch=4/50, Step=224/478, loss=0.094115, lr=0.094414, time_each_step=1.29s, eta=8:4:57\n",
      "2022-01-20 10:38:00 [INFO]\t[TRAIN] Epoch=4/50, Step=226/478, loss=0.084714, lr=0.094407, time_each_step=1.29s, eta=8:4:24\n",
      "2022-01-20 10:38:03 [INFO]\t[TRAIN] Epoch=4/50, Step=228/478, loss=0.067038, lr=0.094400, time_each_step=1.29s, eta=8:3:55\n",
      "2022-01-20 10:38:05 [INFO]\t[TRAIN] Epoch=4/50, Step=230/478, loss=0.088960, lr=0.094394, time_each_step=1.29s, eta=8:2:9\n",
      "2022-01-20 10:38:08 [INFO]\t[TRAIN] Epoch=4/50, Step=232/478, loss=0.064850, lr=0.094387, time_each_step=1.29s, eta=8:2:26\n",
      "2022-01-20 10:38:11 [INFO]\t[TRAIN] Epoch=4/50, Step=234/478, loss=0.108261, lr=0.094380, time_each_step=1.29s, eta=8:3:26\n",
      "2022-01-20 10:38:13 [INFO]\t[TRAIN] Epoch=4/50, Step=236/478, loss=0.071737, lr=0.094373, time_each_step=1.29s, eta=8:2:0\n",
      "2022-01-20 10:38:16 [INFO]\t[TRAIN] Epoch=4/50, Step=238/478, loss=0.095529, lr=0.094366, time_each_step=1.29s, eta=8:3:15\n",
      "2022-01-20 10:38:18 [INFO]\t[TRAIN] Epoch=4/50, Step=240/478, loss=0.095468, lr=0.094360, time_each_step=1.29s, eta=8:3:39\n",
      "2022-01-20 10:38:21 [INFO]\t[TRAIN] Epoch=4/50, Step=242/478, loss=0.076999, lr=0.094353, time_each_step=1.29s, eta=8:2:11\n",
      "2022-01-20 10:38:23 [INFO]\t[TRAIN] Epoch=4/50, Step=244/478, loss=0.074867, lr=0.094346, time_each_step=1.29s, eta=8:4:14\n",
      "2022-01-20 10:38:26 [INFO]\t[TRAIN] Epoch=4/50, Step=246/478, loss=0.110248, lr=0.094339, time_each_step=1.29s, eta=8:1:53\n",
      "2022-01-20 10:38:29 [INFO]\t[TRAIN] Epoch=4/50, Step=248/478, loss=0.094618, lr=0.094332, time_each_step=1.29s, eta=8:2:7\n",
      "2022-01-20 10:38:31 [INFO]\t[TRAIN] Epoch=4/50, Step=250/478, loss=0.059308, lr=0.094326, time_each_step=1.29s, eta=8:3:31\n",
      "2022-01-20 10:38:34 [INFO]\t[TRAIN] Epoch=4/50, Step=252/478, loss=0.092915, lr=0.094319, time_each_step=1.29s, eta=8:2:3\n",
      "2022-01-20 10:38:36 [INFO]\t[TRAIN] Epoch=4/50, Step=254/478, loss=0.092203, lr=0.094312, time_each_step=1.29s, eta=8:2:49\n",
      "2022-01-20 10:38:39 [INFO]\t[TRAIN] Epoch=4/50, Step=256/478, loss=0.091048, lr=0.094305, time_each_step=1.29s, eta=8:3:33\n",
      "2022-01-20 10:38:42 [INFO]\t[TRAIN] Epoch=4/50, Step=258/478, loss=0.090052, lr=0.094299, time_each_step=1.29s, eta=8:1:11\n",
      "2022-01-20 10:38:44 [INFO]\t[TRAIN] Epoch=4/50, Step=260/478, loss=0.096836, lr=0.094292, time_each_step=1.29s, eta=8:2:29\n",
      "2022-01-20 10:38:47 [INFO]\t[TRAIN] Epoch=4/50, Step=262/478, loss=0.071197, lr=0.094285, time_each_step=1.29s, eta=8:2:13\n",
      "2022-01-20 10:38:49 [INFO]\t[TRAIN] Epoch=4/50, Step=264/478, loss=0.077380, lr=0.094278, time_each_step=1.29s, eta=8:2:7\n",
      "2022-01-20 10:38:52 [INFO]\t[TRAIN] Epoch=4/50, Step=266/478, loss=0.073597, lr=0.094271, time_each_step=1.29s, eta=8:1:33\n",
      "2022-01-20 10:38:54 [INFO]\t[TRAIN] Epoch=4/50, Step=268/478, loss=0.091421, lr=0.094265, time_each_step=1.29s, eta=8:1:25\n",
      "2022-01-20 10:38:57 [INFO]\t[TRAIN] Epoch=4/50, Step=270/478, loss=0.078008, lr=0.094258, time_each_step=1.29s, eta=8:1:25\n",
      "2022-01-20 10:39:00 [INFO]\t[TRAIN] Epoch=4/50, Step=272/478, loss=0.101651, lr=0.094251, time_each_step=1.29s, eta=8:1:55\n",
      "2022-01-20 10:39:02 [INFO]\t[TRAIN] Epoch=4/50, Step=274/478, loss=0.078124, lr=0.094244, time_each_step=1.29s, eta=8:1:45\n",
      "2022-01-20 10:39:05 [INFO]\t[TRAIN] Epoch=4/50, Step=276/478, loss=0.075807, lr=0.094237, time_each_step=1.29s, eta=8:2:4\n",
      "2022-01-20 10:39:07 [INFO]\t[TRAIN] Epoch=4/50, Step=278/478, loss=0.082360, lr=0.094231, time_each_step=1.29s, eta=8:1:49\n",
      "2022-01-20 10:39:10 [INFO]\t[TRAIN] Epoch=4/50, Step=280/478, loss=0.085395, lr=0.094224, time_each_step=1.29s, eta=8:1:33\n",
      "2022-01-20 10:39:12 [INFO]\t[TRAIN] Epoch=4/50, Step=282/478, loss=0.065623, lr=0.094217, time_each_step=1.29s, eta=8:1:9\n",
      "2022-01-20 10:39:15 [INFO]\t[TRAIN] Epoch=4/50, Step=284/478, loss=0.076240, lr=0.094210, time_each_step=1.29s, eta=8:1:34\n",
      "2022-01-20 10:39:18 [INFO]\t[TRAIN] Epoch=4/50, Step=286/478, loss=0.149711, lr=0.094203, time_each_step=1.29s, eta=8:0:36\n",
      "2022-01-20 10:39:20 [INFO]\t[TRAIN] Epoch=4/50, Step=288/478, loss=0.111819, lr=0.094197, time_each_step=1.29s, eta=8:1:44\n",
      "2022-01-20 10:39:23 [INFO]\t[TRAIN] Epoch=4/50, Step=290/478, loss=0.083427, lr=0.094190, time_each_step=1.29s, eta=8:2:45\n",
      "2022-01-20 10:39:25 [INFO]\t[TRAIN] Epoch=4/50, Step=292/478, loss=0.083288, lr=0.094183, time_each_step=1.29s, eta=8:0:29\n",
      "2022-01-20 10:39:28 [INFO]\t[TRAIN] Epoch=4/50, Step=294/478, loss=0.066050, lr=0.094176, time_each_step=1.29s, eta=8:1:47\n",
      "2022-01-20 10:39:30 [INFO]\t[TRAIN] Epoch=4/50, Step=296/478, loss=0.089671, lr=0.094169, time_each_step=1.29s, eta=8:1:25\n",
      "2022-01-20 10:39:33 [INFO]\t[TRAIN] Epoch=4/50, Step=298/478, loss=0.082720, lr=0.094163, time_each_step=1.29s, eta=8:0:34\n",
      "2022-01-20 10:39:36 [INFO]\t[TRAIN] Epoch=4/50, Step=300/478, loss=0.079069, lr=0.094156, time_each_step=1.29s, eta=8:1:27\n",
      "2022-01-20 10:39:38 [INFO]\t[TRAIN] Epoch=4/50, Step=302/478, loss=0.095645, lr=0.094149, time_each_step=1.29s, eta=8:1:4\n",
      "2022-01-20 10:39:41 [INFO]\t[TRAIN] Epoch=4/50, Step=304/478, loss=0.055181, lr=0.094142, time_each_step=1.28s, eta=8:0:0\n",
      "2022-01-20 10:39:43 [INFO]\t[TRAIN] Epoch=4/50, Step=306/478, loss=0.060400, lr=0.094135, time_each_step=1.29s, eta=8:1:33\n",
      "2022-01-20 10:39:46 [INFO]\t[TRAIN] Epoch=4/50, Step=308/478, loss=0.121232, lr=0.094129, time_each_step=1.28s, eta=7:59:52\n",
      "2022-01-20 10:39:48 [INFO]\t[TRAIN] Epoch=4/50, Step=310/478, loss=0.077633, lr=0.094122, time_each_step=1.29s, eta=8:0:40\n",
      "2022-01-20 10:39:51 [INFO]\t[TRAIN] Epoch=4/50, Step=312/478, loss=0.087380, lr=0.094115, time_each_step=1.29s, eta=8:0:2\n",
      "2022-01-20 10:39:54 [INFO]\t[TRAIN] Epoch=4/50, Step=314/478, loss=0.073867, lr=0.094108, time_each_step=1.29s, eta=8:0:10\n",
      "2022-01-20 10:39:56 [INFO]\t[TRAIN] Epoch=4/50, Step=316/478, loss=0.068270, lr=0.094101, time_each_step=1.29s, eta=8:1:10\n",
      "2022-01-20 10:39:59 [INFO]\t[TRAIN] Epoch=4/50, Step=318/478, loss=0.085294, lr=0.094095, time_each_step=1.29s, eta=8:2:59\n",
      "2022-01-20 10:40:01 [INFO]\t[TRAIN] Epoch=4/50, Step=320/478, loss=0.076515, lr=0.094088, time_each_step=1.28s, eta=7:59:37\n",
      "2022-01-20 10:40:04 [INFO]\t[TRAIN] Epoch=4/50, Step=322/478, loss=0.085600, lr=0.094081, time_each_step=1.29s, eta=8:0:26\n",
      "2022-01-20 10:40:07 [INFO]\t[TRAIN] Epoch=4/50, Step=324/478, loss=0.113592, lr=0.094074, time_each_step=1.29s, eta=8:1:19\n",
      "2022-01-20 10:40:09 [INFO]\t[TRAIN] Epoch=4/50, Step=326/478, loss=0.092386, lr=0.094067, time_each_step=1.28s, eta=7:59:24\n",
      "2022-01-20 10:40:12 [INFO]\t[TRAIN] Epoch=4/50, Step=328/478, loss=0.076037, lr=0.094061, time_each_step=1.29s, eta=8:0:44\n",
      "2022-01-20 10:40:14 [INFO]\t[TRAIN] Epoch=4/50, Step=330/478, loss=0.077547, lr=0.094054, time_each_step=1.29s, eta=8:1:17\n",
      "2022-01-20 10:40:17 [INFO]\t[TRAIN] Epoch=4/50, Step=332/478, loss=0.095719, lr=0.094047, time_each_step=1.29s, eta=8:0:33\n",
      "2022-01-20 10:40:19 [INFO]\t[TRAIN] Epoch=4/50, Step=334/478, loss=0.061826, lr=0.094040, time_each_step=1.29s, eta=8:0:40\n",
      "2022-01-20 10:40:22 [INFO]\t[TRAIN] Epoch=4/50, Step=336/478, loss=0.075250, lr=0.094033, time_each_step=1.29s, eta=8:0:21\n",
      "2022-01-20 10:40:25 [INFO]\t[TRAIN] Epoch=4/50, Step=338/478, loss=0.091392, lr=0.094027, time_each_step=1.29s, eta=8:0:8\n",
      "2022-01-20 10:40:27 [INFO]\t[TRAIN] Epoch=4/50, Step=340/478, loss=0.086256, lr=0.094020, time_each_step=1.29s, eta=8:1:35\n",
      "2022-01-20 10:40:30 [INFO]\t[TRAIN] Epoch=4/50, Step=342/478, loss=0.081427, lr=0.094013, time_each_step=1.29s, eta=7:59:25\n",
      "2022-01-20 10:40:32 [INFO]\t[TRAIN] Epoch=4/50, Step=344/478, loss=0.065509, lr=0.094006, time_each_step=1.29s, eta=8:0:8\n",
      "2022-01-20 10:40:35 [INFO]\t[TRAIN] Epoch=4/50, Step=346/478, loss=0.058247, lr=0.093999, time_each_step=1.29s, eta=8:1:24\n",
      "2022-01-20 10:40:37 [INFO]\t[TRAIN] Epoch=4/50, Step=348/478, loss=0.063321, lr=0.093993, time_each_step=1.29s, eta=7:59:5\n",
      "2022-01-20 10:40:40 [INFO]\t[TRAIN] Epoch=4/50, Step=350/478, loss=0.068498, lr=0.093986, time_each_step=1.29s, eta=8:0:4\n",
      "2022-01-20 10:40:43 [INFO]\t[TRAIN] Epoch=4/50, Step=352/478, loss=0.073608, lr=0.093979, time_each_step=1.29s, eta=8:1:3\n",
      "2022-01-20 10:40:45 [INFO]\t[TRAIN] Epoch=4/50, Step=354/478, loss=0.080072, lr=0.093972, time_each_step=1.28s, eta=7:58:16\n",
      "2022-01-20 10:40:48 [INFO]\t[TRAIN] Epoch=4/50, Step=356/478, loss=0.084124, lr=0.093965, time_each_step=1.29s, eta=8:0:42\n",
      "2022-01-20 10:40:50 [INFO]\t[TRAIN] Epoch=4/50, Step=358/478, loss=0.079956, lr=0.093959, time_each_step=1.29s, eta=8:0:16\n",
      "2022-01-20 10:40:53 [INFO]\t[TRAIN] Epoch=4/50, Step=360/478, loss=0.077887, lr=0.093952, time_each_step=1.29s, eta=7:59:46\n",
      "2022-01-20 10:40:55 [INFO]\t[TRAIN] Epoch=4/50, Step=362/478, loss=0.086176, lr=0.093945, time_each_step=1.29s, eta=8:0:20\n",
      "2022-01-20 10:40:58 [INFO]\t[TRAIN] Epoch=4/50, Step=364/478, loss=0.062797, lr=0.093938, time_each_step=1.29s, eta=7:59:22\n",
      "2022-01-20 10:41:01 [INFO]\t[TRAIN] Epoch=4/50, Step=366/478, loss=0.092939, lr=0.093931, time_each_step=1.29s, eta=7:59:19\n",
      "2022-01-20 10:41:03 [INFO]\t[TRAIN] Epoch=4/50, Step=368/478, loss=0.053056, lr=0.093925, time_each_step=1.29s, eta=8:0:11\n",
      "2022-01-20 10:41:06 [INFO]\t[TRAIN] Epoch=4/50, Step=370/478, loss=0.105387, lr=0.093918, time_each_step=1.29s, eta=7:58:58\n",
      "2022-01-20 10:41:08 [INFO]\t[TRAIN] Epoch=4/50, Step=372/478, loss=0.070398, lr=0.093911, time_each_step=1.29s, eta=7:59:35\n",
      "2022-01-20 10:41:11 [INFO]\t[TRAIN] Epoch=4/50, Step=374/478, loss=0.082107, lr=0.093904, time_each_step=1.29s, eta=7:59:2\n",
      "2022-01-20 10:41:13 [INFO]\t[TRAIN] Epoch=4/50, Step=376/478, loss=0.085754, lr=0.093897, time_each_step=1.29s, eta=7:58:53\n",
      "2022-01-20 10:41:16 [INFO]\t[TRAIN] Epoch=4/50, Step=378/478, loss=0.072342, lr=0.093891, time_each_step=1.29s, eta=7:59:40\n",
      "2022-01-20 10:41:19 [INFO]\t[TRAIN] Epoch=4/50, Step=380/478, loss=0.102023, lr=0.093884, time_each_step=1.29s, eta=8:1:13\n",
      "2022-01-20 10:41:21 [INFO]\t[TRAIN] Epoch=4/50, Step=382/478, loss=0.095192, lr=0.093877, time_each_step=1.29s, eta=7:58:47\n",
      "2022-01-20 10:41:24 [INFO]\t[TRAIN] Epoch=4/50, Step=384/478, loss=0.063351, lr=0.093870, time_each_step=1.29s, eta=7:58:39\n",
      "2022-01-20 10:41:26 [INFO]\t[TRAIN] Epoch=4/50, Step=386/478, loss=0.085516, lr=0.093863, time_each_step=1.29s, eta=7:58:54\n",
      "2022-01-20 10:41:29 [INFO]\t[TRAIN] Epoch=4/50, Step=388/478, loss=0.052256, lr=0.093857, time_each_step=1.29s, eta=7:58:38\n",
      "2022-01-20 10:41:31 [INFO]\t[TRAIN] Epoch=4/50, Step=390/478, loss=0.078238, lr=0.093850, time_each_step=1.28s, eta=7:57:42\n",
      "2022-01-20 10:41:34 [INFO]\t[TRAIN] Epoch=4/50, Step=392/478, loss=0.097340, lr=0.093843, time_each_step=1.29s, eta=7:58:14\n",
      "2022-01-20 10:41:37 [INFO]\t[TRAIN] Epoch=4/50, Step=394/478, loss=0.091440, lr=0.093836, time_each_step=1.28s, eta=7:57:35\n",
      "2022-01-20 10:41:39 [INFO]\t[TRAIN] Epoch=4/50, Step=396/478, loss=0.133886, lr=0.093829, time_each_step=1.29s, eta=7:58:16\n",
      "2022-01-20 10:41:42 [INFO]\t[TRAIN] Epoch=4/50, Step=398/478, loss=0.103555, lr=0.093823, time_each_step=1.29s, eta=7:59:32\n",
      "2022-01-20 10:41:44 [INFO]\t[TRAIN] Epoch=4/50, Step=400/478, loss=0.100850, lr=0.093816, time_each_step=1.29s, eta=7:58:5\n",
      "2022-01-20 10:41:47 [INFO]\t[TRAIN] Epoch=4/50, Step=402/478, loss=0.088714, lr=0.093809, time_each_step=1.29s, eta=7:58:30\n",
      "2022-01-20 10:41:50 [INFO]\t[TRAIN] Epoch=4/50, Step=404/478, loss=0.092527, lr=0.093802, time_each_step=1.29s, eta=7:59:16\n",
      "2022-01-20 10:41:52 [INFO]\t[TRAIN] Epoch=4/50, Step=406/478, loss=0.084940, lr=0.093795, time_each_step=1.28s, eta=7:57:26\n",
      "2022-01-20 10:41:55 [INFO]\t[TRAIN] Epoch=4/50, Step=408/478, loss=0.053212, lr=0.093789, time_each_step=1.29s, eta=7:59:5\n",
      "2022-01-20 10:41:57 [INFO]\t[TRAIN] Epoch=4/50, Step=410/478, loss=0.095250, lr=0.093782, time_each_step=1.29s, eta=7:59:52\n",
      "2022-01-20 10:42:00 [INFO]\t[TRAIN] Epoch=4/50, Step=412/478, loss=0.067583, lr=0.093775, time_each_step=1.29s, eta=7:59:23\n",
      "2022-01-20 10:42:02 [INFO]\t[TRAIN] Epoch=4/50, Step=414/478, loss=0.115010, lr=0.093768, time_each_step=1.29s, eta=7:59:19\n",
      "2022-01-20 10:42:05 [INFO]\t[TRAIN] Epoch=4/50, Step=416/478, loss=0.070623, lr=0.093761, time_each_step=1.29s, eta=7:58:41\n",
      "2022-01-20 10:42:08 [INFO]\t[TRAIN] Epoch=4/50, Step=418/478, loss=0.079907, lr=0.093755, time_each_step=1.28s, eta=7:57:29\n",
      "2022-01-20 10:42:10 [INFO]\t[TRAIN] Epoch=4/50, Step=420/478, loss=0.139794, lr=0.093748, time_each_step=1.29s, eta=7:59:5\n",
      "2022-01-20 10:42:13 [INFO]\t[TRAIN] Epoch=4/50, Step=422/478, loss=0.111316, lr=0.093741, time_each_step=1.28s, eta=7:57:7\n",
      "2022-01-20 10:42:15 [INFO]\t[TRAIN] Epoch=4/50, Step=424/478, loss=0.088919, lr=0.093734, time_each_step=1.29s, eta=7:57:35\n",
      "2022-01-20 10:42:18 [INFO]\t[TRAIN] Epoch=4/50, Step=426/478, loss=0.046848, lr=0.093727, time_each_step=1.29s, eta=7:58:14\n",
      "2022-01-20 10:42:20 [INFO]\t[TRAIN] Epoch=4/50, Step=428/478, loss=0.085083, lr=0.093721, time_each_step=1.29s, eta=7:57:53\n",
      "2022-01-20 10:42:23 [INFO]\t[TRAIN] Epoch=4/50, Step=430/478, loss=0.121767, lr=0.093714, time_each_step=1.29s, eta=7:58:28\n",
      "2022-01-20 10:42:26 [INFO]\t[TRAIN] Epoch=4/50, Step=432/478, loss=0.072183, lr=0.093707, time_each_step=1.29s, eta=7:58:14\n",
      "2022-01-20 10:42:28 [INFO]\t[TRAIN] Epoch=4/50, Step=434/478, loss=0.090579, lr=0.093700, time_each_step=1.29s, eta=7:58:40\n",
      "2022-01-20 10:42:31 [INFO]\t[TRAIN] Epoch=4/50, Step=436/478, loss=0.080574, lr=0.093693, time_each_step=1.29s, eta=7:57:24\n",
      "2022-01-20 10:42:33 [INFO]\t[TRAIN] Epoch=4/50, Step=438/478, loss=0.115854, lr=0.093687, time_each_step=1.29s, eta=7:58:44\n",
      "2022-01-20 10:42:36 [INFO]\t[TRAIN] Epoch=4/50, Step=440/478, loss=0.084317, lr=0.093680, time_each_step=1.29s, eta=7:57:43\n",
      "2022-01-20 10:42:38 [INFO]\t[TRAIN] Epoch=4/50, Step=442/478, loss=0.070679, lr=0.093673, time_each_step=1.29s, eta=7:57:39\n",
      "2022-01-20 10:42:41 [INFO]\t[TRAIN] Epoch=4/50, Step=444/478, loss=0.089380, lr=0.093666, time_each_step=1.29s, eta=7:58:16\n",
      "2022-01-20 10:42:44 [INFO]\t[TRAIN] Epoch=4/50, Step=446/478, loss=0.087118, lr=0.093659, time_each_step=1.29s, eta=7:57:49\n",
      "2022-01-20 10:42:46 [INFO]\t[TRAIN] Epoch=4/50, Step=448/478, loss=0.081687, lr=0.093653, time_each_step=1.28s, eta=7:55:59\n",
      "2022-01-20 10:42:49 [INFO]\t[TRAIN] Epoch=4/50, Step=450/478, loss=0.086367, lr=0.093646, time_each_step=1.29s, eta=7:57:37\n",
      "2022-01-20 10:42:51 [INFO]\t[TRAIN] Epoch=4/50, Step=452/478, loss=0.104314, lr=0.093639, time_each_step=1.29s, eta=7:57:16\n",
      "2022-01-20 10:42:54 [INFO]\t[TRAIN] Epoch=4/50, Step=454/478, loss=0.090520, lr=0.093632, time_each_step=1.29s, eta=7:57:14\n",
      "2022-01-20 10:42:56 [INFO]\t[TRAIN] Epoch=4/50, Step=456/478, loss=0.071760, lr=0.093625, time_each_step=1.29s, eta=7:56:49\n",
      "2022-01-20 10:42:59 [INFO]\t[TRAIN] Epoch=4/50, Step=458/478, loss=0.116491, lr=0.093619, time_each_step=1.28s, eta=7:56:34\n",
      "2022-01-20 10:43:02 [INFO]\t[TRAIN] Epoch=4/50, Step=460/478, loss=0.076325, lr=0.093612, time_each_step=1.28s, eta=7:56:12\n",
      "2022-01-20 10:43:04 [INFO]\t[TRAIN] Epoch=4/50, Step=462/478, loss=0.073617, lr=0.093605, time_each_step=1.29s, eta=7:57:4\n",
      "2022-01-20 10:43:07 [INFO]\t[TRAIN] Epoch=4/50, Step=464/478, loss=0.115423, lr=0.093598, time_each_step=1.29s, eta=7:56:55\n",
      "2022-01-20 10:43:09 [INFO]\t[TRAIN] Epoch=4/50, Step=466/478, loss=0.093003, lr=0.093591, time_each_step=1.29s, eta=7:56:41\n",
      "2022-01-20 10:43:12 [INFO]\t[TRAIN] Epoch=4/50, Step=468/478, loss=0.065901, lr=0.093585, time_each_step=1.29s, eta=7:57:20\n",
      "2022-01-20 10:43:14 [INFO]\t[TRAIN] Epoch=4/50, Step=470/478, loss=0.101648, lr=0.093578, time_each_step=1.29s, eta=7:57:35\n",
      "2022-01-20 10:43:17 [INFO]\t[TRAIN] Epoch=4/50, Step=472/478, loss=0.102300, lr=0.093571, time_each_step=1.29s, eta=7:56:47\n",
      "2022-01-20 10:43:20 [INFO]\t[TRAIN] Epoch=4/50, Step=474/478, loss=0.107676, lr=0.093564, time_each_step=1.29s, eta=7:58:4\n",
      "2022-01-20 10:43:22 [INFO]\t[TRAIN] Epoch=4/50, Step=476/478, loss=0.083005, lr=0.093557, time_each_step=1.28s, eta=7:55:35\n",
      "2022-01-20 10:43:25 [INFO]\t[TRAIN] Epoch=4/50, Step=478/478, loss=0.073455, lr=0.093550, time_each_step=1.28s, eta=7:55:20\n",
      "2022-01-20 10:43:25 [INFO]\t[TRAIN] Epoch 4 finished, loss=0.088018194 .\n",
      "2022-01-20 10:43:25 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-01-20 10:43:25 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-01-20 10:43:31 [INFO]\t[EVAL] Finished, Epoch=4, miou=0.814006, category_iou=[0.9689098 0.6994233 0.7736849], oacc=0.970330, category_acc=[0.9856591 0.8365019 0.8569013], kappa=0.856336, category_F1-score=[0.98420949 0.82313021 0.87240403] .\n",
      "2022-01-20 10:43:32 [INFO]\tModel saved in model/deeplab_augument_alldata2/best_model.\n",
      "2022-01-20 10:43:32 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_4, miou=0.8140060305595398\n",
      "2022-01-20 10:43:32 [INFO]\tModel saved in model/deeplab_augument_alldata2/epoch_4.\n",
      "2022-01-20 10:43:36 [INFO]\t[TRAIN] Epoch=5/50, Step=2/478, loss=0.060434, lr=0.093544, time_each_step=2.01s, eta=12:22:40\n",
      "2022-01-20 10:43:39 [INFO]\t[TRAIN] Epoch=5/50, Step=4/478, loss=0.088538, lr=0.093537, time_each_step=1.28s, eta=7:55:43\n",
      "2022-01-20 10:43:41 [INFO]\t[TRAIN] Epoch=5/50, Step=6/478, loss=0.095341, lr=0.093530, time_each_step=1.28s, eta=7:55:25\n",
      "2022-01-20 10:43:44 [INFO]\t[TRAIN] Epoch=5/50, Step=8/478, loss=0.080075, lr=0.093523, time_each_step=1.28s, eta=7:55:47\n",
      "2022-01-20 10:43:47 [INFO]\t[TRAIN] Epoch=5/50, Step=10/478, loss=0.100282, lr=0.093516, time_each_step=1.29s, eta=7:56:29\n",
      "2022-01-20 10:43:49 [INFO]\t[TRAIN] Epoch=5/50, Step=12/478, loss=0.075412, lr=0.093510, time_each_step=1.28s, eta=7:55:41\n",
      "2022-01-20 10:43:52 [INFO]\t[TRAIN] Epoch=5/50, Step=14/478, loss=0.079676, lr=0.093503, time_each_step=1.28s, eta=7:55:21\n",
      "2022-01-20 10:43:54 [INFO]\t[TRAIN] Epoch=5/50, Step=16/478, loss=0.080039, lr=0.093496, time_each_step=1.29s, eta=7:56:9\n",
      "2022-01-20 10:43:57 [INFO]\t[TRAIN] Epoch=5/50, Step=18/478, loss=0.088118, lr=0.093489, time_each_step=1.28s, eta=7:55:1\n",
      "2022-01-20 10:43:59 [INFO]\t[TRAIN] Epoch=5/50, Step=20/478, loss=0.088128, lr=0.093482, time_each_step=1.29s, eta=7:56:42\n",
      "2022-01-20 10:44:02 [INFO]\t[TRAIN] Epoch=5/50, Step=22/478, loss=0.158573, lr=0.093476, time_each_step=1.29s, eta=7:57:16\n",
      "2022-01-20 10:44:05 [INFO]\t[TRAIN] Epoch=5/50, Step=24/478, loss=0.096778, lr=0.093469, time_each_step=1.28s, eta=7:54:46\n",
      "2022-01-20 10:44:07 [INFO]\t[TRAIN] Epoch=5/50, Step=26/478, loss=0.075962, lr=0.093462, time_each_step=1.29s, eta=7:57:18\n",
      "2022-01-20 10:44:10 [INFO]\t[TRAIN] Epoch=5/50, Step=28/478, loss=0.080539, lr=0.093455, time_each_step=1.29s, eta=7:56:47\n",
      "2022-01-20 10:44:12 [INFO]\t[TRAIN] Epoch=5/50, Step=30/478, loss=0.093366, lr=0.093448, time_each_step=1.28s, eta=7:55:8\n",
      "2022-01-20 10:44:15 [INFO]\t[TRAIN] Epoch=5/50, Step=32/478, loss=0.074322, lr=0.093442, time_each_step=1.29s, eta=7:56:26\n",
      "2022-01-20 10:44:17 [INFO]\t[TRAIN] Epoch=5/50, Step=34/478, loss=0.086866, lr=0.093435, time_each_step=1.29s, eta=7:56:11\n",
      "2022-01-20 10:44:20 [INFO]\t[TRAIN] Epoch=5/50, Step=36/478, loss=0.085382, lr=0.093428, time_each_step=1.29s, eta=7:56:20\n",
      "2022-01-20 10:44:23 [INFO]\t[TRAIN] Epoch=5/50, Step=38/478, loss=0.090590, lr=0.093421, time_each_step=1.29s, eta=7:56:10\n",
      "2022-01-20 10:44:25 [INFO]\t[TRAIN] Epoch=5/50, Step=40/478, loss=0.094653, lr=0.093414, time_each_step=1.29s, eta=7:55:43\n",
      "2022-01-20 10:44:28 [INFO]\t[TRAIN] Epoch=5/50, Step=42/478, loss=0.057056, lr=0.093408, time_each_step=1.29s, eta=7:55:16\n",
      "2022-01-20 10:44:30 [INFO]\t[TRAIN] Epoch=5/50, Step=44/478, loss=0.081187, lr=0.093401, time_each_step=1.29s, eta=7:56:5\n",
      "2022-01-20 10:44:33 [INFO]\t[TRAIN] Epoch=5/50, Step=46/478, loss=0.085285, lr=0.093394, time_each_step=1.29s, eta=7:55:34\n",
      "2022-01-20 10:44:35 [INFO]\t[TRAIN] Epoch=5/50, Step=48/478, loss=0.088717, lr=0.093387, time_each_step=1.28s, eta=7:54:29\n",
      "2022-01-20 10:44:38 [INFO]\t[TRAIN] Epoch=5/50, Step=50/478, loss=0.118306, lr=0.093380, time_each_step=1.29s, eta=7:56:11\n",
      "2022-01-20 10:44:41 [INFO]\t[TRAIN] Epoch=5/50, Step=52/478, loss=0.103281, lr=0.093373, time_each_step=1.29s, eta=7:55:12\n",
      "2022-01-20 10:44:43 [INFO]\t[TRAIN] Epoch=5/50, Step=54/478, loss=0.096641, lr=0.093367, time_each_step=1.29s, eta=7:55:13\n",
      "2022-01-20 10:44:46 [INFO]\t[TRAIN] Epoch=5/50, Step=56/478, loss=0.082260, lr=0.093360, time_each_step=1.29s, eta=7:55:22\n",
      "2022-01-20 10:44:48 [INFO]\t[TRAIN] Epoch=5/50, Step=58/478, loss=0.075947, lr=0.093353, time_each_step=1.28s, eta=7:54:31\n",
      "2022-01-20 10:44:51 [INFO]\t[TRAIN] Epoch=5/50, Step=60/478, loss=0.089117, lr=0.093346, time_each_step=1.29s, eta=7:55:19\n",
      "2022-01-20 10:44:54 [INFO]\t[TRAIN] Epoch=5/50, Step=62/478, loss=0.071973, lr=0.093339, time_each_step=1.29s, eta=7:56:30\n",
      "2022-01-20 10:44:56 [INFO]\t[TRAIN] Epoch=5/50, Step=64/478, loss=0.099414, lr=0.093333, time_each_step=1.28s, eta=7:54:24\n",
      "2022-01-20 10:44:59 [INFO]\t[TRAIN] Epoch=5/50, Step=66/478, loss=0.100396, lr=0.093326, time_each_step=1.29s, eta=7:55:8\n",
      "2022-01-20 10:45:01 [INFO]\t[TRAIN] Epoch=5/50, Step=68/478, loss=0.075844, lr=0.093319, time_each_step=1.29s, eta=7:55:3\n",
      "2022-01-20 10:45:04 [INFO]\t[TRAIN] Epoch=5/50, Step=70/478, loss=0.077670, lr=0.093312, time_each_step=1.29s, eta=7:55:3\n",
      "2022-01-20 10:45:06 [INFO]\t[TRAIN] Epoch=5/50, Step=72/478, loss=0.106247, lr=0.093305, time_each_step=1.29s, eta=7:55:10\n",
      "2022-01-20 10:45:09 [INFO]\t[TRAIN] Epoch=5/50, Step=74/478, loss=0.101980, lr=0.093299, time_each_step=1.29s, eta=7:55:18\n",
      "2022-01-20 10:45:12 [INFO]\t[TRAIN] Epoch=5/50, Step=76/478, loss=0.078104, lr=0.093292, time_each_step=1.29s, eta=7:55:12\n",
      "2022-01-20 10:45:14 [INFO]\t[TRAIN] Epoch=5/50, Step=78/478, loss=0.061137, lr=0.093285, time_each_step=1.29s, eta=7:54:32\n",
      "2022-01-20 10:45:17 [INFO]\t[TRAIN] Epoch=5/50, Step=80/478, loss=0.128124, lr=0.093278, time_each_step=1.29s, eta=7:55:26\n",
      "2022-01-20 10:45:19 [INFO]\t[TRAIN] Epoch=5/50, Step=82/478, loss=0.074927, lr=0.093271, time_each_step=1.29s, eta=7:54:24\n",
      "2022-01-20 10:45:22 [INFO]\t[TRAIN] Epoch=5/50, Step=84/478, loss=0.138971, lr=0.093264, time_each_step=1.28s, eta=7:54:6\n",
      "2022-01-20 10:45:24 [INFO]\t[TRAIN] Epoch=5/50, Step=86/478, loss=0.071128, lr=0.093258, time_each_step=1.29s, eta=7:55:25\n",
      "2022-01-20 10:45:27 [INFO]\t[TRAIN] Epoch=5/50, Step=88/478, loss=0.077502, lr=0.093251, time_each_step=1.29s, eta=7:54:29\n",
      "2022-01-20 10:45:30 [INFO]\t[TRAIN] Epoch=5/50, Step=90/478, loss=0.050692, lr=0.093244, time_each_step=1.29s, eta=7:54:14\n",
      "2022-01-20 10:45:32 [INFO]\t[TRAIN] Epoch=5/50, Step=92/478, loss=0.076042, lr=0.093237, time_each_step=1.29s, eta=7:55:7\n",
      "2022-01-20 10:45:35 [INFO]\t[TRAIN] Epoch=5/50, Step=94/478, loss=0.075527, lr=0.093230, time_each_step=1.28s, eta=7:53:42\n",
      "2022-01-20 10:45:37 [INFO]\t[TRAIN] Epoch=5/50, Step=96/478, loss=0.073523, lr=0.093224, time_each_step=1.29s, eta=7:55:2\n",
      "2022-01-20 10:45:40 [INFO]\t[TRAIN] Epoch=5/50, Step=98/478, loss=0.090551, lr=0.093217, time_each_step=1.29s, eta=7:54:39\n",
      "2022-01-20 10:45:42 [INFO]\t[TRAIN] Epoch=5/50, Step=100/478, loss=0.053901, lr=0.093210, time_each_step=1.28s, eta=7:53:54\n",
      "2022-01-20 10:45:45 [INFO]\t[TRAIN] Epoch=5/50, Step=102/478, loss=0.076357, lr=0.093203, time_each_step=1.29s, eta=7:53:58\n",
      "2022-01-20 10:45:48 [INFO]\t[TRAIN] Epoch=5/50, Step=104/478, loss=0.075262, lr=0.093196, time_each_step=1.29s, eta=7:55:15\n",
      "2022-01-20 10:45:50 [INFO]\t[TRAIN] Epoch=5/50, Step=106/478, loss=0.092918, lr=0.093190, time_each_step=1.29s, eta=7:55:41\n",
      "2022-01-20 10:45:53 [INFO]\t[TRAIN] Epoch=5/50, Step=108/478, loss=0.083072, lr=0.093183, time_each_step=1.29s, eta=7:54:39\n",
      "2022-01-20 10:45:55 [INFO]\t[TRAIN] Epoch=5/50, Step=110/478, loss=0.134701, lr=0.093176, time_each_step=1.29s, eta=7:55:20\n",
      "2022-01-20 10:45:58 [INFO]\t[TRAIN] Epoch=5/50, Step=112/478, loss=0.094115, lr=0.093169, time_each_step=1.29s, eta=7:54:35\n",
      "2022-01-20 10:46:00 [INFO]\t[TRAIN] Epoch=5/50, Step=114/478, loss=0.066366, lr=0.093162, time_each_step=1.29s, eta=7:54:16\n",
      "2022-01-20 10:46:03 [INFO]\t[TRAIN] Epoch=5/50, Step=116/478, loss=0.084276, lr=0.093155, time_each_step=1.29s, eta=7:54:33\n",
      "2022-01-20 10:46:06 [INFO]\t[TRAIN] Epoch=5/50, Step=118/478, loss=0.079314, lr=0.093149, time_each_step=1.28s, eta=7:52:59\n",
      "2022-01-20 10:46:08 [INFO]\t[TRAIN] Epoch=5/50, Step=120/478, loss=0.075670, lr=0.093142, time_each_step=1.28s, eta=7:53:20\n",
      "2022-01-20 10:46:11 [INFO]\t[TRAIN] Epoch=5/50, Step=122/478, loss=0.079500, lr=0.093135, time_each_step=1.29s, eta=7:53:35\n",
      "2022-01-20 10:46:13 [INFO]\t[TRAIN] Epoch=5/50, Step=124/478, loss=0.073401, lr=0.093128, time_each_step=1.29s, eta=7:53:34\n",
      "2022-01-20 10:46:16 [INFO]\t[TRAIN] Epoch=5/50, Step=126/478, loss=0.090518, lr=0.093121, time_each_step=1.29s, eta=7:53:53\n",
      "2022-01-20 10:46:18 [INFO]\t[TRAIN] Epoch=5/50, Step=128/478, loss=0.087911, lr=0.093115, time_each_step=1.29s, eta=7:53:37\n",
      "2022-01-20 10:46:21 [INFO]\t[TRAIN] Epoch=5/50, Step=130/478, loss=0.097337, lr=0.093108, time_each_step=1.28s, eta=7:52:58\n",
      "2022-01-20 10:46:24 [INFO]\t[TRAIN] Epoch=5/50, Step=132/478, loss=0.090898, lr=0.093101, time_each_step=1.29s, eta=7:53:46\n",
      "2022-01-20 10:46:26 [INFO]\t[TRAIN] Epoch=5/50, Step=134/478, loss=0.088633, lr=0.093094, time_each_step=1.29s, eta=7:53:42\n",
      "2022-01-20 10:46:29 [INFO]\t[TRAIN] Epoch=5/50, Step=136/478, loss=0.101231, lr=0.093087, time_each_step=1.29s, eta=7:53:34\n",
      "2022-01-20 10:46:31 [INFO]\t[TRAIN] Epoch=5/50, Step=138/478, loss=0.062921, lr=0.093081, time_each_step=1.28s, eta=7:52:57\n",
      "2022-01-20 10:46:34 [INFO]\t[TRAIN] Epoch=5/50, Step=140/478, loss=0.101237, lr=0.093074, time_each_step=1.29s, eta=7:55:20\n",
      "2022-01-20 10:46:36 [INFO]\t[TRAIN] Epoch=5/50, Step=142/478, loss=0.054622, lr=0.093067, time_each_step=1.28s, eta=7:52:46\n",
      "2022-01-20 10:46:39 [INFO]\t[TRAIN] Epoch=5/50, Step=144/478, loss=0.099382, lr=0.093060, time_each_step=1.29s, eta=7:53:42\n",
      "2022-01-20 10:46:42 [INFO]\t[TRAIN] Epoch=5/50, Step=146/478, loss=0.065299, lr=0.093053, time_each_step=1.29s, eta=7:54:24\n",
      "2022-01-20 10:46:44 [INFO]\t[TRAIN] Epoch=5/50, Step=148/478, loss=0.051651, lr=0.093046, time_each_step=1.28s, eta=7:52:14\n",
      "2022-01-20 10:46:47 [INFO]\t[TRAIN] Epoch=5/50, Step=150/478, loss=0.095894, lr=0.093040, time_each_step=1.29s, eta=7:53:10\n",
      "2022-01-20 10:46:49 [INFO]\t[TRAIN] Epoch=5/50, Step=152/478, loss=0.088957, lr=0.093033, time_each_step=1.29s, eta=7:54:17\n",
      "2022-01-20 10:46:52 [INFO]\t[TRAIN] Epoch=5/50, Step=154/478, loss=0.121120, lr=0.093026, time_each_step=1.29s, eta=7:52:52\n",
      "2022-01-20 10:46:54 [INFO]\t[TRAIN] Epoch=5/50, Step=156/478, loss=0.117330, lr=0.093019, time_each_step=1.29s, eta=7:54:8\n",
      "2022-01-20 10:46:57 [INFO]\t[TRAIN] Epoch=5/50, Step=158/478, loss=0.070888, lr=0.093012, time_each_step=1.29s, eta=7:53:53\n",
      "2022-01-20 10:47:00 [INFO]\t[TRAIN] Epoch=5/50, Step=160/478, loss=0.081083, lr=0.093006, time_each_step=1.29s, eta=7:53:50\n",
      "2022-01-20 10:47:02 [INFO]\t[TRAIN] Epoch=5/50, Step=162/478, loss=0.099488, lr=0.092999, time_each_step=1.29s, eta=7:53:5\n",
      "2022-01-20 10:47:05 [INFO]\t[TRAIN] Epoch=5/50, Step=164/478, loss=0.096716, lr=0.092992, time_each_step=1.29s, eta=7:53:28\n",
      "2022-01-20 10:47:07 [INFO]\t[TRAIN] Epoch=5/50, Step=166/478, loss=0.115659, lr=0.092985, time_each_step=1.29s, eta=7:52:40\n",
      "2022-01-20 10:47:10 [INFO]\t[TRAIN] Epoch=5/50, Step=168/478, loss=0.074794, lr=0.092978, time_each_step=1.28s, eta=7:52:9\n",
      "2022-01-20 10:47:12 [INFO]\t[TRAIN] Epoch=5/50, Step=170/478, loss=0.083357, lr=0.092971, time_each_step=1.29s, eta=7:53:31\n",
      "2022-01-20 10:47:15 [INFO]\t[TRAIN] Epoch=5/50, Step=172/478, loss=0.075411, lr=0.092965, time_each_step=1.29s, eta=7:52:53\n",
      "2022-01-20 10:47:18 [INFO]\t[TRAIN] Epoch=5/50, Step=174/478, loss=0.085189, lr=0.092958, time_each_step=1.29s, eta=7:53:14\n",
      "2022-01-20 10:47:20 [INFO]\t[TRAIN] Epoch=5/50, Step=176/478, loss=0.116345, lr=0.092951, time_each_step=1.29s, eta=7:53:5\n",
      "2022-01-20 10:47:23 [INFO]\t[TRAIN] Epoch=5/50, Step=178/478, loss=0.092203, lr=0.092944, time_each_step=1.28s, eta=7:52:12\n",
      "2022-01-20 10:47:25 [INFO]\t[TRAIN] Epoch=5/50, Step=180/478, loss=0.079374, lr=0.092937, time_each_step=1.29s, eta=7:52:33\n",
      "2022-01-20 10:47:28 [INFO]\t[TRAIN] Epoch=5/50, Step=182/478, loss=0.053999, lr=0.092931, time_each_step=1.29s, eta=7:52:41\n",
      "2022-01-20 10:47:30 [INFO]\t[TRAIN] Epoch=5/50, Step=184/478, loss=0.116261, lr=0.092924, time_each_step=1.29s, eta=7:52:45\n",
      "2022-01-20 10:47:33 [INFO]\t[TRAIN] Epoch=5/50, Step=186/478, loss=0.103505, lr=0.092917, time_each_step=1.29s, eta=7:52:29\n",
      "2022-01-20 10:47:36 [INFO]\t[TRAIN] Epoch=5/50, Step=188/478, loss=0.062151, lr=0.092910, time_each_step=1.28s, eta=7:51:36\n",
      "2022-01-20 10:47:38 [INFO]\t[TRAIN] Epoch=5/50, Step=190/478, loss=0.097678, lr=0.092903, time_each_step=1.29s, eta=7:52:27\n",
      "2022-01-20 10:47:41 [INFO]\t[TRAIN] Epoch=5/50, Step=192/478, loss=0.084548, lr=0.092896, time_each_step=1.29s, eta=7:52:18\n",
      "2022-01-20 10:47:43 [INFO]\t[TRAIN] Epoch=5/50, Step=194/478, loss=0.086570, lr=0.092890, time_each_step=1.29s, eta=7:52:34\n",
      "2022-01-20 10:47:46 [INFO]\t[TRAIN] Epoch=5/50, Step=196/478, loss=0.068689, lr=0.092883, time_each_step=1.29s, eta=7:52:42\n",
      "2022-01-20 10:47:48 [INFO]\t[TRAIN] Epoch=5/50, Step=198/478, loss=0.078794, lr=0.092876, time_each_step=1.29s, eta=7:52:1\n",
      "2022-01-20 10:47:51 [INFO]\t[TRAIN] Epoch=5/50, Step=200/478, loss=0.104647, lr=0.092869, time_each_step=1.29s, eta=7:52:56\n",
      "2022-01-20 10:47:54 [INFO]\t[TRAIN] Epoch=5/50, Step=202/478, loss=0.089497, lr=0.092862, time_each_step=1.29s, eta=7:52:19\n",
      "2022-01-20 10:47:56 [INFO]\t[TRAIN] Epoch=5/50, Step=204/478, loss=0.106160, lr=0.092856, time_each_step=1.28s, eta=7:51:13\n",
      "2022-01-20 10:47:59 [INFO]\t[TRAIN] Epoch=5/50, Step=206/478, loss=0.070016, lr=0.092849, time_each_step=1.29s, eta=7:51:56\n",
      "2022-01-20 10:48:01 [INFO]\t[TRAIN] Epoch=5/50, Step=208/478, loss=0.074584, lr=0.092842, time_each_step=1.29s, eta=7:53:0\n",
      "2022-01-20 10:48:04 [INFO]\t[TRAIN] Epoch=5/50, Step=210/478, loss=0.058445, lr=0.092835, time_each_step=1.28s, eta=7:51:18\n",
      "2022-01-20 10:48:06 [INFO]\t[TRAIN] Epoch=5/50, Step=212/478, loss=0.062493, lr=0.092828, time_each_step=1.29s, eta=7:54:41\n",
      "2022-01-20 10:48:09 [INFO]\t[TRAIN] Epoch=5/50, Step=214/478, loss=0.104888, lr=0.092821, time_each_step=1.29s, eta=7:51:33\n",
      "2022-01-20 10:48:12 [INFO]\t[TRAIN] Epoch=5/50, Step=216/478, loss=0.093256, lr=0.092815, time_each_step=1.29s, eta=7:51:36\n",
      "2022-01-20 10:48:14 [INFO]\t[TRAIN] Epoch=5/50, Step=218/478, loss=0.070800, lr=0.092808, time_each_step=1.29s, eta=7:51:59\n",
      "2022-01-20 10:48:17 [INFO]\t[TRAIN] Epoch=5/50, Step=220/478, loss=0.080211, lr=0.092801, time_each_step=1.28s, eta=7:51:2\n",
      "2022-01-20 10:48:19 [INFO]\t[TRAIN] Epoch=5/50, Step=222/478, loss=0.069594, lr=0.092794, time_each_step=1.29s, eta=7:51:32\n",
      "2022-01-20 10:48:22 [INFO]\t[TRAIN] Epoch=5/50, Step=224/478, loss=0.064609, lr=0.092787, time_each_step=1.29s, eta=7:53:15\n",
      "2022-01-20 10:48:24 [INFO]\t[TRAIN] Epoch=5/50, Step=226/478, loss=0.068047, lr=0.092780, time_each_step=1.28s, eta=7:50:53\n",
      "2022-01-20 10:48:27 [INFO]\t[TRAIN] Epoch=5/50, Step=228/478, loss=0.107560, lr=0.092774, time_each_step=1.28s, eta=7:50:52\n",
      "2022-01-20 10:48:30 [INFO]\t[TRAIN] Epoch=5/50, Step=230/478, loss=0.056727, lr=0.092767, time_each_step=1.29s, eta=7:51:37\n",
      "2022-01-20 10:48:32 [INFO]\t[TRAIN] Epoch=5/50, Step=232/478, loss=0.073303, lr=0.092760, time_each_step=1.28s, eta=7:50:41\n",
      "2022-01-20 10:48:35 [INFO]\t[TRAIN] Epoch=5/50, Step=234/478, loss=0.101793, lr=0.092753, time_each_step=1.29s, eta=7:51:27\n",
      "2022-01-20 10:48:37 [INFO]\t[TRAIN] Epoch=5/50, Step=236/478, loss=0.058478, lr=0.092746, time_each_step=1.29s, eta=7:52:18\n",
      "2022-01-20 10:48:40 [INFO]\t[TRAIN] Epoch=5/50, Step=238/478, loss=0.123232, lr=0.092740, time_each_step=1.29s, eta=7:51:12\n",
      "2022-01-20 10:48:42 [INFO]\t[TRAIN] Epoch=5/50, Step=240/478, loss=0.069634, lr=0.092733, time_each_step=1.29s, eta=7:51:49\n",
      "2022-01-20 10:48:45 [INFO]\t[TRAIN] Epoch=5/50, Step=242/478, loss=0.078795, lr=0.092726, time_each_step=1.29s, eta=7:51:55\n",
      "2022-01-20 10:48:48 [INFO]\t[TRAIN] Epoch=5/50, Step=244/478, loss=0.080020, lr=0.092719, time_each_step=1.29s, eta=7:51:17\n",
      "2022-01-20 10:48:50 [INFO]\t[TRAIN] Epoch=5/50, Step=246/478, loss=0.060804, lr=0.092712, time_each_step=1.29s, eta=7:51:19\n",
      "2022-01-20 10:48:53 [INFO]\t[TRAIN] Epoch=5/50, Step=248/478, loss=0.058044, lr=0.092705, time_each_step=1.29s, eta=7:51:58\n",
      "2022-01-20 10:48:55 [INFO]\t[TRAIN] Epoch=5/50, Step=250/478, loss=0.070166, lr=0.092699, time_each_step=1.28s, eta=7:50:26\n",
      "2022-01-20 10:48:58 [INFO]\t[TRAIN] Epoch=5/50, Step=252/478, loss=0.071443, lr=0.092692, time_each_step=1.29s, eta=7:51:29\n",
      "2022-01-20 10:49:00 [INFO]\t[TRAIN] Epoch=5/50, Step=254/478, loss=0.073624, lr=0.092685, time_each_step=1.29s, eta=7:52:23\n",
      "2022-01-20 10:49:03 [INFO]\t[TRAIN] Epoch=5/50, Step=256/478, loss=0.085333, lr=0.092678, time_each_step=1.29s, eta=7:51:6\n",
      "2022-01-20 10:49:06 [INFO]\t[TRAIN] Epoch=5/50, Step=258/478, loss=0.099756, lr=0.092671, time_each_step=1.29s, eta=7:51:10\n",
      "2022-01-20 10:49:08 [INFO]\t[TRAIN] Epoch=5/50, Step=260/478, loss=0.077370, lr=0.092665, time_each_step=1.29s, eta=7:51:22\n",
      "2022-01-20 10:49:11 [INFO]\t[TRAIN] Epoch=5/50, Step=262/478, loss=0.072115, lr=0.092658, time_each_step=1.29s, eta=7:50:38\n",
      "2022-01-20 10:49:13 [INFO]\t[TRAIN] Epoch=5/50, Step=264/478, loss=0.095348, lr=0.092651, time_each_step=1.28s, eta=7:50:13\n",
      "2022-01-20 10:49:16 [INFO]\t[TRAIN] Epoch=5/50, Step=266/478, loss=0.078313, lr=0.092644, time_each_step=1.29s, eta=7:51:14\n",
      "2022-01-20 10:49:18 [INFO]\t[TRAIN] Epoch=5/50, Step=268/478, loss=0.049535, lr=0.092637, time_each_step=1.29s, eta=7:50:24\n",
      "2022-01-20 10:49:21 [INFO]\t[TRAIN] Epoch=5/50, Step=270/478, loss=0.120906, lr=0.092630, time_each_step=1.29s, eta=7:50:35\n",
      "2022-01-20 10:49:24 [INFO]\t[TRAIN] Epoch=5/50, Step=272/478, loss=0.111993, lr=0.092624, time_each_step=1.28s, eta=7:49:47\n",
      "2022-01-20 10:49:26 [INFO]\t[TRAIN] Epoch=5/50, Step=274/478, loss=0.086145, lr=0.092617, time_each_step=1.29s, eta=7:50:30\n",
      "2022-01-20 10:49:29 [INFO]\t[TRAIN] Epoch=5/50, Step=276/478, loss=0.088965, lr=0.092610, time_each_step=1.28s, eta=7:50:11\n",
      "2022-01-20 10:49:31 [INFO]\t[TRAIN] Epoch=5/50, Step=278/478, loss=0.108645, lr=0.092603, time_each_step=1.29s, eta=7:51:10\n",
      "2022-01-20 10:49:34 [INFO]\t[TRAIN] Epoch=5/50, Step=280/478, loss=0.103331, lr=0.092596, time_each_step=1.29s, eta=7:50:54\n",
      "2022-01-20 10:49:37 [INFO]\t[TRAIN] Epoch=5/50, Step=282/478, loss=0.067041, lr=0.092589, time_each_step=1.29s, eta=7:50:21\n",
      "2022-01-20 10:49:39 [INFO]\t[TRAIN] Epoch=5/50, Step=284/478, loss=0.077877, lr=0.092583, time_each_step=1.29s, eta=7:50:41\n",
      "2022-01-20 10:49:42 [INFO]\t[TRAIN] Epoch=5/50, Step=286/478, loss=0.078011, lr=0.092576, time_each_step=1.29s, eta=7:50:51\n",
      "2022-01-20 10:49:44 [INFO]\t[TRAIN] Epoch=5/50, Step=288/478, loss=0.098798, lr=0.092569, time_each_step=1.29s, eta=7:50:17\n",
      "2022-01-20 10:49:47 [INFO]\t[TRAIN] Epoch=5/50, Step=290/478, loss=0.088380, lr=0.092562, time_each_step=1.29s, eta=7:50:36\n",
      "2022-01-20 10:49:49 [INFO]\t[TRAIN] Epoch=5/50, Step=292/478, loss=0.087928, lr=0.092555, time_each_step=1.29s, eta=7:49:53\n",
      "2022-01-20 10:49:52 [INFO]\t[TRAIN] Epoch=5/50, Step=294/478, loss=0.114550, lr=0.092549, time_each_step=1.28s, eta=7:49:44\n",
      "2022-01-20 10:49:55 [INFO]\t[TRAIN] Epoch=5/50, Step=296/478, loss=0.060206, lr=0.092542, time_each_step=1.29s, eta=7:50:13\n",
      "2022-01-20 10:49:57 [INFO]\t[TRAIN] Epoch=5/50, Step=298/478, loss=0.065456, lr=0.092535, time_each_step=1.29s, eta=7:49:55\n",
      "2022-01-20 10:50:00 [INFO]\t[TRAIN] Epoch=5/50, Step=300/478, loss=0.107230, lr=0.092528, time_each_step=1.29s, eta=7:50:4\n",
      "2022-01-20 10:50:02 [INFO]\t[TRAIN] Epoch=5/50, Step=302/478, loss=0.074738, lr=0.092521, time_each_step=1.29s, eta=7:50:45\n",
      "2022-01-20 10:50:05 [INFO]\t[TRAIN] Epoch=5/50, Step=304/478, loss=0.187706, lr=0.092514, time_each_step=1.29s, eta=7:50:0\n",
      "2022-01-20 10:50:07 [INFO]\t[TRAIN] Epoch=5/50, Step=306/478, loss=0.061657, lr=0.092508, time_each_step=1.28s, eta=7:49:32\n",
      "2022-01-20 10:50:10 [INFO]\t[TRAIN] Epoch=5/50, Step=308/478, loss=0.091632, lr=0.092501, time_each_step=1.29s, eta=7:51:48\n",
      "2022-01-20 10:50:13 [INFO]\t[TRAIN] Epoch=5/50, Step=310/478, loss=0.079249, lr=0.092494, time_each_step=1.28s, eta=7:49:18\n",
      "2022-01-20 10:50:15 [INFO]\t[TRAIN] Epoch=5/50, Step=312/478, loss=0.071039, lr=0.092487, time_each_step=1.28s, eta=7:49:2\n",
      "2022-01-20 10:50:18 [INFO]\t[TRAIN] Epoch=5/50, Step=314/478, loss=0.066811, lr=0.092480, time_each_step=1.29s, eta=7:50:27\n",
      "2022-01-20 10:50:20 [INFO]\t[TRAIN] Epoch=5/50, Step=316/478, loss=0.056648, lr=0.092473, time_each_step=1.29s, eta=7:49:34\n",
      "2022-01-20 10:50:23 [INFO]\t[TRAIN] Epoch=5/50, Step=318/478, loss=0.104084, lr=0.092467, time_each_step=1.28s, eta=7:49:5\n",
      "2022-01-20 10:50:25 [INFO]\t[TRAIN] Epoch=5/50, Step=320/478, loss=0.069338, lr=0.092460, time_each_step=1.29s, eta=7:50:53\n",
      "2022-01-20 10:50:28 [INFO]\t[TRAIN] Epoch=5/50, Step=322/478, loss=0.093360, lr=0.092453, time_each_step=1.29s, eta=7:49:17\n",
      "2022-01-20 10:50:31 [INFO]\t[TRAIN] Epoch=5/50, Step=324/478, loss=0.067436, lr=0.092446, time_each_step=1.29s, eta=7:50:3\n",
      "2022-01-20 10:50:33 [INFO]\t[TRAIN] Epoch=5/50, Step=326/478, loss=0.117028, lr=0.092439, time_each_step=1.29s, eta=7:50:44\n",
      "2022-01-20 10:50:36 [INFO]\t[TRAIN] Epoch=5/50, Step=328/478, loss=0.082950, lr=0.092432, time_each_step=1.28s, eta=7:47:56\n",
      "2022-01-20 10:50:38 [INFO]\t[TRAIN] Epoch=5/50, Step=330/478, loss=0.109887, lr=0.092426, time_each_step=1.29s, eta=7:50:1\n",
      "2022-01-20 10:50:41 [INFO]\t[TRAIN] Epoch=5/50, Step=332/478, loss=0.068902, lr=0.092419, time_each_step=1.29s, eta=7:50:21\n",
      "2022-01-20 10:50:43 [INFO]\t[TRAIN] Epoch=5/50, Step=334/478, loss=0.064922, lr=0.092412, time_each_step=1.28s, eta=7:48:45\n",
      "2022-01-20 10:50:46 [INFO]\t[TRAIN] Epoch=5/50, Step=336/478, loss=0.090501, lr=0.092405, time_each_step=1.29s, eta=7:49:17\n",
      "2022-01-20 10:50:49 [INFO]\t[TRAIN] Epoch=5/50, Step=338/478, loss=0.097069, lr=0.092398, time_each_step=1.29s, eta=7:50:37\n",
      "2022-01-20 10:50:51 [INFO]\t[TRAIN] Epoch=5/50, Step=340/478, loss=0.097942, lr=0.092391, time_each_step=1.29s, eta=7:49:3\n",
      "2022-01-20 10:50:54 [INFO]\t[TRAIN] Epoch=5/50, Step=342/478, loss=0.086676, lr=0.092385, time_each_step=1.29s, eta=7:49:4\n",
      "2022-01-20 10:50:56 [INFO]\t[TRAIN] Epoch=5/50, Step=344/478, loss=0.067845, lr=0.092378, time_each_step=1.29s, eta=7:50:14\n",
      "2022-01-20 10:50:59 [INFO]\t[TRAIN] Epoch=5/50, Step=346/478, loss=0.070827, lr=0.092371, time_each_step=1.28s, eta=7:48:32\n",
      "2022-01-20 10:51:01 [INFO]\t[TRAIN] Epoch=5/50, Step=348/478, loss=0.131740, lr=0.092364, time_each_step=1.29s, eta=7:48:58\n",
      "2022-01-20 10:51:04 [INFO]\t[TRAIN] Epoch=5/50, Step=350/478, loss=0.127141, lr=0.092357, time_each_step=1.29s, eta=7:50:2\n",
      "2022-01-20 10:51:07 [INFO]\t[TRAIN] Epoch=5/50, Step=352/478, loss=0.074966, lr=0.092351, time_each_step=1.28s, eta=7:48:16\n",
      "2022-01-20 10:51:09 [INFO]\t[TRAIN] Epoch=5/50, Step=354/478, loss=0.114506, lr=0.092344, time_each_step=1.29s, eta=7:49:21\n",
      "2022-01-20 10:51:12 [INFO]\t[TRAIN] Epoch=5/50, Step=356/478, loss=0.087510, lr=0.092337, time_each_step=1.29s, eta=7:49:40\n",
      "2022-01-20 10:51:14 [INFO]\t[TRAIN] Epoch=5/50, Step=358/478, loss=0.120463, lr=0.092330, time_each_step=1.28s, eta=7:48:8\n",
      "2022-01-20 10:51:17 [INFO]\t[TRAIN] Epoch=5/50, Step=360/478, loss=0.080504, lr=0.092323, time_each_step=1.29s, eta=7:49:4\n",
      "2022-01-20 10:51:19 [INFO]\t[TRAIN] Epoch=5/50, Step=362/478, loss=0.092181, lr=0.092316, time_each_step=1.29s, eta=7:50:0\n",
      "2022-01-20 10:51:22 [INFO]\t[TRAIN] Epoch=5/50, Step=364/478, loss=0.161693, lr=0.092310, time_each_step=1.29s, eta=7:49:17\n",
      "2022-01-20 10:51:25 [INFO]\t[TRAIN] Epoch=5/50, Step=366/478, loss=0.073427, lr=0.092303, time_each_step=1.29s, eta=7:48:50\n",
      "2022-01-20 10:51:27 [INFO]\t[TRAIN] Epoch=5/50, Step=368/478, loss=0.119041, lr=0.092296, time_each_step=1.29s, eta=7:49:55\n",
      "2022-01-20 10:51:30 [INFO]\t[TRAIN] Epoch=5/50, Step=370/478, loss=0.051673, lr=0.092289, time_each_step=1.28s, eta=7:47:15\n",
      "2022-01-20 10:51:32 [INFO]\t[TRAIN] Epoch=5/50, Step=372/478, loss=0.135878, lr=0.092282, time_each_step=1.29s, eta=7:48:44\n",
      "2022-01-20 10:51:35 [INFO]\t[TRAIN] Epoch=5/50, Step=374/478, loss=0.081782, lr=0.092275, time_each_step=1.29s, eta=7:49:5\n",
      "2022-01-20 10:51:37 [INFO]\t[TRAIN] Epoch=5/50, Step=376/478, loss=0.108782, lr=0.092269, time_each_step=1.28s, eta=7:47:44\n",
      "2022-01-20 10:51:40 [INFO]\t[TRAIN] Epoch=5/50, Step=378/478, loss=0.091612, lr=0.092262, time_each_step=1.28s, eta=7:47:26\n",
      "2022-01-20 10:51:43 [INFO]\t[TRAIN] Epoch=5/50, Step=380/478, loss=0.080555, lr=0.092255, time_each_step=1.29s, eta=7:48:18\n",
      "2022-01-20 10:51:45 [INFO]\t[TRAIN] Epoch=5/50, Step=382/478, loss=0.063929, lr=0.092248, time_each_step=1.29s, eta=7:48:0\n",
      "2022-01-20 10:51:48 [INFO]\t[TRAIN] Epoch=5/50, Step=384/478, loss=0.064214, lr=0.092241, time_each_step=1.29s, eta=7:47:53\n",
      "2022-01-20 10:51:50 [INFO]\t[TRAIN] Epoch=5/50, Step=386/478, loss=0.062101, lr=0.092234, time_each_step=1.29s, eta=7:48:31\n",
      "2022-01-20 10:51:53 [INFO]\t[TRAIN] Epoch=5/50, Step=388/478, loss=0.099448, lr=0.092228, time_each_step=1.29s, eta=7:48:5\n",
      "2022-01-20 10:51:55 [INFO]\t[TRAIN] Epoch=5/50, Step=390/478, loss=0.095612, lr=0.092221, time_each_step=1.28s, eta=7:47:34\n",
      "2022-01-20 10:51:58 [INFO]\t[TRAIN] Epoch=5/50, Step=392/478, loss=0.083895, lr=0.092214, time_each_step=1.29s, eta=7:48:27\n",
      "2022-01-20 10:52:01 [INFO]\t[TRAIN] Epoch=5/50, Step=394/478, loss=0.045860, lr=0.092207, time_each_step=1.28s, eta=7:47:32\n",
      "2022-01-20 10:52:03 [INFO]\t[TRAIN] Epoch=5/50, Step=396/478, loss=0.091209, lr=0.092200, time_each_step=1.29s, eta=7:47:54\n",
      "2022-01-20 10:52:06 [INFO]\t[TRAIN] Epoch=5/50, Step=398/478, loss=0.064751, lr=0.092193, time_each_step=1.29s, eta=7:48:42\n",
      "2022-01-20 10:52:08 [INFO]\t[TRAIN] Epoch=5/50, Step=400/478, loss=0.114452, lr=0.092187, time_each_step=1.28s, eta=7:47:31\n",
      "2022-01-20 10:52:11 [INFO]\t[TRAIN] Epoch=5/50, Step=402/478, loss=0.115647, lr=0.092180, time_each_step=1.28s, eta=7:46:52\n",
      "2022-01-20 10:52:13 [INFO]\t[TRAIN] Epoch=5/50, Step=404/478, loss=0.060389, lr=0.092173, time_each_step=1.29s, eta=7:48:38\n",
      "2022-01-20 10:52:16 [INFO]\t[TRAIN] Epoch=5/50, Step=406/478, loss=0.047769, lr=0.092166, time_each_step=1.28s, eta=7:46:56\n",
      "2022-01-20 10:52:19 [INFO]\t[TRAIN] Epoch=5/50, Step=408/478, loss=0.093270, lr=0.092159, time_each_step=1.29s, eta=7:47:58\n",
      "2022-01-20 10:52:21 [INFO]\t[TRAIN] Epoch=5/50, Step=410/478, loss=0.072849, lr=0.092152, time_each_step=1.29s, eta=7:48:48\n",
      "2022-01-20 10:52:24 [INFO]\t[TRAIN] Epoch=5/50, Step=412/478, loss=0.090440, lr=0.092146, time_each_step=1.28s, eta=7:47:1\n",
      "2022-01-20 10:52:26 [INFO]\t[TRAIN] Epoch=5/50, Step=414/478, loss=0.085354, lr=0.092139, time_each_step=1.29s, eta=7:48:22\n",
      "2022-01-20 10:52:29 [INFO]\t[TRAIN] Epoch=5/50, Step=416/478, loss=0.056859, lr=0.092132, time_each_step=1.29s, eta=7:48:7\n",
      "2022-01-20 10:52:31 [INFO]\t[TRAIN] Epoch=5/50, Step=418/478, loss=0.095830, lr=0.092125, time_each_step=1.29s, eta=7:47:46\n",
      "2022-01-20 10:52:34 [INFO]\t[TRAIN] Epoch=5/50, Step=420/478, loss=0.083466, lr=0.092118, time_each_step=1.28s, eta=7:47:5\n",
      "2022-01-20 10:52:37 [INFO]\t[TRAIN] Epoch=5/50, Step=422/478, loss=0.089941, lr=0.092111, time_each_step=1.29s, eta=7:48:17\n",
      "2022-01-20 10:52:39 [INFO]\t[TRAIN] Epoch=5/50, Step=424/478, loss=0.055450, lr=0.092105, time_each_step=1.29s, eta=7:47:32\n",
      "2022-01-20 10:52:42 [INFO]\t[TRAIN] Epoch=5/50, Step=426/478, loss=0.115334, lr=0.092098, time_each_step=1.29s, eta=7:47:12\n",
      "2022-01-20 10:52:44 [INFO]\t[TRAIN] Epoch=5/50, Step=428/478, loss=0.077375, lr=0.092091, time_each_step=1.29s, eta=7:47:56\n",
      "2022-01-20 10:52:47 [INFO]\t[TRAIN] Epoch=5/50, Step=430/478, loss=0.070033, lr=0.092084, time_each_step=1.28s, eta=7:46:7\n",
      "2022-01-20 10:52:49 [INFO]\t[TRAIN] Epoch=5/50, Step=432/478, loss=0.077830, lr=0.092077, time_each_step=1.29s, eta=7:47:19\n",
      "2022-01-20 10:52:52 [INFO]\t[TRAIN] Epoch=5/50, Step=434/478, loss=0.085937, lr=0.092070, time_each_step=1.29s, eta=7:47:36\n",
      "2022-01-20 10:52:55 [INFO]\t[TRAIN] Epoch=5/50, Step=436/478, loss=0.079127, lr=0.092064, time_each_step=1.29s, eta=7:47:42\n",
      "2022-01-20 10:52:57 [INFO]\t[TRAIN] Epoch=5/50, Step=438/478, loss=0.119036, lr=0.092057, time_each_step=1.29s, eta=7:47:1\n",
      "2022-01-20 10:53:00 [INFO]\t[TRAIN] Epoch=5/50, Step=440/478, loss=0.113809, lr=0.092050, time_each_step=1.29s, eta=7:47:1\n",
      "2022-01-20 10:53:02 [INFO]\t[TRAIN] Epoch=5/50, Step=442/478, loss=0.075149, lr=0.092043, time_each_step=1.29s, eta=7:47:6\n",
      "2022-01-20 10:53:05 [INFO]\t[TRAIN] Epoch=5/50, Step=444/478, loss=0.079034, lr=0.092036, time_each_step=1.28s, eta=7:46:31\n",
      "2022-01-20 10:53:07 [INFO]\t[TRAIN] Epoch=5/50, Step=446/478, loss=0.086890, lr=0.092029, time_each_step=1.29s, eta=7:47:23\n",
      "2022-01-20 10:53:10 [INFO]\t[TRAIN] Epoch=5/50, Step=448/478, loss=0.104260, lr=0.092023, time_each_step=1.28s, eta=7:45:47\n",
      "2022-01-20 10:53:13 [INFO]\t[TRAIN] Epoch=5/50, Step=450/478, loss=0.098386, lr=0.092016, time_each_step=1.29s, eta=7:46:56\n",
      "2022-01-20 10:53:15 [INFO]\t[TRAIN] Epoch=5/50, Step=452/478, loss=0.115853, lr=0.092009, time_each_step=1.29s, eta=7:46:30\n",
      "2022-01-20 10:53:18 [INFO]\t[TRAIN] Epoch=5/50, Step=454/478, loss=0.050707, lr=0.092002, time_each_step=1.29s, eta=7:47:21\n",
      "2022-01-20 10:53:20 [INFO]\t[TRAIN] Epoch=5/50, Step=456/478, loss=0.081171, lr=0.091995, time_each_step=1.29s, eta=7:47:7\n",
      "2022-01-20 10:53:23 [INFO]\t[TRAIN] Epoch=5/50, Step=458/478, loss=0.066768, lr=0.091988, time_each_step=1.29s, eta=7:47:30\n",
      "2022-01-20 10:53:25 [INFO]\t[TRAIN] Epoch=5/50, Step=460/478, loss=0.063228, lr=0.091982, time_each_step=1.29s, eta=7:46:56\n",
      "2022-01-20 10:53:28 [INFO]\t[TRAIN] Epoch=5/50, Step=462/478, loss=0.066308, lr=0.091975, time_each_step=1.28s, eta=7:45:58\n",
      "2022-01-20 10:53:31 [INFO]\t[TRAIN] Epoch=5/50, Step=464/478, loss=0.065731, lr=0.091968, time_each_step=1.29s, eta=7:47:31\n",
      "2022-01-20 10:53:33 [INFO]\t[TRAIN] Epoch=5/50, Step=466/478, loss=0.062876, lr=0.091961, time_each_step=1.29s, eta=7:46:34\n",
      "2022-01-20 10:53:36 [INFO]\t[TRAIN] Epoch=5/50, Step=468/478, loss=0.082326, lr=0.091954, time_each_step=1.29s, eta=7:46:56\n",
      "2022-01-20 10:53:38 [INFO]\t[TRAIN] Epoch=5/50, Step=470/478, loss=0.058372, lr=0.091947, time_each_step=1.29s, eta=7:46:56\n",
      "2022-01-20 10:53:41 [INFO]\t[TRAIN] Epoch=5/50, Step=472/478, loss=0.075069, lr=0.091941, time_each_step=1.29s, eta=7:46:12\n",
      "2022-01-20 10:53:43 [INFO]\t[TRAIN] Epoch=5/50, Step=474/478, loss=0.094358, lr=0.091934, time_each_step=1.29s, eta=7:46:35\n",
      "2022-01-20 10:53:46 [INFO]\t[TRAIN] Epoch=5/50, Step=476/478, loss=0.073962, lr=0.091927, time_each_step=1.28s, eta=7:45:45\n",
      "2022-01-20 10:53:49 [INFO]\t[TRAIN] Epoch=5/50, Step=478/478, loss=0.080845, lr=0.091920, time_each_step=1.28s, eta=7:45:9\n",
      "2022-01-20 10:53:49 [INFO]\t[TRAIN] Epoch 5 finished, loss=0.08399265 .\n",
      "2022-01-20 10:53:49 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-01-20 10:53:49 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-01-20 10:53:55 [INFO]\t[EVAL] Finished, Epoch=5, miou=0.800589, category_iou=[0.967633  0.6762756 0.757857 ], oacc=0.969285, category_acc=[0.978234   0.89161754 0.89155734], kappa=0.843693, category_F1-score=[0.98355029 0.80687875 0.86225101] .\n",
      "2022-01-20 10:53:55 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_4, miou=0.8140060305595398\n",
      "2022-01-20 10:53:56 [INFO]\tModel saved in model/deeplab_augument_alldata2/epoch_5.\n",
      "2022-01-20 10:53:59 [INFO]\t[TRAIN] Epoch=6/50, Step=2/478, loss=0.104734, lr=0.091913, time_each_step=1.79s, eta=10:46:20\n",
      "2022-01-20 10:54:02 [INFO]\t[TRAIN] Epoch=6/50, Step=4/478, loss=0.127172, lr=0.091906, time_each_step=1.29s, eta=7:46:29\n",
      "2022-01-20 10:54:04 [INFO]\t[TRAIN] Epoch=6/50, Step=6/478, loss=0.071730, lr=0.091900, time_each_step=1.29s, eta=7:45:24\n",
      "2022-01-20 10:54:07 [INFO]\t[TRAIN] Epoch=6/50, Step=8/478, loss=0.060378, lr=0.091893, time_each_step=1.29s, eta=7:45:19\n",
      "2022-01-20 10:54:10 [INFO]\t[TRAIN] Epoch=6/50, Step=10/478, loss=0.052920, lr=0.091886, time_each_step=1.29s, eta=7:45:22\n",
      "2022-01-20 10:54:12 [INFO]\t[TRAIN] Epoch=6/50, Step=12/478, loss=0.104117, lr=0.091879, time_each_step=1.28s, eta=7:44:20\n",
      "2022-01-20 10:54:15 [INFO]\t[TRAIN] Epoch=6/50, Step=14/478, loss=0.053533, lr=0.091872, time_each_step=1.29s, eta=7:46:17\n",
      "2022-01-20 10:54:17 [INFO]\t[TRAIN] Epoch=6/50, Step=16/478, loss=0.108028, lr=0.091865, time_each_step=1.29s, eta=7:45:59\n",
      "2022-01-20 10:54:20 [INFO]\t[TRAIN] Epoch=6/50, Step=18/478, loss=0.083734, lr=0.091858, time_each_step=1.28s, eta=7:44:53\n",
      "2022-01-20 10:54:22 [INFO]\t[TRAIN] Epoch=6/50, Step=20/478, loss=0.067059, lr=0.091852, time_each_step=1.29s, eta=7:47:11\n",
      "2022-01-20 10:54:25 [INFO]\t[TRAIN] Epoch=6/50, Step=22/478, loss=0.047424, lr=0.091845, time_each_step=1.29s, eta=7:45:22\n",
      "2022-01-20 10:54:28 [INFO]\t[TRAIN] Epoch=6/50, Step=24/478, loss=0.049414, lr=0.091838, time_each_step=1.28s, eta=7:44:19\n",
      "2022-01-20 10:54:30 [INFO]\t[TRAIN] Epoch=6/50, Step=26/478, loss=0.078723, lr=0.091831, time_each_step=1.29s, eta=7:46:14\n",
      "2022-01-20 10:54:33 [INFO]\t[TRAIN] Epoch=6/50, Step=28/478, loss=0.065838, lr=0.091824, time_each_step=1.29s, eta=7:45:5\n",
      "2022-01-20 10:54:35 [INFO]\t[TRAIN] Epoch=6/50, Step=30/478, loss=0.063357, lr=0.091817, time_each_step=1.29s, eta=7:44:45\n",
      "2022-01-20 10:54:38 [INFO]\t[TRAIN] Epoch=6/50, Step=32/478, loss=0.125749, lr=0.091811, time_each_step=1.29s, eta=7:46:23\n",
      "2022-01-20 10:54:40 [INFO]\t[TRAIN] Epoch=6/50, Step=34/478, loss=0.074808, lr=0.091804, time_each_step=1.29s, eta=7:45:13\n",
      "2022-01-20 10:54:43 [INFO]\t[TRAIN] Epoch=6/50, Step=36/478, loss=0.064516, lr=0.091797, time_each_step=1.29s, eta=7:45:22\n",
      "2022-01-20 10:54:46 [INFO]\t[TRAIN] Epoch=6/50, Step=38/478, loss=0.092713, lr=0.091790, time_each_step=1.29s, eta=7:45:8\n",
      "2022-01-20 10:54:48 [INFO]\t[TRAIN] Epoch=6/50, Step=40/478, loss=0.050311, lr=0.091783, time_each_step=1.29s, eta=7:44:31\n",
      "2022-01-20 10:54:51 [INFO]\t[TRAIN] Epoch=6/50, Step=42/478, loss=0.052753, lr=0.091776, time_each_step=1.28s, eta=7:43:33\n",
      "2022-01-20 10:54:53 [INFO]\t[TRAIN] Epoch=6/50, Step=44/478, loss=0.071045, lr=0.091770, time_each_step=1.29s, eta=7:45:13\n",
      "2022-01-20 10:54:56 [INFO]\t[TRAIN] Epoch=6/50, Step=46/478, loss=0.071579, lr=0.091763, time_each_step=1.29s, eta=7:44:56\n",
      "2022-01-20 10:54:58 [INFO]\t[TRAIN] Epoch=6/50, Step=48/478, loss=0.083173, lr=0.091756, time_each_step=1.28s, eta=7:43:56\n",
      "2022-01-20 10:55:01 [INFO]\t[TRAIN] Epoch=6/50, Step=50/478, loss=0.084191, lr=0.091749, time_each_step=1.28s, eta=7:43:44\n",
      "2022-01-20 10:55:04 [INFO]\t[TRAIN] Epoch=6/50, Step=52/478, loss=0.088857, lr=0.091742, time_each_step=1.29s, eta=7:45:15\n",
      "2022-01-20 10:55:06 [INFO]\t[TRAIN] Epoch=6/50, Step=54/478, loss=0.077499, lr=0.091735, time_each_step=1.29s, eta=7:44:38\n",
      "2022-01-20 10:55:09 [INFO]\t[TRAIN] Epoch=6/50, Step=56/478, loss=0.072955, lr=0.091729, time_each_step=1.29s, eta=7:45:32\n",
      "2022-01-20 10:55:11 [INFO]\t[TRAIN] Epoch=6/50, Step=58/478, loss=0.111236, lr=0.091722, time_each_step=1.29s, eta=7:44:18\n",
      "2022-01-20 10:55:14 [INFO]\t[TRAIN] Epoch=6/50, Step=60/478, loss=0.085803, lr=0.091715, time_each_step=1.29s, eta=7:44:28\n",
      "2022-01-20 10:55:16 [INFO]\t[TRAIN] Epoch=6/50, Step=62/478, loss=0.081675, lr=0.091708, time_each_step=1.29s, eta=7:44:59\n",
      "2022-01-20 10:55:19 [INFO]\t[TRAIN] Epoch=6/50, Step=64/478, loss=0.049357, lr=0.091701, time_each_step=1.29s, eta=7:45:45\n",
      "2022-01-20 10:55:22 [INFO]\t[TRAIN] Epoch=6/50, Step=66/478, loss=0.077667, lr=0.091694, time_each_step=1.29s, eta=7:44:16\n",
      "2022-01-20 10:55:24 [INFO]\t[TRAIN] Epoch=6/50, Step=68/478, loss=0.074695, lr=0.091687, time_each_step=1.29s, eta=7:45:11\n",
      "2022-01-20 10:55:27 [INFO]\t[TRAIN] Epoch=6/50, Step=70/478, loss=0.118057, lr=0.091681, time_each_step=1.29s, eta=7:43:53\n",
      "2022-01-20 10:55:29 [INFO]\t[TRAIN] Epoch=6/50, Step=72/478, loss=0.079358, lr=0.091674, time_each_step=1.28s, eta=7:43:28\n",
      "2022-01-20 10:55:32 [INFO]\t[TRAIN] Epoch=6/50, Step=74/478, loss=0.107459, lr=0.091667, time_each_step=1.29s, eta=7:44:56\n",
      "2022-01-20 10:55:34 [INFO]\t[TRAIN] Epoch=6/50, Step=76/478, loss=0.065559, lr=0.091660, time_each_step=1.29s, eta=7:44:22\n",
      "2022-01-20 10:55:37 [INFO]\t[TRAIN] Epoch=6/50, Step=78/478, loss=0.093817, lr=0.091653, time_each_step=1.28s, eta=7:42:56\n",
      "2022-01-20 10:55:40 [INFO]\t[TRAIN] Epoch=6/50, Step=80/478, loss=0.068515, lr=0.091646, time_each_step=1.28s, eta=7:43:15\n",
      "2022-01-20 10:55:42 [INFO]\t[TRAIN] Epoch=6/50, Step=82/478, loss=0.087707, lr=0.091640, time_each_step=1.29s, eta=7:43:53\n",
      "2022-01-20 10:55:45 [INFO]\t[TRAIN] Epoch=6/50, Step=84/478, loss=0.065854, lr=0.091633, time_each_step=1.29s, eta=7:43:55\n",
      "2022-01-20 10:55:47 [INFO]\t[TRAIN] Epoch=6/50, Step=86/478, loss=0.061082, lr=0.091626, time_each_step=1.29s, eta=7:44:17\n",
      "2022-01-20 10:55:50 [INFO]\t[TRAIN] Epoch=6/50, Step=88/478, loss=0.067163, lr=0.091619, time_each_step=1.29s, eta=7:43:45\n",
      "2022-01-20 10:55:52 [INFO]\t[TRAIN] Epoch=6/50, Step=90/478, loss=0.083549, lr=0.091612, time_each_step=1.29s, eta=7:44:43\n",
      "2022-01-20 10:55:55 [INFO]\t[TRAIN] Epoch=6/50, Step=92/478, loss=0.123028, lr=0.091605, time_each_step=1.29s, eta=7:44:57\n",
      "2022-01-20 10:55:58 [INFO]\t[TRAIN] Epoch=6/50, Step=94/478, loss=0.074303, lr=0.091599, time_each_step=1.28s, eta=7:43:17\n",
      "2022-01-20 10:56:00 [INFO]\t[TRAIN] Epoch=6/50, Step=96/478, loss=0.104998, lr=0.091592, time_each_step=1.28s, eta=7:42:16\n",
      "2022-01-20 10:56:03 [INFO]\t[TRAIN] Epoch=6/50, Step=98/478, loss=0.081724, lr=0.091585, time_each_step=1.29s, eta=7:44:4\n",
      "2022-01-20 10:56:05 [INFO]\t[TRAIN] Epoch=6/50, Step=100/478, loss=0.068722, lr=0.091578, time_each_step=1.29s, eta=7:44:9\n",
      "2022-01-20 10:56:08 [INFO]\t[TRAIN] Epoch=6/50, Step=102/478, loss=0.104319, lr=0.091571, time_each_step=1.29s, eta=7:43:49\n",
      "2022-01-20 10:56:10 [INFO]\t[TRAIN] Epoch=6/50, Step=104/478, loss=0.083197, lr=0.091564, time_each_step=1.29s, eta=7:43:32\n",
      "2022-01-20 10:56:13 [INFO]\t[TRAIN] Epoch=6/50, Step=106/478, loss=0.058263, lr=0.091557, time_each_step=1.29s, eta=7:43:34\n",
      "2022-01-20 10:56:16 [INFO]\t[TRAIN] Epoch=6/50, Step=108/478, loss=0.100601, lr=0.091551, time_each_step=1.28s, eta=7:42:52\n",
      "2022-01-20 10:56:18 [INFO]\t[TRAIN] Epoch=6/50, Step=110/478, loss=0.097478, lr=0.091544, time_each_step=1.29s, eta=7:43:30\n",
      "2022-01-20 10:56:21 [INFO]\t[TRAIN] Epoch=6/50, Step=112/478, loss=0.069863, lr=0.091537, time_each_step=1.28s, eta=7:42:26\n",
      "2022-01-20 10:56:23 [INFO]\t[TRAIN] Epoch=6/50, Step=114/478, loss=0.084989, lr=0.091530, time_each_step=1.29s, eta=7:43:47\n",
      "2022-01-20 10:56:26 [INFO]\t[TRAIN] Epoch=6/50, Step=116/478, loss=0.059468, lr=0.091523, time_each_step=1.29s, eta=7:43:30\n",
      "2022-01-20 10:56:28 [INFO]\t[TRAIN] Epoch=6/50, Step=118/478, loss=0.071550, lr=0.091516, time_each_step=1.28s, eta=7:42:48\n",
      "2022-01-20 10:56:31 [INFO]\t[TRAIN] Epoch=6/50, Step=120/478, loss=0.078146, lr=0.091510, time_each_step=1.28s, eta=7:42:44\n",
      "2022-01-20 10:56:34 [INFO]\t[TRAIN] Epoch=6/50, Step=122/478, loss=0.055069, lr=0.091503, time_each_step=1.29s, eta=7:43:23\n",
      "2022-01-20 10:56:36 [INFO]\t[TRAIN] Epoch=6/50, Step=124/478, loss=0.059200, lr=0.091496, time_each_step=1.28s, eta=7:42:36\n",
      "2022-01-20 10:56:39 [INFO]\t[TRAIN] Epoch=6/50, Step=126/478, loss=0.101321, lr=0.091489, time_each_step=1.28s, eta=7:42:9\n",
      "2022-01-20 10:56:41 [INFO]\t[TRAIN] Epoch=6/50, Step=128/478, loss=0.078829, lr=0.091482, time_each_step=1.29s, eta=7:44:9\n",
      "2022-01-20 10:56:44 [INFO]\t[TRAIN] Epoch=6/50, Step=130/478, loss=0.088239, lr=0.091475, time_each_step=1.29s, eta=7:42:58\n",
      "2022-01-20 10:56:46 [INFO]\t[TRAIN] Epoch=6/50, Step=132/478, loss=0.071541, lr=0.091469, time_each_step=1.29s, eta=7:43:8\n",
      "2022-01-20 10:56:49 [INFO]\t[TRAIN] Epoch=6/50, Step=134/478, loss=0.079024, lr=0.091462, time_each_step=1.29s, eta=7:44:16\n",
      "2022-01-20 10:56:52 [INFO]\t[TRAIN] Epoch=6/50, Step=136/478, loss=0.097739, lr=0.091455, time_each_step=1.29s, eta=7:42:36\n",
      "2022-01-20 10:56:54 [INFO]\t[TRAIN] Epoch=6/50, Step=138/478, loss=0.084110, lr=0.091448, time_each_step=1.29s, eta=7:42:26\n",
      "2022-01-20 10:56:57 [INFO]\t[TRAIN] Epoch=6/50, Step=140/478, loss=0.096016, lr=0.091441, time_each_step=1.29s, eta=7:44:13\n",
      "2022-01-20 10:56:59 [INFO]\t[TRAIN] Epoch=6/50, Step=142/478, loss=0.085710, lr=0.091434, time_each_step=1.28s, eta=7:42:1\n",
      "2022-01-20 10:57:02 [INFO]\t[TRAIN] Epoch=6/50, Step=144/478, loss=0.113787, lr=0.091427, time_each_step=1.29s, eta=7:42:26\n",
      "2022-01-20 10:57:05 [INFO]\t[TRAIN] Epoch=6/50, Step=146/478, loss=0.058323, lr=0.091421, time_each_step=1.29s, eta=7:44:5\n",
      "2022-01-20 10:57:07 [INFO]\t[TRAIN] Epoch=6/50, Step=148/478, loss=0.062457, lr=0.091414, time_each_step=1.29s, eta=7:42:33\n",
      "2022-01-20 10:57:10 [INFO]\t[TRAIN] Epoch=6/50, Step=150/478, loss=0.052789, lr=0.091407, time_each_step=1.29s, eta=7:42:18\n",
      "2022-01-20 10:57:12 [INFO]\t[TRAIN] Epoch=6/50, Step=152/478, loss=0.061225, lr=0.091400, time_each_step=1.29s, eta=7:43:20\n",
      "2022-01-20 10:57:15 [INFO]\t[TRAIN] Epoch=6/50, Step=154/478, loss=0.097337, lr=0.091393, time_each_step=1.29s, eta=7:42:17\n",
      "2022-01-20 10:57:17 [INFO]\t[TRAIN] Epoch=6/50, Step=156/478, loss=0.092085, lr=0.091386, time_each_step=1.28s, eta=7:41:59\n",
      "2022-01-20 10:57:20 [INFO]\t[TRAIN] Epoch=6/50, Step=158/478, loss=0.059491, lr=0.091380, time_each_step=1.29s, eta=7:42:36\n",
      "2022-01-20 10:57:23 [INFO]\t[TRAIN] Epoch=6/50, Step=160/478, loss=0.100850, lr=0.091373, time_each_step=1.29s, eta=7:42:14\n",
      "2022-01-20 10:57:25 [INFO]\t[TRAIN] Epoch=6/50, Step=162/478, loss=0.072381, lr=0.091366, time_each_step=1.28s, eta=7:41:40\n",
      "2022-01-20 10:57:28 [INFO]\t[TRAIN] Epoch=6/50, Step=164/478, loss=0.086461, lr=0.091359, time_each_step=1.29s, eta=7:43:23\n",
      "2022-01-20 10:57:30 [INFO]\t[TRAIN] Epoch=6/50, Step=166/478, loss=0.087032, lr=0.091352, time_each_step=1.28s, eta=7:41:18\n",
      "2022-01-20 10:57:33 [INFO]\t[TRAIN] Epoch=6/50, Step=168/478, loss=0.097815, lr=0.091345, time_each_step=1.29s, eta=7:42:12\n",
      "2022-01-20 10:57:35 [INFO]\t[TRAIN] Epoch=6/50, Step=170/478, loss=0.046103, lr=0.091338, time_each_step=1.29s, eta=7:42:43\n",
      "2022-01-20 10:57:38 [INFO]\t[TRAIN] Epoch=6/50, Step=172/478, loss=0.090190, lr=0.091332, time_each_step=1.29s, eta=7:42:16\n",
      "2022-01-20 10:57:41 [INFO]\t[TRAIN] Epoch=6/50, Step=174/478, loss=0.101202, lr=0.091325, time_each_step=1.29s, eta=7:41:54\n",
      "2022-01-20 10:57:43 [INFO]\t[TRAIN] Epoch=6/50, Step=176/478, loss=0.080954, lr=0.091318, time_each_step=1.28s, eta=7:40:56\n",
      "2022-01-20 10:57:46 [INFO]\t[TRAIN] Epoch=6/50, Step=178/478, loss=0.127765, lr=0.091311, time_each_step=1.29s, eta=7:41:56\n",
      "2022-01-20 10:57:48 [INFO]\t[TRAIN] Epoch=6/50, Step=180/478, loss=0.102744, lr=0.091304, time_each_step=1.29s, eta=7:41:57\n",
      "2022-01-20 10:57:51 [INFO]\t[TRAIN] Epoch=6/50, Step=182/478, loss=0.084366, lr=0.091297, time_each_step=1.29s, eta=7:42:13\n",
      "2022-01-20 10:57:53 [INFO]\t[TRAIN] Epoch=6/50, Step=184/478, loss=0.098673, lr=0.091290, time_each_step=1.29s, eta=7:42:22\n",
      "2022-01-20 10:57:56 [INFO]\t[TRAIN] Epoch=6/50, Step=186/478, loss=0.067849, lr=0.091284, time_each_step=1.29s, eta=7:41:49\n",
      "2022-01-20 10:57:59 [INFO]\t[TRAIN] Epoch=6/50, Step=188/478, loss=0.073081, lr=0.091277, time_each_step=1.29s, eta=7:42:25\n",
      "2022-01-20 10:58:01 [INFO]\t[TRAIN] Epoch=6/50, Step=190/478, loss=0.064966, lr=0.091270, time_each_step=1.29s, eta=7:41:42\n",
      "2022-01-20 10:58:04 [INFO]\t[TRAIN] Epoch=6/50, Step=192/478, loss=0.077108, lr=0.091263, time_each_step=1.28s, eta=7:41:13\n",
      "2022-01-20 10:58:06 [INFO]\t[TRAIN] Epoch=6/50, Step=194/478, loss=0.099932, lr=0.091256, time_each_step=1.29s, eta=7:43:58\n",
      "2022-01-20 10:58:09 [INFO]\t[TRAIN] Epoch=6/50, Step=196/478, loss=0.052834, lr=0.091249, time_each_step=1.29s, eta=7:41:34\n",
      "2022-01-20 10:58:11 [INFO]\t[TRAIN] Epoch=6/50, Step=198/478, loss=0.088694, lr=0.091243, time_each_step=1.29s, eta=7:41:12\n",
      "2022-01-20 10:58:14 [INFO]\t[TRAIN] Epoch=6/50, Step=200/478, loss=0.083273, lr=0.091236, time_each_step=1.29s, eta=7:41:33\n",
      "2022-01-20 10:58:17 [INFO]\t[TRAIN] Epoch=6/50, Step=202/478, loss=0.058718, lr=0.091229, time_each_step=1.29s, eta=7:41:2\n",
      "2022-01-20 10:58:19 [INFO]\t[TRAIN] Epoch=6/50, Step=204/478, loss=0.140903, lr=0.091222, time_each_step=1.28s, eta=7:40:44\n",
      "2022-01-20 10:58:22 [INFO]\t[TRAIN] Epoch=6/50, Step=206/478, loss=0.080435, lr=0.091215, time_each_step=1.29s, eta=7:41:16\n",
      "2022-01-20 10:58:24 [INFO]\t[TRAIN] Epoch=6/50, Step=208/478, loss=0.075681, lr=0.091208, time_each_step=1.29s, eta=7:40:55\n",
      "2022-01-20 10:58:27 [INFO]\t[TRAIN] Epoch=6/50, Step=210/478, loss=0.103576, lr=0.091201, time_each_step=1.29s, eta=7:41:8\n",
      "2022-01-20 10:58:29 [INFO]\t[TRAIN] Epoch=6/50, Step=212/478, loss=0.095561, lr=0.091195, time_each_step=1.29s, eta=7:41:25\n",
      "2022-01-20 10:58:32 [INFO]\t[TRAIN] Epoch=6/50, Step=214/478, loss=0.064822, lr=0.091188, time_each_step=1.29s, eta=7:40:49\n",
      "2022-01-20 10:58:35 [INFO]\t[TRAIN] Epoch=6/50, Step=216/478, loss=0.087114, lr=0.091181, time_each_step=1.28s, eta=7:40:27\n",
      "2022-01-20 10:58:37 [INFO]\t[TRAIN] Epoch=6/50, Step=218/478, loss=0.103091, lr=0.091174, time_each_step=1.29s, eta=7:41:38\n",
      "2022-01-20 10:58:40 [INFO]\t[TRAIN] Epoch=6/50, Step=220/478, loss=0.063184, lr=0.091167, time_each_step=1.29s, eta=7:41:3\n",
      "2022-01-20 10:58:42 [INFO]\t[TRAIN] Epoch=6/50, Step=222/478, loss=0.122077, lr=0.091160, time_each_step=1.28s, eta=7:40:24\n",
      "2022-01-20 10:58:45 [INFO]\t[TRAIN] Epoch=6/50, Step=224/478, loss=0.053562, lr=0.091153, time_each_step=1.29s, eta=7:42:19\n",
      "2022-01-20 10:58:47 [INFO]\t[TRAIN] Epoch=6/50, Step=226/478, loss=0.077455, lr=0.091147, time_each_step=1.28s, eta=7:39:57\n",
      "2022-01-20 10:58:50 [INFO]\t[TRAIN] Epoch=6/50, Step=228/478, loss=0.071118, lr=0.091140, time_each_step=1.29s, eta=7:40:38\n",
      "2022-01-20 10:58:53 [INFO]\t[TRAIN] Epoch=6/50, Step=230/478, loss=0.059684, lr=0.091133, time_each_step=1.29s, eta=7:42:9\n",
      "2022-01-20 10:58:55 [INFO]\t[TRAIN] Epoch=6/50, Step=232/478, loss=0.059482, lr=0.091126, time_each_step=1.28s, eta=7:40:7\n",
      "2022-01-20 10:58:58 [INFO]\t[TRAIN] Epoch=6/50, Step=234/478, loss=0.073034, lr=0.091119, time_each_step=1.29s, eta=7:40:36\n",
      "2022-01-20 10:59:00 [INFO]\t[TRAIN] Epoch=6/50, Step=236/478, loss=0.082271, lr=0.091112, time_each_step=1.29s, eta=7:41:8\n",
      "2022-01-20 10:59:03 [INFO]\t[TRAIN] Epoch=6/50, Step=238/478, loss=0.089713, lr=0.091106, time_each_step=1.29s, eta=7:40:43\n",
      "2022-01-20 10:59:05 [INFO]\t[TRAIN] Epoch=6/50, Step=240/478, loss=0.077940, lr=0.091099, time_each_step=1.29s, eta=7:40:29\n",
      "2022-01-20 10:59:08 [INFO]\t[TRAIN] Epoch=6/50, Step=242/478, loss=0.081214, lr=0.091092, time_each_step=1.29s, eta=7:42:33\n",
      "2022-01-20 10:59:11 [INFO]\t[TRAIN] Epoch=6/50, Step=244/478, loss=0.087986, lr=0.091085, time_each_step=1.29s, eta=7:40:48\n",
      "2022-01-20 10:59:13 [INFO]\t[TRAIN] Epoch=6/50, Step=246/478, loss=0.045373, lr=0.091078, time_each_step=1.29s, eta=7:41:6\n",
      "2022-01-20 10:59:16 [INFO]\t[TRAIN] Epoch=6/50, Step=248/478, loss=0.057329, lr=0.091071, time_each_step=1.29s, eta=7:40:53\n",
      "2022-01-20 10:59:18 [INFO]\t[TRAIN] Epoch=6/50, Step=250/478, loss=0.087966, lr=0.091064, time_each_step=1.29s, eta=7:40:7\n",
      "2022-01-20 10:59:21 [INFO]\t[TRAIN] Epoch=6/50, Step=252/478, loss=0.052089, lr=0.091058, time_each_step=1.28s, eta=7:39:40\n",
      "2022-01-20 10:59:23 [INFO]\t[TRAIN] Epoch=6/50, Step=254/478, loss=0.068071, lr=0.091051, time_each_step=1.29s, eta=7:41:4\n",
      "2022-01-20 10:59:26 [INFO]\t[TRAIN] Epoch=6/50, Step=256/478, loss=0.072955, lr=0.091044, time_each_step=1.29s, eta=7:40:10\n",
      "2022-01-20 10:59:29 [INFO]\t[TRAIN] Epoch=6/50, Step=258/478, loss=0.085508, lr=0.091037, time_each_step=1.29s, eta=7:40:5\n",
      "2022-01-20 10:59:31 [INFO]\t[TRAIN] Epoch=6/50, Step=260/478, loss=0.093628, lr=0.091030, time_each_step=1.29s, eta=7:40:15\n",
      "2022-01-20 10:59:34 [INFO]\t[TRAIN] Epoch=6/50, Step=262/478, loss=0.068347, lr=0.091023, time_each_step=1.28s, eta=7:39:28\n",
      "2022-01-20 10:59:36 [INFO]\t[TRAIN] Epoch=6/50, Step=264/478, loss=0.085152, lr=0.091016, time_each_step=1.29s, eta=7:39:45\n",
      "2022-01-20 10:59:39 [INFO]\t[TRAIN] Epoch=6/50, Step=266/478, loss=0.068942, lr=0.091010, time_each_step=1.29s, eta=7:39:49\n",
      "2022-01-20 10:59:41 [INFO]\t[TRAIN] Epoch=6/50, Step=268/478, loss=0.092887, lr=0.091003, time_each_step=1.29s, eta=7:39:46\n",
      "2022-01-20 10:59:44 [INFO]\t[TRAIN] Epoch=6/50, Step=270/478, loss=0.062199, lr=0.090996, time_each_step=1.29s, eta=7:40:37\n",
      "2022-01-20 10:59:47 [INFO]\t[TRAIN] Epoch=6/50, Step=272/478, loss=0.075197, lr=0.090989, time_each_step=1.29s, eta=7:40:53\n",
      "2022-01-20 10:59:49 [INFO]\t[TRAIN] Epoch=6/50, Step=274/478, loss=0.090905, lr=0.090982, time_each_step=1.29s, eta=7:40:25\n",
      "2022-01-20 10:59:52 [INFO]\t[TRAIN] Epoch=6/50, Step=276/478, loss=0.122530, lr=0.090975, time_each_step=1.29s, eta=7:39:49\n",
      "2022-01-20 10:59:54 [INFO]\t[TRAIN] Epoch=6/50, Step=278/478, loss=0.082070, lr=0.090968, time_each_step=1.29s, eta=7:39:59\n",
      "2022-01-20 10:59:57 [INFO]\t[TRAIN] Epoch=6/50, Step=280/478, loss=0.076923, lr=0.090962, time_each_step=1.29s, eta=7:39:49\n",
      "2022-01-20 10:59:59 [INFO]\t[TRAIN] Epoch=6/50, Step=282/478, loss=0.084229, lr=0.090955, time_each_step=1.29s, eta=7:39:42\n",
      "2022-01-20 11:00:02 [INFO]\t[TRAIN] Epoch=6/50, Step=284/478, loss=0.108137, lr=0.090948, time_each_step=1.29s, eta=7:40:30\n",
      "2022-01-20 11:00:05 [INFO]\t[TRAIN] Epoch=6/50, Step=286/478, loss=0.080258, lr=0.090941, time_each_step=1.29s, eta=7:39:32\n",
      "2022-01-20 11:00:07 [INFO]\t[TRAIN] Epoch=6/50, Step=288/478, loss=0.095457, lr=0.090934, time_each_step=1.29s, eta=7:40:4\n",
      "2022-01-20 11:00:10 [INFO]\t[TRAIN] Epoch=6/50, Step=290/478, loss=0.138795, lr=0.090927, time_each_step=1.29s, eta=7:39:48\n",
      "2022-01-20 11:00:12 [INFO]\t[TRAIN] Epoch=6/50, Step=292/478, loss=0.105911, lr=0.090920, time_each_step=1.29s, eta=7:39:7\n",
      "2022-01-20 11:00:15 [INFO]\t[TRAIN] Epoch=6/50, Step=294/478, loss=0.069828, lr=0.090914, time_each_step=1.29s, eta=7:39:41\n",
      "2022-01-20 11:00:17 [INFO]\t[TRAIN] Epoch=6/50, Step=296/478, loss=0.072403, lr=0.090907, time_each_step=1.29s, eta=7:40:56\n",
      "2022-01-20 11:00:20 [INFO]\t[TRAIN] Epoch=6/50, Step=298/478, loss=0.095199, lr=0.090900, time_each_step=1.29s, eta=7:39:25\n",
      "2022-01-20 11:00:23 [INFO]\t[TRAIN] Epoch=6/50, Step=300/478, loss=0.070906, lr=0.090893, time_each_step=1.29s, eta=7:39:14\n",
      "2022-01-20 11:00:25 [INFO]\t[TRAIN] Epoch=6/50, Step=302/478, loss=0.053715, lr=0.090886, time_each_step=1.29s, eta=7:39:34\n",
      "2022-01-20 11:00:28 [INFO]\t[TRAIN] Epoch=6/50, Step=304/478, loss=0.065733, lr=0.090879, time_each_step=1.28s, eta=7:38:22\n",
      "2022-01-20 11:00:30 [INFO]\t[TRAIN] Epoch=6/50, Step=306/478, loss=0.079974, lr=0.090872, time_each_step=1.29s, eta=7:38:53\n",
      "2022-01-20 11:00:33 [INFO]\t[TRAIN] Epoch=6/50, Step=308/478, loss=0.065764, lr=0.090866, time_each_step=1.29s, eta=7:39:52\n",
      "2022-01-20 11:00:35 [INFO]\t[TRAIN] Epoch=6/50, Step=310/478, loss=0.085954, lr=0.090859, time_each_step=1.29s, eta=7:39:8\n",
      "2022-01-20 11:00:38 [INFO]\t[TRAIN] Epoch=6/50, Step=312/478, loss=0.080102, lr=0.090852, time_each_step=1.28s, eta=7:38:29\n",
      "2022-01-20 11:00:41 [INFO]\t[TRAIN] Epoch=6/50, Step=314/478, loss=0.053688, lr=0.090845, time_each_step=1.29s, eta=7:40:36\n",
      "2022-01-20 11:00:43 [INFO]\t[TRAIN] Epoch=6/50, Step=316/478, loss=0.058916, lr=0.090838, time_each_step=1.28s, eta=7:38:27\n",
      "2022-01-20 11:00:46 [INFO]\t[TRAIN] Epoch=6/50, Step=318/478, loss=0.073139, lr=0.090831, time_each_step=1.29s, eta=7:38:45\n",
      "2022-01-20 11:00:48 [INFO]\t[TRAIN] Epoch=6/50, Step=320/478, loss=0.063507, lr=0.090824, time_each_step=1.29s, eta=7:39:44\n",
      "2022-01-20 11:00:51 [INFO]\t[TRAIN] Epoch=6/50, Step=322/478, loss=0.066214, lr=0.090818, time_each_step=1.28s, eta=7:37:53\n",
      "2022-01-20 11:00:53 [INFO]\t[TRAIN] Epoch=6/50, Step=324/478, loss=0.056679, lr=0.090811, time_each_step=1.29s, eta=7:39:0\n",
      "2022-01-20 11:00:56 [INFO]\t[TRAIN] Epoch=6/50, Step=326/478, loss=0.105729, lr=0.090804, time_each_step=1.29s, eta=7:39:23\n",
      "2022-01-20 11:00:59 [INFO]\t[TRAIN] Epoch=6/50, Step=328/478, loss=0.095519, lr=0.090797, time_each_step=1.29s, eta=7:38:50\n",
      "2022-01-20 11:01:01 [INFO]\t[TRAIN] Epoch=6/50, Step=330/478, loss=0.068827, lr=0.090790, time_each_step=1.28s, eta=7:38:15\n",
      "2022-01-20 11:01:04 [INFO]\t[TRAIN] Epoch=6/50, Step=332/478, loss=0.064873, lr=0.090783, time_each_step=1.29s, eta=7:39:2\n",
      "2022-01-20 11:01:06 [INFO]\t[TRAIN] Epoch=6/50, Step=334/478, loss=0.082444, lr=0.090776, time_each_step=1.29s, eta=7:38:27\n",
      "2022-01-20 11:01:09 [INFO]\t[TRAIN] Epoch=6/50, Step=336/478, loss=0.065964, lr=0.090770, time_each_step=1.28s, eta=7:37:49\n",
      "2022-01-20 11:01:12 [INFO]\t[TRAIN] Epoch=6/50, Step=338/478, loss=0.116783, lr=0.090763, time_each_step=1.29s, eta=7:39:26\n",
      "2022-01-20 11:01:14 [INFO]\t[TRAIN] Epoch=6/50, Step=340/478, loss=0.065455, lr=0.090756, time_each_step=1.28s, eta=7:37:33\n",
      "2022-01-20 11:01:17 [INFO]\t[TRAIN] Epoch=6/50, Step=342/478, loss=0.088169, lr=0.090749, time_each_step=1.28s, eta=7:37:53\n",
      "2022-01-20 11:01:19 [INFO]\t[TRAIN] Epoch=6/50, Step=344/478, loss=0.125980, lr=0.090742, time_each_step=1.29s, eta=7:39:6\n",
      "2022-01-20 11:01:22 [INFO]\t[TRAIN] Epoch=6/50, Step=346/478, loss=0.107464, lr=0.090735, time_each_step=1.29s, eta=7:38:43\n",
      "2022-01-20 11:01:24 [INFO]\t[TRAIN] Epoch=6/50, Step=348/478, loss=0.050266, lr=0.090728, time_each_step=1.29s, eta=7:38:44\n",
      "2022-01-20 11:01:27 [INFO]\t[TRAIN] Epoch=6/50, Step=350/478, loss=0.065444, lr=0.090722, time_each_step=1.29s, eta=7:38:43\n",
      "2022-01-20 11:01:30 [INFO]\t[TRAIN] Epoch=6/50, Step=352/478, loss=0.104095, lr=0.090715, time_each_step=1.28s, eta=7:37:24\n",
      "2022-01-20 11:01:32 [INFO]\t[TRAIN] Epoch=6/50, Step=354/478, loss=0.094260, lr=0.090708, time_each_step=1.29s, eta=7:38:10\n",
      "2022-01-20 11:01:35 [INFO]\t[TRAIN] Epoch=6/50, Step=356/478, loss=0.081479, lr=0.090701, time_each_step=1.29s, eta=7:37:57\n",
      "2022-01-20 11:01:37 [INFO]\t[TRAIN] Epoch=6/50, Step=358/478, loss=0.111427, lr=0.090694, time_each_step=1.29s, eta=7:38:7\n",
      "2022-01-20 11:01:40 [INFO]\t[TRAIN] Epoch=6/50, Step=360/478, loss=0.051300, lr=0.090687, time_each_step=1.29s, eta=7:38:22\n",
      "2022-01-20 11:01:42 [INFO]\t[TRAIN] Epoch=6/50, Step=362/478, loss=0.077676, lr=0.090680, time_each_step=1.28s, eta=7:37:3\n",
      "2022-01-20 11:01:45 [INFO]\t[TRAIN] Epoch=6/50, Step=364/478, loss=0.072772, lr=0.090674, time_each_step=1.29s, eta=7:39:10\n",
      "2022-01-20 11:01:48 [INFO]\t[TRAIN] Epoch=6/50, Step=366/478, loss=0.069098, lr=0.090667, time_each_step=1.28s, eta=7:37:2\n",
      "2022-01-20 11:01:50 [INFO]\t[TRAIN] Epoch=6/50, Step=368/478, loss=0.098056, lr=0.090660, time_each_step=1.29s, eta=7:38:46\n",
      "2022-01-20 11:01:53 [INFO]\t[TRAIN] Epoch=6/50, Step=370/478, loss=0.081109, lr=0.090653, time_each_step=1.29s, eta=7:37:47\n",
      "2022-01-20 11:01:55 [INFO]\t[TRAIN] Epoch=6/50, Step=372/478, loss=0.066866, lr=0.090646, time_each_step=1.29s, eta=7:37:34\n",
      "2022-01-20 11:01:58 [INFO]\t[TRAIN] Epoch=6/50, Step=374/478, loss=0.069565, lr=0.090639, time_each_step=1.29s, eta=7:39:13\n",
      "2022-01-20 11:02:00 [INFO]\t[TRAIN] Epoch=6/50, Step=376/478, loss=0.071242, lr=0.090632, time_each_step=1.28s, eta=7:37:14\n",
      "2022-01-20 11:02:03 [INFO]\t[TRAIN] Epoch=6/50, Step=378/478, loss=0.112581, lr=0.090626, time_each_step=1.29s, eta=7:37:28\n",
      "2022-01-20 11:02:06 [INFO]\t[TRAIN] Epoch=6/50, Step=380/478, loss=0.058905, lr=0.090619, time_each_step=1.29s, eta=7:37:39\n",
      "2022-01-20 11:02:08 [INFO]\t[TRAIN] Epoch=6/50, Step=382/478, loss=0.094736, lr=0.090612, time_each_step=1.28s, eta=7:37:1\n",
      "2022-01-20 11:02:11 [INFO]\t[TRAIN] Epoch=6/50, Step=384/478, loss=0.104792, lr=0.090605, time_each_step=1.28s, eta=7:37:1\n",
      "2022-01-20 11:02:13 [INFO]\t[TRAIN] Epoch=6/50, Step=386/478, loss=0.087161, lr=0.090598, time_each_step=1.29s, eta=7:37:31\n",
      "2022-01-20 11:02:16 [INFO]\t[TRAIN] Epoch=6/50, Step=388/478, loss=0.054568, lr=0.090591, time_each_step=1.29s, eta=7:37:43\n",
      "2022-01-20 11:02:18 [INFO]\t[TRAIN] Epoch=6/50, Step=390/478, loss=0.104443, lr=0.090584, time_each_step=1.29s, eta=7:37:17\n",
      "2022-01-20 11:02:21 [INFO]\t[TRAIN] Epoch=6/50, Step=392/478, loss=0.087334, lr=0.090578, time_each_step=1.29s, eta=7:38:37\n",
      "2022-01-20 11:02:24 [INFO]\t[TRAIN] Epoch=6/50, Step=394/478, loss=0.058880, lr=0.090571, time_each_step=1.29s, eta=7:37:21\n",
      "2022-01-20 11:02:26 [INFO]\t[TRAIN] Epoch=6/50, Step=396/478, loss=0.118742, lr=0.090564, time_each_step=1.29s, eta=7:37:9\n",
      "2022-01-20 11:02:29 [INFO]\t[TRAIN] Epoch=6/50, Step=398/478, loss=0.073502, lr=0.090557, time_each_step=1.29s, eta=7:38:30\n",
      "2022-01-20 11:02:31 [INFO]\t[TRAIN] Epoch=6/50, Step=400/478, loss=0.077787, lr=0.090550, time_each_step=1.29s, eta=7:36:58\n",
      "2022-01-20 11:02:34 [INFO]\t[TRAIN] Epoch=6/50, Step=402/478, loss=0.067891, lr=0.090543, time_each_step=1.29s, eta=7:36:48\n",
      "2022-01-20 11:02:36 [INFO]\t[TRAIN] Epoch=6/50, Step=404/478, loss=0.058565, lr=0.090536, time_each_step=1.29s, eta=7:37:49\n",
      "2022-01-20 11:02:39 [INFO]\t[TRAIN] Epoch=6/50, Step=406/478, loss=0.083847, lr=0.090529, time_each_step=1.29s, eta=7:36:40\n",
      "2022-01-20 11:02:42 [INFO]\t[TRAIN] Epoch=6/50, Step=408/478, loss=0.089230, lr=0.090523, time_each_step=1.29s, eta=7:36:58\n",
      "2022-01-20 11:02:44 [INFO]\t[TRAIN] Epoch=6/50, Step=410/478, loss=0.067677, lr=0.090516, time_each_step=1.29s, eta=7:37:14\n",
      "2022-01-20 11:02:47 [INFO]\t[TRAIN] Epoch=6/50, Step=412/478, loss=0.070560, lr=0.090509, time_each_step=1.29s, eta=7:37:8\n",
      "2022-01-20 11:02:49 [INFO]\t[TRAIN] Epoch=6/50, Step=414/478, loss=0.085428, lr=0.090502, time_each_step=1.28s, eta=7:36:15\n",
      "2022-01-20 11:02:52 [INFO]\t[TRAIN] Epoch=6/50, Step=416/478, loss=0.088207, lr=0.090495, time_each_step=1.29s, eta=7:37:40\n",
      "2022-01-20 11:02:54 [INFO]\t[TRAIN] Epoch=6/50, Step=418/478, loss=0.076756, lr=0.090488, time_each_step=1.28s, eta=7:35:52\n",
      "2022-01-20 11:02:57 [INFO]\t[TRAIN] Epoch=6/50, Step=420/478, loss=0.078408, lr=0.090481, time_each_step=1.29s, eta=7:36:57\n",
      "2022-01-20 11:03:00 [INFO]\t[TRAIN] Epoch=6/50, Step=422/478, loss=0.068021, lr=0.090475, time_each_step=1.29s, eta=7:37:14\n",
      "2022-01-20 11:03:02 [INFO]\t[TRAIN] Epoch=6/50, Step=424/478, loss=0.100422, lr=0.090468, time_each_step=1.29s, eta=7:36:33\n",
      "2022-01-20 11:03:05 [INFO]\t[TRAIN] Epoch=6/50, Step=426/478, loss=0.065731, lr=0.090461, time_each_step=1.29s, eta=7:36:22\n",
      "2022-01-20 11:03:07 [INFO]\t[TRAIN] Epoch=6/50, Step=428/478, loss=0.066658, lr=0.090454, time_each_step=1.29s, eta=7:37:20\n",
      "2022-01-20 11:03:10 [INFO]\t[TRAIN] Epoch=6/50, Step=430/478, loss=0.063918, lr=0.090447, time_each_step=1.29s, eta=7:36:24\n",
      "2022-01-20 11:03:12 [INFO]\t[TRAIN] Epoch=6/50, Step=432/478, loss=0.056170, lr=0.090440, time_each_step=1.29s, eta=7:36:14\n",
      "2022-01-20 11:03:15 [INFO]\t[TRAIN] Epoch=6/50, Step=434/478, loss=0.085585, lr=0.090433, time_each_step=1.29s, eta=7:36:46\n",
      "2022-01-20 11:03:18 [INFO]\t[TRAIN] Epoch=6/50, Step=436/478, loss=0.071566, lr=0.090427, time_each_step=1.29s, eta=7:36:15\n",
      "2022-01-20 11:03:20 [INFO]\t[TRAIN] Epoch=6/50, Step=438/478, loss=0.076432, lr=0.090420, time_each_step=1.29s, eta=7:36:11\n",
      "2022-01-20 11:03:23 [INFO]\t[TRAIN] Epoch=6/50, Step=440/478, loss=0.066258, lr=0.090413, time_each_step=1.29s, eta=7:36:22\n",
      "2022-01-20 11:03:25 [INFO]\t[TRAIN] Epoch=6/50, Step=442/478, loss=0.072600, lr=0.090406, time_each_step=1.29s, eta=7:35:53\n",
      "2022-01-20 11:03:28 [INFO]\t[TRAIN] Epoch=6/50, Step=444/478, loss=0.107374, lr=0.090399, time_each_step=1.29s, eta=7:35:54\n",
      "2022-01-20 11:03:30 [INFO]\t[TRAIN] Epoch=6/50, Step=446/478, loss=0.063245, lr=0.090392, time_each_step=1.29s, eta=7:36:42\n",
      "2022-01-20 11:03:33 [INFO]\t[TRAIN] Epoch=6/50, Step=448/478, loss=0.117859, lr=0.090385, time_each_step=1.29s, eta=7:36:54\n",
      "2022-01-20 11:03:36 [INFO]\t[TRAIN] Epoch=6/50, Step=450/478, loss=0.073523, lr=0.090378, time_each_step=1.29s, eta=7:36:23\n",
      "2022-01-20 11:03:38 [INFO]\t[TRAIN] Epoch=6/50, Step=452/478, loss=0.064036, lr=0.090372, time_each_step=1.29s, eta=7:36:2\n",
      "2022-01-20 11:03:41 [INFO]\t[TRAIN] Epoch=6/50, Step=454/478, loss=0.100566, lr=0.090365, time_each_step=1.29s, eta=7:36:42\n",
      "2022-01-20 11:03:43 [INFO]\t[TRAIN] Epoch=6/50, Step=456/478, loss=0.082444, lr=0.090358, time_each_step=1.28s, eta=7:35:2\n",
      "2022-01-20 11:03:46 [INFO]\t[TRAIN] Epoch=6/50, Step=458/478, loss=0.079823, lr=0.090351, time_each_step=1.29s, eta=7:37:24\n",
      "2022-01-20 11:03:48 [INFO]\t[TRAIN] Epoch=6/50, Step=460/478, loss=0.090474, lr=0.090344, time_each_step=1.29s, eta=7:35:55\n",
      "2022-01-20 11:03:51 [INFO]\t[TRAIN] Epoch=6/50, Step=462/478, loss=0.081962, lr=0.090337, time_each_step=1.29s, eta=7:36:2\n",
      "2022-01-20 11:03:54 [INFO]\t[TRAIN] Epoch=6/50, Step=464/478, loss=0.050767, lr=0.090330, time_each_step=1.29s, eta=7:36:36\n",
      "2022-01-20 11:03:56 [INFO]\t[TRAIN] Epoch=6/50, Step=466/478, loss=0.069701, lr=0.090324, time_each_step=1.29s, eta=7:35:29\n",
      "2022-01-20 11:03:59 [INFO]\t[TRAIN] Epoch=6/50, Step=468/478, loss=0.085607, lr=0.090317, time_each_step=1.29s, eta=7:35:54\n",
      "2022-01-20 11:04:01 [INFO]\t[TRAIN] Epoch=6/50, Step=470/478, loss=0.103063, lr=0.090310, time_each_step=1.29s, eta=7:36:21\n",
      "2022-01-20 11:04:04 [INFO]\t[TRAIN] Epoch=6/50, Step=472/478, loss=0.094953, lr=0.090303, time_each_step=1.28s, eta=7:35:5\n",
      "2022-01-20 11:04:06 [INFO]\t[TRAIN] Epoch=6/50, Step=474/478, loss=0.092541, lr=0.090296, time_each_step=1.28s, eta=7:34:58\n",
      "2022-01-20 11:04:09 [INFO]\t[TRAIN] Epoch=6/50, Step=476/478, loss=0.071332, lr=0.090289, time_each_step=1.29s, eta=7:35:45\n",
      "2022-01-20 11:04:12 [INFO]\t[TRAIN] Epoch=6/50, Step=478/478, loss=0.101375, lr=0.090282, time_each_step=1.28s, eta=7:34:32\n",
      "2022-01-20 11:04:12 [INFO]\t[TRAIN] Epoch 6 finished, loss=0.0805928 .\n",
      "2022-01-20 11:04:12 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-01-20 11:04:12 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-01-20 11:04:18 [INFO]\t[EVAL] Finished, Epoch=6, miou=0.833151, category_iou=[0.97193265 0.7317512  0.7957689 ], oacc=0.973401, category_acc=[0.9879514  0.85005695 0.8666424 ], kappa=0.871871, category_F1-score=[0.98576654 0.84509974 0.88627098] .\n",
      "2022-01-20 11:04:19 [INFO]\tModel saved in model/deeplab_augument_alldata2/best_model.\n",
      "2022-01-20 11:04:19 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_6, miou=0.8331509232521057\n",
      "2022-01-20 11:04:19 [INFO]\tModel saved in model/deeplab_augument_alldata2/epoch_6.\n",
      "2022-01-20 11:04:23 [INFO]\t[TRAIN] Epoch=7/50, Step=2/478, loss=0.079206, lr=0.090275, time_each_step=1.93s, eta=11:22:58\n",
      "2022-01-20 11:04:26 [INFO]\t[TRAIN] Epoch=7/50, Step=4/478, loss=0.096823, lr=0.090269, time_each_step=1.28s, eta=7:34:25\n",
      "2022-01-20 11:04:28 [INFO]\t[TRAIN] Epoch=7/50, Step=6/478, loss=0.072578, lr=0.090262, time_each_step=1.28s, eta=7:34:30\n",
      "2022-01-20 11:04:31 [INFO]\t[TRAIN] Epoch=7/50, Step=8/478, loss=0.072331, lr=0.090255, time_each_step=1.28s, eta=7:35:3\n",
      "2022-01-20 11:04:33 [INFO]\t[TRAIN] Epoch=7/50, Step=10/478, loss=0.111842, lr=0.090248, time_each_step=1.28s, eta=7:34:4\n",
      "2022-01-20 11:04:36 [INFO]\t[TRAIN] Epoch=7/50, Step=12/478, loss=0.074302, lr=0.090241, time_each_step=1.28s, eta=7:34:19\n",
      "2022-01-20 11:04:39 [INFO]\t[TRAIN] Epoch=7/50, Step=14/478, loss=0.103946, lr=0.090234, time_each_step=1.29s, eta=7:35:26\n",
      "2022-01-20 11:04:41 [INFO]\t[TRAIN] Epoch=7/50, Step=16/478, loss=0.069248, lr=0.090227, time_each_step=1.29s, eta=7:36:6\n",
      "2022-01-20 11:04:44 [INFO]\t[TRAIN] Epoch=7/50, Step=18/478, loss=0.077966, lr=0.090220, time_each_step=1.28s, eta=7:34:20\n",
      "2022-01-20 11:04:46 [INFO]\t[TRAIN] Epoch=7/50, Step=20/478, loss=0.058516, lr=0.090214, time_each_step=1.29s, eta=7:35:20\n",
      "2022-01-20 11:04:49 [INFO]\t[TRAIN] Epoch=7/50, Step=22/478, loss=0.099864, lr=0.090207, time_each_step=1.29s, eta=7:36:34\n",
      "2022-01-20 11:04:51 [INFO]\t[TRAIN] Epoch=7/50, Step=24/478, loss=0.066128, lr=0.090200, time_each_step=1.29s, eta=7:35:10\n",
      "2022-01-20 11:04:54 [INFO]\t[TRAIN] Epoch=7/50, Step=26/478, loss=0.093047, lr=0.090193, time_each_step=1.29s, eta=7:34:58\n",
      "2022-01-20 11:04:57 [INFO]\t[TRAIN] Epoch=7/50, Step=28/478, loss=0.072993, lr=0.090186, time_each_step=1.29s, eta=7:35:27\n",
      "2022-01-20 11:04:59 [INFO]\t[TRAIN] Epoch=7/50, Step=30/478, loss=0.091871, lr=0.090179, time_each_step=1.28s, eta=7:33:58\n",
      "2022-01-20 11:05:02 [INFO]\t[TRAIN] Epoch=7/50, Step=32/478, loss=0.084310, lr=0.090172, time_each_step=1.29s, eta=7:35:12\n",
      "2022-01-20 11:05:04 [INFO]\t[TRAIN] Epoch=7/50, Step=34/478, loss=0.061404, lr=0.090166, time_each_step=1.29s, eta=7:35:36\n",
      "2022-01-20 11:05:07 [INFO]\t[TRAIN] Epoch=7/50, Step=36/478, loss=0.049667, lr=0.090159, time_each_step=1.28s, eta=7:34:25\n",
      "2022-01-20 11:05:09 [INFO]\t[TRAIN] Epoch=7/50, Step=38/478, loss=0.070060, lr=0.090152, time_each_step=1.29s, eta=7:37:23\n",
      "2022-01-20 11:05:12 [INFO]\t[TRAIN] Epoch=7/50, Step=40/478, loss=0.073940, lr=0.090145, time_each_step=1.29s, eta=7:35:39\n",
      "2022-01-20 11:05:15 [INFO]\t[TRAIN] Epoch=7/50, Step=42/478, loss=0.077369, lr=0.090138, time_each_step=1.28s, eta=7:34:28\n",
      "2022-01-20 11:05:17 [INFO]\t[TRAIN] Epoch=7/50, Step=44/478, loss=0.054497, lr=0.090131, time_each_step=1.29s, eta=7:35:24\n",
      "2022-01-20 11:05:20 [INFO]\t[TRAIN] Epoch=7/50, Step=46/478, loss=0.053785, lr=0.090124, time_each_step=1.29s, eta=7:35:35\n",
      "2022-01-20 11:05:22 [INFO]\t[TRAIN] Epoch=7/50, Step=48/478, loss=0.062152, lr=0.090117, time_each_step=1.28s, eta=7:34:9\n",
      "2022-01-20 11:05:25 [INFO]\t[TRAIN] Epoch=7/50, Step=50/478, loss=0.070035, lr=0.090111, time_each_step=1.29s, eta=7:35:21\n",
      "2022-01-20 11:05:27 [INFO]\t[TRAIN] Epoch=7/50, Step=52/478, loss=0.061807, lr=0.090104, time_each_step=1.29s, eta=7:34:56\n",
      "2022-01-20 11:05:30 [INFO]\t[TRAIN] Epoch=7/50, Step=54/478, loss=0.061838, lr=0.090097, time_each_step=1.29s, eta=7:34:55\n",
      "2022-01-20 11:05:33 [INFO]\t[TRAIN] Epoch=7/50, Step=56/478, loss=0.102653, lr=0.090090, time_each_step=1.29s, eta=7:34:36\n",
      "2022-01-20 11:05:35 [INFO]\t[TRAIN] Epoch=7/50, Step=58/478, loss=0.079253, lr=0.090083, time_each_step=1.29s, eta=7:35:10\n",
      "2022-01-20 11:05:38 [INFO]\t[TRAIN] Epoch=7/50, Step=60/478, loss=0.063118, lr=0.090076, time_each_step=1.28s, eta=7:34:6\n",
      "2022-01-20 11:05:40 [INFO]\t[TRAIN] Epoch=7/50, Step=62/478, loss=0.075843, lr=0.090069, time_each_step=1.29s, eta=7:34:56\n",
      "2022-01-20 11:05:43 [INFO]\t[TRAIN] Epoch=7/50, Step=64/478, loss=0.079886, lr=0.090062, time_each_step=1.29s, eta=7:34:24\n",
      "2022-01-20 11:05:45 [INFO]\t[TRAIN] Epoch=7/50, Step=66/478, loss=0.071535, lr=0.090056, time_each_step=1.29s, eta=7:34:42\n",
      "2022-01-20 11:05:48 [INFO]\t[TRAIN] Epoch=7/50, Step=68/478, loss=0.073646, lr=0.090049, time_each_step=1.29s, eta=7:35:5\n",
      "2022-01-20 11:05:51 [INFO]\t[TRAIN] Epoch=7/50, Step=70/478, loss=0.069510, lr=0.090042, time_each_step=1.29s, eta=7:34:31\n",
      "2022-01-20 11:05:53 [INFO]\t[TRAIN] Epoch=7/50, Step=72/478, loss=0.093259, lr=0.090035, time_each_step=1.28s, eta=7:33:51\n",
      "2022-01-20 11:05:56 [INFO]\t[TRAIN] Epoch=7/50, Step=74/478, loss=0.075462, lr=0.090028, time_each_step=1.29s, eta=7:34:53\n",
      "2022-01-20 11:05:58 [INFO]\t[TRAIN] Epoch=7/50, Step=76/478, loss=0.078636, lr=0.090021, time_each_step=1.29s, eta=7:34:35\n",
      "2022-01-20 11:06:01 [INFO]\t[TRAIN] Epoch=7/50, Step=78/478, loss=0.091260, lr=0.090014, time_each_step=1.29s, eta=7:34:2\n",
      "2022-01-20 11:06:03 [INFO]\t[TRAIN] Epoch=7/50, Step=80/478, loss=0.046463, lr=0.090007, time_each_step=1.29s, eta=7:34:18\n",
      "2022-01-20 11:06:06 [INFO]\t[TRAIN] Epoch=7/50, Step=82/478, loss=0.085457, lr=0.090001, time_each_step=1.29s, eta=7:34:25\n",
      "2022-01-20 11:06:09 [INFO]\t[TRAIN] Epoch=7/50, Step=84/478, loss=0.062553, lr=0.089994, time_each_step=1.29s, eta=7:34:30\n",
      "2022-01-20 11:06:11 [INFO]\t[TRAIN] Epoch=7/50, Step=86/478, loss=0.107404, lr=0.089987, time_each_step=1.29s, eta=7:34:20\n",
      "2022-01-20 11:06:14 [INFO]\t[TRAIN] Epoch=7/50, Step=88/478, loss=0.124001, lr=0.089980, time_each_step=1.29s, eta=7:34:0\n",
      "2022-01-20 11:06:16 [INFO]\t[TRAIN] Epoch=7/50, Step=90/478, loss=0.097286, lr=0.089973, time_each_step=1.28s, eta=7:33:13\n",
      "2022-01-20 11:06:19 [INFO]\t[TRAIN] Epoch=7/50, Step=92/478, loss=0.093437, lr=0.089966, time_each_step=1.29s, eta=7:34:53\n",
      "2022-01-20 11:06:21 [INFO]\t[TRAIN] Epoch=7/50, Step=94/478, loss=0.058272, lr=0.089959, time_each_step=1.29s, eta=7:33:27\n",
      "2022-01-20 11:06:24 [INFO]\t[TRAIN] Epoch=7/50, Step=96/478, loss=0.118257, lr=0.089953, time_each_step=1.29s, eta=7:33:35\n",
      "2022-01-20 11:06:27 [INFO]\t[TRAIN] Epoch=7/50, Step=98/478, loss=0.082989, lr=0.089946, time_each_step=1.29s, eta=7:34:50\n",
      "2022-01-20 11:06:29 [INFO]\t[TRAIN] Epoch=7/50, Step=100/478, loss=0.076862, lr=0.089939, time_each_step=1.28s, eta=7:33:10\n",
      "2022-01-20 11:06:32 [INFO]\t[TRAIN] Epoch=7/50, Step=102/478, loss=0.063049, lr=0.089932, time_each_step=1.29s, eta=7:34:3\n",
      "2022-01-20 11:06:34 [INFO]\t[TRAIN] Epoch=7/50, Step=104/478, loss=0.050829, lr=0.089925, time_each_step=1.29s, eta=7:34:55\n",
      "2022-01-20 11:06:37 [INFO]\t[TRAIN] Epoch=7/50, Step=106/478, loss=0.091216, lr=0.089918, time_each_step=1.28s, eta=7:33:4\n",
      "2022-01-20 11:06:39 [INFO]\t[TRAIN] Epoch=7/50, Step=108/478, loss=0.076848, lr=0.089911, time_each_step=1.29s, eta=7:35:0\n",
      "2022-01-20 11:06:42 [INFO]\t[TRAIN] Epoch=7/50, Step=110/478, loss=0.107811, lr=0.089904, time_each_step=1.29s, eta=7:34:4\n",
      "2022-01-20 11:06:45 [INFO]\t[TRAIN] Epoch=7/50, Step=112/478, loss=0.072203, lr=0.089898, time_each_step=1.28s, eta=7:33:1\n",
      "2022-01-20 11:06:47 [INFO]\t[TRAIN] Epoch=7/50, Step=114/478, loss=0.060539, lr=0.089891, time_each_step=1.29s, eta=7:33:49\n",
      "2022-01-20 11:06:50 [INFO]\t[TRAIN] Epoch=7/50, Step=116/478, loss=0.080142, lr=0.089884, time_each_step=1.29s, eta=7:33:39\n",
      "2022-01-20 11:06:52 [INFO]\t[TRAIN] Epoch=7/50, Step=118/478, loss=0.042745, lr=0.089877, time_each_step=1.29s, eta=7:33:44\n",
      "2022-01-20 11:06:55 [INFO]\t[TRAIN] Epoch=7/50, Step=120/478, loss=0.061765, lr=0.089870, time_each_step=1.29s, eta=7:33:46\n",
      "2022-01-20 11:06:57 [INFO]\t[TRAIN] Epoch=7/50, Step=122/478, loss=0.055849, lr=0.089863, time_each_step=1.29s, eta=7:33:25\n",
      "2022-01-20 11:07:00 [INFO]\t[TRAIN] Epoch=7/50, Step=124/478, loss=0.092157, lr=0.089856, time_each_step=1.28s, eta=7:32:39\n",
      "2022-01-20 11:07:03 [INFO]\t[TRAIN] Epoch=7/50, Step=126/478, loss=0.070728, lr=0.089849, time_each_step=1.29s, eta=7:33:50\n",
      "2022-01-20 11:07:05 [INFO]\t[TRAIN] Epoch=7/50, Step=128/478, loss=0.106432, lr=0.089842, time_each_step=1.29s, eta=7:33:17\n",
      "2022-01-20 11:07:08 [INFO]\t[TRAIN] Epoch=7/50, Step=130/478, loss=0.056717, lr=0.089836, time_each_step=1.29s, eta=7:33:17\n",
      "2022-01-20 11:07:10 [INFO]\t[TRAIN] Epoch=7/50, Step=132/478, loss=0.070725, lr=0.089829, time_each_step=1.29s, eta=7:33:44\n",
      "2022-01-20 11:07:13 [INFO]\t[TRAIN] Epoch=7/50, Step=134/478, loss=0.081430, lr=0.089822, time_each_step=1.28s, eta=7:32:33\n",
      "2022-01-20 11:07:15 [INFO]\t[TRAIN] Epoch=7/50, Step=136/478, loss=0.099087, lr=0.089815, time_each_step=1.29s, eta=7:32:48\n",
      "2022-01-20 11:07:18 [INFO]\t[TRAIN] Epoch=7/50, Step=138/478, loss=0.066163, lr=0.089808, time_each_step=1.29s, eta=7:33:16\n",
      "2022-01-20 11:07:21 [INFO]\t[TRAIN] Epoch=7/50, Step=140/478, loss=0.093501, lr=0.089801, time_each_step=1.29s, eta=7:33:32\n",
      "2022-01-20 11:07:23 [INFO]\t[TRAIN] Epoch=7/50, Step=142/478, loss=0.084326, lr=0.089794, time_each_step=1.28s, eta=7:32:12\n",
      "2022-01-20 11:07:26 [INFO]\t[TRAIN] Epoch=7/50, Step=144/478, loss=0.099672, lr=0.089787, time_each_step=1.29s, eta=7:33:34\n",
      "2022-01-20 11:07:28 [INFO]\t[TRAIN] Epoch=7/50, Step=146/478, loss=0.094072, lr=0.089781, time_each_step=1.29s, eta=7:32:46\n",
      "2022-01-20 11:07:31 [INFO]\t[TRAIN] Epoch=7/50, Step=148/478, loss=0.113171, lr=0.089774, time_each_step=1.29s, eta=7:32:20\n",
      "2022-01-20 11:07:34 [INFO]\t[TRAIN] Epoch=7/50, Step=150/478, loss=0.073447, lr=0.089767, time_each_step=1.29s, eta=7:32:33\n",
      "2022-01-20 11:07:36 [INFO]\t[TRAIN] Epoch=7/50, Step=152/478, loss=0.070236, lr=0.089760, time_each_step=1.29s, eta=7:32:27\n",
      "2022-01-20 11:07:39 [INFO]\t[TRAIN] Epoch=7/50, Step=154/478, loss=0.082078, lr=0.089753, time_each_step=1.29s, eta=7:32:23\n",
      "2022-01-20 11:07:41 [INFO]\t[TRAIN] Epoch=7/50, Step=156/478, loss=0.067141, lr=0.089746, time_each_step=1.29s, eta=7:32:31\n",
      "2022-01-20 11:07:44 [INFO]\t[TRAIN] Epoch=7/50, Step=158/478, loss=0.069898, lr=0.089739, time_each_step=1.28s, eta=7:32:0\n",
      "2022-01-20 11:07:46 [INFO]\t[TRAIN] Epoch=7/50, Step=160/478, loss=0.083005, lr=0.089732, time_each_step=1.28s, eta=7:31:34\n",
      "2022-01-20 11:07:49 [INFO]\t[TRAIN] Epoch=7/50, Step=162/478, loss=0.085518, lr=0.089726, time_each_step=1.29s, eta=7:33:11\n",
      "2022-01-20 11:07:52 [INFO]\t[TRAIN] Epoch=7/50, Step=164/478, loss=0.085476, lr=0.089719, time_each_step=1.29s, eta=7:32:18\n",
      "2022-01-20 11:07:54 [INFO]\t[TRAIN] Epoch=7/50, Step=166/478, loss=0.077489, lr=0.089712, time_each_step=1.28s, eta=7:31:43\n",
      "2022-01-20 11:07:57 [INFO]\t[TRAIN] Epoch=7/50, Step=168/478, loss=0.084130, lr=0.089705, time_each_step=1.29s, eta=7:33:6\n",
      "2022-01-20 11:07:59 [INFO]\t[TRAIN] Epoch=7/50, Step=170/478, loss=0.096519, lr=0.089698, time_each_step=1.29s, eta=7:32:11\n",
      "2022-01-20 11:08:02 [INFO]\t[TRAIN] Epoch=7/50, Step=172/478, loss=0.092632, lr=0.089691, time_each_step=1.28s, eta=7:31:42\n",
      "2022-01-20 11:08:04 [INFO]\t[TRAIN] Epoch=7/50, Step=174/478, loss=0.055666, lr=0.089684, time_each_step=1.28s, eta=7:31:36\n",
      "2022-01-20 11:08:07 [INFO]\t[TRAIN] Epoch=7/50, Step=176/478, loss=0.082368, lr=0.089677, time_each_step=1.29s, eta=7:32:27\n",
      "2022-01-20 11:08:10 [INFO]\t[TRAIN] Epoch=7/50, Step=178/478, loss=0.086719, lr=0.089671, time_each_step=1.29s, eta=7:32:33\n",
      "2022-01-20 11:08:12 [INFO]\t[TRAIN] Epoch=7/50, Step=180/478, loss=0.049812, lr=0.089664, time_each_step=1.29s, eta=7:31:53\n",
      "2022-01-20 11:08:15 [INFO]\t[TRAIN] Epoch=7/50, Step=182/478, loss=0.072715, lr=0.089657, time_each_step=1.29s, eta=7:32:33\n",
      "2022-01-20 11:08:17 [INFO]\t[TRAIN] Epoch=7/50, Step=184/478, loss=0.049574, lr=0.089650, time_each_step=1.29s, eta=7:32:33\n",
      "2022-01-20 11:08:20 [INFO]\t[TRAIN] Epoch=7/50, Step=186/478, loss=0.057429, lr=0.089643, time_each_step=1.29s, eta=7:32:43\n",
      "2022-01-20 11:08:22 [INFO]\t[TRAIN] Epoch=7/50, Step=188/478, loss=0.068743, lr=0.089636, time_each_step=1.29s, eta=7:32:2\n",
      "2022-01-20 11:08:25 [INFO]\t[TRAIN] Epoch=7/50, Step=190/478, loss=0.076472, lr=0.089629, time_each_step=1.28s, eta=7:31:10\n",
      "2022-01-20 11:08:28 [INFO]\t[TRAIN] Epoch=7/50, Step=192/478, loss=0.065792, lr=0.089622, time_each_step=1.29s, eta=7:32:4\n",
      "2022-01-20 11:08:30 [INFO]\t[TRAIN] Epoch=7/50, Step=194/478, loss=0.074558, lr=0.089616, time_each_step=1.28s, eta=7:30:46\n",
      "2022-01-20 11:08:33 [INFO]\t[TRAIN] Epoch=7/50, Step=196/478, loss=0.081349, lr=0.089609, time_each_step=1.29s, eta=7:31:25\n",
      "2022-01-20 11:08:35 [INFO]\t[TRAIN] Epoch=7/50, Step=198/478, loss=0.054367, lr=0.089602, time_each_step=1.29s, eta=7:32:0\n",
      "2022-01-20 11:08:38 [INFO]\t[TRAIN] Epoch=7/50, Step=200/478, loss=0.090856, lr=0.089595, time_each_step=1.29s, eta=7:31:31\n",
      "2022-01-20 11:08:40 [INFO]\t[TRAIN] Epoch=7/50, Step=202/478, loss=0.084038, lr=0.089588, time_each_step=1.29s, eta=7:31:12\n",
      "2022-01-20 11:08:43 [INFO]\t[TRAIN] Epoch=7/50, Step=204/478, loss=0.085863, lr=0.089581, time_each_step=1.29s, eta=7:31:53\n",
      "2022-01-20 11:08:46 [INFO]\t[TRAIN] Epoch=7/50, Step=206/478, loss=0.071402, lr=0.089574, time_each_step=1.28s, eta=7:30:42\n",
      "2022-01-20 11:08:48 [INFO]\t[TRAIN] Epoch=7/50, Step=208/478, loss=0.053914, lr=0.089567, time_each_step=1.29s, eta=7:31:36\n",
      "2022-01-20 11:08:51 [INFO]\t[TRAIN] Epoch=7/50, Step=210/478, loss=0.050995, lr=0.089560, time_each_step=1.29s, eta=7:31:44\n",
      "2022-01-20 11:08:53 [INFO]\t[TRAIN] Epoch=7/50, Step=212/478, loss=0.094473, lr=0.089554, time_each_step=1.29s, eta=7:31:22\n",
      "2022-01-20 11:08:56 [INFO]\t[TRAIN] Epoch=7/50, Step=214/478, loss=0.077480, lr=0.089547, time_each_step=1.28s, eta=7:30:33\n",
      "2022-01-20 11:08:58 [INFO]\t[TRAIN] Epoch=7/50, Step=216/478, loss=0.088474, lr=0.089540, time_each_step=1.29s, eta=7:31:22\n",
      "2022-01-20 11:09:01 [INFO]\t[TRAIN] Epoch=7/50, Step=218/478, loss=0.071368, lr=0.089533, time_each_step=1.29s, eta=7:31:51\n",
      "2022-01-20 11:09:04 [INFO]\t[TRAIN] Epoch=7/50, Step=220/478, loss=0.063392, lr=0.089526, time_each_step=1.28s, eta=7:30:10\n",
      "2022-01-20 11:09:06 [INFO]\t[TRAIN] Epoch=7/50, Step=222/478, loss=0.098688, lr=0.089519, time_each_step=1.29s, eta=7:31:45\n",
      "2022-01-20 11:09:09 [INFO]\t[TRAIN] Epoch=7/50, Step=224/478, loss=0.124315, lr=0.089512, time_each_step=1.29s, eta=7:31:48\n",
      "2022-01-20 11:09:11 [INFO]\t[TRAIN] Epoch=7/50, Step=226/478, loss=0.097754, lr=0.089505, time_each_step=1.29s, eta=7:31:33\n",
      "2022-01-20 11:09:14 [INFO]\t[TRAIN] Epoch=7/50, Step=228/478, loss=0.080915, lr=0.089499, time_each_step=1.29s, eta=7:32:31\n",
      "2022-01-20 11:09:16 [INFO]\t[TRAIN] Epoch=7/50, Step=230/478, loss=0.089069, lr=0.089492, time_each_step=1.29s, eta=7:31:5\n",
      "2022-01-20 11:09:19 [INFO]\t[TRAIN] Epoch=7/50, Step=232/478, loss=0.080290, lr=0.089485, time_each_step=1.29s, eta=7:31:7\n",
      "2022-01-20 11:09:22 [INFO]\t[TRAIN] Epoch=7/50, Step=234/478, loss=0.076689, lr=0.089478, time_each_step=1.29s, eta=7:30:54\n",
      "2022-01-20 11:09:24 [INFO]\t[TRAIN] Epoch=7/50, Step=236/478, loss=0.065273, lr=0.089471, time_each_step=1.29s, eta=7:30:24\n",
      "2022-01-20 11:09:27 [INFO]\t[TRAIN] Epoch=7/50, Step=238/478, loss=0.083655, lr=0.089464, time_each_step=1.29s, eta=7:30:42\n",
      "2022-01-20 11:09:29 [INFO]\t[TRAIN] Epoch=7/50, Step=240/478, loss=0.076455, lr=0.089457, time_each_step=1.29s, eta=7:30:35\n",
      "2022-01-20 11:09:32 [INFO]\t[TRAIN] Epoch=7/50, Step=242/478, loss=0.085694, lr=0.089450, time_each_step=1.29s, eta=7:30:28\n",
      "2022-01-20 11:09:34 [INFO]\t[TRAIN] Epoch=7/50, Step=244/478, loss=0.061838, lr=0.089443, time_each_step=1.29s, eta=7:30:27\n",
      "2022-01-20 11:09:37 [INFO]\t[TRAIN] Epoch=7/50, Step=246/478, loss=0.071264, lr=0.089437, time_each_step=1.29s, eta=7:30:55\n",
      "2022-01-20 11:09:40 [INFO]\t[TRAIN] Epoch=7/50, Step=248/478, loss=0.185820, lr=0.089430, time_each_step=1.28s, eta=7:29:30\n",
      "2022-01-20 11:09:42 [INFO]\t[TRAIN] Epoch=7/50, Step=250/478, loss=0.080610, lr=0.089423, time_each_step=1.29s, eta=7:30:32\n",
      "2022-01-20 11:09:45 [INFO]\t[TRAIN] Epoch=7/50, Step=252/478, loss=0.056080, lr=0.089416, time_each_step=1.29s, eta=7:31:54\n",
      "2022-01-20 11:09:47 [INFO]\t[TRAIN] Epoch=7/50, Step=254/478, loss=0.067259, lr=0.089409, time_each_step=1.29s, eta=7:30:7\n",
      "2022-01-20 11:09:50 [INFO]\t[TRAIN] Epoch=7/50, Step=256/478, loss=0.078352, lr=0.089402, time_each_step=1.29s, eta=7:30:8\n",
      "2022-01-20 11:09:52 [INFO]\t[TRAIN] Epoch=7/50, Step=258/478, loss=0.068529, lr=0.089395, time_each_step=1.29s, eta=7:31:7\n",
      "2022-01-20 11:09:55 [INFO]\t[TRAIN] Epoch=7/50, Step=260/478, loss=0.061092, lr=0.089388, time_each_step=1.28s, eta=7:29:43\n",
      "2022-01-20 11:09:58 [INFO]\t[TRAIN] Epoch=7/50, Step=262/478, loss=0.085512, lr=0.089381, time_each_step=1.28s, eta=7:29:11\n",
      "2022-01-20 11:10:00 [INFO]\t[TRAIN] Epoch=7/50, Step=264/478, loss=0.069302, lr=0.089375, time_each_step=1.29s, eta=7:31:49\n",
      "2022-01-20 11:10:03 [INFO]\t[TRAIN] Epoch=7/50, Step=266/478, loss=0.079145, lr=0.089368, time_each_step=1.28s, eta=7:29:11\n",
      "2022-01-20 11:10:05 [INFO]\t[TRAIN] Epoch=7/50, Step=268/478, loss=0.053013, lr=0.089361, time_each_step=1.29s, eta=7:29:54\n",
      "2022-01-20 11:10:08 [INFO]\t[TRAIN] Epoch=7/50, Step=270/478, loss=0.083128, lr=0.089354, time_each_step=1.29s, eta=7:30:56\n",
      "2022-01-20 11:10:10 [INFO]\t[TRAIN] Epoch=7/50, Step=272/478, loss=0.055065, lr=0.089347, time_each_step=1.28s, eta=7:29:17\n",
      "2022-01-20 11:10:13 [INFO]\t[TRAIN] Epoch=7/50, Step=274/478, loss=0.076674, lr=0.089340, time_each_step=1.29s, eta=7:30:33\n",
      "2022-01-20 11:10:16 [INFO]\t[TRAIN] Epoch=7/50, Step=276/478, loss=0.085055, lr=0.089333, time_each_step=1.29s, eta=7:30:14\n",
      "2022-01-20 11:10:18 [INFO]\t[TRAIN] Epoch=7/50, Step=278/478, loss=0.058512, lr=0.089326, time_each_step=1.29s, eta=7:30:4\n",
      "2022-01-20 11:10:21 [INFO]\t[TRAIN] Epoch=7/50, Step=280/478, loss=0.050627, lr=0.089320, time_each_step=1.29s, eta=7:31:17\n",
      "2022-01-20 11:10:23 [INFO]\t[TRAIN] Epoch=7/50, Step=282/478, loss=0.075832, lr=0.089313, time_each_step=1.29s, eta=7:30:57\n",
      "2022-01-20 11:10:26 [INFO]\t[TRAIN] Epoch=7/50, Step=284/478, loss=0.064071, lr=0.089306, time_each_step=1.28s, eta=7:29:8\n",
      "2022-01-20 11:10:28 [INFO]\t[TRAIN] Epoch=7/50, Step=286/478, loss=0.070125, lr=0.089299, time_each_step=1.29s, eta=7:29:53\n",
      "2022-01-20 11:10:31 [INFO]\t[TRAIN] Epoch=7/50, Step=288/478, loss=0.073379, lr=0.089292, time_each_step=1.29s, eta=7:30:23\n",
      "2022-01-20 11:10:34 [INFO]\t[TRAIN] Epoch=7/50, Step=290/478, loss=0.059911, lr=0.089285, time_each_step=1.28s, eta=7:29:10\n",
      "2022-01-20 11:10:36 [INFO]\t[TRAIN] Epoch=7/50, Step=292/478, loss=0.060876, lr=0.089278, time_each_step=1.29s, eta=7:29:47\n",
      "2022-01-20 11:10:39 [INFO]\t[TRAIN] Epoch=7/50, Step=294/478, loss=0.075301, lr=0.089271, time_each_step=1.29s, eta=7:30:35\n",
      "2022-01-20 11:10:41 [INFO]\t[TRAIN] Epoch=7/50, Step=296/478, loss=0.053393, lr=0.089264, time_each_step=1.28s, eta=7:28:46\n",
      "2022-01-20 11:10:44 [INFO]\t[TRAIN] Epoch=7/50, Step=298/478, loss=0.112954, lr=0.089258, time_each_step=1.29s, eta=7:29:10\n",
      "2022-01-20 11:10:46 [INFO]\t[TRAIN] Epoch=7/50, Step=300/478, loss=0.112757, lr=0.089251, time_each_step=1.28s, eta=7:28:40\n",
      "2022-01-20 11:10:49 [INFO]\t[TRAIN] Epoch=7/50, Step=302/478, loss=0.089284, lr=0.089244, time_each_step=1.29s, eta=7:29:23\n",
      "2022-01-20 11:10:52 [INFO]\t[TRAIN] Epoch=7/50, Step=304/478, loss=0.055591, lr=0.089237, time_each_step=1.29s, eta=7:28:57\n",
      "2022-01-20 11:10:54 [INFO]\t[TRAIN] Epoch=7/50, Step=306/478, loss=0.087263, lr=0.089230, time_each_step=1.29s, eta=7:29:8\n",
      "2022-01-20 11:10:57 [INFO]\t[TRAIN] Epoch=7/50, Step=308/478, loss=0.067721, lr=0.089223, time_each_step=1.28s, eta=7:28:31\n",
      "2022-01-20 11:10:59 [INFO]\t[TRAIN] Epoch=7/50, Step=310/478, loss=0.079366, lr=0.089216, time_each_step=1.29s, eta=7:29:35\n",
      "2022-01-20 11:11:02 [INFO]\t[TRAIN] Epoch=7/50, Step=312/478, loss=0.079769, lr=0.089209, time_each_step=1.29s, eta=7:29:42\n",
      "2022-01-20 11:11:04 [INFO]\t[TRAIN] Epoch=7/50, Step=314/478, loss=0.092103, lr=0.089202, time_each_step=1.29s, eta=7:29:31\n",
      "2022-01-20 11:11:07 [INFO]\t[TRAIN] Epoch=7/50, Step=316/478, loss=0.062086, lr=0.089196, time_each_step=1.29s, eta=7:29:7\n",
      "2022-01-20 11:11:10 [INFO]\t[TRAIN] Epoch=7/50, Step=318/478, loss=0.082963, lr=0.089189, time_each_step=1.29s, eta=7:29:34\n",
      "2022-01-20 11:11:12 [INFO]\t[TRAIN] Epoch=7/50, Step=320/478, loss=0.097666, lr=0.089182, time_each_step=1.29s, eta=7:29:10\n",
      "2022-01-20 11:11:15 [INFO]\t[TRAIN] Epoch=7/50, Step=322/478, loss=0.089682, lr=0.089175, time_each_step=1.28s, eta=7:28:30\n",
      "2022-01-20 11:11:17 [INFO]\t[TRAIN] Epoch=7/50, Step=324/478, loss=0.051507, lr=0.089168, time_each_step=1.29s, eta=7:28:57\n",
      "2022-01-20 11:11:20 [INFO]\t[TRAIN] Epoch=7/50, Step=326/478, loss=0.064015, lr=0.089161, time_each_step=1.29s, eta=7:28:43\n",
      "2022-01-20 11:11:22 [INFO]\t[TRAIN] Epoch=7/50, Step=328/478, loss=0.042893, lr=0.089154, time_each_step=1.28s, eta=7:28:3\n",
      "2022-01-20 11:11:25 [INFO]\t[TRAIN] Epoch=7/50, Step=330/478, loss=0.078159, lr=0.089147, time_each_step=1.29s, eta=7:29:5\n",
      "2022-01-20 11:11:28 [INFO]\t[TRAIN] Epoch=7/50, Step=332/478, loss=0.080599, lr=0.089140, time_each_step=1.29s, eta=7:29:34\n",
      "2022-01-20 11:11:30 [INFO]\t[TRAIN] Epoch=7/50, Step=334/478, loss=0.081782, lr=0.089134, time_each_step=1.29s, eta=7:28:45\n",
      "2022-01-20 11:11:33 [INFO]\t[TRAIN] Epoch=7/50, Step=336/478, loss=0.091609, lr=0.089127, time_each_step=1.29s, eta=7:29:1\n",
      "2022-01-20 11:11:35 [INFO]\t[TRAIN] Epoch=7/50, Step=338/478, loss=0.076089, lr=0.089120, time_each_step=1.29s, eta=7:28:28\n",
      "2022-01-20 11:11:38 [INFO]\t[TRAIN] Epoch=7/50, Step=340/478, loss=0.085806, lr=0.089113, time_each_step=1.29s, eta=7:28:46\n",
      "2022-01-20 11:11:40 [INFO]\t[TRAIN] Epoch=7/50, Step=342/478, loss=0.085163, lr=0.089106, time_each_step=1.29s, eta=7:29:14\n",
      "2022-01-20 11:11:43 [INFO]\t[TRAIN] Epoch=7/50, Step=344/478, loss=0.071676, lr=0.089099, time_each_step=1.28s, eta=7:27:26\n",
      "2022-01-20 11:11:46 [INFO]\t[TRAIN] Epoch=7/50, Step=346/478, loss=0.073245, lr=0.089092, time_each_step=1.29s, eta=7:28:46\n",
      "2022-01-20 11:11:48 [INFO]\t[TRAIN] Epoch=7/50, Step=348/478, loss=0.093368, lr=0.089085, time_each_step=1.29s, eta=7:29:28\n",
      "2022-01-20 11:11:51 [INFO]\t[TRAIN] Epoch=7/50, Step=350/478, loss=0.080024, lr=0.089078, time_each_step=1.28s, eta=7:27:20\n",
      "2022-01-20 11:11:53 [INFO]\t[TRAIN] Epoch=7/50, Step=352/478, loss=0.070000, lr=0.089072, time_each_step=1.29s, eta=7:28:8\n",
      "2022-01-20 11:11:56 [INFO]\t[TRAIN] Epoch=7/50, Step=354/478, loss=0.074674, lr=0.089065, time_each_step=1.29s, eta=7:29:15\n",
      "2022-01-20 11:11:59 [INFO]\t[TRAIN] Epoch=7/50, Step=356/478, loss=0.104474, lr=0.089058, time_each_step=1.29s, eta=7:28:27\n",
      "2022-01-20 11:12:01 [INFO]\t[TRAIN] Epoch=7/50, Step=358/478, loss=0.069155, lr=0.089051, time_each_step=1.29s, eta=7:27:51\n",
      "2022-01-20 11:12:04 [INFO]\t[TRAIN] Epoch=7/50, Step=360/478, loss=0.065160, lr=0.089044, time_each_step=1.29s, eta=7:29:25\n",
      "2022-01-20 11:12:06 [INFO]\t[TRAIN] Epoch=7/50, Step=362/478, loss=0.078616, lr=0.089037, time_each_step=1.28s, eta=7:27:3\n",
      "2022-01-20 11:12:09 [INFO]\t[TRAIN] Epoch=7/50, Step=364/478, loss=0.154193, lr=0.089030, time_each_step=1.28s, eta=7:27:18\n",
      "2022-01-20 11:12:11 [INFO]\t[TRAIN] Epoch=7/50, Step=366/478, loss=0.077845, lr=0.089023, time_each_step=1.29s, eta=7:28:49\n",
      "2022-01-20 11:12:14 [INFO]\t[TRAIN] Epoch=7/50, Step=368/478, loss=0.064723, lr=0.089016, time_each_step=1.28s, eta=7:27:22\n",
      "2022-01-20 11:12:17 [INFO]\t[TRAIN] Epoch=7/50, Step=370/478, loss=0.090280, lr=0.089010, time_each_step=1.29s, eta=7:28:47\n",
      "2022-01-20 11:12:19 [INFO]\t[TRAIN] Epoch=7/50, Step=372/478, loss=0.081879, lr=0.089003, time_each_step=1.29s, eta=7:29:2\n",
      "2022-01-20 11:12:22 [INFO]\t[TRAIN] Epoch=7/50, Step=374/478, loss=0.094399, lr=0.088996, time_each_step=1.29s, eta=7:27:32\n",
      "2022-01-20 11:12:24 [INFO]\t[TRAIN] Epoch=7/50, Step=376/478, loss=0.088527, lr=0.088989, time_each_step=1.29s, eta=7:27:46\n",
      "2022-01-20 11:12:27 [INFO]\t[TRAIN] Epoch=7/50, Step=378/478, loss=0.100881, lr=0.088982, time_each_step=1.29s, eta=7:29:23\n",
      "2022-01-20 11:12:29 [INFO]\t[TRAIN] Epoch=7/50, Step=380/478, loss=0.064152, lr=0.088975, time_each_step=1.28s, eta=7:27:2\n",
      "2022-01-20 11:12:32 [INFO]\t[TRAIN] Epoch=7/50, Step=382/478, loss=0.078764, lr=0.088968, time_each_step=1.29s, eta=7:27:58\n",
      "2022-01-20 11:12:35 [INFO]\t[TRAIN] Epoch=7/50, Step=384/478, loss=0.080472, lr=0.088961, time_each_step=1.29s, eta=7:29:18\n",
      "2022-01-20 11:12:37 [INFO]\t[TRAIN] Epoch=7/50, Step=386/478, loss=0.094978, lr=0.088954, time_each_step=1.28s, eta=7:26:53\n",
      "2022-01-20 11:12:40 [INFO]\t[TRAIN] Epoch=7/50, Step=388/478, loss=0.097135, lr=0.088947, time_each_step=1.29s, eta=7:27:36\n",
      "2022-01-20 11:12:42 [INFO]\t[TRAIN] Epoch=7/50, Step=390/478, loss=0.077331, lr=0.088941, time_each_step=1.29s, eta=7:28:11\n",
      "2022-01-20 11:12:45 [INFO]\t[TRAIN] Epoch=7/50, Step=392/478, loss=0.081036, lr=0.088934, time_each_step=1.28s, eta=7:26:41\n",
      "2022-01-20 11:12:47 [INFO]\t[TRAIN] Epoch=7/50, Step=394/478, loss=0.106769, lr=0.088927, time_each_step=1.28s, eta=7:26:57\n",
      "2022-01-20 11:12:50 [INFO]\t[TRAIN] Epoch=7/50, Step=396/478, loss=0.083128, lr=0.088920, time_each_step=1.29s, eta=7:29:40\n",
      "2022-01-20 11:12:53 [INFO]\t[TRAIN] Epoch=7/50, Step=398/478, loss=0.061487, lr=0.088913, time_each_step=1.28s, eta=7:26:24\n",
      "2022-01-20 11:12:55 [INFO]\t[TRAIN] Epoch=7/50, Step=400/478, loss=0.067121, lr=0.088906, time_each_step=1.29s, eta=7:27:26\n",
      "2022-01-20 11:12:58 [INFO]\t[TRAIN] Epoch=7/50, Step=402/478, loss=0.077367, lr=0.088899, time_each_step=1.29s, eta=7:28:29\n",
      "2022-01-20 11:13:00 [INFO]\t[TRAIN] Epoch=7/50, Step=404/478, loss=0.075848, lr=0.088892, time_each_step=1.28s, eta=7:26:30\n",
      "2022-01-20 11:13:03 [INFO]\t[TRAIN] Epoch=7/50, Step=406/478, loss=0.072008, lr=0.088885, time_each_step=1.29s, eta=7:27:19\n",
      "2022-01-20 11:13:05 [INFO]\t[TRAIN] Epoch=7/50, Step=408/478, loss=0.094189, lr=0.088879, time_each_step=1.29s, eta=7:27:50\n",
      "2022-01-20 11:13:08 [INFO]\t[TRAIN] Epoch=7/50, Step=410/478, loss=0.074023, lr=0.088872, time_each_step=1.28s, eta=7:25:25\n",
      "2022-01-20 11:13:11 [INFO]\t[TRAIN] Epoch=7/50, Step=412/478, loss=0.080204, lr=0.088865, time_each_step=1.29s, eta=7:27:42\n",
      "2022-01-20 11:13:13 [INFO]\t[TRAIN] Epoch=7/50, Step=414/478, loss=0.093040, lr=0.088858, time_each_step=1.29s, eta=7:28:6\n",
      "2022-01-20 11:13:16 [INFO]\t[TRAIN] Epoch=7/50, Step=416/478, loss=0.109146, lr=0.088851, time_each_step=1.29s, eta=7:26:50\n",
      "2022-01-20 11:13:18 [INFO]\t[TRAIN] Epoch=7/50, Step=418/478, loss=0.076435, lr=0.088844, time_each_step=1.29s, eta=7:27:13\n",
      "2022-01-20 11:13:21 [INFO]\t[TRAIN] Epoch=7/50, Step=420/478, loss=0.083740, lr=0.088837, time_each_step=1.29s, eta=7:27:43\n",
      "2022-01-20 11:13:23 [INFO]\t[TRAIN] Epoch=7/50, Step=422/478, loss=0.052846, lr=0.088830, time_each_step=1.29s, eta=7:27:58\n",
      "2022-01-20 11:13:26 [INFO]\t[TRAIN] Epoch=7/50, Step=424/478, loss=0.110292, lr=0.088823, time_each_step=1.29s, eta=7:27:1\n",
      "2022-01-20 11:13:29 [INFO]\t[TRAIN] Epoch=7/50, Step=426/478, loss=0.078918, lr=0.088816, time_each_step=1.29s, eta=7:26:51\n",
      "2022-01-20 11:13:31 [INFO]\t[TRAIN] Epoch=7/50, Step=428/478, loss=0.064163, lr=0.088810, time_each_step=1.28s, eta=7:26:13\n",
      "2022-01-20 11:13:34 [INFO]\t[TRAIN] Epoch=7/50, Step=430/478, loss=0.068379, lr=0.088803, time_each_step=1.29s, eta=7:27:25\n",
      "2022-01-20 11:13:36 [INFO]\t[TRAIN] Epoch=7/50, Step=432/478, loss=0.065402, lr=0.088796, time_each_step=1.29s, eta=7:27:2\n",
      "2022-01-20 11:13:39 [INFO]\t[TRAIN] Epoch=7/50, Step=434/478, loss=0.054476, lr=0.088789, time_each_step=1.29s, eta=7:27:35\n",
      "2022-01-20 11:13:41 [INFO]\t[TRAIN] Epoch=7/50, Step=436/478, loss=0.074479, lr=0.088782, time_each_step=1.29s, eta=7:27:2\n",
      "2022-01-20 11:13:44 [INFO]\t[TRAIN] Epoch=7/50, Step=438/478, loss=0.071700, lr=0.088775, time_each_step=1.29s, eta=7:27:5\n",
      "2022-01-20 11:13:47 [INFO]\t[TRAIN] Epoch=7/50, Step=440/478, loss=0.059111, lr=0.088768, time_each_step=1.29s, eta=7:27:14\n",
      "2022-01-20 11:13:49 [INFO]\t[TRAIN] Epoch=7/50, Step=442/478, loss=0.063814, lr=0.088761, time_each_step=1.29s, eta=7:26:38\n",
      "2022-01-20 11:13:52 [INFO]\t[TRAIN] Epoch=7/50, Step=444/478, loss=0.084386, lr=0.088754, time_each_step=1.29s, eta=7:26:51\n",
      "2022-01-20 11:13:54 [INFO]\t[TRAIN] Epoch=7/50, Step=446/478, loss=0.105410, lr=0.088748, time_each_step=1.29s, eta=7:26:17\n",
      "2022-01-20 11:13:57 [INFO]\t[TRAIN] Epoch=7/50, Step=448/478, loss=0.065585, lr=0.088741, time_each_step=1.29s, eta=7:26:31\n",
      "2022-01-20 11:13:59 [INFO]\t[TRAIN] Epoch=7/50, Step=450/478, loss=0.096285, lr=0.088734, time_each_step=1.28s, eta=7:25:33\n",
      "2022-01-20 11:14:02 [INFO]\t[TRAIN] Epoch=7/50, Step=452/478, loss=0.069951, lr=0.088727, time_each_step=1.29s, eta=7:26:9\n",
      "2022-01-20 11:14:05 [INFO]\t[TRAIN] Epoch=7/50, Step=454/478, loss=0.082443, lr=0.088720, time_each_step=1.29s, eta=7:26:16\n",
      "2022-01-20 11:14:07 [INFO]\t[TRAIN] Epoch=7/50, Step=456/478, loss=0.082762, lr=0.088713, time_each_step=1.29s, eta=7:25:54\n",
      "2022-01-20 11:14:10 [INFO]\t[TRAIN] Epoch=7/50, Step=458/478, loss=0.052306, lr=0.088706, time_each_step=1.28s, eta=7:25:34\n",
      "2022-01-20 11:14:12 [INFO]\t[TRAIN] Epoch=7/50, Step=460/478, loss=0.082085, lr=0.088699, time_each_step=1.29s, eta=7:25:40\n",
      "2022-01-20 11:14:15 [INFO]\t[TRAIN] Epoch=7/50, Step=462/478, loss=0.062319, lr=0.088692, time_each_step=1.29s, eta=7:25:47\n",
      "2022-01-20 11:14:17 [INFO]\t[TRAIN] Epoch=7/50, Step=464/478, loss=0.065673, lr=0.088685, time_each_step=1.28s, eta=7:24:53\n",
      "2022-01-20 11:14:20 [INFO]\t[TRAIN] Epoch=7/50, Step=466/478, loss=0.103076, lr=0.088679, time_each_step=1.29s, eta=7:27:50\n",
      "2022-01-20 11:14:23 [INFO]\t[TRAIN] Epoch=7/50, Step=468/478, loss=0.078228, lr=0.088672, time_each_step=1.29s, eta=7:26:5\n",
      "2022-01-20 11:14:25 [INFO]\t[TRAIN] Epoch=7/50, Step=470/478, loss=0.068981, lr=0.088665, time_each_step=1.29s, eta=7:25:46\n",
      "2022-01-20 11:14:28 [INFO]\t[TRAIN] Epoch=7/50, Step=472/478, loss=0.076373, lr=0.088658, time_each_step=1.29s, eta=7:26:1\n",
      "2022-01-20 11:14:30 [INFO]\t[TRAIN] Epoch=7/50, Step=474/478, loss=0.099672, lr=0.088651, time_each_step=1.28s, eta=7:24:56\n",
      "2022-01-20 11:14:33 [INFO]\t[TRAIN] Epoch=7/50, Step=476/478, loss=0.051894, lr=0.088644, time_each_step=1.28s, eta=7:24:48\n",
      "2022-01-20 11:14:35 [INFO]\t[TRAIN] Epoch=7/50, Step=478/478, loss=0.080283, lr=0.088637, time_each_step=1.29s, eta=7:26:8\n",
      "2022-01-20 11:14:36 [INFO]\t[TRAIN] Epoch 7 finished, loss=0.078169964 .\n",
      "2022-01-20 11:14:36 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-01-20 11:14:36 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-01-20 11:14:42 [INFO]\t[EVAL] Finished, Epoch=7, miou=0.832036, category_iou=[0.9710792  0.73175454 0.7932757 ], oacc=0.972809, category_acc=[0.9882614  0.85646933 0.8577772 ], kappa=0.869673, category_F1-score=[0.98532738 0.84510189 0.88472251] .\n",
      "2022-01-20 11:14:42 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_6, miou=0.8331509232521057\n",
      "2022-01-20 11:14:43 [INFO]\tModel saved in model/deeplab_augument_alldata2/epoch_7.\n",
      "2022-01-20 11:14:46 [INFO]\t[TRAIN] Epoch=8/50, Step=2/478, loss=0.096011, lr=0.088630, time_each_step=1.94s, eta=11:7:21\n",
      "2022-01-20 11:14:49 [INFO]\t[TRAIN] Epoch=8/50, Step=4/478, loss=0.084223, lr=0.088623, time_each_step=1.29s, eta=7:25:28\n",
      "2022-01-20 11:14:52 [INFO]\t[TRAIN] Epoch=8/50, Step=6/478, loss=0.062654, lr=0.088616, time_each_step=1.28s, eta=7:22:38\n",
      "2022-01-20 11:14:54 [INFO]\t[TRAIN] Epoch=8/50, Step=8/478, loss=0.078903, lr=0.088610, time_each_step=1.28s, eta=7:24:6\n",
      "2022-01-20 11:14:57 [INFO]\t[TRAIN] Epoch=8/50, Step=10/478, loss=0.056074, lr=0.088603, time_each_step=1.29s, eta=7:24:41\n",
      "2022-01-20 11:14:59 [INFO]\t[TRAIN] Epoch=8/50, Step=12/478, loss=0.051926, lr=0.088596, time_each_step=1.29s, eta=7:24:26\n",
      "2022-01-20 11:15:02 [INFO]\t[TRAIN] Epoch=8/50, Step=14/478, loss=0.062646, lr=0.088589, time_each_step=1.29s, eta=7:25:4\n",
      "2022-01-20 11:15:04 [INFO]\t[TRAIN] Epoch=8/50, Step=16/478, loss=0.059479, lr=0.088582, time_each_step=1.28s, eta=7:23:37\n",
      "2022-01-20 11:15:07 [INFO]\t[TRAIN] Epoch=8/50, Step=18/478, loss=0.082140, lr=0.088575, time_each_step=1.29s, eta=7:24:29\n",
      "2022-01-20 11:15:10 [INFO]\t[TRAIN] Epoch=8/50, Step=20/478, loss=0.092455, lr=0.088568, time_each_step=1.29s, eta=7:24:17\n",
      "2022-01-20 11:15:12 [INFO]\t[TRAIN] Epoch=8/50, Step=22/478, loss=0.073882, lr=0.088561, time_each_step=1.28s, eta=7:24:11\n",
      "2022-01-20 11:15:15 [INFO]\t[TRAIN] Epoch=8/50, Step=24/478, loss=0.061296, lr=0.088554, time_each_step=1.29s, eta=7:25:1\n",
      "2022-01-20 11:15:17 [INFO]\t[TRAIN] Epoch=8/50, Step=26/478, loss=0.099492, lr=0.088547, time_each_step=1.29s, eta=7:25:4\n",
      "2022-01-20 11:15:20 [INFO]\t[TRAIN] Epoch=8/50, Step=28/478, loss=0.096789, lr=0.088541, time_each_step=1.28s, eta=7:23:11\n",
      "2022-01-20 11:15:22 [INFO]\t[TRAIN] Epoch=8/50, Step=30/478, loss=0.048343, lr=0.088534, time_each_step=1.29s, eta=7:25:9\n",
      "2022-01-20 11:15:25 [INFO]\t[TRAIN] Epoch=8/50, Step=32/478, loss=0.054304, lr=0.088527, time_each_step=1.29s, eta=7:24:31\n",
      "2022-01-20 11:15:28 [INFO]\t[TRAIN] Epoch=8/50, Step=34/478, loss=0.073340, lr=0.088520, time_each_step=1.29s, eta=7:24:14\n",
      "2022-01-20 11:15:30 [INFO]\t[TRAIN] Epoch=8/50, Step=36/478, loss=0.058236, lr=0.088513, time_each_step=1.29s, eta=7:25:9\n",
      "2022-01-20 11:15:33 [INFO]\t[TRAIN] Epoch=8/50, Step=38/478, loss=0.069379, lr=0.088506, time_each_step=1.28s, eta=7:23:40\n",
      "2022-01-20 11:15:35 [INFO]\t[TRAIN] Epoch=8/50, Step=40/478, loss=0.061433, lr=0.088499, time_each_step=1.28s, eta=7:23:29\n",
      "2022-01-20 11:15:38 [INFO]\t[TRAIN] Epoch=8/50, Step=42/478, loss=0.074789, lr=0.088492, time_each_step=1.29s, eta=7:25:27\n",
      "2022-01-20 11:15:40 [INFO]\t[TRAIN] Epoch=8/50, Step=44/478, loss=0.071015, lr=0.088485, time_each_step=1.29s, eta=7:24:10\n",
      "2022-01-20 11:15:43 [INFO]\t[TRAIN] Epoch=8/50, Step=46/478, loss=0.079241, lr=0.088478, time_each_step=1.28s, eta=7:22:45\n",
      "2022-01-20 11:15:46 [INFO]\t[TRAIN] Epoch=8/50, Step=48/478, loss=0.083767, lr=0.088471, time_each_step=1.29s, eta=7:24:44\n",
      "2022-01-20 11:15:48 [INFO]\t[TRAIN] Epoch=8/50, Step=50/478, loss=0.048359, lr=0.088465, time_each_step=1.28s, eta=7:23:34\n",
      "2022-01-20 11:15:51 [INFO]\t[TRAIN] Epoch=8/50, Step=52/478, loss=0.069370, lr=0.088458, time_each_step=1.28s, eta=7:23:17\n",
      "2022-01-20 11:15:53 [INFO]\t[TRAIN] Epoch=8/50, Step=54/478, loss=0.080855, lr=0.088451, time_each_step=1.29s, eta=7:25:34\n",
      "2022-01-20 11:15:56 [INFO]\t[TRAIN] Epoch=8/50, Step=56/478, loss=0.050740, lr=0.088444, time_each_step=1.29s, eta=7:24:27\n",
      "2022-01-20 11:15:58 [INFO]\t[TRAIN] Epoch=8/50, Step=58/478, loss=0.074131, lr=0.088437, time_each_step=1.29s, eta=7:23:47\n",
      "2022-01-20 11:16:01 [INFO]\t[TRAIN] Epoch=8/50, Step=60/478, loss=0.066921, lr=0.088430, time_each_step=1.29s, eta=7:25:3\n",
      "2022-01-20 11:16:04 [INFO]\t[TRAIN] Epoch=8/50, Step=62/478, loss=0.080525, lr=0.088423, time_each_step=1.29s, eta=7:24:29\n",
      "2022-01-20 11:16:06 [INFO]\t[TRAIN] Epoch=8/50, Step=64/478, loss=0.066589, lr=0.088416, time_each_step=1.28s, eta=7:23:9\n",
      "2022-01-20 11:16:09 [INFO]\t[TRAIN] Epoch=8/50, Step=66/478, loss=0.055052, lr=0.088409, time_each_step=1.29s, eta=7:24:29\n",
      "2022-01-20 11:16:11 [INFO]\t[TRAIN] Epoch=8/50, Step=68/478, loss=0.062962, lr=0.088402, time_each_step=1.29s, eta=7:23:36\n",
      "2022-01-20 11:16:14 [INFO]\t[TRAIN] Epoch=8/50, Step=70/478, loss=0.051470, lr=0.088396, time_each_step=1.28s, eta=7:22:59\n",
      "2022-01-20 11:16:16 [INFO]\t[TRAIN] Epoch=8/50, Step=72/478, loss=0.067176, lr=0.088389, time_each_step=1.29s, eta=7:24:12\n",
      "2022-01-20 11:16:19 [INFO]\t[TRAIN] Epoch=8/50, Step=74/478, loss=0.079553, lr=0.088382, time_each_step=1.28s, eta=7:22:54\n",
      "2022-01-20 11:16:22 [INFO]\t[TRAIN] Epoch=8/50, Step=76/478, loss=0.054398, lr=0.088375, time_each_step=1.29s, eta=7:23:24\n",
      "2022-01-20 11:16:24 [INFO]\t[TRAIN] Epoch=8/50, Step=78/478, loss=0.072115, lr=0.088368, time_each_step=1.29s, eta=7:23:33\n",
      "2022-01-20 11:16:27 [INFO]\t[TRAIN] Epoch=8/50, Step=80/478, loss=0.073095, lr=0.088361, time_each_step=1.29s, eta=7:23:36\n",
      "2022-01-20 11:16:29 [INFO]\t[TRAIN] Epoch=8/50, Step=82/478, loss=0.078497, lr=0.088354, time_each_step=1.29s, eta=7:23:6\n",
      "2022-01-20 11:16:32 [INFO]\t[TRAIN] Epoch=8/50, Step=84/478, loss=0.075552, lr=0.088347, time_each_step=1.29s, eta=7:24:9\n",
      "2022-01-20 11:16:34 [INFO]\t[TRAIN] Epoch=8/50, Step=86/478, loss=0.080305, lr=0.088340, time_each_step=1.29s, eta=7:23:11\n",
      "2022-01-20 11:16:37 [INFO]\t[TRAIN] Epoch=8/50, Step=88/478, loss=0.079294, lr=0.088333, time_each_step=1.29s, eta=7:22:57\n",
      "2022-01-20 11:16:40 [INFO]\t[TRAIN] Epoch=8/50, Step=90/478, loss=0.069381, lr=0.088327, time_each_step=1.29s, eta=7:22:58\n",
      "2022-01-20 11:16:42 [INFO]\t[TRAIN] Epoch=8/50, Step=92/478, loss=0.065675, lr=0.088320, time_each_step=1.28s, eta=7:22:10\n",
      "2022-01-20 11:16:45 [INFO]\t[TRAIN] Epoch=8/50, Step=94/478, loss=0.065621, lr=0.088313, time_each_step=1.28s, eta=7:22:5\n",
      "2022-01-20 11:16:47 [INFO]\t[TRAIN] Epoch=8/50, Step=96/478, loss=0.077679, lr=0.088306, time_each_step=1.28s, eta=7:22:16\n",
      "2022-01-20 11:16:50 [INFO]\t[TRAIN] Epoch=8/50, Step=98/478, loss=0.035265, lr=0.088299, time_each_step=1.29s, eta=7:22:51\n",
      "2022-01-20 11:16:52 [INFO]\t[TRAIN] Epoch=8/50, Step=100/478, loss=0.072765, lr=0.088292, time_each_step=1.28s, eta=7:22:19\n",
      "2022-01-20 11:16:55 [INFO]\t[TRAIN] Epoch=8/50, Step=102/478, loss=0.062435, lr=0.088285, time_each_step=1.29s, eta=7:24:33\n",
      "2022-01-20 11:16:58 [INFO]\t[TRAIN] Epoch=8/50, Step=104/478, loss=0.105865, lr=0.088278, time_each_step=1.29s, eta=7:23:30\n",
      "2022-01-20 11:17:00 [INFO]\t[TRAIN] Epoch=8/50, Step=106/478, loss=0.074242, lr=0.088271, time_each_step=1.28s, eta=7:22:21\n",
      "2022-01-20 11:17:03 [INFO]\t[TRAIN] Epoch=8/50, Step=108/478, loss=0.088344, lr=0.088264, time_each_step=1.29s, eta=7:22:47\n",
      "2022-01-20 11:17:05 [INFO]\t[TRAIN] Epoch=8/50, Step=110/478, loss=0.103873, lr=0.088257, time_each_step=1.29s, eta=7:24:2\n",
      "2022-01-20 11:17:08 [INFO]\t[TRAIN] Epoch=8/50, Step=112/478, loss=0.055598, lr=0.088251, time_each_step=1.29s, eta=7:22:40\n",
      "2022-01-20 11:17:11 [INFO]\t[TRAIN] Epoch=8/50, Step=114/478, loss=0.056250, lr=0.088244, time_each_step=1.29s, eta=7:23:34\n",
      "2022-01-20 11:17:13 [INFO]\t[TRAIN] Epoch=8/50, Step=116/478, loss=0.095417, lr=0.088237, time_each_step=1.29s, eta=7:22:54\n",
      "2022-01-20 11:17:16 [INFO]\t[TRAIN] Epoch=8/50, Step=118/478, loss=0.086777, lr=0.088230, time_each_step=1.29s, eta=7:22:46\n",
      "2022-01-20 11:17:18 [INFO]\t[TRAIN] Epoch=8/50, Step=120/478, loss=0.060281, lr=0.088223, time_each_step=1.29s, eta=7:22:55\n",
      "2022-01-20 11:17:21 [INFO]\t[TRAIN] Epoch=8/50, Step=122/478, loss=0.142914, lr=0.088216, time_each_step=1.29s, eta=7:22:18\n",
      "2022-01-20 11:17:23 [INFO]\t[TRAIN] Epoch=8/50, Step=124/478, loss=0.069091, lr=0.088209, time_each_step=1.29s, eta=7:22:24\n",
      "2022-01-20 11:17:26 [INFO]\t[TRAIN] Epoch=8/50, Step=126/478, loss=0.059256, lr=0.088202, time_each_step=1.29s, eta=7:22:4\n",
      "2022-01-20 11:17:29 [INFO]\t[TRAIN] Epoch=8/50, Step=128/478, loss=0.087024, lr=0.088195, time_each_step=1.28s, eta=7:21:12\n",
      "2022-01-20 11:17:31 [INFO]\t[TRAIN] Epoch=8/50, Step=130/478, loss=0.057437, lr=0.088188, time_each_step=1.28s, eta=7:21:51\n",
      "2022-01-20 11:17:34 [INFO]\t[TRAIN] Epoch=8/50, Step=132/478, loss=0.074177, lr=0.088181, time_each_step=1.29s, eta=7:23:35\n",
      "2022-01-20 11:17:36 [INFO]\t[TRAIN] Epoch=8/50, Step=134/478, loss=0.069028, lr=0.088175, time_each_step=1.28s, eta=7:21:43\n",
      "2022-01-20 11:17:39 [INFO]\t[TRAIN] Epoch=8/50, Step=136/478, loss=0.080162, lr=0.088168, time_each_step=1.29s, eta=7:22:35\n",
      "2022-01-20 11:17:41 [INFO]\t[TRAIN] Epoch=8/50, Step=138/478, loss=0.078660, lr=0.088161, time_each_step=1.29s, eta=7:22:17\n",
      "2022-01-20 11:17:44 [INFO]\t[TRAIN] Epoch=8/50, Step=140/478, loss=0.072308, lr=0.088154, time_each_step=1.29s, eta=7:21:51\n",
      "2022-01-20 11:17:47 [INFO]\t[TRAIN] Epoch=8/50, Step=142/478, loss=0.095385, lr=0.088147, time_each_step=1.29s, eta=7:21:55\n",
      "2022-01-20 11:17:49 [INFO]\t[TRAIN] Epoch=8/50, Step=144/478, loss=0.067206, lr=0.088140, time_each_step=1.29s, eta=7:23:8\n",
      "2022-01-20 11:17:52 [INFO]\t[TRAIN] Epoch=8/50, Step=146/478, loss=0.096461, lr=0.088133, time_each_step=1.29s, eta=7:21:58\n",
      "2022-01-20 11:17:54 [INFO]\t[TRAIN] Epoch=8/50, Step=148/478, loss=0.085764, lr=0.088126, time_each_step=1.29s, eta=7:22:8\n",
      "2022-01-20 11:17:57 [INFO]\t[TRAIN] Epoch=8/50, Step=150/478, loss=0.106012, lr=0.088119, time_each_step=1.29s, eta=7:24:4\n",
      "2022-01-20 11:17:59 [INFO]\t[TRAIN] Epoch=8/50, Step=152/478, loss=0.118991, lr=0.088112, time_each_step=1.29s, eta=7:22:55\n",
      "2022-01-20 11:18:02 [INFO]\t[TRAIN] Epoch=8/50, Step=154/478, loss=0.107011, lr=0.088105, time_each_step=1.29s, eta=7:23:11\n",
      "2022-01-20 11:18:05 [INFO]\t[TRAIN] Epoch=8/50, Step=156/478, loss=0.092719, lr=0.088099, time_each_step=1.29s, eta=7:23:59\n",
      "2022-01-20 11:18:07 [INFO]\t[TRAIN] Epoch=8/50, Step=158/478, loss=0.068469, lr=0.088092, time_each_step=1.29s, eta=7:23:33\n",
      "2022-01-20 11:18:10 [INFO]\t[TRAIN] Epoch=8/50, Step=160/478, loss=0.077321, lr=0.088085, time_each_step=1.29s, eta=7:24:16\n",
      "2022-01-20 11:18:12 [INFO]\t[TRAIN] Epoch=8/50, Step=162/478, loss=0.085786, lr=0.088078, time_each_step=1.29s, eta=7:22:17\n",
      "2022-01-20 11:18:15 [INFO]\t[TRAIN] Epoch=8/50, Step=164/478, loss=0.073194, lr=0.088071, time_each_step=1.29s, eta=7:23:7\n",
      "2022-01-20 11:18:17 [INFO]\t[TRAIN] Epoch=8/50, Step=166/478, loss=0.078509, lr=0.088064, time_each_step=1.3s, eta=7:24:42\n",
      "2022-01-20 11:18:20 [INFO]\t[TRAIN] Epoch=8/50, Step=168/478, loss=0.065017, lr=0.088057, time_each_step=1.29s, eta=7:24:16\n",
      "2022-01-20 11:18:23 [INFO]\t[TRAIN] Epoch=8/50, Step=170/478, loss=0.052034, lr=0.088050, time_each_step=1.29s, eta=7:24:1\n",
      "2022-01-20 11:18:25 [INFO]\t[TRAIN] Epoch=8/50, Step=172/478, loss=0.084343, lr=0.088043, time_each_step=1.29s, eta=7:22:29\n",
      "2022-01-20 11:18:28 [INFO]\t[TRAIN] Epoch=8/50, Step=174/478, loss=0.087065, lr=0.088036, time_each_step=1.3s, eta=7:24:56\n",
      "2022-01-20 11:18:30 [INFO]\t[TRAIN] Epoch=8/50, Step=176/478, loss=0.072600, lr=0.088029, time_each_step=1.29s, eta=7:23:25\n",
      "2022-01-20 11:18:33 [INFO]\t[TRAIN] Epoch=8/50, Step=178/478, loss=0.077668, lr=0.088023, time_each_step=1.29s, eta=7:22:48\n",
      "2022-01-20 11:18:36 [INFO]\t[TRAIN] Epoch=8/50, Step=180/478, loss=0.069172, lr=0.088016, time_each_step=1.29s, eta=7:24:3\n",
      "2022-01-20 11:18:38 [INFO]\t[TRAIN] Epoch=8/50, Step=182/478, loss=0.059801, lr=0.088009, time_each_step=1.29s, eta=7:22:13\n",
      "2022-01-20 11:18:41 [INFO]\t[TRAIN] Epoch=8/50, Step=184/478, loss=0.086975, lr=0.088002, time_each_step=1.3s, eta=7:24:20\n",
      "2022-01-20 11:18:43 [INFO]\t[TRAIN] Epoch=8/50, Step=186/478, loss=0.102255, lr=0.087995, time_each_step=1.29s, eta=7:21:57\n",
      "2022-01-20 11:18:46 [INFO]\t[TRAIN] Epoch=8/50, Step=188/478, loss=0.073879, lr=0.087988, time_each_step=1.29s, eta=7:22:32\n",
      "2022-01-20 11:18:49 [INFO]\t[TRAIN] Epoch=8/50, Step=190/478, loss=0.096232, lr=0.087981, time_each_step=1.29s, eta=7:23:34\n",
      "2022-01-20 11:18:51 [INFO]\t[TRAIN] Epoch=8/50, Step=192/478, loss=0.068289, lr=0.087974, time_each_step=1.29s, eta=7:22:26\n",
      "2022-01-20 11:18:54 [INFO]\t[TRAIN] Epoch=8/50, Step=194/478, loss=0.088546, lr=0.087967, time_each_step=1.3s, eta=7:24:11\n",
      "2022-01-20 11:18:56 [INFO]\t[TRAIN] Epoch=8/50, Step=196/478, loss=0.084370, lr=0.087960, time_each_step=1.29s, eta=7:21:12\n",
      "2022-01-20 11:18:59 [INFO]\t[TRAIN] Epoch=8/50, Step=198/478, loss=0.053279, lr=0.087953, time_each_step=1.29s, eta=7:21:50\n",
      "2022-01-20 11:19:01 [INFO]\t[TRAIN] Epoch=8/50, Step=200/478, loss=0.090551, lr=0.087947, time_each_step=1.3s, eta=7:24:36\n",
      "2022-01-20 11:19:04 [INFO]\t[TRAIN] Epoch=8/50, Step=202/478, loss=0.107901, lr=0.087940, time_each_step=1.29s, eta=7:22:30\n",
      "2022-01-20 11:19:07 [INFO]\t[TRAIN] Epoch=8/50, Step=204/478, loss=0.092355, lr=0.087933, time_each_step=1.29s, eta=7:23:37\n",
      "2022-01-20 11:19:09 [INFO]\t[TRAIN] Epoch=8/50, Step=206/478, loss=0.064519, lr=0.087926, time_each_step=1.29s, eta=7:21:52\n",
      "2022-01-20 11:19:12 [INFO]\t[TRAIN] Epoch=8/50, Step=208/478, loss=0.065284, lr=0.087919, time_each_step=1.29s, eta=7:21:56\n",
      "2022-01-20 11:19:14 [INFO]\t[TRAIN] Epoch=8/50, Step=210/478, loss=0.056399, lr=0.087912, time_each_step=1.3s, eta=7:23:39\n",
      "2022-01-20 11:19:17 [INFO]\t[TRAIN] Epoch=8/50, Step=212/478, loss=0.106581, lr=0.087905, time_each_step=1.29s, eta=7:21:28\n",
      "2022-01-20 11:19:20 [INFO]\t[TRAIN] Epoch=8/50, Step=214/478, loss=0.067325, lr=0.087898, time_each_step=1.29s, eta=7:23:22\n",
      "2022-01-20 11:19:22 [INFO]\t[TRAIN] Epoch=8/50, Step=216/478, loss=0.088027, lr=0.087891, time_each_step=1.29s, eta=7:21:40\n",
      "2022-01-20 11:19:25 [INFO]\t[TRAIN] Epoch=8/50, Step=218/478, loss=0.039921, lr=0.087884, time_each_step=1.29s, eta=7:21:17\n",
      "2022-01-20 11:19:27 [INFO]\t[TRAIN] Epoch=8/50, Step=220/478, loss=0.087177, lr=0.087877, time_each_step=1.3s, eta=7:23:53\n",
      "2022-01-20 11:19:30 [INFO]\t[TRAIN] Epoch=8/50, Step=222/478, loss=0.077955, lr=0.087870, time_each_step=1.29s, eta=7:21:21\n",
      "2022-01-20 11:19:32 [INFO]\t[TRAIN] Epoch=8/50, Step=224/478, loss=0.075271, lr=0.087864, time_each_step=1.3s, eta=7:23:52\n",
      "2022-01-20 11:19:35 [INFO]\t[TRAIN] Epoch=8/50, Step=226/478, loss=0.072660, lr=0.087857, time_each_step=1.29s, eta=7:20:32\n",
      "2022-01-20 11:19:38 [INFO]\t[TRAIN] Epoch=8/50, Step=228/478, loss=0.064589, lr=0.087850, time_each_step=1.29s, eta=7:20:39\n",
      "2022-01-20 11:19:40 [INFO]\t[TRAIN] Epoch=8/50, Step=230/478, loss=0.070888, lr=0.087843, time_each_step=1.3s, eta=7:23:33\n",
      "2022-01-20 11:19:43 [INFO]\t[TRAIN] Epoch=8/50, Step=232/478, loss=0.086928, lr=0.087836, time_each_step=1.29s, eta=7:21:43\n",
      "2022-01-20 11:19:45 [INFO]\t[TRAIN] Epoch=8/50, Step=234/478, loss=0.101442, lr=0.087829, time_each_step=1.29s, eta=7:22:23\n",
      "2022-01-20 11:19:48 [INFO]\t[TRAIN] Epoch=8/50, Step=236/478, loss=0.083960, lr=0.087822, time_each_step=1.29s, eta=7:20:53\n",
      "2022-01-20 11:19:51 [INFO]\t[TRAIN] Epoch=8/50, Step=238/478, loss=0.059119, lr=0.087815, time_each_step=1.29s, eta=7:20:58\n",
      "2022-01-20 11:19:53 [INFO]\t[TRAIN] Epoch=8/50, Step=240/478, loss=0.059114, lr=0.087808, time_each_step=1.29s, eta=7:22:7\n",
      "2022-01-20 11:19:56 [INFO]\t[TRAIN] Epoch=8/50, Step=242/478, loss=0.058267, lr=0.087801, time_each_step=1.29s, eta=7:20:33\n",
      "2022-01-20 11:19:58 [INFO]\t[TRAIN] Epoch=8/50, Step=244/478, loss=0.083558, lr=0.087794, time_each_step=1.29s, eta=7:21:51\n",
      "2022-01-20 11:20:01 [INFO]\t[TRAIN] Epoch=8/50, Step=246/478, loss=0.071007, lr=0.087787, time_each_step=1.29s, eta=7:20:51\n",
      "2022-01-20 11:20:03 [INFO]\t[TRAIN] Epoch=8/50, Step=248/478, loss=0.050923, lr=0.087781, time_each_step=1.29s, eta=7:20:22\n",
      "2022-01-20 11:20:06 [INFO]\t[TRAIN] Epoch=8/50, Step=250/478, loss=0.073259, lr=0.087774, time_each_step=1.3s, eta=7:23:20\n",
      "2022-01-20 11:20:09 [INFO]\t[TRAIN] Epoch=8/50, Step=252/478, loss=0.104038, lr=0.087767, time_each_step=1.29s, eta=7:21:6\n",
      "2022-01-20 11:20:11 [INFO]\t[TRAIN] Epoch=8/50, Step=254/478, loss=0.063993, lr=0.087760, time_each_step=1.3s, eta=7:22:54\n",
      "2022-01-20 11:20:14 [INFO]\t[TRAIN] Epoch=8/50, Step=256/478, loss=0.068296, lr=0.087753, time_each_step=1.29s, eta=7:20:45\n",
      "2022-01-20 11:20:16 [INFO]\t[TRAIN] Epoch=8/50, Step=258/478, loss=0.091270, lr=0.087746, time_each_step=1.29s, eta=7:19:49\n",
      "2022-01-20 11:20:19 [INFO]\t[TRAIN] Epoch=8/50, Step=260/478, loss=0.083535, lr=0.087739, time_each_step=1.29s, eta=7:22:4\n",
      "2022-01-20 11:20:21 [INFO]\t[TRAIN] Epoch=8/50, Step=262/478, loss=0.068079, lr=0.087732, time_each_step=1.29s, eta=7:19:59\n",
      "2022-01-20 11:20:24 [INFO]\t[TRAIN] Epoch=8/50, Step=264/478, loss=0.083171, lr=0.087725, time_each_step=1.29s, eta=7:21:19\n",
      "2022-01-20 11:20:27 [INFO]\t[TRAIN] Epoch=8/50, Step=266/478, loss=0.082421, lr=0.087718, time_each_step=1.29s, eta=7:20:58\n",
      "2022-01-20 11:20:29 [INFO]\t[TRAIN] Epoch=8/50, Step=268/478, loss=0.124494, lr=0.087711, time_each_step=1.29s, eta=7:21:0\n",
      "2022-01-20 11:20:32 [INFO]\t[TRAIN] Epoch=8/50, Step=270/478, loss=0.068022, lr=0.087704, time_each_step=1.29s, eta=7:20:49\n",
      "2022-01-20 11:20:34 [INFO]\t[TRAIN] Epoch=8/50, Step=272/478, loss=0.083606, lr=0.087698, time_each_step=1.29s, eta=7:20:44\n",
      "2022-01-20 11:20:37 [INFO]\t[TRAIN] Epoch=8/50, Step=274/478, loss=0.090461, lr=0.087691, time_each_step=1.29s, eta=7:19:22\n",
      "2022-01-20 11:20:40 [INFO]\t[TRAIN] Epoch=8/50, Step=276/478, loss=0.072397, lr=0.087684, time_each_step=1.29s, eta=7:20:54\n",
      "2022-01-20 11:20:42 [INFO]\t[TRAIN] Epoch=8/50, Step=278/478, loss=0.071226, lr=0.087677, time_each_step=1.28s, eta=7:18:41\n",
      "2022-01-20 11:20:45 [INFO]\t[TRAIN] Epoch=8/50, Step=280/478, loss=0.078675, lr=0.087670, time_each_step=1.28s, eta=7:18:22\n",
      "2022-01-20 11:20:47 [INFO]\t[TRAIN] Epoch=8/50, Step=282/478, loss=0.100459, lr=0.087663, time_each_step=1.29s, eta=7:20:27\n",
      "2022-01-20 11:20:50 [INFO]\t[TRAIN] Epoch=8/50, Step=284/478, loss=0.056816, lr=0.087656, time_each_step=1.29s, eta=7:18:45\n",
      "2022-01-20 11:20:52 [INFO]\t[TRAIN] Epoch=8/50, Step=286/478, loss=0.066077, lr=0.087649, time_each_step=1.29s, eta=7:19:53\n",
      "2022-01-20 11:20:55 [INFO]\t[TRAIN] Epoch=8/50, Step=288/478, loss=0.069655, lr=0.087642, time_each_step=1.29s, eta=7:20:49\n",
      "2022-01-20 11:20:58 [INFO]\t[TRAIN] Epoch=8/50, Step=290/478, loss=0.060453, lr=0.087635, time_each_step=1.29s, eta=7:18:39\n",
      "2022-01-20 11:21:00 [INFO]\t[TRAIN] Epoch=8/50, Step=292/478, loss=0.053542, lr=0.087628, time_each_step=1.29s, eta=7:21:38\n",
      "2022-01-20 11:21:03 [INFO]\t[TRAIN] Epoch=8/50, Step=294/478, loss=0.077108, lr=0.087621, time_each_step=1.29s, eta=7:19:42\n",
      "2022-01-20 11:21:05 [INFO]\t[TRAIN] Epoch=8/50, Step=296/478, loss=0.067532, lr=0.087615, time_each_step=1.29s, eta=7:18:54\n",
      "2022-01-20 11:21:08 [INFO]\t[TRAIN] Epoch=8/50, Step=298/478, loss=0.076852, lr=0.087608, time_each_step=1.29s, eta=7:20:5\n",
      "2022-01-20 11:21:10 [INFO]\t[TRAIN] Epoch=8/50, Step=300/478, loss=0.065116, lr=0.087601, time_each_step=1.29s, eta=7:18:48\n",
      "2022-01-20 11:21:13 [INFO]\t[TRAIN] Epoch=8/50, Step=302/478, loss=0.089803, lr=0.087594, time_each_step=1.29s, eta=7:18:42\n",
      "2022-01-20 11:21:16 [INFO]\t[TRAIN] Epoch=8/50, Step=304/478, loss=0.063000, lr=0.087587, time_each_step=1.3s, eta=7:22:32\n",
      "2022-01-20 11:21:18 [INFO]\t[TRAIN] Epoch=8/50, Step=306/478, loss=0.074389, lr=0.087580, time_each_step=1.29s, eta=7:19:25\n",
      "2022-01-20 11:21:21 [INFO]\t[TRAIN] Epoch=8/50, Step=308/478, loss=0.054812, lr=0.087573, time_each_step=1.29s, eta=7:20:4\n",
      "2022-01-20 11:21:23 [INFO]\t[TRAIN] Epoch=8/50, Step=310/478, loss=0.061239, lr=0.087566, time_each_step=1.29s, eta=7:19:11\n",
      "2022-01-20 11:21:26 [INFO]\t[TRAIN] Epoch=8/50, Step=312/478, loss=0.093101, lr=0.087559, time_each_step=1.29s, eta=7:19:25\n",
      "2022-01-20 11:21:29 [INFO]\t[TRAIN] Epoch=8/50, Step=314/478, loss=0.048537, lr=0.087552, time_each_step=1.29s, eta=7:20:14\n",
      "2022-01-20 11:21:31 [INFO]\t[TRAIN] Epoch=8/50, Step=316/478, loss=0.059543, lr=0.087545, time_each_step=1.29s, eta=7:19:14\n",
      "2022-01-20 11:21:34 [INFO]\t[TRAIN] Epoch=8/50, Step=318/478, loss=0.082463, lr=0.087538, time_each_step=1.29s, eta=7:18:44\n",
      "2022-01-20 11:21:36 [INFO]\t[TRAIN] Epoch=8/50, Step=320/478, loss=0.070534, lr=0.087531, time_each_step=1.29s, eta=7:19:32\n",
      "2022-01-20 11:21:39 [INFO]\t[TRAIN] Epoch=8/50, Step=322/478, loss=0.081639, lr=0.087525, time_each_step=1.28s, eta=7:17:37\n",
      "2022-01-20 11:21:41 [INFO]\t[TRAIN] Epoch=8/50, Step=324/478, loss=0.048954, lr=0.087518, time_each_step=1.29s, eta=7:18:33\n",
      "2022-01-20 11:21:44 [INFO]\t[TRAIN] Epoch=8/50, Step=326/478, loss=0.096636, lr=0.087511, time_each_step=1.29s, eta=7:19:17\n",
      "2022-01-20 11:21:47 [INFO]\t[TRAIN] Epoch=8/50, Step=328/478, loss=0.096303, lr=0.087504, time_each_step=1.29s, eta=7:18:15\n",
      "2022-01-20 11:21:49 [INFO]\t[TRAIN] Epoch=8/50, Step=330/478, loss=0.079386, lr=0.087497, time_each_step=1.29s, eta=7:19:11\n",
      "2022-01-20 11:21:52 [INFO]\t[TRAIN] Epoch=8/50, Step=332/478, loss=0.080862, lr=0.087490, time_each_step=1.29s, eta=7:20:50\n",
      "2022-01-20 11:21:54 [INFO]\t[TRAIN] Epoch=8/50, Step=334/478, loss=0.082994, lr=0.087483, time_each_step=1.29s, eta=7:18:44\n",
      "2022-01-20 11:21:57 [INFO]\t[TRAIN] Epoch=8/50, Step=336/478, loss=0.070485, lr=0.087476, time_each_step=1.29s, eta=7:18:27\n",
      "2022-01-20 11:21:59 [INFO]\t[TRAIN] Epoch=8/50, Step=338/478, loss=0.082754, lr=0.087469, time_each_step=1.29s, eta=7:18:16\n",
      "2022-01-20 11:22:02 [INFO]\t[TRAIN] Epoch=8/50, Step=340/478, loss=0.054450, lr=0.087462, time_each_step=1.29s, eta=7:18:34\n",
      "2022-01-20 11:22:05 [INFO]\t[TRAIN] Epoch=8/50, Step=342/478, loss=0.080615, lr=0.087455, time_each_step=1.29s, eta=7:18:45\n",
      "2022-01-20 11:22:07 [INFO]\t[TRAIN] Epoch=8/50, Step=344/478, loss=0.073088, lr=0.087448, time_each_step=1.28s, eta=7:17:9\n",
      "2022-01-20 11:22:10 [INFO]\t[TRAIN] Epoch=8/50, Step=346/478, loss=0.069467, lr=0.087441, time_each_step=1.29s, eta=7:18:4\n",
      "2022-01-20 11:22:12 [INFO]\t[TRAIN] Epoch=8/50, Step=348/478, loss=0.076767, lr=0.087435, time_each_step=1.29s, eta=7:18:12\n",
      "2022-01-20 11:22:15 [INFO]\t[TRAIN] Epoch=8/50, Step=350/478, loss=0.068938, lr=0.087428, time_each_step=1.29s, eta=7:17:55\n",
      "2022-01-20 11:22:17 [INFO]\t[TRAIN] Epoch=8/50, Step=352/478, loss=0.063071, lr=0.087421, time_each_step=1.29s, eta=7:18:6\n",
      "2022-01-20 11:22:20 [INFO]\t[TRAIN] Epoch=8/50, Step=354/478, loss=0.076185, lr=0.087414, time_each_step=1.29s, eta=7:20:28\n",
      "2022-01-20 11:22:23 [INFO]\t[TRAIN] Epoch=8/50, Step=356/478, loss=0.100888, lr=0.087407, time_each_step=1.28s, eta=7:16:57\n",
      "2022-01-20 11:22:25 [INFO]\t[TRAIN] Epoch=8/50, Step=358/478, loss=0.103690, lr=0.087400, time_each_step=1.29s, eta=7:19:27\n",
      "2022-01-20 11:22:28 [INFO]\t[TRAIN] Epoch=8/50, Step=360/478, loss=0.088172, lr=0.087393, time_each_step=1.29s, eta=7:18:39\n",
      "2022-01-20 11:22:30 [INFO]\t[TRAIN] Epoch=8/50, Step=362/478, loss=0.085405, lr=0.087386, time_each_step=1.29s, eta=7:17:36\n",
      "2022-01-20 11:22:33 [INFO]\t[TRAIN] Epoch=8/50, Step=364/478, loss=0.070212, lr=0.087379, time_each_step=1.29s, eta=7:18:22\n",
      "2022-01-20 11:22:36 [INFO]\t[TRAIN] Epoch=8/50, Step=366/478, loss=0.087704, lr=0.087372, time_each_step=1.29s, eta=7:17:35\n",
      "2022-01-20 11:22:38 [INFO]\t[TRAIN] Epoch=8/50, Step=368/478, loss=0.089167, lr=0.087365, time_each_step=1.29s, eta=7:18:6\n",
      "2022-01-20 11:22:41 [INFO]\t[TRAIN] Epoch=8/50, Step=370/478, loss=0.083375, lr=0.087358, time_each_step=1.29s, eta=7:18:56\n",
      "2022-01-20 11:22:43 [INFO]\t[TRAIN] Epoch=8/50, Step=372/478, loss=0.102157, lr=0.087351, time_each_step=1.29s, eta=7:17:6\n",
      "2022-01-20 11:22:46 [INFO]\t[TRAIN] Epoch=8/50, Step=374/478, loss=0.048889, lr=0.087345, time_each_step=1.29s, eta=7:17:48\n",
      "2022-01-20 11:22:48 [INFO]\t[TRAIN] Epoch=8/50, Step=376/478, loss=0.077295, lr=0.087338, time_each_step=1.29s, eta=7:17:46\n",
      "2022-01-20 11:22:51 [INFO]\t[TRAIN] Epoch=8/50, Step=378/478, loss=0.059296, lr=0.087331, time_each_step=1.29s, eta=7:16:39\n",
      "2022-01-20 11:22:54 [INFO]\t[TRAIN] Epoch=8/50, Step=380/478, loss=0.078713, lr=0.087324, time_each_step=1.29s, eta=7:17:13\n",
      "2022-01-20 11:22:56 [INFO]\t[TRAIN] Epoch=8/50, Step=382/478, loss=0.078318, lr=0.087317, time_each_step=1.29s, eta=7:17:26\n",
      "2022-01-20 11:22:59 [INFO]\t[TRAIN] Epoch=8/50, Step=384/478, loss=0.113036, lr=0.087310, time_each_step=1.29s, eta=7:17:16\n",
      "2022-01-20 11:23:01 [INFO]\t[TRAIN] Epoch=8/50, Step=386/478, loss=0.071525, lr=0.087303, time_each_step=1.29s, eta=7:16:49\n",
      "2022-01-20 11:23:04 [INFO]\t[TRAIN] Epoch=8/50, Step=388/478, loss=0.060163, lr=0.087296, time_each_step=1.29s, eta=7:17:32\n",
      "2022-01-20 11:23:06 [INFO]\t[TRAIN] Epoch=8/50, Step=390/478, loss=0.073390, lr=0.087289, time_each_step=1.29s, eta=7:16:24\n",
      "2022-01-20 11:23:09 [INFO]\t[TRAIN] Epoch=8/50, Step=392/478, loss=0.075678, lr=0.087282, time_each_step=1.29s, eta=7:16:34\n",
      "2022-01-20 11:23:12 [INFO]\t[TRAIN] Epoch=8/50, Step=394/478, loss=0.083689, lr=0.087275, time_each_step=1.29s, eta=7:17:8\n",
      "2022-01-20 11:23:14 [INFO]\t[TRAIN] Epoch=8/50, Step=396/478, loss=0.071317, lr=0.087268, time_each_step=1.28s, eta=7:15:57\n",
      "2022-01-20 11:23:17 [INFO]\t[TRAIN] Epoch=8/50, Step=398/478, loss=0.061434, lr=0.087261, time_each_step=1.29s, eta=7:16:34\n",
      "2022-01-20 11:23:19 [INFO]\t[TRAIN] Epoch=8/50, Step=400/478, loss=0.081693, lr=0.087255, time_each_step=1.29s, eta=7:17:26\n",
      "2022-01-20 11:23:22 [INFO]\t[TRAIN] Epoch=8/50, Step=402/478, loss=0.098285, lr=0.087248, time_each_step=1.29s, eta=7:16:59\n",
      "2022-01-20 11:23:24 [INFO]\t[TRAIN] Epoch=8/50, Step=404/478, loss=0.075087, lr=0.087241, time_each_step=1.29s, eta=7:18:22\n",
      "2022-01-20 11:23:27 [INFO]\t[TRAIN] Epoch=8/50, Step=406/478, loss=0.086233, lr=0.087234, time_each_step=1.29s, eta=7:18:5\n",
      "2022-01-20 11:23:30 [INFO]\t[TRAIN] Epoch=8/50, Step=408/478, loss=0.075859, lr=0.087227, time_each_step=1.29s, eta=7:17:46\n",
      "2022-01-20 11:23:32 [INFO]\t[TRAIN] Epoch=8/50, Step=410/478, loss=0.066406, lr=0.087220, time_each_step=1.29s, eta=7:17:46\n",
      "2022-01-20 11:23:35 [INFO]\t[TRAIN] Epoch=8/50, Step=412/478, loss=0.081121, lr=0.087213, time_each_step=1.29s, eta=7:16:33\n",
      "2022-01-20 11:23:37 [INFO]\t[TRAIN] Epoch=8/50, Step=414/478, loss=0.070069, lr=0.087206, time_each_step=1.29s, eta=7:16:1\n",
      "2022-01-20 11:23:40 [INFO]\t[TRAIN] Epoch=8/50, Step=416/478, loss=0.059346, lr=0.087199, time_each_step=1.29s, eta=7:17:46\n",
      "2022-01-20 11:23:43 [INFO]\t[TRAIN] Epoch=8/50, Step=418/478, loss=0.052263, lr=0.087192, time_each_step=1.29s, eta=7:15:49\n",
      "2022-01-20 11:23:45 [INFO]\t[TRAIN] Epoch=8/50, Step=420/478, loss=0.088403, lr=0.087185, time_each_step=1.29s, eta=7:16:30\n",
      "2022-01-20 11:23:48 [INFO]\t[TRAIN] Epoch=8/50, Step=422/478, loss=0.050142, lr=0.087178, time_each_step=1.29s, eta=7:17:33\n",
      "2022-01-20 11:23:50 [INFO]\t[TRAIN] Epoch=8/50, Step=424/478, loss=0.071759, lr=0.087171, time_each_step=1.28s, eta=7:15:28\n",
      "2022-01-20 11:23:53 [INFO]\t[TRAIN] Epoch=8/50, Step=426/478, loss=0.074463, lr=0.087164, time_each_step=1.29s, eta=7:16:9\n",
      "2022-01-20 11:23:55 [INFO]\t[TRAIN] Epoch=8/50, Step=428/478, loss=0.052632, lr=0.087158, time_each_step=1.29s, eta=7:16:32\n",
      "2022-01-20 11:23:58 [INFO]\t[TRAIN] Epoch=8/50, Step=430/478, loss=0.070024, lr=0.087151, time_each_step=1.28s, eta=7:14:59\n",
      "2022-01-20 11:24:01 [INFO]\t[TRAIN] Epoch=8/50, Step=432/478, loss=0.052996, lr=0.087144, time_each_step=1.29s, eta=7:15:56\n",
      "2022-01-20 11:24:03 [INFO]\t[TRAIN] Epoch=8/50, Step=434/478, loss=0.100218, lr=0.087137, time_each_step=1.29s, eta=7:17:5\n",
      "2022-01-20 11:24:06 [INFO]\t[TRAIN] Epoch=8/50, Step=436/478, loss=0.073817, lr=0.087130, time_each_step=1.28s, eta=7:15:7\n",
      "2022-01-20 11:24:08 [INFO]\t[TRAIN] Epoch=8/50, Step=438/478, loss=0.061137, lr=0.087123, time_each_step=1.29s, eta=7:16:3\n",
      "2022-01-20 11:24:11 [INFO]\t[TRAIN] Epoch=8/50, Step=440/478, loss=0.084922, lr=0.087116, time_each_step=1.29s, eta=7:17:37\n",
      "2022-01-20 11:24:13 [INFO]\t[TRAIN] Epoch=8/50, Step=442/478, loss=0.055191, lr=0.087109, time_each_step=1.28s, eta=7:15:4\n",
      "2022-01-20 11:24:16 [INFO]\t[TRAIN] Epoch=8/50, Step=444/478, loss=0.049948, lr=0.087102, time_each_step=1.29s, eta=7:18:11\n",
      "2022-01-20 11:24:19 [INFO]\t[TRAIN] Epoch=8/50, Step=446/478, loss=0.072135, lr=0.087095, time_each_step=1.29s, eta=7:16:21\n",
      "2022-01-20 11:24:21 [INFO]\t[TRAIN] Epoch=8/50, Step=448/478, loss=0.076779, lr=0.087088, time_each_step=1.29s, eta=7:15:33\n",
      "2022-01-20 11:24:24 [INFO]\t[TRAIN] Epoch=8/50, Step=450/478, loss=0.078165, lr=0.087081, time_each_step=1.28s, eta=7:14:49\n",
      "2022-01-20 11:24:26 [INFO]\t[TRAIN] Epoch=8/50, Step=452/478, loss=0.089447, lr=0.087074, time_each_step=1.29s, eta=7:15:9\n",
      "2022-01-20 11:24:29 [INFO]\t[TRAIN] Epoch=8/50, Step=454/478, loss=0.052830, lr=0.087067, time_each_step=1.29s, eta=7:15:37\n",
      "2022-01-20 11:24:31 [INFO]\t[TRAIN] Epoch=8/50, Step=456/478, loss=0.102163, lr=0.087061, time_each_step=1.29s, eta=7:15:58\n",
      "2022-01-20 11:24:34 [INFO]\t[TRAIN] Epoch=8/50, Step=458/478, loss=0.061076, lr=0.087054, time_each_step=1.29s, eta=7:15:29\n",
      "2022-01-20 11:24:37 [INFO]\t[TRAIN] Epoch=8/50, Step=460/478, loss=0.104777, lr=0.087047, time_each_step=1.29s, eta=7:15:2\n",
      "2022-01-20 11:24:39 [INFO]\t[TRAIN] Epoch=8/50, Step=462/478, loss=0.051359, lr=0.087040, time_each_step=1.29s, eta=7:16:45\n",
      "2022-01-20 11:24:42 [INFO]\t[TRAIN] Epoch=8/50, Step=464/478, loss=0.078224, lr=0.087033, time_each_step=1.28s, eta=7:14:20\n",
      "2022-01-20 11:24:44 [INFO]\t[TRAIN] Epoch=8/50, Step=466/478, loss=0.071355, lr=0.087026, time_each_step=1.29s, eta=7:15:53\n",
      "2022-01-20 11:24:47 [INFO]\t[TRAIN] Epoch=8/50, Step=468/478, loss=0.060324, lr=0.087019, time_each_step=1.28s, eta=7:14:38\n",
      "2022-01-20 11:24:49 [INFO]\t[TRAIN] Epoch=8/50, Step=470/478, loss=0.062163, lr=0.087012, time_each_step=1.29s, eta=7:14:57\n",
      "2022-01-20 11:24:52 [INFO]\t[TRAIN] Epoch=8/50, Step=472/478, loss=0.055118, lr=0.087005, time_each_step=1.29s, eta=7:15:41\n",
      "2022-01-20 11:24:55 [INFO]\t[TRAIN] Epoch=8/50, Step=474/478, loss=0.064406, lr=0.086998, time_each_step=1.29s, eta=7:15:37\n",
      "2022-01-20 11:24:57 [INFO]\t[TRAIN] Epoch=8/50, Step=476/478, loss=0.054754, lr=0.086991, time_each_step=1.28s, eta=7:14:24\n",
      "2022-01-20 11:25:00 [INFO]\t[TRAIN] Epoch=8/50, Step=478/478, loss=0.049858, lr=0.086984, time_each_step=1.28s, eta=7:13:54\n",
      "2022-01-20 11:25:00 [INFO]\t[TRAIN] Epoch 8 finished, loss=0.07433909 .\n",
      "2022-01-20 11:25:00 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-01-20 11:25:00 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-01-20 11:25:06 [INFO]\t[EVAL] Finished, Epoch=8, miou=0.821015, category_iou=[0.9683194  0.7179783  0.77674776], oacc=0.970185, category_acc=[0.98848325 0.8179494  0.84218335], kappa=0.858751, category_F1-score=[0.98390477 0.83584096 0.87434776] .\n",
      "2022-01-20 11:25:06 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_6, miou=0.8331509232521057\n",
      "2022-01-20 11:25:07 [INFO]\tModel saved in model/deeplab_augument_alldata2/epoch_8.\n",
      "2022-01-20 11:25:11 [INFO]\t[TRAIN] Epoch=9/50, Step=2/478, loss=0.071886, lr=0.086977, time_each_step=1.91s, eta=10:44:0\n",
      "2022-01-20 11:25:13 [INFO]\t[TRAIN] Epoch=9/50, Step=4/478, loss=0.080343, lr=0.086970, time_each_step=1.29s, eta=7:14:31\n",
      "2022-01-20 11:25:16 [INFO]\t[TRAIN] Epoch=9/50, Step=6/478, loss=0.066571, lr=0.086963, time_each_step=1.29s, eta=7:15:25\n",
      "2022-01-20 11:25:18 [INFO]\t[TRAIN] Epoch=9/50, Step=8/478, loss=0.060410, lr=0.086957, time_each_step=1.29s, eta=7:14:58\n",
      "2022-01-20 11:25:21 [INFO]\t[TRAIN] Epoch=9/50, Step=10/478, loss=0.075203, lr=0.086950, time_each_step=1.28s, eta=7:14:9\n",
      "2022-01-20 11:25:24 [INFO]\t[TRAIN] Epoch=9/50, Step=12/478, loss=0.061357, lr=0.086943, time_each_step=1.29s, eta=7:15:15\n",
      "2022-01-20 11:25:26 [INFO]\t[TRAIN] Epoch=9/50, Step=14/478, loss=0.051884, lr=0.086936, time_each_step=1.29s, eta=7:15:34\n",
      "2022-01-20 11:25:29 [INFO]\t[TRAIN] Epoch=9/50, Step=16/478, loss=0.078578, lr=0.086929, time_each_step=1.28s, eta=7:13:22\n",
      "2022-01-20 11:25:31 [INFO]\t[TRAIN] Epoch=9/50, Step=18/478, loss=0.068112, lr=0.086922, time_each_step=1.29s, eta=7:14:37\n",
      "2022-01-20 11:25:34 [INFO]\t[TRAIN] Epoch=9/50, Step=20/478, loss=0.053778, lr=0.086915, time_each_step=1.29s, eta=7:15:20\n",
      "2022-01-20 11:25:36 [INFO]\t[TRAIN] Epoch=9/50, Step=22/478, loss=0.046303, lr=0.086908, time_each_step=1.29s, eta=7:14:34\n",
      "2022-01-20 11:25:39 [INFO]\t[TRAIN] Epoch=9/50, Step=24/478, loss=0.076924, lr=0.086901, time_each_step=1.29s, eta=7:14:56\n",
      "2022-01-20 11:25:42 [INFO]\t[TRAIN] Epoch=9/50, Step=26/478, loss=0.075705, lr=0.086894, time_each_step=1.29s, eta=7:14:5\n",
      "2022-01-20 11:25:44 [INFO]\t[TRAIN] Epoch=9/50, Step=28/478, loss=0.072139, lr=0.086887, time_each_step=1.29s, eta=7:14:9\n",
      "2022-01-20 11:25:47 [INFO]\t[TRAIN] Epoch=9/50, Step=30/478, loss=0.064283, lr=0.086880, time_each_step=1.29s, eta=7:14:53\n",
      "2022-01-20 11:25:49 [INFO]\t[TRAIN] Epoch=9/50, Step=32/478, loss=0.077488, lr=0.086873, time_each_step=1.28s, eta=7:13:35\n",
      "2022-01-20 11:25:52 [INFO]\t[TRAIN] Epoch=9/50, Step=34/478, loss=0.065593, lr=0.086866, time_each_step=1.29s, eta=7:14:8\n",
      "2022-01-20 11:25:54 [INFO]\t[TRAIN] Epoch=9/50, Step=36/478, loss=0.058631, lr=0.086859, time_each_step=1.29s, eta=7:14:38\n",
      "2022-01-20 11:25:57 [INFO]\t[TRAIN] Epoch=9/50, Step=38/478, loss=0.061519, lr=0.086853, time_each_step=1.29s, eta=7:14:43\n",
      "2022-01-20 11:26:00 [INFO]\t[TRAIN] Epoch=9/50, Step=40/478, loss=0.083518, lr=0.086846, time_each_step=1.29s, eta=7:14:33\n",
      "2022-01-20 11:26:02 [INFO]\t[TRAIN] Epoch=9/50, Step=42/478, loss=0.064508, lr=0.086839, time_each_step=1.29s, eta=7:15:21\n",
      "2022-01-20 11:26:05 [INFO]\t[TRAIN] Epoch=9/50, Step=44/478, loss=0.073181, lr=0.086832, time_each_step=1.29s, eta=7:13:42\n",
      "2022-01-20 11:26:07 [INFO]\t[TRAIN] Epoch=9/50, Step=46/478, loss=0.088661, lr=0.086825, time_each_step=1.29s, eta=7:13:50\n",
      "2022-01-20 11:26:10 [INFO]\t[TRAIN] Epoch=9/50, Step=48/478, loss=0.062109, lr=0.086818, time_each_step=1.29s, eta=7:13:55\n",
      "2022-01-20 11:26:12 [INFO]\t[TRAIN] Epoch=9/50, Step=50/478, loss=0.081449, lr=0.086811, time_each_step=1.29s, eta=7:14:23\n",
      "2022-01-20 11:26:15 [INFO]\t[TRAIN] Epoch=9/50, Step=52/478, loss=0.083410, lr=0.086804, time_each_step=1.28s, eta=7:13:5\n",
      "2022-01-20 11:26:18 [INFO]\t[TRAIN] Epoch=9/50, Step=54/478, loss=0.071682, lr=0.086797, time_each_step=1.29s, eta=7:13:51\n",
      "2022-01-20 11:26:20 [INFO]\t[TRAIN] Epoch=9/50, Step=56/478, loss=0.077167, lr=0.086790, time_each_step=1.29s, eta=7:13:47\n",
      "2022-01-20 11:26:23 [INFO]\t[TRAIN] Epoch=9/50, Step=58/478, loss=0.072894, lr=0.086783, time_each_step=1.29s, eta=7:13:16\n",
      "2022-01-20 11:26:25 [INFO]\t[TRAIN] Epoch=9/50, Step=60/478, loss=0.070372, lr=0.086776, time_each_step=1.29s, eta=7:13:58\n",
      "2022-01-20 11:26:28 [INFO]\t[TRAIN] Epoch=9/50, Step=62/478, loss=0.066332, lr=0.086769, time_each_step=1.29s, eta=7:13:4\n",
      "2022-01-20 11:26:30 [INFO]\t[TRAIN] Epoch=9/50, Step=64/478, loss=0.087804, lr=0.086762, time_each_step=1.29s, eta=7:13:10\n",
      "2022-01-20 11:26:33 [INFO]\t[TRAIN] Epoch=9/50, Step=66/478, loss=0.075729, lr=0.086755, time_each_step=1.29s, eta=7:13:19\n",
      "2022-01-20 11:26:36 [INFO]\t[TRAIN] Epoch=9/50, Step=68/478, loss=0.062898, lr=0.086749, time_each_step=1.28s, eta=7:12:28\n",
      "2022-01-20 11:26:38 [INFO]\t[TRAIN] Epoch=9/50, Step=70/478, loss=0.050135, lr=0.086742, time_each_step=1.29s, eta=7:13:7\n",
      "2022-01-20 11:26:41 [INFO]\t[TRAIN] Epoch=9/50, Step=72/478, loss=0.091975, lr=0.086735, time_each_step=1.29s, eta=7:13:17\n",
      "2022-01-20 11:26:43 [INFO]\t[TRAIN] Epoch=9/50, Step=74/478, loss=0.095185, lr=0.086728, time_each_step=1.29s, eta=7:13:53\n",
      "2022-01-20 11:26:46 [INFO]\t[TRAIN] Epoch=9/50, Step=76/478, loss=0.070716, lr=0.086721, time_each_step=1.28s, eta=7:12:28\n",
      "2022-01-20 11:26:49 [INFO]\t[TRAIN] Epoch=9/50, Step=78/478, loss=0.101526, lr=0.086714, time_each_step=1.29s, eta=7:13:24\n",
      "2022-01-20 11:26:51 [INFO]\t[TRAIN] Epoch=9/50, Step=80/478, loss=0.107556, lr=0.086707, time_each_step=1.29s, eta=7:13:41\n",
      "2022-01-20 11:26:54 [INFO]\t[TRAIN] Epoch=9/50, Step=82/478, loss=0.051987, lr=0.086700, time_each_step=1.28s, eta=7:12:31\n",
      "2022-01-20 11:26:56 [INFO]\t[TRAIN] Epoch=9/50, Step=84/478, loss=0.062413, lr=0.086693, time_each_step=1.29s, eta=7:13:22\n",
      "2022-01-20 11:26:59 [INFO]\t[TRAIN] Epoch=9/50, Step=86/478, loss=0.092183, lr=0.086686, time_each_step=1.29s, eta=7:12:57\n",
      "2022-01-20 11:27:01 [INFO]\t[TRAIN] Epoch=9/50, Step=88/478, loss=0.076775, lr=0.086679, time_each_step=1.29s, eta=7:12:47\n",
      "2022-01-20 11:27:04 [INFO]\t[TRAIN] Epoch=9/50, Step=90/478, loss=0.085969, lr=0.086672, time_each_step=1.29s, eta=7:13:46\n",
      "2022-01-20 11:27:07 [INFO]\t[TRAIN] Epoch=9/50, Step=92/478, loss=0.082442, lr=0.086665, time_each_step=1.29s, eta=7:12:47\n",
      "2022-01-20 11:27:09 [INFO]\t[TRAIN] Epoch=9/50, Step=94/478, loss=0.067127, lr=0.086658, time_each_step=1.29s, eta=7:13:28\n",
      "2022-01-20 11:27:12 [INFO]\t[TRAIN] Epoch=9/50, Step=96/478, loss=0.083916, lr=0.086651, time_each_step=1.29s, eta=7:13:9\n",
      "2022-01-20 11:27:14 [INFO]\t[TRAIN] Epoch=9/50, Step=98/478, loss=0.074986, lr=0.086644, time_each_step=1.28s, eta=7:12:12\n",
      "2022-01-20 11:27:17 [INFO]\t[TRAIN] Epoch=9/50, Step=100/478, loss=0.072891, lr=0.086637, time_each_step=1.28s, eta=7:11:33\n",
      "2022-01-20 11:27:19 [INFO]\t[TRAIN] Epoch=9/50, Step=102/478, loss=0.083489, lr=0.086631, time_each_step=1.29s, eta=7:13:6\n",
      "2022-01-20 11:27:22 [INFO]\t[TRAIN] Epoch=9/50, Step=104/478, loss=0.063700, lr=0.086624, time_each_step=1.29s, eta=7:12:14\n",
      "2022-01-20 11:27:25 [INFO]\t[TRAIN] Epoch=9/50, Step=106/478, loss=0.070204, lr=0.086617, time_each_step=1.29s, eta=7:12:16\n",
      "2022-01-20 11:27:27 [INFO]\t[TRAIN] Epoch=9/50, Step=108/478, loss=0.068965, lr=0.086610, time_each_step=1.29s, eta=7:13:20\n",
      "2022-01-20 11:27:30 [INFO]\t[TRAIN] Epoch=9/50, Step=110/478, loss=0.079734, lr=0.086603, time_each_step=1.29s, eta=7:12:30\n",
      "2022-01-20 11:27:32 [INFO]\t[TRAIN] Epoch=9/50, Step=112/478, loss=0.067243, lr=0.086596, time_each_step=1.29s, eta=7:12:21\n",
      "2022-01-20 11:27:35 [INFO]\t[TRAIN] Epoch=9/50, Step=114/478, loss=0.087425, lr=0.086589, time_each_step=1.29s, eta=7:13:19\n",
      "2022-01-20 11:27:37 [INFO]\t[TRAIN] Epoch=9/50, Step=116/478, loss=0.056740, lr=0.086582, time_each_step=1.28s, eta=7:11:46\n",
      "2022-01-20 11:27:40 [INFO]\t[TRAIN] Epoch=9/50, Step=118/478, loss=0.078667, lr=0.086575, time_each_step=1.29s, eta=7:12:30\n",
      "2022-01-20 11:27:43 [INFO]\t[TRAIN] Epoch=9/50, Step=120/478, loss=0.085981, lr=0.086568, time_each_step=1.29s, eta=7:12:32\n",
      "2022-01-20 11:27:45 [INFO]\t[TRAIN] Epoch=9/50, Step=122/478, loss=0.082493, lr=0.086561, time_each_step=1.28s, eta=7:11:32\n",
      "2022-01-20 11:27:48 [INFO]\t[TRAIN] Epoch=9/50, Step=124/478, loss=0.064617, lr=0.086554, time_each_step=1.29s, eta=7:12:22\n",
      "2022-01-20 11:27:50 [INFO]\t[TRAIN] Epoch=9/50, Step=126/478, loss=0.112663, lr=0.086547, time_each_step=1.29s, eta=7:13:2\n",
      "2022-01-20 11:27:53 [INFO]\t[TRAIN] Epoch=9/50, Step=128/478, loss=0.060079, lr=0.086540, time_each_step=1.28s, eta=7:10:56\n",
      "2022-01-20 11:27:55 [INFO]\t[TRAIN] Epoch=9/50, Step=130/478, loss=0.078087, lr=0.086533, time_each_step=1.29s, eta=7:11:43\n",
      "2022-01-20 11:27:58 [INFO]\t[TRAIN] Epoch=9/50, Step=132/478, loss=0.076915, lr=0.086526, time_each_step=1.29s, eta=7:12:25\n",
      "2022-01-20 11:28:01 [INFO]\t[TRAIN] Epoch=9/50, Step=134/478, loss=0.075381, lr=0.086520, time_each_step=1.28s, eta=7:10:21\n",
      "2022-01-20 11:28:03 [INFO]\t[TRAIN] Epoch=9/50, Step=136/478, loss=0.063995, lr=0.086513, time_each_step=1.29s, eta=7:11:28\n",
      "2022-01-20 11:28:06 [INFO]\t[TRAIN] Epoch=9/50, Step=138/478, loss=0.095905, lr=0.086506, time_each_step=1.29s, eta=7:11:45\n",
      "2022-01-20 11:28:08 [INFO]\t[TRAIN] Epoch=9/50, Step=140/478, loss=0.086899, lr=0.086499, time_each_step=1.29s, eta=7:11:51\n",
      "2022-01-20 11:28:11 [INFO]\t[TRAIN] Epoch=9/50, Step=142/478, loss=0.086364, lr=0.086492, time_each_step=1.28s, eta=7:11:6\n",
      "2022-01-20 11:28:13 [INFO]\t[TRAIN] Epoch=9/50, Step=144/478, loss=0.043361, lr=0.086485, time_each_step=1.29s, eta=7:11:52\n",
      "2022-01-20 11:28:16 [INFO]\t[TRAIN] Epoch=9/50, Step=146/478, loss=0.057113, lr=0.086478, time_each_step=1.29s, eta=7:13:5\n",
      "2022-01-20 11:28:19 [INFO]\t[TRAIN] Epoch=9/50, Step=148/478, loss=0.067138, lr=0.086471, time_each_step=1.29s, eta=7:11:33\n",
      "2022-01-20 11:28:21 [INFO]\t[TRAIN] Epoch=9/50, Step=150/478, loss=0.115777, lr=0.086464, time_each_step=1.29s, eta=7:12:9\n",
      "2022-01-20 11:28:24 [INFO]\t[TRAIN] Epoch=9/50, Step=152/478, loss=0.089018, lr=0.086457, time_each_step=1.29s, eta=7:11:10\n",
      "2022-01-20 11:28:26 [INFO]\t[TRAIN] Epoch=9/50, Step=154/478, loss=0.063461, lr=0.086450, time_each_step=1.29s, eta=7:11:42\n",
      "2022-01-20 11:28:29 [INFO]\t[TRAIN] Epoch=9/50, Step=156/478, loss=0.079959, lr=0.086443, time_each_step=1.28s, eta=7:10:54\n",
      "2022-01-20 11:28:31 [INFO]\t[TRAIN] Epoch=9/50, Step=158/478, loss=0.054440, lr=0.086436, time_each_step=1.29s, eta=7:12:0\n",
      "2022-01-20 11:28:34 [INFO]\t[TRAIN] Epoch=9/50, Step=160/478, loss=0.055125, lr=0.086429, time_each_step=1.29s, eta=7:11:30\n",
      "2022-01-20 11:28:37 [INFO]\t[TRAIN] Epoch=9/50, Step=162/478, loss=0.093480, lr=0.086422, time_each_step=1.29s, eta=7:11:35\n",
      "2022-01-20 11:28:39 [INFO]\t[TRAIN] Epoch=9/50, Step=164/478, loss=0.080282, lr=0.086415, time_each_step=1.29s, eta=7:11:32\n",
      "2022-01-20 11:28:42 [INFO]\t[TRAIN] Epoch=9/50, Step=166/478, loss=0.067362, lr=0.086408, time_each_step=1.29s, eta=7:11:1\n",
      "2022-01-20 11:28:44 [INFO]\t[TRAIN] Epoch=9/50, Step=168/478, loss=0.064980, lr=0.086401, time_each_step=1.29s, eta=7:11:47\n",
      "2022-01-20 11:28:47 [INFO]\t[TRAIN] Epoch=9/50, Step=170/478, loss=0.071125, lr=0.086395, time_each_step=1.29s, eta=7:11:6\n",
      "2022-01-20 11:28:49 [INFO]\t[TRAIN] Epoch=9/50, Step=172/478, loss=0.069166, lr=0.086388, time_each_step=1.29s, eta=7:11:1\n",
      "2022-01-20 11:28:52 [INFO]\t[TRAIN] Epoch=9/50, Step=174/478, loss=0.082921, lr=0.086381, time_each_step=1.29s, eta=7:10:41\n",
      "2022-01-20 11:28:55 [INFO]\t[TRAIN] Epoch=9/50, Step=176/478, loss=0.061645, lr=0.086374, time_each_step=1.28s, eta=7:10:22\n",
      "2022-01-20 11:28:57 [INFO]\t[TRAIN] Epoch=9/50, Step=178/478, loss=0.087056, lr=0.086367, time_each_step=1.28s, eta=7:10:32\n",
      "2022-01-20 11:29:00 [INFO]\t[TRAIN] Epoch=9/50, Step=180/478, loss=0.055041, lr=0.086360, time_each_step=1.29s, eta=7:11:9\n",
      "2022-01-20 11:29:02 [INFO]\t[TRAIN] Epoch=9/50, Step=182/478, loss=0.069977, lr=0.086353, time_each_step=1.29s, eta=7:10:37\n",
      "2022-01-20 11:29:05 [INFO]\t[TRAIN] Epoch=9/50, Step=184/478, loss=0.061308, lr=0.086346, time_each_step=1.28s, eta=7:10:24\n",
      "2022-01-20 11:29:07 [INFO]\t[TRAIN] Epoch=9/50, Step=186/478, loss=0.069161, lr=0.086339, time_each_step=1.29s, eta=7:10:54\n",
      "2022-01-20 11:29:10 [INFO]\t[TRAIN] Epoch=9/50, Step=188/478, loss=0.053301, lr=0.086332, time_each_step=1.29s, eta=7:10:31\n",
      "2022-01-20 11:29:13 [INFO]\t[TRAIN] Epoch=9/50, Step=190/478, loss=0.076376, lr=0.086325, time_each_step=1.29s, eta=7:11:33\n",
      "2022-01-20 11:29:15 [INFO]\t[TRAIN] Epoch=9/50, Step=192/478, loss=0.065998, lr=0.086318, time_each_step=1.29s, eta=7:11:28\n",
      "2022-01-20 11:29:18 [INFO]\t[TRAIN] Epoch=9/50, Step=194/478, loss=0.080210, lr=0.086311, time_each_step=1.29s, eta=7:10:20\n",
      "2022-01-20 11:29:20 [INFO]\t[TRAIN] Epoch=9/50, Step=196/478, loss=0.075943, lr=0.086304, time_each_step=1.29s, eta=7:10:47\n",
      "2022-01-20 11:29:23 [INFO]\t[TRAIN] Epoch=9/50, Step=198/478, loss=0.058485, lr=0.086297, time_each_step=1.29s, eta=7:12:0\n",
      "2022-01-20 11:29:25 [INFO]\t[TRAIN] Epoch=9/50, Step=200/478, loss=0.109262, lr=0.086290, time_each_step=1.29s, eta=7:12:1\n",
      "2022-01-20 11:29:28 [INFO]\t[TRAIN] Epoch=9/50, Step=202/478, loss=0.054427, lr=0.086283, time_each_step=1.29s, eta=7:10:34\n",
      "2022-01-20 11:29:31 [INFO]\t[TRAIN] Epoch=9/50, Step=204/478, loss=0.070732, lr=0.086276, time_each_step=1.29s, eta=7:13:3\n",
      "2022-01-20 11:29:33 [INFO]\t[TRAIN] Epoch=9/50, Step=206/478, loss=0.059255, lr=0.086270, time_each_step=1.29s, eta=7:11:3\n",
      "2022-01-20 11:29:36 [INFO]\t[TRAIN] Epoch=9/50, Step=208/478, loss=0.079366, lr=0.086263, time_each_step=1.29s, eta=7:11:32\n",
      "2022-01-20 11:29:38 [INFO]\t[TRAIN] Epoch=9/50, Step=210/478, loss=0.069935, lr=0.086256, time_each_step=1.29s, eta=7:10:44\n",
      "2022-01-20 11:29:41 [INFO]\t[TRAIN] Epoch=9/50, Step=212/478, loss=0.074642, lr=0.086249, time_each_step=1.28s, eta=7:9:44\n",
      "2022-01-20 11:29:43 [INFO]\t[TRAIN] Epoch=9/50, Step=214/478, loss=0.066699, lr=0.086242, time_each_step=1.29s, eta=7:10:26\n",
      "2022-01-20 11:29:46 [INFO]\t[TRAIN] Epoch=9/50, Step=216/478, loss=0.064861, lr=0.086235, time_each_step=1.29s, eta=7:10:15\n",
      "2022-01-20 11:29:49 [INFO]\t[TRAIN] Epoch=9/50, Step=218/478, loss=0.102729, lr=0.086228, time_each_step=1.28s, eta=7:9:27\n",
      "2022-01-20 11:29:51 [INFO]\t[TRAIN] Epoch=9/50, Step=220/478, loss=0.064457, lr=0.086221, time_each_step=1.29s, eta=7:10:20\n",
      "2022-01-20 11:29:54 [INFO]\t[TRAIN] Epoch=9/50, Step=222/478, loss=0.061855, lr=0.086214, time_each_step=1.28s, eta=7:9:27\n",
      "2022-01-20 11:29:56 [INFO]\t[TRAIN] Epoch=9/50, Step=224/478, loss=0.089455, lr=0.086207, time_each_step=1.28s, eta=7:9:32\n",
      "2022-01-20 11:29:59 [INFO]\t[TRAIN] Epoch=9/50, Step=226/478, loss=0.076118, lr=0.086200, time_each_step=1.29s, eta=7:10:5\n",
      "2022-01-20 11:30:01 [INFO]\t[TRAIN] Epoch=9/50, Step=228/478, loss=0.058215, lr=0.086193, time_each_step=1.29s, eta=7:10:1\n",
      "2022-01-20 11:30:04 [INFO]\t[TRAIN] Epoch=9/50, Step=230/478, loss=0.061545, lr=0.086186, time_each_step=1.28s, eta=7:9:8\n",
      "2022-01-20 11:30:07 [INFO]\t[TRAIN] Epoch=9/50, Step=232/478, loss=0.087497, lr=0.086179, time_each_step=1.29s, eta=7:9:55\n",
      "2022-01-20 11:30:09 [INFO]\t[TRAIN] Epoch=9/50, Step=234/478, loss=0.071808, lr=0.086172, time_each_step=1.29s, eta=7:9:27\n",
      "2022-01-20 11:30:12 [INFO]\t[TRAIN] Epoch=9/50, Step=236/478, loss=0.108441, lr=0.086165, time_each_step=1.29s, eta=7:9:32\n",
      "2022-01-20 11:30:14 [INFO]\t[TRAIN] Epoch=9/50, Step=238/478, loss=0.081192, lr=0.086158, time_each_step=1.29s, eta=7:9:53\n",
      "2022-01-20 11:30:17 [INFO]\t[TRAIN] Epoch=9/50, Step=240/478, loss=0.085005, lr=0.086151, time_each_step=1.29s, eta=7:9:31\n",
      "2022-01-20 11:30:19 [INFO]\t[TRAIN] Epoch=9/50, Step=242/478, loss=0.091945, lr=0.086144, time_each_step=1.28s, eta=7:9:6\n",
      "2022-01-20 11:30:22 [INFO]\t[TRAIN] Epoch=9/50, Step=244/478, loss=0.081147, lr=0.086138, time_each_step=1.29s, eta=7:10:28\n",
      "2022-01-20 11:30:25 [INFO]\t[TRAIN] Epoch=9/50, Step=246/478, loss=0.072269, lr=0.086131, time_each_step=1.29s, eta=7:9:30\n",
      "2022-01-20 11:30:27 [INFO]\t[TRAIN] Epoch=9/50, Step=248/478, loss=0.089676, lr=0.086124, time_each_step=1.29s, eta=7:10:36\n",
      "2022-01-20 11:30:30 [INFO]\t[TRAIN] Epoch=9/50, Step=250/478, loss=0.068236, lr=0.086117, time_each_step=1.29s, eta=7:9:57\n",
      "2022-01-20 11:30:32 [INFO]\t[TRAIN] Epoch=9/50, Step=252/478, loss=0.094115, lr=0.086110, time_each_step=1.29s, eta=7:9:8\n",
      "2022-01-20 11:30:35 [INFO]\t[TRAIN] Epoch=9/50, Step=254/478, loss=0.079944, lr=0.086103, time_each_step=1.29s, eta=7:9:13\n",
      "2022-01-20 11:30:38 [INFO]\t[TRAIN] Epoch=9/50, Step=256/478, loss=0.062426, lr=0.086096, time_each_step=1.29s, eta=7:9:51\n",
      "2022-01-20 11:30:40 [INFO]\t[TRAIN] Epoch=9/50, Step=258/478, loss=0.079094, lr=0.086089, time_each_step=1.29s, eta=7:9:0\n",
      "2022-01-20 11:30:43 [INFO]\t[TRAIN] Epoch=9/50, Step=260/478, loss=0.070338, lr=0.086082, time_each_step=1.29s, eta=7:9:14\n",
      "2022-01-20 11:30:45 [INFO]\t[TRAIN] Epoch=9/50, Step=262/478, loss=0.061566, lr=0.086075, time_each_step=1.29s, eta=7:10:3\n",
      "2022-01-20 11:30:48 [INFO]\t[TRAIN] Epoch=9/50, Step=264/478, loss=0.063851, lr=0.086068, time_each_step=1.28s, eta=7:8:10\n",
      "2022-01-20 11:30:50 [INFO]\t[TRAIN] Epoch=9/50, Step=266/478, loss=0.066584, lr=0.086061, time_each_step=1.29s, eta=7:8:59\n",
      "2022-01-20 11:30:53 [INFO]\t[TRAIN] Epoch=9/50, Step=268/478, loss=0.074631, lr=0.086054, time_each_step=1.29s, eta=7:9:42\n",
      "2022-01-20 11:30:56 [INFO]\t[TRAIN] Epoch=9/50, Step=270/478, loss=0.049986, lr=0.086047, time_each_step=1.28s, eta=7:8:10\n",
      "2022-01-20 11:30:58 [INFO]\t[TRAIN] Epoch=9/50, Step=272/478, loss=0.100165, lr=0.086040, time_each_step=1.29s, eta=7:9:10\n",
      "2022-01-20 11:31:01 [INFO]\t[TRAIN] Epoch=9/50, Step=274/478, loss=0.055561, lr=0.086033, time_each_step=1.29s, eta=7:10:4\n",
      "2022-01-20 11:31:03 [INFO]\t[TRAIN] Epoch=9/50, Step=276/478, loss=0.055878, lr=0.086026, time_each_step=1.29s, eta=7:8:47\n",
      "2022-01-20 11:31:06 [INFO]\t[TRAIN] Epoch=9/50, Step=278/478, loss=0.058981, lr=0.086019, time_each_step=1.28s, eta=7:8:19\n",
      "2022-01-20 11:31:08 [INFO]\t[TRAIN] Epoch=9/50, Step=280/478, loss=0.048965, lr=0.086012, time_each_step=1.29s, eta=7:9:35\n",
      "2022-01-20 11:31:11 [INFO]\t[TRAIN] Epoch=9/50, Step=282/478, loss=0.052174, lr=0.086005, time_each_step=1.28s, eta=7:7:6\n",
      "2022-01-20 11:31:14 [INFO]\t[TRAIN] Epoch=9/50, Step=284/478, loss=0.065276, lr=0.085999, time_each_step=1.28s, eta=7:8:8\n",
      "2022-01-20 11:31:16 [INFO]\t[TRAIN] Epoch=9/50, Step=286/478, loss=0.075657, lr=0.085992, time_each_step=1.29s, eta=7:8:59\n",
      "2022-01-20 11:31:19 [INFO]\t[TRAIN] Epoch=9/50, Step=288/478, loss=0.070668, lr=0.085985, time_each_step=1.28s, eta=7:7:58\n",
      "2022-01-20 11:31:21 [INFO]\t[TRAIN] Epoch=9/50, Step=290/478, loss=0.054346, lr=0.085978, time_each_step=1.29s, eta=7:8:23\n",
      "2022-01-20 11:31:24 [INFO]\t[TRAIN] Epoch=9/50, Step=292/478, loss=0.042981, lr=0.085971, time_each_step=1.29s, eta=7:9:11\n",
      "2022-01-20 11:31:26 [INFO]\t[TRAIN] Epoch=9/50, Step=294/478, loss=0.098835, lr=0.085964, time_each_step=1.29s, eta=7:8:55\n",
      "2022-01-20 11:31:29 [INFO]\t[TRAIN] Epoch=9/50, Step=296/478, loss=0.081458, lr=0.085957, time_each_step=1.29s, eta=7:8:57\n",
      "2022-01-20 11:31:32 [INFO]\t[TRAIN] Epoch=9/50, Step=298/478, loss=0.090102, lr=0.085950, time_each_step=1.28s, eta=7:7:25\n",
      "2022-01-20 11:31:34 [INFO]\t[TRAIN] Epoch=9/50, Step=300/478, loss=0.130288, lr=0.085943, time_each_step=1.29s, eta=7:9:54\n",
      "2022-01-20 11:31:37 [INFO]\t[TRAIN] Epoch=9/50, Step=302/478, loss=0.071292, lr=0.085936, time_each_step=1.28s, eta=7:7:41\n",
      "2022-01-20 11:31:39 [INFO]\t[TRAIN] Epoch=9/50, Step=304/478, loss=0.054639, lr=0.085929, time_each_step=1.29s, eta=7:8:41\n",
      "2022-01-20 11:31:42 [INFO]\t[TRAIN] Epoch=9/50, Step=306/478, loss=0.081985, lr=0.085922, time_each_step=1.29s, eta=7:8:27\n",
      "2022-01-20 11:31:44 [INFO]\t[TRAIN] Epoch=9/50, Step=308/478, loss=0.088375, lr=0.085915, time_each_step=1.28s, eta=7:7:42\n",
      "2022-01-20 11:31:47 [INFO]\t[TRAIN] Epoch=9/50, Step=310/478, loss=0.107382, lr=0.085908, time_each_step=1.29s, eta=7:8:16\n",
      "2022-01-20 11:31:50 [INFO]\t[TRAIN] Epoch=9/50, Step=312/478, loss=0.058448, lr=0.085901, time_each_step=1.29s, eta=7:8:29\n",
      "2022-01-20 11:31:52 [INFO]\t[TRAIN] Epoch=9/50, Step=314/478, loss=0.074919, lr=0.085894, time_each_step=1.29s, eta=7:7:58\n",
      "2022-01-20 11:31:55 [INFO]\t[TRAIN] Epoch=9/50, Step=316/478, loss=0.087397, lr=0.085887, time_each_step=1.28s, eta=7:7:17\n",
      "2022-01-20 11:31:57 [INFO]\t[TRAIN] Epoch=9/50, Step=318/478, loss=0.084235, lr=0.085880, time_each_step=1.29s, eta=7:9:10\n",
      "2022-01-20 11:32:00 [INFO]\t[TRAIN] Epoch=9/50, Step=320/478, loss=0.057663, lr=0.085873, time_each_step=1.29s, eta=7:8:38\n",
      "2022-01-20 11:32:02 [INFO]\t[TRAIN] Epoch=9/50, Step=322/478, loss=0.062683, lr=0.085866, time_each_step=1.29s, eta=7:8:8\n",
      "2022-01-20 11:32:05 [INFO]\t[TRAIN] Epoch=9/50, Step=324/478, loss=0.067312, lr=0.085859, time_each_step=1.29s, eta=7:7:49\n",
      "2022-01-20 11:32:08 [INFO]\t[TRAIN] Epoch=9/50, Step=326/478, loss=0.059096, lr=0.085853, time_each_step=1.29s, eta=7:7:28\n",
      "2022-01-20 11:32:10 [INFO]\t[TRAIN] Epoch=9/50, Step=328/478, loss=0.080145, lr=0.085846, time_each_step=1.29s, eta=7:8:2\n",
      "2022-01-20 11:32:13 [INFO]\t[TRAIN] Epoch=9/50, Step=330/478, loss=0.053823, lr=0.085839, time_each_step=1.28s, eta=7:7:3\n",
      "2022-01-20 11:32:15 [INFO]\t[TRAIN] Epoch=9/50, Step=332/478, loss=0.066847, lr=0.085832, time_each_step=1.29s, eta=7:7:22\n",
      "2022-01-20 11:32:18 [INFO]\t[TRAIN] Epoch=9/50, Step=334/478, loss=0.060735, lr=0.085825, time_each_step=1.29s, eta=7:8:13\n",
      "2022-01-20 11:32:20 [INFO]\t[TRAIN] Epoch=9/50, Step=336/478, loss=0.068738, lr=0.085818, time_each_step=1.29s, eta=7:7:15\n",
      "2022-01-20 11:32:23 [INFO]\t[TRAIN] Epoch=9/50, Step=338/478, loss=0.065712, lr=0.085811, time_each_step=1.28s, eta=7:7:7\n",
      "2022-01-20 11:32:26 [INFO]\t[TRAIN] Epoch=9/50, Step=340/478, loss=0.052183, lr=0.085804, time_each_step=1.29s, eta=7:8:14\n",
      "2022-01-20 11:32:28 [INFO]\t[TRAIN] Epoch=9/50, Step=342/478, loss=0.064542, lr=0.085797, time_each_step=1.28s, eta=7:7:2\n",
      "2022-01-20 11:32:31 [INFO]\t[TRAIN] Epoch=9/50, Step=344/478, loss=0.063489, lr=0.085790, time_each_step=1.28s, eta=7:6:56\n",
      "2022-01-20 11:32:33 [INFO]\t[TRAIN] Epoch=9/50, Step=346/478, loss=0.048429, lr=0.085783, time_each_step=1.29s, eta=7:8:42\n",
      "2022-01-20 11:32:36 [INFO]\t[TRAIN] Epoch=9/50, Step=348/478, loss=0.066545, lr=0.085776, time_each_step=1.28s, eta=7:6:39\n",
      "2022-01-20 11:32:38 [INFO]\t[TRAIN] Epoch=9/50, Step=350/478, loss=0.071773, lr=0.085769, time_each_step=1.29s, eta=7:7:44\n",
      "2022-01-20 11:32:41 [INFO]\t[TRAIN] Epoch=9/50, Step=352/478, loss=0.069230, lr=0.085762, time_each_step=1.29s, eta=7:7:11\n",
      "2022-01-20 11:32:44 [INFO]\t[TRAIN] Epoch=9/50, Step=354/478, loss=0.068273, lr=0.085755, time_each_step=1.28s, eta=7:6:36\n",
      "2022-01-20 11:32:46 [INFO]\t[TRAIN] Epoch=9/50, Step=356/478, loss=0.084499, lr=0.085748, time_each_step=1.29s, eta=7:7:7\n",
      "2022-01-20 11:32:49 [INFO]\t[TRAIN] Epoch=9/50, Step=358/478, loss=0.080327, lr=0.085741, time_each_step=1.29s, eta=7:8:3\n",
      "2022-01-20 11:32:51 [INFO]\t[TRAIN] Epoch=9/50, Step=360/478, loss=0.077923, lr=0.085734, time_each_step=1.29s, eta=7:6:41\n",
      "2022-01-20 11:32:54 [INFO]\t[TRAIN] Epoch=9/50, Step=362/478, loss=0.112339, lr=0.085727, time_each_step=1.29s, eta=7:7:5\n",
      "2022-01-20 11:32:56 [INFO]\t[TRAIN] Epoch=9/50, Step=364/478, loss=0.061114, lr=0.085720, time_each_step=1.29s, eta=7:7:25\n",
      "2022-01-20 11:32:59 [INFO]\t[TRAIN] Epoch=9/50, Step=366/478, loss=0.092254, lr=0.085713, time_each_step=1.29s, eta=7:6:58\n",
      "2022-01-20 11:33:02 [INFO]\t[TRAIN] Epoch=9/50, Step=368/478, loss=0.059343, lr=0.085706, time_each_step=1.29s, eta=7:7:0\n",
      "2022-01-20 11:33:04 [INFO]\t[TRAIN] Epoch=9/50, Step=370/478, loss=0.042320, lr=0.085699, time_each_step=1.29s, eta=7:7:22\n",
      "2022-01-20 11:33:07 [INFO]\t[TRAIN] Epoch=9/50, Step=372/478, loss=0.091537, lr=0.085693, time_each_step=1.29s, eta=7:6:55\n",
      "2022-01-20 11:33:09 [INFO]\t[TRAIN] Epoch=9/50, Step=374/478, loss=0.075109, lr=0.085686, time_each_step=1.29s, eta=7:6:46\n",
      "2022-01-20 11:33:12 [INFO]\t[TRAIN] Epoch=9/50, Step=376/478, loss=0.064988, lr=0.085679, time_each_step=1.29s, eta=7:6:49\n",
      "2022-01-20 11:33:14 [INFO]\t[TRAIN] Epoch=9/50, Step=378/478, loss=0.078904, lr=0.085672, time_each_step=1.29s, eta=7:6:32\n",
      "2022-01-20 11:33:17 [INFO]\t[TRAIN] Epoch=9/50, Step=380/478, loss=0.046800, lr=0.085665, time_each_step=1.28s, eta=7:6:8\n",
      "2022-01-20 11:33:20 [INFO]\t[TRAIN] Epoch=9/50, Step=382/478, loss=0.065790, lr=0.085658, time_each_step=1.29s, eta=7:7:27\n",
      "2022-01-20 11:33:22 [INFO]\t[TRAIN] Epoch=9/50, Step=384/478, loss=0.053267, lr=0.085651, time_each_step=1.29s, eta=7:6:33\n",
      "2022-01-20 11:33:25 [INFO]\t[TRAIN] Epoch=9/50, Step=386/478, loss=0.066043, lr=0.085644, time_each_step=1.29s, eta=7:6:33\n",
      "2022-01-20 11:33:27 [INFO]\t[TRAIN] Epoch=9/50, Step=388/478, loss=0.072998, lr=0.085637, time_each_step=1.29s, eta=7:6:44\n",
      "2022-01-20 11:33:30 [INFO]\t[TRAIN] Epoch=9/50, Step=390/478, loss=0.105284, lr=0.085630, time_each_step=1.29s, eta=7:6:16\n",
      "2022-01-20 11:33:32 [INFO]\t[TRAIN] Epoch=9/50, Step=392/478, loss=0.069225, lr=0.085623, time_each_step=1.29s, eta=7:6:10\n",
      "2022-01-20 11:33:35 [INFO]\t[TRAIN] Epoch=9/50, Step=394/478, loss=0.068260, lr=0.085616, time_each_step=1.29s, eta=7:6:17\n",
      "2022-01-20 11:33:38 [INFO]\t[TRAIN] Epoch=9/50, Step=396/478, loss=0.045406, lr=0.085609, time_each_step=1.29s, eta=7:5:57\n",
      "2022-01-20 11:33:40 [INFO]\t[TRAIN] Epoch=9/50, Step=398/478, loss=0.073383, lr=0.085602, time_each_step=1.28s, eta=7:5:45\n",
      "2022-01-20 11:33:43 [INFO]\t[TRAIN] Epoch=9/50, Step=400/478, loss=0.098524, lr=0.085595, time_each_step=1.29s, eta=7:5:57\n",
      "2022-01-20 11:33:45 [INFO]\t[TRAIN] Epoch=9/50, Step=402/478, loss=0.066043, lr=0.085588, time_each_step=1.29s, eta=7:6:47\n",
      "2022-01-20 11:33:48 [INFO]\t[TRAIN] Epoch=9/50, Step=404/478, loss=0.081809, lr=0.085581, time_each_step=1.29s, eta=7:6:18\n",
      "2022-01-20 11:33:50 [INFO]\t[TRAIN] Epoch=9/50, Step=406/478, loss=0.081798, lr=0.085574, time_each_step=1.29s, eta=7:8:31\n",
      "2022-01-20 11:33:53 [INFO]\t[TRAIN] Epoch=9/50, Step=408/478, loss=0.058444, lr=0.085567, time_each_step=1.29s, eta=7:6:13\n",
      "2022-01-20 11:33:56 [INFO]\t[TRAIN] Epoch=9/50, Step=410/478, loss=0.065451, lr=0.085560, time_each_step=1.28s, eta=7:5:35\n",
      "2022-01-20 11:33:58 [INFO]\t[TRAIN] Epoch=9/50, Step=412/478, loss=0.062910, lr=0.085553, time_each_step=1.29s, eta=7:6:5\n",
      "2022-01-20 11:34:01 [INFO]\t[TRAIN] Epoch=9/50, Step=414/478, loss=0.068847, lr=0.085546, time_each_step=1.29s, eta=7:5:54\n",
      "2022-01-20 11:34:03 [INFO]\t[TRAIN] Epoch=9/50, Step=416/478, loss=0.061627, lr=0.085539, time_each_step=1.28s, eta=7:5:3\n",
      "2022-01-20 11:34:06 [INFO]\t[TRAIN] Epoch=9/50, Step=418/478, loss=0.114626, lr=0.085532, time_each_step=1.29s, eta=7:6:11\n",
      "2022-01-20 11:34:08 [INFO]\t[TRAIN] Epoch=9/50, Step=420/478, loss=0.074601, lr=0.085525, time_each_step=1.29s, eta=7:5:46\n",
      "2022-01-20 11:34:11 [INFO]\t[TRAIN] Epoch=9/50, Step=422/478, loss=0.050505, lr=0.085519, time_each_step=1.29s, eta=7:5:43\n",
      "2022-01-20 11:34:14 [INFO]\t[TRAIN] Epoch=9/50, Step=424/478, loss=0.062282, lr=0.085512, time_each_step=1.29s, eta=7:6:6\n",
      "2022-01-20 11:34:16 [INFO]\t[TRAIN] Epoch=9/50, Step=426/478, loss=0.057668, lr=0.085505, time_each_step=1.29s, eta=7:5:32\n",
      "2022-01-20 11:34:19 [INFO]\t[TRAIN] Epoch=9/50, Step=428/478, loss=0.080328, lr=0.085498, time_each_step=1.28s, eta=7:4:55\n",
      "2022-01-20 11:34:21 [INFO]\t[TRAIN] Epoch=9/50, Step=430/478, loss=0.097879, lr=0.085491, time_each_step=1.29s, eta=7:5:48\n",
      "2022-01-20 11:34:24 [INFO]\t[TRAIN] Epoch=9/50, Step=432/478, loss=0.051165, lr=0.085484, time_each_step=1.28s, eta=7:4:52\n",
      "2022-01-20 11:34:26 [INFO]\t[TRAIN] Epoch=9/50, Step=434/478, loss=0.048369, lr=0.085477, time_each_step=1.29s, eta=7:5:25\n",
      "2022-01-20 11:34:29 [INFO]\t[TRAIN] Epoch=9/50, Step=436/478, loss=0.081126, lr=0.085470, time_each_step=1.29s, eta=7:5:32\n",
      "2022-01-20 11:34:32 [INFO]\t[TRAIN] Epoch=9/50, Step=438/478, loss=0.056319, lr=0.085463, time_each_step=1.28s, eta=7:4:45\n",
      "2022-01-20 11:34:34 [INFO]\t[TRAIN] Epoch=9/50, Step=440/478, loss=0.060380, lr=0.085456, time_each_step=1.28s, eta=7:4:46\n",
      "2022-01-20 11:34:37 [INFO]\t[TRAIN] Epoch=9/50, Step=442/478, loss=0.070838, lr=0.085449, time_each_step=1.29s, eta=7:6:25\n",
      "2022-01-20 11:34:39 [INFO]\t[TRAIN] Epoch=9/50, Step=444/478, loss=0.068787, lr=0.085442, time_each_step=1.28s, eta=7:4:47\n",
      "2022-01-20 11:34:42 [INFO]\t[TRAIN] Epoch=9/50, Step=446/478, loss=0.049023, lr=0.085435, time_each_step=1.28s, eta=7:4:43\n",
      "2022-01-20 11:34:45 [INFO]\t[TRAIN] Epoch=9/50, Step=448/478, loss=0.075168, lr=0.085428, time_each_step=1.29s, eta=7:6:29\n",
      "2022-01-20 11:34:47 [INFO]\t[TRAIN] Epoch=9/50, Step=450/478, loss=0.089832, lr=0.085421, time_each_step=1.29s, eta=7:5:17\n",
      "2022-01-20 11:34:50 [INFO]\t[TRAIN] Epoch=9/50, Step=452/478, loss=0.069290, lr=0.085414, time_each_step=1.28s, eta=7:4:29\n",
      "2022-01-20 11:34:52 [INFO]\t[TRAIN] Epoch=9/50, Step=454/478, loss=0.094466, lr=0.085407, time_each_step=1.29s, eta=7:5:6\n",
      "2022-01-20 11:34:55 [INFO]\t[TRAIN] Epoch=9/50, Step=456/478, loss=0.111031, lr=0.085400, time_each_step=1.29s, eta=7:5:40\n",
      "2022-01-20 11:34:57 [INFO]\t[TRAIN] Epoch=9/50, Step=458/478, loss=0.060033, lr=0.085393, time_each_step=1.29s, eta=7:5:25\n",
      "2022-01-20 11:35:00 [INFO]\t[TRAIN] Epoch=9/50, Step=460/478, loss=0.088518, lr=0.085386, time_each_step=1.29s, eta=7:5:2\n",
      "2022-01-20 11:35:03 [INFO]\t[TRAIN] Epoch=9/50, Step=462/478, loss=0.077558, lr=0.085379, time_each_step=1.29s, eta=7:6:1\n",
      "2022-01-20 11:35:05 [INFO]\t[TRAIN] Epoch=9/50, Step=464/478, loss=0.092642, lr=0.085372, time_each_step=1.29s, eta=7:4:29\n",
      "2022-01-20 11:35:08 [INFO]\t[TRAIN] Epoch=9/50, Step=466/478, loss=0.120721, lr=0.085365, time_each_step=1.29s, eta=7:4:33\n",
      "2022-01-20 11:35:10 [INFO]\t[TRAIN] Epoch=9/50, Step=468/478, loss=0.078095, lr=0.085358, time_each_step=1.29s, eta=7:4:43\n",
      "2022-01-20 11:35:13 [INFO]\t[TRAIN] Epoch=9/50, Step=470/478, loss=0.072380, lr=0.085351, time_each_step=1.28s, eta=7:4:7\n",
      "2022-01-20 11:35:15 [INFO]\t[TRAIN] Epoch=9/50, Step=472/478, loss=0.049630, lr=0.085344, time_each_step=1.29s, eta=7:5:5\n",
      "2022-01-20 11:35:18 [INFO]\t[TRAIN] Epoch=9/50, Step=474/478, loss=0.078980, lr=0.085337, time_each_step=1.29s, eta=7:4:49\n",
      "2022-01-20 11:35:21 [INFO]\t[TRAIN] Epoch=9/50, Step=476/478, loss=0.074942, lr=0.085330, time_each_step=1.28s, eta=7:4:7\n",
      "2022-01-20 11:35:23 [INFO]\t[TRAIN] Epoch=9/50, Step=478/478, loss=0.061297, lr=0.085324, time_each_step=1.29s, eta=7:4:41\n",
      "2022-01-20 11:35:23 [INFO]\t[TRAIN] Epoch 9 finished, loss=0.073342726 .\n",
      "2022-01-20 11:35:23 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-01-20 11:35:23 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-01-20 11:35:30 [INFO]\t[EVAL] Finished, Epoch=9, miou=0.828668, category_iou=[0.9701235  0.73078865 0.7850929 ], oacc=0.972037, category_acc=[0.98601305 0.84364116 0.8697279 ], kappa=0.864377, category_F1-score=[0.98483523 0.84445743 0.87961015] .\n",
      "2022-01-20 11:35:30 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_6, miou=0.8331509232521057\n",
      "2022-01-20 11:35:30 [INFO]\tModel saved in model/deeplab_augument_alldata2/epoch_9.\n",
      "2022-01-20 11:35:34 [INFO]\t[TRAIN] Epoch=10/50, Step=2/478, loss=0.067668, lr=0.085317, time_each_step=1.93s, eta=10:32:59\n",
      "2022-01-20 11:35:37 [INFO]\t[TRAIN] Epoch=10/50, Step=4/478, loss=0.055720, lr=0.085310, time_each_step=1.29s, eta=7:4:19\n",
      "2022-01-20 11:35:39 [INFO]\t[TRAIN] Epoch=10/50, Step=6/478, loss=0.057475, lr=0.085303, time_each_step=1.28s, eta=7:3:40\n",
      "2022-01-20 11:35:42 [INFO]\t[TRAIN] Epoch=10/50, Step=8/478, loss=0.083831, lr=0.085296, time_each_step=1.29s, eta=7:4:14\n",
      "2022-01-20 11:35:44 [INFO]\t[TRAIN] Epoch=10/50, Step=10/478, loss=0.073920, lr=0.085289, time_each_step=1.29s, eta=7:3:48\n",
      "2022-01-20 11:35:47 [INFO]\t[TRAIN] Epoch=10/50, Step=12/478, loss=0.051733, lr=0.085282, time_each_step=1.29s, eta=7:4:2\n",
      "2022-01-20 11:35:49 [INFO]\t[TRAIN] Epoch=10/50, Step=14/478, loss=0.083116, lr=0.085275, time_each_step=1.29s, eta=7:5:2\n",
      "2022-01-20 11:35:52 [INFO]\t[TRAIN] Epoch=10/50, Step=16/478, loss=0.055705, lr=0.085268, time_each_step=1.29s, eta=7:3:59\n",
      "2022-01-20 11:35:55 [INFO]\t[TRAIN] Epoch=10/50, Step=18/478, loss=0.131236, lr=0.085261, time_each_step=1.29s, eta=7:3:43\n",
      "2022-01-20 11:35:57 [INFO]\t[TRAIN] Epoch=10/50, Step=20/478, loss=0.081916, lr=0.085254, time_each_step=1.28s, eta=7:3:30\n",
      "2022-01-20 11:36:00 [INFO]\t[TRAIN] Epoch=10/50, Step=22/478, loss=0.063441, lr=0.085247, time_each_step=1.29s, eta=7:3:41\n",
      "2022-01-20 11:36:02 [INFO]\t[TRAIN] Epoch=10/50, Step=24/478, loss=0.080426, lr=0.085240, time_each_step=1.28s, eta=7:2:51\n",
      "2022-01-20 11:36:05 [INFO]\t[TRAIN] Epoch=10/50, Step=26/478, loss=0.073996, lr=0.085233, time_each_step=1.29s, eta=7:5:1\n",
      "2022-01-20 11:36:07 [INFO]\t[TRAIN] Epoch=10/50, Step=28/478, loss=0.070167, lr=0.085226, time_each_step=1.29s, eta=7:3:53\n",
      "2022-01-20 11:36:10 [INFO]\t[TRAIN] Epoch=10/50, Step=30/478, loss=0.066319, lr=0.085219, time_each_step=1.28s, eta=7:2:57\n",
      "2022-01-20 11:36:13 [INFO]\t[TRAIN] Epoch=10/50, Step=32/478, loss=0.073908, lr=0.085212, time_each_step=1.29s, eta=7:4:45\n",
      "2022-01-20 11:36:15 [INFO]\t[TRAIN] Epoch=10/50, Step=34/478, loss=0.078018, lr=0.085205, time_each_step=1.29s, eta=7:3:43\n",
      "2022-01-20 11:36:18 [INFO]\t[TRAIN] Epoch=10/50, Step=36/478, loss=0.076264, lr=0.085198, time_each_step=1.29s, eta=7:4:11\n",
      "2022-01-20 11:36:20 [INFO]\t[TRAIN] Epoch=10/50, Step=38/478, loss=0.052162, lr=0.085191, time_each_step=1.29s, eta=7:3:45\n",
      "2022-01-20 11:36:23 [INFO]\t[TRAIN] Epoch=10/50, Step=40/478, loss=0.064523, lr=0.085184, time_each_step=1.29s, eta=7:4:0\n",
      "2022-01-20 11:36:25 [INFO]\t[TRAIN] Epoch=10/50, Step=42/478, loss=0.098541, lr=0.085177, time_each_step=1.28s, eta=7:2:56\n",
      "2022-01-20 11:36:28 [INFO]\t[TRAIN] Epoch=10/50, Step=44/478, loss=0.066447, lr=0.085170, time_each_step=1.29s, eta=7:3:41\n",
      "2022-01-20 11:36:31 [INFO]\t[TRAIN] Epoch=10/50, Step=46/478, loss=0.092468, lr=0.085163, time_each_step=1.28s, eta=7:2:44\n",
      "2022-01-20 11:36:33 [INFO]\t[TRAIN] Epoch=10/50, Step=48/478, loss=0.068564, lr=0.085156, time_each_step=1.29s, eta=7:3:0\n",
      "2022-01-20 11:36:36 [INFO]\t[TRAIN] Epoch=10/50, Step=50/478, loss=0.055783, lr=0.085149, time_each_step=1.29s, eta=7:3:45\n",
      "2022-01-20 11:36:38 [INFO]\t[TRAIN] Epoch=10/50, Step=52/478, loss=0.086980, lr=0.085142, time_each_step=1.29s, eta=7:3:0\n",
      "2022-01-20 11:36:41 [INFO]\t[TRAIN] Epoch=10/50, Step=54/478, loss=0.055657, lr=0.085135, time_each_step=1.29s, eta=7:2:59\n",
      "2022-01-20 11:36:43 [INFO]\t[TRAIN] Epoch=10/50, Step=56/478, loss=0.077028, lr=0.085128, time_each_step=1.29s, eta=7:3:3\n",
      "2022-01-20 11:36:46 [INFO]\t[TRAIN] Epoch=10/50, Step=58/478, loss=0.074050, lr=0.085121, time_each_step=1.29s, eta=7:3:6\n",
      "2022-01-20 11:36:49 [INFO]\t[TRAIN] Epoch=10/50, Step=60/478, loss=0.070926, lr=0.085114, time_each_step=1.29s, eta=7:3:45\n",
      "2022-01-20 11:36:51 [INFO]\t[TRAIN] Epoch=10/50, Step=62/478, loss=0.107339, lr=0.085108, time_each_step=1.29s, eta=7:3:26\n",
      "2022-01-20 11:36:54 [INFO]\t[TRAIN] Epoch=10/50, Step=64/478, loss=0.060330, lr=0.085101, time_each_step=1.29s, eta=7:2:44\n",
      "2022-01-20 11:36:56 [INFO]\t[TRAIN] Epoch=10/50, Step=66/478, loss=0.077874, lr=0.085094, time_each_step=1.29s, eta=7:2:40\n",
      "2022-01-20 11:36:59 [INFO]\t[TRAIN] Epoch=10/50, Step=68/478, loss=0.051963, lr=0.085087, time_each_step=1.29s, eta=7:3:29\n",
      "2022-01-20 11:37:01 [INFO]\t[TRAIN] Epoch=10/50, Step=70/478, loss=0.086757, lr=0.085080, time_each_step=1.28s, eta=7:2:10\n",
      "2022-01-20 11:37:04 [INFO]\t[TRAIN] Epoch=10/50, Step=72/478, loss=0.067831, lr=0.085073, time_each_step=1.29s, eta=7:2:59\n",
      "2022-01-20 11:37:07 [INFO]\t[TRAIN] Epoch=10/50, Step=74/478, loss=0.054550, lr=0.085066, time_each_step=1.29s, eta=7:3:48\n",
      "2022-01-20 11:37:09 [INFO]\t[TRAIN] Epoch=10/50, Step=76/478, loss=0.073657, lr=0.085059, time_each_step=1.28s, eta=7:1:59\n",
      "2022-01-20 11:37:12 [INFO]\t[TRAIN] Epoch=10/50, Step=78/478, loss=0.065632, lr=0.085052, time_each_step=1.29s, eta=7:3:0\n",
      "2022-01-20 11:37:14 [INFO]\t[TRAIN] Epoch=10/50, Step=80/478, loss=0.078766, lr=0.085045, time_each_step=1.29s, eta=7:4:37\n",
      "2022-01-20 11:37:17 [INFO]\t[TRAIN] Epoch=10/50, Step=82/478, loss=0.114539, lr=0.085038, time_each_step=1.29s, eta=7:2:13\n",
      "2022-01-20 11:37:19 [INFO]\t[TRAIN] Epoch=10/50, Step=84/478, loss=0.081553, lr=0.085031, time_each_step=1.28s, eta=7:2:0\n",
      "2022-01-20 11:37:22 [INFO]\t[TRAIN] Epoch=10/50, Step=86/478, loss=0.092180, lr=0.085024, time_each_step=1.29s, eta=7:2:35\n",
      "2022-01-20 11:37:25 [INFO]\t[TRAIN] Epoch=10/50, Step=88/478, loss=0.070355, lr=0.085017, time_each_step=1.29s, eta=7:2:52\n",
      "2022-01-20 11:37:27 [INFO]\t[TRAIN] Epoch=10/50, Step=90/478, loss=0.084229, lr=0.085010, time_each_step=1.29s, eta=7:2:40\n",
      "2022-01-20 11:37:30 [INFO]\t[TRAIN] Epoch=10/50, Step=92/478, loss=0.078421, lr=0.085003, time_each_step=1.29s, eta=7:2:42\n",
      "2022-01-20 11:37:32 [INFO]\t[TRAIN] Epoch=10/50, Step=94/478, loss=0.074345, lr=0.084996, time_each_step=1.28s, eta=7:1:38\n",
      "2022-01-20 11:37:35 [INFO]\t[TRAIN] Epoch=10/50, Step=96/478, loss=0.086142, lr=0.084989, time_each_step=1.28s, eta=7:1:38\n",
      "2022-01-20 11:37:37 [INFO]\t[TRAIN] Epoch=10/50, Step=98/478, loss=0.099233, lr=0.084982, time_each_step=1.29s, eta=7:3:9\n",
      "2022-01-20 11:37:40 [INFO]\t[TRAIN] Epoch=10/50, Step=100/478, loss=0.056130, lr=0.084975, time_each_step=1.29s, eta=7:1:56\n",
      "2022-01-20 11:37:43 [INFO]\t[TRAIN] Epoch=10/50, Step=102/478, loss=0.067024, lr=0.084968, time_each_step=1.29s, eta=7:2:29\n",
      "2022-01-20 11:37:45 [INFO]\t[TRAIN] Epoch=10/50, Step=104/478, loss=0.071454, lr=0.084961, time_each_step=1.29s, eta=7:2:35\n",
      "2022-01-20 11:37:48 [INFO]\t[TRAIN] Epoch=10/50, Step=106/478, loss=0.100016, lr=0.084954, time_each_step=1.29s, eta=7:1:51\n",
      "2022-01-20 11:37:50 [INFO]\t[TRAIN] Epoch=10/50, Step=108/478, loss=0.045714, lr=0.084947, time_each_step=1.29s, eta=7:2:5\n",
      "2022-01-20 11:37:53 [INFO]\t[TRAIN] Epoch=10/50, Step=110/478, loss=0.065668, lr=0.084940, time_each_step=1.29s, eta=7:3:1\n",
      "2022-01-20 11:37:55 [INFO]\t[TRAIN] Epoch=10/50, Step=112/478, loss=0.043451, lr=0.084933, time_each_step=1.28s, eta=7:1:3\n",
      "2022-01-20 11:37:58 [INFO]\t[TRAIN] Epoch=10/50, Step=114/478, loss=0.082579, lr=0.084926, time_each_step=1.29s, eta=7:1:34\n",
      "2022-01-20 11:38:01 [INFO]\t[TRAIN] Epoch=10/50, Step=116/478, loss=0.056270, lr=0.084919, time_each_step=1.29s, eta=7:2:25\n",
      "2022-01-20 11:38:03 [INFO]\t[TRAIN] Epoch=10/50, Step=118/478, loss=0.054361, lr=0.084912, time_each_step=1.29s, eta=7:1:51\n",
      "2022-01-20 11:38:06 [INFO]\t[TRAIN] Epoch=10/50, Step=120/478, loss=0.086397, lr=0.084905, time_each_step=1.29s, eta=7:1:27\n",
      "2022-01-20 11:38:08 [INFO]\t[TRAIN] Epoch=10/50, Step=122/478, loss=0.055651, lr=0.084898, time_each_step=1.29s, eta=7:2:59\n",
      "2022-01-20 11:38:11 [INFO]\t[TRAIN] Epoch=10/50, Step=124/478, loss=0.066946, lr=0.084891, time_each_step=1.28s, eta=7:0:9\n",
      "2022-01-20 11:38:14 [INFO]\t[TRAIN] Epoch=10/50, Step=126/478, loss=0.102145, lr=0.084884, time_each_step=1.29s, eta=7:1:18\n",
      "2022-01-20 11:38:16 [INFO]\t[TRAIN] Epoch=10/50, Step=128/478, loss=0.075925, lr=0.084877, time_each_step=1.29s, eta=7:2:10\n",
      "2022-01-20 11:38:19 [INFO]\t[TRAIN] Epoch=10/50, Step=130/478, loss=0.098312, lr=0.084870, time_each_step=1.29s, eta=7:2:29\n",
      "2022-01-20 11:38:21 [INFO]\t[TRAIN] Epoch=10/50, Step=132/478, loss=0.092675, lr=0.084863, time_each_step=1.29s, eta=7:1:14\n",
      "2022-01-20 11:38:24 [INFO]\t[TRAIN] Epoch=10/50, Step=134/478, loss=0.086843, lr=0.084857, time_each_step=1.28s, eta=7:0:59\n",
      "2022-01-20 11:38:26 [INFO]\t[TRAIN] Epoch=10/50, Step=136/478, loss=0.073925, lr=0.084850, time_each_step=1.29s, eta=7:1:21\n",
      "2022-01-20 11:38:29 [INFO]\t[TRAIN] Epoch=10/50, Step=138/478, loss=0.083900, lr=0.084843, time_each_step=1.29s, eta=7:1:11\n",
      "2022-01-20 11:38:32 [INFO]\t[TRAIN] Epoch=10/50, Step=140/478, loss=0.061278, lr=0.084836, time_each_step=1.29s, eta=7:1:9\n",
      "2022-01-20 11:38:34 [INFO]\t[TRAIN] Epoch=10/50, Step=142/478, loss=0.093779, lr=0.084829, time_each_step=1.29s, eta=7:1:14\n",
      "2022-01-20 11:38:37 [INFO]\t[TRAIN] Epoch=10/50, Step=144/478, loss=0.097488, lr=0.084822, time_each_step=1.29s, eta=7:0:53\n",
      "2022-01-20 11:38:39 [INFO]\t[TRAIN] Epoch=10/50, Step=146/478, loss=0.082425, lr=0.084815, time_each_step=1.29s, eta=7:1:4\n",
      "2022-01-20 11:38:42 [INFO]\t[TRAIN] Epoch=10/50, Step=148/478, loss=0.056471, lr=0.084808, time_each_step=1.29s, eta=7:1:20\n",
      "2022-01-20 11:38:44 [INFO]\t[TRAIN] Epoch=10/50, Step=150/478, loss=0.082901, lr=0.084801, time_each_step=1.29s, eta=7:0:59\n",
      "2022-01-20 11:38:47 [INFO]\t[TRAIN] Epoch=10/50, Step=152/478, loss=0.068051, lr=0.084794, time_each_step=1.29s, eta=7:1:6\n",
      "2022-01-20 11:38:50 [INFO]\t[TRAIN] Epoch=10/50, Step=154/478, loss=0.074574, lr=0.084787, time_each_step=1.29s, eta=7:0:45\n",
      "2022-01-20 11:38:52 [INFO]\t[TRAIN] Epoch=10/50, Step=156/478, loss=0.096216, lr=0.084780, time_each_step=1.28s, eta=7:0:15\n",
      "2022-01-20 11:38:55 [INFO]\t[TRAIN] Epoch=10/50, Step=158/478, loss=0.077882, lr=0.084773, time_each_step=1.29s, eta=7:1:18\n",
      "2022-01-20 11:38:57 [INFO]\t[TRAIN] Epoch=10/50, Step=160/478, loss=0.045362, lr=0.084766, time_each_step=1.28s, eta=7:0:6\n",
      "2022-01-20 11:39:00 [INFO]\t[TRAIN] Epoch=10/50, Step=162/478, loss=0.098815, lr=0.084759, time_each_step=1.28s, eta=7:0:12\n",
      "2022-01-20 11:39:02 [INFO]\t[TRAIN] Epoch=10/50, Step=164/478, loss=0.081196, lr=0.084752, time_each_step=1.29s, eta=7:1:30\n",
      "2022-01-20 11:39:05 [INFO]\t[TRAIN] Epoch=10/50, Step=166/478, loss=0.079402, lr=0.084745, time_each_step=1.28s, eta=7:0:5\n",
      "2022-01-20 11:39:08 [INFO]\t[TRAIN] Epoch=10/50, Step=168/478, loss=0.055686, lr=0.084738, time_each_step=1.29s, eta=7:1:1\n",
      "2022-01-20 11:39:10 [INFO]\t[TRAIN] Epoch=10/50, Step=170/478, loss=0.043765, lr=0.084731, time_each_step=1.29s, eta=7:1:54\n",
      "2022-01-20 11:39:13 [INFO]\t[TRAIN] Epoch=10/50, Step=172/478, loss=0.068607, lr=0.084724, time_each_step=1.28s, eta=7:0:2\n",
      "2022-01-20 11:39:15 [INFO]\t[TRAIN] Epoch=10/50, Step=174/478, loss=0.068205, lr=0.084717, time_each_step=1.29s, eta=7:0:25\n",
      "2022-01-20 11:39:18 [INFO]\t[TRAIN] Epoch=10/50, Step=176/478, loss=0.055246, lr=0.084710, time_each_step=1.29s, eta=7:1:25\n",
      "2022-01-20 11:39:20 [INFO]\t[TRAIN] Epoch=10/50, Step=178/478, loss=0.077500, lr=0.084703, time_each_step=1.29s, eta=7:0:37\n",
      "2022-01-20 11:39:23 [INFO]\t[TRAIN] Epoch=10/50, Step=180/478, loss=0.074116, lr=0.084696, time_each_step=1.29s, eta=7:0:13\n",
      "2022-01-20 11:39:26 [INFO]\t[TRAIN] Epoch=10/50, Step=182/478, loss=0.086889, lr=0.084689, time_each_step=1.29s, eta=7:0:18\n",
      "2022-01-20 11:39:28 [INFO]\t[TRAIN] Epoch=10/50, Step=184/478, loss=0.050918, lr=0.084682, time_each_step=1.29s, eta=7:0:11\n",
      "2022-01-20 11:39:31 [INFO]\t[TRAIN] Epoch=10/50, Step=186/478, loss=0.097078, lr=0.084675, time_each_step=1.29s, eta=7:0:9\n",
      "2022-01-20 11:39:33 [INFO]\t[TRAIN] Epoch=10/50, Step=188/478, loss=0.056842, lr=0.084668, time_each_step=1.29s, eta=7:1:4\n",
      "2022-01-20 11:39:36 [INFO]\t[TRAIN] Epoch=10/50, Step=190/478, loss=0.072131, lr=0.084661, time_each_step=1.28s, eta=6:59:47\n",
      "2022-01-20 11:39:38 [INFO]\t[TRAIN] Epoch=10/50, Step=192/478, loss=0.040070, lr=0.084654, time_each_step=1.29s, eta=7:0:26\n",
      "2022-01-20 11:39:41 [INFO]\t[TRAIN] Epoch=10/50, Step=194/478, loss=0.058555, lr=0.084647, time_each_step=1.29s, eta=7:0:10\n",
      "2022-01-20 11:39:44 [INFO]\t[TRAIN] Epoch=10/50, Step=196/478, loss=0.076420, lr=0.084640, time_each_step=1.29s, eta=6:59:58\n",
      "2022-01-20 11:39:46 [INFO]\t[TRAIN] Epoch=10/50, Step=198/478, loss=0.075204, lr=0.084633, time_each_step=1.28s, eta=6:59:37\n",
      "2022-01-20 11:39:49 [INFO]\t[TRAIN] Epoch=10/50, Step=200/478, loss=0.077135, lr=0.084626, time_each_step=1.29s, eta=7:0:35\n",
      "2022-01-20 11:39:51 [INFO]\t[TRAIN] Epoch=10/50, Step=202/478, loss=0.051087, lr=0.084619, time_each_step=1.29s, eta=7:0:27\n",
      "2022-01-20 11:39:54 [INFO]\t[TRAIN] Epoch=10/50, Step=204/478, loss=0.117610, lr=0.084612, time_each_step=1.29s, eta=6:59:54\n",
      "2022-01-20 11:39:56 [INFO]\t[TRAIN] Epoch=10/50, Step=206/478, loss=0.114582, lr=0.084605, time_each_step=1.29s, eta=6:59:55\n",
      "2022-01-20 11:39:59 [INFO]\t[TRAIN] Epoch=10/50, Step=208/478, loss=0.076685, lr=0.084598, time_each_step=1.29s, eta=6:59:57\n",
      "2022-01-20 11:40:02 [INFO]\t[TRAIN] Epoch=10/50, Step=210/478, loss=0.055982, lr=0.084591, time_each_step=1.29s, eta=6:59:33\n",
      "2022-01-20 11:40:04 [INFO]\t[TRAIN] Epoch=10/50, Step=212/478, loss=0.089985, lr=0.084584, time_each_step=1.29s, eta=7:0:30\n",
      "2022-01-20 11:40:07 [INFO]\t[TRAIN] Epoch=10/50, Step=214/478, loss=0.063884, lr=0.084577, time_each_step=1.29s, eta=6:59:38\n",
      "2022-01-20 11:40:09 [INFO]\t[TRAIN] Epoch=10/50, Step=216/478, loss=0.073151, lr=0.084570, time_each_step=1.29s, eta=6:59:56\n",
      "2022-01-20 11:40:12 [INFO]\t[TRAIN] Epoch=10/50, Step=218/478, loss=0.071045, lr=0.084563, time_each_step=1.29s, eta=6:59:57\n",
      "2022-01-20 11:40:14 [INFO]\t[TRAIN] Epoch=10/50, Step=220/478, loss=0.072370, lr=0.084556, time_each_step=1.29s, eta=6:59:19\n",
      "2022-01-20 11:40:17 [INFO]\t[TRAIN] Epoch=10/50, Step=222/478, loss=0.089681, lr=0.084549, time_each_step=1.29s, eta=6:59:13\n",
      "2022-01-20 11:40:20 [INFO]\t[TRAIN] Epoch=10/50, Step=224/478, loss=0.079511, lr=0.084542, time_each_step=1.29s, eta=6:59:27\n",
      "2022-01-20 11:40:22 [INFO]\t[TRAIN] Epoch=10/50, Step=226/478, loss=0.053582, lr=0.084536, time_each_step=1.28s, eta=6:58:52\n",
      "2022-01-20 11:40:25 [INFO]\t[TRAIN] Epoch=10/50, Step=228/478, loss=0.077859, lr=0.084529, time_each_step=1.29s, eta=6:59:21\n",
      "2022-01-20 11:40:27 [INFO]\t[TRAIN] Epoch=10/50, Step=230/478, loss=0.082060, lr=0.084522, time_each_step=1.29s, eta=6:59:48\n",
      "2022-01-20 11:40:30 [INFO]\t[TRAIN] Epoch=10/50, Step=232/478, loss=0.053510, lr=0.084515, time_each_step=1.29s, eta=7:0:21\n",
      "2022-01-20 11:40:32 [INFO]\t[TRAIN] Epoch=10/50, Step=234/478, loss=0.078997, lr=0.084508, time_each_step=1.29s, eta=7:0:25\n",
      "2022-01-20 11:40:35 [INFO]\t[TRAIN] Epoch=10/50, Step=236/478, loss=0.075933, lr=0.084501, time_each_step=1.29s, eta=6:59:38\n",
      "2022-01-20 11:40:38 [INFO]\t[TRAIN] Epoch=10/50, Step=238/478, loss=0.061430, lr=0.084494, time_each_step=1.29s, eta=6:59:25\n",
      "2022-01-20 11:40:40 [INFO]\t[TRAIN] Epoch=10/50, Step=240/478, loss=0.095249, lr=0.084487, time_each_step=1.28s, eta=6:58:45\n",
      "2022-01-20 11:40:43 [INFO]\t[TRAIN] Epoch=10/50, Step=242/478, loss=0.086557, lr=0.084480, time_each_step=1.29s, eta=6:59:25\n",
      "2022-01-20 11:40:45 [INFO]\t[TRAIN] Epoch=10/50, Step=244/478, loss=0.045668, lr=0.084473, time_each_step=1.28s, eta=6:58:33\n",
      "2022-01-20 11:40:48 [INFO]\t[TRAIN] Epoch=10/50, Step=246/478, loss=0.053294, lr=0.084466, time_each_step=1.28s, eta=6:58:8\n",
      "2022-01-20 11:40:50 [INFO]\t[TRAIN] Epoch=10/50, Step=248/478, loss=0.070816, lr=0.084459, time_each_step=1.29s, eta=6:59:52\n",
      "2022-01-20 11:40:53 [INFO]\t[TRAIN] Epoch=10/50, Step=250/478, loss=0.067894, lr=0.084452, time_each_step=1.29s, eta=6:58:38\n",
      "2022-01-20 11:40:56 [INFO]\t[TRAIN] Epoch=10/50, Step=252/478, loss=0.051208, lr=0.084445, time_each_step=1.29s, eta=6:58:59\n",
      "2022-01-20 11:40:58 [INFO]\t[TRAIN] Epoch=10/50, Step=254/478, loss=0.080038, lr=0.084438, time_each_step=1.29s, eta=6:59:12\n",
      "2022-01-20 11:41:01 [INFO]\t[TRAIN] Epoch=10/50, Step=256/478, loss=0.051382, lr=0.084431, time_each_step=1.29s, eta=6:58:32\n",
      "2022-01-20 11:41:03 [INFO]\t[TRAIN] Epoch=10/50, Step=258/478, loss=0.071301, lr=0.084424, time_each_step=1.28s, eta=6:58:25\n",
      "2022-01-20 11:41:06 [INFO]\t[TRAIN] Epoch=10/50, Step=260/478, loss=0.080958, lr=0.084417, time_each_step=1.29s, eta=6:58:38\n",
      "2022-01-20 11:41:08 [INFO]\t[TRAIN] Epoch=10/50, Step=262/478, loss=0.100168, lr=0.084410, time_each_step=1.28s, eta=6:58:7\n",
      "2022-01-20 11:41:11 [INFO]\t[TRAIN] Epoch=10/50, Step=264/478, loss=0.047170, lr=0.084403, time_each_step=1.29s, eta=6:59:10\n",
      "2022-01-20 11:41:14 [INFO]\t[TRAIN] Epoch=10/50, Step=266/478, loss=0.057002, lr=0.084396, time_each_step=1.29s, eta=6:59:4\n",
      "2022-01-20 11:41:16 [INFO]\t[TRAIN] Epoch=10/50, Step=268/478, loss=0.063489, lr=0.084389, time_each_step=1.29s, eta=6:58:31\n",
      "2022-01-20 11:41:19 [INFO]\t[TRAIN] Epoch=10/50, Step=270/478, loss=0.083235, lr=0.084382, time_each_step=1.29s, eta=6:58:34\n",
      "2022-01-20 11:41:21 [INFO]\t[TRAIN] Epoch=10/50, Step=272/478, loss=0.061860, lr=0.084375, time_each_step=1.29s, eta=6:59:5\n",
      "2022-01-20 11:41:24 [INFO]\t[TRAIN] Epoch=10/50, Step=274/478, loss=0.056301, lr=0.084368, time_each_step=1.28s, eta=6:57:40\n",
      "2022-01-20 11:41:26 [INFO]\t[TRAIN] Epoch=10/50, Step=276/478, loss=0.081791, lr=0.084361, time_each_step=1.29s, eta=6:58:40\n",
      "2022-01-20 11:41:29 [INFO]\t[TRAIN] Epoch=10/50, Step=278/478, loss=0.080149, lr=0.084354, time_each_step=1.29s, eta=6:59:21\n",
      "2022-01-20 11:41:32 [INFO]\t[TRAIN] Epoch=10/50, Step=280/478, loss=0.093360, lr=0.084347, time_each_step=1.28s, eta=6:57:26\n",
      "2022-01-20 11:41:34 [INFO]\t[TRAIN] Epoch=10/50, Step=282/478, loss=0.065398, lr=0.084340, time_each_step=1.28s, eta=6:57:51\n",
      "2022-01-20 11:41:37 [INFO]\t[TRAIN] Epoch=10/50, Step=284/478, loss=0.073804, lr=0.084333, time_each_step=1.29s, eta=7:0:6\n",
      "2022-01-20 11:41:39 [INFO]\t[TRAIN] Epoch=10/50, Step=286/478, loss=0.060649, lr=0.084326, time_each_step=1.29s, eta=6:57:56\n",
      "2022-01-20 11:41:42 [INFO]\t[TRAIN] Epoch=10/50, Step=288/478, loss=0.077229, lr=0.084319, time_each_step=1.29s, eta=6:57:53\n",
      "2022-01-20 11:41:44 [INFO]\t[TRAIN] Epoch=10/50, Step=290/478, loss=0.063454, lr=0.084312, time_each_step=1.29s, eta=6:59:1\n",
      "2022-01-20 11:41:47 [INFO]\t[TRAIN] Epoch=10/50, Step=292/478, loss=0.105502, lr=0.084305, time_each_step=1.28s, eta=6:57:5\n",
      "2022-01-20 11:41:50 [INFO]\t[TRAIN] Epoch=10/50, Step=294/478, loss=0.049276, lr=0.084298, time_each_step=1.28s, eta=6:57:28\n",
      "2022-01-20 11:41:52 [INFO]\t[TRAIN] Epoch=10/50, Step=296/478, loss=0.078255, lr=0.084291, time_each_step=1.29s, eta=6:58:10\n",
      "2022-01-20 11:41:55 [INFO]\t[TRAIN] Epoch=10/50, Step=298/478, loss=0.088627, lr=0.084284, time_each_step=1.29s, eta=6:58:8\n",
      "2022-01-20 11:41:57 [INFO]\t[TRAIN] Epoch=10/50, Step=300/478, loss=0.088943, lr=0.084277, time_each_step=1.29s, eta=6:57:44\n",
      "2022-01-20 11:42:00 [INFO]\t[TRAIN] Epoch=10/50, Step=302/478, loss=0.049529, lr=0.084270, time_each_step=1.29s, eta=6:58:26\n",
      "2022-01-20 11:42:02 [INFO]\t[TRAIN] Epoch=10/50, Step=304/478, loss=0.077864, lr=0.084263, time_each_step=1.28s, eta=6:56:58\n",
      "2022-01-20 11:42:05 [INFO]\t[TRAIN] Epoch=10/50, Step=306/478, loss=0.050268, lr=0.084256, time_each_step=1.28s, eta=6:57:18\n",
      "2022-01-20 11:42:08 [INFO]\t[TRAIN] Epoch=10/50, Step=308/478, loss=0.117060, lr=0.084249, time_each_step=1.29s, eta=6:59:40\n",
      "2022-01-20 11:42:10 [INFO]\t[TRAIN] Epoch=10/50, Step=310/478, loss=0.082648, lr=0.084242, time_each_step=1.29s, eta=6:57:23\n",
      "2022-01-20 11:42:13 [INFO]\t[TRAIN] Epoch=10/50, Step=312/478, loss=0.102931, lr=0.084235, time_each_step=1.28s, eta=6:56:54\n",
      "2022-01-20 11:42:15 [INFO]\t[TRAIN] Epoch=10/50, Step=314/478, loss=0.048726, lr=0.084228, time_each_step=1.29s, eta=6:58:8\n",
      "2022-01-20 11:42:18 [INFO]\t[TRAIN] Epoch=10/50, Step=316/478, loss=0.076669, lr=0.084221, time_each_step=1.28s, eta=6:56:41\n",
      "2022-01-20 11:42:20 [INFO]\t[TRAIN] Epoch=10/50, Step=318/478, loss=0.091933, lr=0.084214, time_each_step=1.29s, eta=6:58:15\n",
      "2022-01-20 11:42:23 [INFO]\t[TRAIN] Epoch=10/50, Step=320/478, loss=0.061452, lr=0.084207, time_each_step=1.29s, eta=6:58:44\n",
      "2022-01-20 11:42:26 [INFO]\t[TRAIN] Epoch=10/50, Step=322/478, loss=0.044706, lr=0.084200, time_each_step=1.28s, eta=6:56:43\n",
      "2022-01-20 11:42:28 [INFO]\t[TRAIN] Epoch=10/50, Step=324/478, loss=0.066582, lr=0.084193, time_each_step=1.29s, eta=6:59:29\n",
      "2022-01-20 11:42:31 [INFO]\t[TRAIN] Epoch=10/50, Step=326/478, loss=0.057670, lr=0.084186, time_each_step=1.29s, eta=6:58:22\n",
      "2022-01-20 11:42:33 [INFO]\t[TRAIN] Epoch=10/50, Step=328/478, loss=0.066241, lr=0.084179, time_each_step=1.29s, eta=6:57:26\n",
      "2022-01-20 11:42:36 [INFO]\t[TRAIN] Epoch=10/50, Step=330/478, loss=0.081299, lr=0.084172, time_each_step=1.29s, eta=6:57:46\n",
      "2022-01-20 11:42:38 [INFO]\t[TRAIN] Epoch=10/50, Step=332/478, loss=0.078723, lr=0.084165, time_each_step=1.29s, eta=6:57:28\n",
      "2022-01-20 11:42:41 [INFO]\t[TRAIN] Epoch=10/50, Step=334/478, loss=0.081994, lr=0.084158, time_each_step=1.29s, eta=6:57:15\n",
      "2022-01-20 11:42:44 [INFO]\t[TRAIN] Epoch=10/50, Step=336/478, loss=0.075985, lr=0.084151, time_each_step=1.29s, eta=6:57:22\n",
      "2022-01-20 11:42:46 [INFO]\t[TRAIN] Epoch=10/50, Step=338/478, loss=0.051779, lr=0.084144, time_each_step=1.28s, eta=6:56:35\n",
      "2022-01-20 11:42:49 [INFO]\t[TRAIN] Epoch=10/50, Step=340/478, loss=0.067390, lr=0.084137, time_each_step=1.28s, eta=6:56:33\n",
      "2022-01-20 11:42:51 [INFO]\t[TRAIN] Epoch=10/50, Step=342/478, loss=0.069996, lr=0.084130, time_each_step=1.29s, eta=6:58:29\n",
      "2022-01-20 11:42:54 [INFO]\t[TRAIN] Epoch=10/50, Step=344/478, loss=0.063465, lr=0.084123, time_each_step=1.28s, eta=6:56:31\n",
      "2022-01-20 11:42:56 [INFO]\t[TRAIN] Epoch=10/50, Step=346/478, loss=0.083695, lr=0.084116, time_each_step=1.29s, eta=6:56:42\n",
      "2022-01-20 11:42:59 [INFO]\t[TRAIN] Epoch=10/50, Step=348/478, loss=0.051725, lr=0.084109, time_each_step=1.29s, eta=6:57:35\n",
      "2022-01-20 11:43:02 [INFO]\t[TRAIN] Epoch=10/50, Step=350/478, loss=0.071593, lr=0.084102, time_each_step=1.29s, eta=6:56:41\n",
      "2022-01-20 11:43:04 [INFO]\t[TRAIN] Epoch=10/50, Step=352/478, loss=0.086988, lr=0.084095, time_each_step=1.29s, eta=6:56:40\n",
      "2022-01-20 11:43:07 [INFO]\t[TRAIN] Epoch=10/50, Step=354/478, loss=0.175510, lr=0.084088, time_each_step=1.29s, eta=6:57:26\n",
      "2022-01-20 11:43:09 [INFO]\t[TRAIN] Epoch=10/50, Step=356/478, loss=0.058641, lr=0.084081, time_each_step=1.29s, eta=6:56:42\n",
      "2022-01-20 11:43:12 [INFO]\t[TRAIN] Epoch=10/50, Step=358/478, loss=0.067578, lr=0.084074, time_each_step=1.29s, eta=6:56:29\n",
      "2022-01-20 11:43:15 [INFO]\t[TRAIN] Epoch=10/50, Step=360/478, loss=0.077130, lr=0.084067, time_each_step=1.29s, eta=6:56:59\n",
      "2022-01-20 11:43:17 [INFO]\t[TRAIN] Epoch=10/50, Step=362/478, loss=0.074346, lr=0.084060, time_each_step=1.29s, eta=6:56:52\n",
      "2022-01-20 11:43:20 [INFO]\t[TRAIN] Epoch=10/50, Step=364/478, loss=0.078657, lr=0.084053, time_each_step=1.28s, eta=6:55:44\n",
      "2022-01-20 11:43:22 [INFO]\t[TRAIN] Epoch=10/50, Step=366/478, loss=0.098421, lr=0.084046, time_each_step=1.29s, eta=6:56:29\n",
      "2022-01-20 11:43:25 [INFO]\t[TRAIN] Epoch=10/50, Step=368/478, loss=0.072451, lr=0.084039, time_each_step=1.29s, eta=6:57:7\n",
      "2022-01-20 11:43:27 [INFO]\t[TRAIN] Epoch=10/50, Step=370/478, loss=0.070982, lr=0.084032, time_each_step=1.29s, eta=6:56:6\n",
      "2022-01-20 11:43:30 [INFO]\t[TRAIN] Epoch=10/50, Step=372/478, loss=0.078661, lr=0.084025, time_each_step=1.29s, eta=6:56:31\n",
      "2022-01-20 11:43:33 [INFO]\t[TRAIN] Epoch=10/50, Step=374/478, loss=0.085473, lr=0.084018, time_each_step=1.29s, eta=6:56:35\n",
      "2022-01-20 11:43:35 [INFO]\t[TRAIN] Epoch=10/50, Step=376/478, loss=0.076944, lr=0.084011, time_each_step=1.28s, eta=6:55:44\n",
      "2022-01-20 11:43:38 [INFO]\t[TRAIN] Epoch=10/50, Step=378/478, loss=0.082955, lr=0.084004, time_each_step=1.29s, eta=6:56:35\n",
      "2022-01-20 11:43:40 [INFO]\t[TRAIN] Epoch=10/50, Step=380/478, loss=0.083689, lr=0.083997, time_each_step=1.29s, eta=6:56:13\n",
      "2022-01-20 11:43:43 [INFO]\t[TRAIN] Epoch=10/50, Step=382/478, loss=0.066851, lr=0.083990, time_each_step=1.29s, eta=6:56:2\n",
      "2022-01-20 11:43:45 [INFO]\t[TRAIN] Epoch=10/50, Step=384/478, loss=0.061959, lr=0.083984, time_each_step=1.29s, eta=6:56:52\n",
      "2022-01-20 11:43:48 [INFO]\t[TRAIN] Epoch=10/50, Step=386/478, loss=0.123514, lr=0.083977, time_each_step=1.29s, eta=6:56:48\n",
      "2022-01-20 11:43:51 [INFO]\t[TRAIN] Epoch=10/50, Step=388/478, loss=0.060850, lr=0.083970, time_each_step=1.29s, eta=6:56:24\n",
      "2022-01-20 11:43:53 [INFO]\t[TRAIN] Epoch=10/50, Step=390/478, loss=0.068219, lr=0.083963, time_each_step=1.29s, eta=6:57:59\n",
      "2022-01-20 11:43:56 [INFO]\t[TRAIN] Epoch=10/50, Step=392/478, loss=0.056908, lr=0.083956, time_each_step=1.29s, eta=6:56:45\n",
      "2022-01-20 11:43:58 [INFO]\t[TRAIN] Epoch=10/50, Step=394/478, loss=0.071657, lr=0.083949, time_each_step=1.28s, eta=6:55:5\n",
      "2022-01-20 11:44:01 [INFO]\t[TRAIN] Epoch=10/50, Step=396/478, loss=0.062081, lr=0.083942, time_each_step=1.29s, eta=6:56:23\n",
      "2022-01-20 11:44:03 [INFO]\t[TRAIN] Epoch=10/50, Step=398/478, loss=0.076241, lr=0.083935, time_each_step=1.29s, eta=6:55:49\n",
      "2022-01-20 11:44:06 [INFO]\t[TRAIN] Epoch=10/50, Step=400/478, loss=0.063264, lr=0.083928, time_each_step=1.28s, eta=6:54:37\n",
      "2022-01-20 11:44:09 [INFO]\t[TRAIN] Epoch=10/50, Step=402/478, loss=0.068372, lr=0.083921, time_each_step=1.29s, eta=6:56:19\n",
      "2022-01-20 11:44:11 [INFO]\t[TRAIN] Epoch=10/50, Step=404/478, loss=0.074980, lr=0.083914, time_each_step=1.28s, eta=6:55:2\n",
      "2022-01-20 11:44:14 [INFO]\t[TRAIN] Epoch=10/50, Step=406/478, loss=0.101077, lr=0.083907, time_each_step=1.29s, eta=6:55:35\n",
      "2022-01-20 11:44:16 [INFO]\t[TRAIN] Epoch=10/50, Step=408/478, loss=0.095671, lr=0.083900, time_each_step=1.29s, eta=6:56:6\n",
      "2022-01-20 11:44:19 [INFO]\t[TRAIN] Epoch=10/50, Step=410/478, loss=0.086465, lr=0.083893, time_each_step=1.29s, eta=6:55:25\n",
      "2022-01-20 11:44:21 [INFO]\t[TRAIN] Epoch=10/50, Step=412/478, loss=0.055958, lr=0.083886, time_each_step=1.28s, eta=6:54:56\n",
      "2022-01-20 11:44:24 [INFO]\t[TRAIN] Epoch=10/50, Step=414/478, loss=0.065687, lr=0.083879, time_each_step=1.29s, eta=6:55:49\n",
      "2022-01-20 11:44:27 [INFO]\t[TRAIN] Epoch=10/50, Step=416/478, loss=0.060541, lr=0.083872, time_each_step=1.29s, eta=6:55:21\n",
      "2022-01-20 11:44:29 [INFO]\t[TRAIN] Epoch=10/50, Step=418/478, loss=0.059728, lr=0.083865, time_each_step=1.29s, eta=6:55:27\n",
      "2022-01-20 11:44:32 [INFO]\t[TRAIN] Epoch=10/50, Step=420/478, loss=0.078292, lr=0.083858, time_each_step=1.29s, eta=6:56:4\n",
      "2022-01-20 11:44:34 [INFO]\t[TRAIN] Epoch=10/50, Step=422/478, loss=0.070944, lr=0.083851, time_each_step=1.29s, eta=6:55:2\n",
      "2022-01-20 11:44:37 [INFO]\t[TRAIN] Epoch=10/50, Step=424/478, loss=0.069482, lr=0.083844, time_each_step=1.29s, eta=6:55:33\n",
      "2022-01-20 11:44:39 [INFO]\t[TRAIN] Epoch=10/50, Step=426/478, loss=0.073235, lr=0.083837, time_each_step=1.29s, eta=6:56:4\n",
      "2022-01-20 11:44:42 [INFO]\t[TRAIN] Epoch=10/50, Step=428/478, loss=0.112305, lr=0.083830, time_each_step=1.28s, eta=6:54:37\n",
      "2022-01-20 11:44:45 [INFO]\t[TRAIN] Epoch=10/50, Step=430/478, loss=0.079491, lr=0.083823, time_each_step=1.29s, eta=6:55:13\n",
      "2022-01-20 11:44:47 [INFO]\t[TRAIN] Epoch=10/50, Step=432/478, loss=0.053368, lr=0.083816, time_each_step=1.28s, eta=6:54:34\n",
      "2022-01-20 11:44:50 [INFO]\t[TRAIN] Epoch=10/50, Step=434/478, loss=0.074575, lr=0.083809, time_each_step=1.28s, eta=6:54:16\n",
      "2022-01-20 11:44:52 [INFO]\t[TRAIN] Epoch=10/50, Step=436/478, loss=0.085311, lr=0.083802, time_each_step=1.28s, eta=6:54:36\n",
      "2022-01-20 11:44:55 [INFO]\t[TRAIN] Epoch=10/50, Step=438/478, loss=0.079781, lr=0.083795, time_each_step=1.28s, eta=6:54:9\n",
      "2022-01-20 11:44:57 [INFO]\t[TRAIN] Epoch=10/50, Step=440/478, loss=0.060521, lr=0.083788, time_each_step=1.29s, eta=6:55:44\n",
      "2022-01-20 11:45:00 [INFO]\t[TRAIN] Epoch=10/50, Step=442/478, loss=0.083423, lr=0.083781, time_each_step=1.29s, eta=6:55:14\n",
      "2022-01-20 11:45:03 [INFO]\t[TRAIN] Epoch=10/50, Step=444/478, loss=0.057161, lr=0.083774, time_each_step=1.29s, eta=6:56:10\n",
      "2022-01-20 11:45:05 [INFO]\t[TRAIN] Epoch=10/50, Step=446/478, loss=0.117752, lr=0.083767, time_each_step=1.29s, eta=6:55:1\n",
      "2022-01-20 11:45:08 [INFO]\t[TRAIN] Epoch=10/50, Step=448/478, loss=0.116318, lr=0.083760, time_each_step=1.29s, eta=6:54:52\n",
      "2022-01-20 11:45:10 [INFO]\t[TRAIN] Epoch=10/50, Step=450/478, loss=0.080832, lr=0.083753, time_each_step=1.29s, eta=6:55:2\n",
      "2022-01-20 11:45:13 [INFO]\t[TRAIN] Epoch=10/50, Step=452/478, loss=0.069964, lr=0.083746, time_each_step=1.29s, eta=6:54:30\n",
      "2022-01-20 11:45:15 [INFO]\t[TRAIN] Epoch=10/50, Step=454/478, loss=0.092801, lr=0.083739, time_each_step=1.29s, eta=6:54:19\n",
      "2022-01-20 11:45:18 [INFO]\t[TRAIN] Epoch=10/50, Step=456/478, loss=0.058094, lr=0.083732, time_each_step=1.29s, eta=6:55:47\n",
      "2022-01-20 11:45:21 [INFO]\t[TRAIN] Epoch=10/50, Step=458/478, loss=0.067664, lr=0.083725, time_each_step=1.29s, eta=6:54:30\n",
      "2022-01-20 11:45:23 [INFO]\t[TRAIN] Epoch=10/50, Step=460/478, loss=0.063075, lr=0.083718, time_each_step=1.28s, eta=6:53:57\n",
      "2022-01-20 11:45:26 [INFO]\t[TRAIN] Epoch=10/50, Step=462/478, loss=0.048014, lr=0.083711, time_each_step=1.29s, eta=6:54:49\n",
      "2022-01-20 11:45:28 [INFO]\t[TRAIN] Epoch=10/50, Step=464/478, loss=0.045463, lr=0.083704, time_each_step=1.29s, eta=6:54:6\n",
      "2022-01-20 11:45:31 [INFO]\t[TRAIN] Epoch=10/50, Step=466/478, loss=0.086507, lr=0.083697, time_each_step=1.29s, eta=6:54:24\n",
      "2022-01-20 11:45:33 [INFO]\t[TRAIN] Epoch=10/50, Step=468/478, loss=0.066227, lr=0.083690, time_each_step=1.29s, eta=6:54:0\n",
      "2022-01-20 11:45:36 [INFO]\t[TRAIN] Epoch=10/50, Step=470/478, loss=0.081798, lr=0.083683, time_each_step=1.29s, eta=6:54:15\n",
      "2022-01-20 11:45:39 [INFO]\t[TRAIN] Epoch=10/50, Step=472/478, loss=0.065544, lr=0.083676, time_each_step=1.29s, eta=6:54:17\n",
      "2022-01-20 11:45:41 [INFO]\t[TRAIN] Epoch=10/50, Step=474/478, loss=0.080300, lr=0.083669, time_each_step=1.29s, eta=6:54:7\n",
      "2022-01-20 11:45:44 [INFO]\t[TRAIN] Epoch=10/50, Step=476/478, loss=0.060290, lr=0.083662, time_each_step=1.28s, eta=6:53:31\n",
      "2022-01-20 11:45:46 [INFO]\t[TRAIN] Epoch=10/50, Step=478/478, loss=0.055455, lr=0.083655, time_each_step=1.28s, eta=6:53:29\n",
      "2022-01-20 11:45:46 [INFO]\t[TRAIN] Epoch 10 finished, loss=0.073749244 .\n",
      "2022-01-20 11:45:46 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-01-20 11:45:47 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-01-20 11:45:53 [INFO]\t[EVAL] Finished, Epoch=10, miou=0.816600, category_iou=[0.9684891  0.7169367  0.76437414], oacc=0.970326, category_acc=[0.98113704 0.8589883  0.8862851 ], kappa=0.851842, category_F1-score=[0.98399235 0.83513475 0.86645359] .\n",
      "2022-01-20 11:45:53 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_6, miou=0.8331509232521057\n",
      "2022-01-20 11:45:53 [INFO]\tModel saved in model/deeplab_augument_alldata2/epoch_10.\n",
      "2022-01-20 11:45:57 [INFO]\t[TRAIN] Epoch=11/50, Step=2/478, loss=0.049182, lr=0.083648, time_each_step=1.87s, eta=10:0:14\n",
      "2022-01-20 11:46:00 [INFO]\t[TRAIN] Epoch=11/50, Step=4/478, loss=0.057944, lr=0.083641, time_each_step=1.29s, eta=6:54:4\n",
      "2022-01-20 11:46:02 [INFO]\t[TRAIN] Epoch=11/50, Step=6/478, loss=0.050933, lr=0.083634, time_each_step=1.28s, eta=6:52:51\n",
      "2022-01-20 11:46:05 [INFO]\t[TRAIN] Epoch=11/50, Step=8/478, loss=0.054586, lr=0.083627, time_each_step=1.29s, eta=6:53:33\n",
      "2022-01-20 11:46:07 [INFO]\t[TRAIN] Epoch=11/50, Step=10/478, loss=0.087691, lr=0.083620, time_each_step=1.29s, eta=6:54:26\n",
      "2022-01-20 11:46:10 [INFO]\t[TRAIN] Epoch=11/50, Step=12/478, loss=0.054554, lr=0.083613, time_each_step=1.28s, eta=6:53:13\n",
      "2022-01-20 11:46:13 [INFO]\t[TRAIN] Epoch=11/50, Step=14/478, loss=0.059440, lr=0.083606, time_each_step=1.29s, eta=6:54:18\n",
      "2022-01-20 11:46:15 [INFO]\t[TRAIN] Epoch=11/50, Step=16/478, loss=0.071786, lr=0.083599, time_each_step=1.29s, eta=6:55:5\n",
      "2022-01-20 11:46:18 [INFO]\t[TRAIN] Epoch=11/50, Step=18/478, loss=0.085974, lr=0.083592, time_each_step=1.28s, eta=6:52:25\n",
      "2022-01-20 11:46:20 [INFO]\t[TRAIN] Epoch=11/50, Step=20/478, loss=0.092377, lr=0.083585, time_each_step=1.29s, eta=6:53:56\n",
      "2022-01-20 11:46:23 [INFO]\t[TRAIN] Epoch=11/50, Step=22/478, loss=0.073289, lr=0.083578, time_each_step=1.29s, eta=6:54:7\n",
      "2022-01-20 11:46:25 [INFO]\t[TRAIN] Epoch=11/50, Step=24/478, loss=0.119433, lr=0.083571, time_each_step=1.28s, eta=6:53:2\n",
      "2022-01-20 11:46:28 [INFO]\t[TRAIN] Epoch=11/50, Step=26/478, loss=0.082889, lr=0.083564, time_each_step=1.29s, eta=6:53:26\n",
      "2022-01-20 11:46:31 [INFO]\t[TRAIN] Epoch=11/50, Step=28/478, loss=0.051305, lr=0.083557, time_each_step=1.29s, eta=6:54:29\n",
      "2022-01-20 11:46:33 [INFO]\t[TRAIN] Epoch=11/50, Step=30/478, loss=0.048783, lr=0.083550, time_each_step=1.28s, eta=6:52:35\n",
      "2022-01-20 11:46:36 [INFO]\t[TRAIN] Epoch=11/50, Step=32/478, loss=0.081299, lr=0.083543, time_each_step=1.29s, eta=6:53:13\n",
      "2022-01-20 11:46:38 [INFO]\t[TRAIN] Epoch=11/50, Step=34/478, loss=0.060412, lr=0.083536, time_each_step=1.29s, eta=6:53:28\n",
      "2022-01-20 11:46:41 [INFO]\t[TRAIN] Epoch=11/50, Step=36/478, loss=0.122032, lr=0.083529, time_each_step=1.28s, eta=6:52:8\n",
      "2022-01-20 11:46:43 [INFO]\t[TRAIN] Epoch=11/50, Step=38/478, loss=0.055066, lr=0.083522, time_each_step=1.29s, eta=6:54:20\n",
      "2022-01-20 11:46:46 [INFO]\t[TRAIN] Epoch=11/50, Step=40/478, loss=0.073816, lr=0.083515, time_each_step=1.29s, eta=6:53:39\n",
      "2022-01-20 11:46:49 [INFO]\t[TRAIN] Epoch=11/50, Step=42/478, loss=0.102418, lr=0.083508, time_each_step=1.29s, eta=6:53:16\n",
      "2022-01-20 11:46:51 [INFO]\t[TRAIN] Epoch=11/50, Step=44/478, loss=0.079388, lr=0.083501, time_each_step=1.28s, eta=6:52:37\n",
      "2022-01-20 11:46:54 [INFO]\t[TRAIN] Epoch=11/50, Step=46/478, loss=0.072029, lr=0.083494, time_each_step=1.29s, eta=6:53:28\n",
      "2022-01-20 11:46:56 [INFO]\t[TRAIN] Epoch=11/50, Step=48/478, loss=0.062407, lr=0.083487, time_each_step=1.29s, eta=6:54:1\n",
      "2022-01-20 11:46:59 [INFO]\t[TRAIN] Epoch=11/50, Step=50/478, loss=0.061817, lr=0.083480, time_each_step=1.29s, eta=6:53:34\n",
      "2022-01-20 11:47:01 [INFO]\t[TRAIN] Epoch=11/50, Step=52/478, loss=0.069832, lr=0.083473, time_each_step=1.29s, eta=6:52:56\n",
      "2022-01-20 11:47:04 [INFO]\t[TRAIN] Epoch=11/50, Step=54/478, loss=0.067696, lr=0.083466, time_each_step=1.29s, eta=6:52:32\n",
      "2022-01-20 11:47:07 [INFO]\t[TRAIN] Epoch=11/50, Step=56/478, loss=0.057504, lr=0.083459, time_each_step=1.29s, eta=6:52:52\n",
      "2022-01-20 11:47:09 [INFO]\t[TRAIN] Epoch=11/50, Step=58/478, loss=0.088902, lr=0.083452, time_each_step=1.29s, eta=6:54:1\n",
      "2022-01-20 11:47:12 [INFO]\t[TRAIN] Epoch=11/50, Step=60/478, loss=0.053537, lr=0.083445, time_each_step=1.29s, eta=6:52:49\n",
      "2022-01-20 11:47:14 [INFO]\t[TRAIN] Epoch=11/50, Step=62/478, loss=0.061023, lr=0.083438, time_each_step=1.28s, eta=6:52:3\n",
      "2022-01-20 11:47:17 [INFO]\t[TRAIN] Epoch=11/50, Step=64/478, loss=0.069065, lr=0.083431, time_each_step=1.29s, eta=6:53:54\n",
      "2022-01-20 11:47:19 [INFO]\t[TRAIN] Epoch=11/50, Step=66/478, loss=0.095179, lr=0.083424, time_each_step=1.29s, eta=6:52:44\n",
      "2022-01-20 11:47:22 [INFO]\t[TRAIN] Epoch=11/50, Step=68/478, loss=0.074500, lr=0.083417, time_each_step=1.29s, eta=6:53:1\n",
      "2022-01-20 11:47:25 [INFO]\t[TRAIN] Epoch=11/50, Step=70/478, loss=0.066796, lr=0.083410, time_each_step=1.28s, eta=6:52:4\n",
      "2022-01-20 11:47:27 [INFO]\t[TRAIN] Epoch=11/50, Step=72/478, loss=0.068005, lr=0.083403, time_each_step=1.29s, eta=6:52:21\n",
      "2022-01-20 11:47:30 [INFO]\t[TRAIN] Epoch=11/50, Step=74/478, loss=0.064824, lr=0.083396, time_each_step=1.29s, eta=6:52:25\n",
      "2022-01-20 11:47:32 [INFO]\t[TRAIN] Epoch=11/50, Step=76/478, loss=0.089501, lr=0.083389, time_each_step=1.28s, eta=6:51:54\n",
      "2022-01-20 11:47:35 [INFO]\t[TRAIN] Epoch=11/50, Step=78/478, loss=0.058426, lr=0.083382, time_each_step=1.29s, eta=6:52:36\n",
      "2022-01-20 11:47:37 [INFO]\t[TRAIN] Epoch=11/50, Step=80/478, loss=0.067509, lr=0.083375, time_each_step=1.29s, eta=6:52:39\n",
      "2022-01-20 11:47:40 [INFO]\t[TRAIN] Epoch=11/50, Step=82/478, loss=0.058948, lr=0.083368, time_each_step=1.29s, eta=6:52:5\n",
      "2022-01-20 11:47:43 [INFO]\t[TRAIN] Epoch=11/50, Step=84/478, loss=0.067786, lr=0.083361, time_each_step=1.29s, eta=6:52:21\n",
      "2022-01-20 11:47:45 [INFO]\t[TRAIN] Epoch=11/50, Step=86/478, loss=0.086745, lr=0.083354, time_each_step=1.29s, eta=6:52:37\n",
      "2022-01-20 11:47:48 [INFO]\t[TRAIN] Epoch=11/50, Step=88/478, loss=0.058171, lr=0.083347, time_each_step=1.29s, eta=6:52:2\n",
      "2022-01-20 11:47:50 [INFO]\t[TRAIN] Epoch=11/50, Step=90/478, loss=0.060620, lr=0.083340, time_each_step=1.29s, eta=6:51:45\n",
      "2022-01-20 11:47:53 [INFO]\t[TRAIN] Epoch=11/50, Step=92/478, loss=0.086264, lr=0.083333, time_each_step=1.29s, eta=6:51:55\n",
      "2022-01-20 11:47:55 [INFO]\t[TRAIN] Epoch=11/50, Step=94/478, loss=0.082884, lr=0.083326, time_each_step=1.28s, eta=6:50:53\n",
      "2022-01-20 11:47:58 [INFO]\t[TRAIN] Epoch=11/50, Step=96/478, loss=0.071104, lr=0.083318, time_each_step=1.28s, eta=6:51:3\n",
      "2022-01-20 11:48:01 [INFO]\t[TRAIN] Epoch=11/50, Step=98/478, loss=0.092883, lr=0.083311, time_each_step=1.29s, eta=6:52:34\n",
      "2022-01-20 11:48:03 [INFO]\t[TRAIN] Epoch=11/50, Step=100/478, loss=0.074619, lr=0.083304, time_each_step=1.28s, eta=6:51:11\n",
      "2022-01-20 11:48:06 [INFO]\t[TRAIN] Epoch=11/50, Step=102/478, loss=0.062382, lr=0.083297, time_each_step=1.28s, eta=6:51:5\n",
      "2022-01-20 11:48:08 [INFO]\t[TRAIN] Epoch=11/50, Step=104/478, loss=0.037772, lr=0.083290, time_each_step=1.29s, eta=6:51:51\n",
      "2022-01-20 11:48:11 [INFO]\t[TRAIN] Epoch=11/50, Step=106/478, loss=0.082222, lr=0.083283, time_each_step=1.28s, eta=6:51:9\n",
      "2022-01-20 11:48:13 [INFO]\t[TRAIN] Epoch=11/50, Step=108/478, loss=0.081833, lr=0.083276, time_each_step=1.28s, eta=6:50:30\n",
      "2022-01-20 11:48:16 [INFO]\t[TRAIN] Epoch=11/50, Step=110/478, loss=0.084817, lr=0.083269, time_each_step=1.29s, eta=6:52:15\n",
      "2022-01-20 11:48:19 [INFO]\t[TRAIN] Epoch=11/50, Step=112/478, loss=0.081683, lr=0.083262, time_each_step=1.29s, eta=6:51:45\n",
      "2022-01-20 11:48:21 [INFO]\t[TRAIN] Epoch=11/50, Step=114/478, loss=0.072068, lr=0.083255, time_each_step=1.29s, eta=6:51:29\n",
      "2022-01-20 11:48:24 [INFO]\t[TRAIN] Epoch=11/50, Step=116/478, loss=0.079294, lr=0.083248, time_each_step=1.29s, eta=6:52:2\n",
      "2022-01-20 11:48:26 [INFO]\t[TRAIN] Epoch=11/50, Step=118/478, loss=0.069924, lr=0.083241, time_each_step=1.29s, eta=6:51:40\n",
      "2022-01-20 11:48:29 [INFO]\t[TRAIN] Epoch=11/50, Step=120/478, loss=0.070145, lr=0.083234, time_each_step=1.28s, eta=6:50:46\n",
      "2022-01-20 11:48:31 [INFO]\t[TRAIN] Epoch=11/50, Step=122/478, loss=0.070651, lr=0.083227, time_each_step=1.29s, eta=6:52:7\n",
      "2022-01-20 11:48:34 [INFO]\t[TRAIN] Epoch=11/50, Step=124/478, loss=0.049952, lr=0.083220, time_each_step=1.28s, eta=6:50:45\n",
      "2022-01-20 11:48:37 [INFO]\t[TRAIN] Epoch=11/50, Step=126/478, loss=0.051893, lr=0.083213, time_each_step=1.29s, eta=6:51:19\n",
      "2022-01-20 11:48:39 [INFO]\t[TRAIN] Epoch=11/50, Step=128/478, loss=0.047177, lr=0.083206, time_each_step=1.29s, eta=6:51:40\n",
      "2022-01-20 11:48:42 [INFO]\t[TRAIN] Epoch=11/50, Step=130/478, loss=0.049301, lr=0.083199, time_each_step=1.29s, eta=6:51:24\n",
      "2022-01-20 11:48:44 [INFO]\t[TRAIN] Epoch=11/50, Step=132/478, loss=0.074519, lr=0.083192, time_each_step=1.29s, eta=6:51:9\n",
      "2022-01-20 11:48:47 [INFO]\t[TRAIN] Epoch=11/50, Step=134/478, loss=0.066436, lr=0.083185, time_each_step=1.29s, eta=6:52:5\n",
      "2022-01-20 11:48:49 [INFO]\t[TRAIN] Epoch=11/50, Step=136/478, loss=0.084238, lr=0.083178, time_each_step=1.29s, eta=6:50:44\n",
      "2022-01-20 11:48:52 [INFO]\t[TRAIN] Epoch=11/50, Step=138/478, loss=0.065541, lr=0.083171, time_each_step=1.29s, eta=6:51:3\n",
      "2022-01-20 11:48:55 [INFO]\t[TRAIN] Epoch=11/50, Step=140/478, loss=0.052586, lr=0.083164, time_each_step=1.29s, eta=6:51:4\n",
      "2022-01-20 11:48:57 [INFO]\t[TRAIN] Epoch=11/50, Step=142/478, loss=0.083718, lr=0.083157, time_each_step=1.29s, eta=6:50:56\n",
      "2022-01-20 11:49:00 [INFO]\t[TRAIN] Epoch=11/50, Step=144/478, loss=0.046776, lr=0.083150, time_each_step=1.29s, eta=6:51:9\n",
      "2022-01-20 11:49:02 [INFO]\t[TRAIN] Epoch=11/50, Step=146/478, loss=0.088992, lr=0.083143, time_each_step=1.29s, eta=6:51:35\n",
      "2022-01-20 11:49:05 [INFO]\t[TRAIN] Epoch=11/50, Step=148/478, loss=0.057701, lr=0.083136, time_each_step=1.29s, eta=6:50:43\n",
      "2022-01-20 11:49:07 [INFO]\t[TRAIN] Epoch=11/50, Step=150/478, loss=0.084166, lr=0.083129, time_each_step=1.29s, eta=6:50:35\n",
      "2022-01-20 11:49:10 [INFO]\t[TRAIN] Epoch=11/50, Step=152/478, loss=0.082532, lr=0.083122, time_each_step=1.29s, eta=6:51:8\n",
      "2022-01-20 11:49:13 [INFO]\t[TRAIN] Epoch=11/50, Step=154/478, loss=0.070492, lr=0.083115, time_each_step=1.29s, eta=6:50:43\n",
      "2022-01-20 11:49:15 [INFO]\t[TRAIN] Epoch=11/50, Step=156/478, loss=0.054973, lr=0.083108, time_each_step=1.29s, eta=6:50:23\n",
      "2022-01-20 11:49:18 [INFO]\t[TRAIN] Epoch=11/50, Step=158/478, loss=0.052228, lr=0.083101, time_each_step=1.29s, eta=6:51:7\n",
      "2022-01-20 11:49:20 [INFO]\t[TRAIN] Epoch=11/50, Step=160/478, loss=0.076705, lr=0.083094, time_each_step=1.29s, eta=6:50:22\n",
      "2022-01-20 11:49:23 [INFO]\t[TRAIN] Epoch=11/50, Step=162/478, loss=0.058813, lr=0.083087, time_each_step=1.29s, eta=6:50:23\n",
      "2022-01-20 11:49:25 [INFO]\t[TRAIN] Epoch=11/50, Step=164/478, loss=0.074825, lr=0.083080, time_each_step=1.28s, eta=6:49:45\n",
      "2022-01-20 11:49:28 [INFO]\t[TRAIN] Epoch=11/50, Step=166/478, loss=0.066690, lr=0.083073, time_each_step=1.29s, eta=6:50:51\n",
      "2022-01-20 11:49:31 [INFO]\t[TRAIN] Epoch=11/50, Step=168/478, loss=0.067150, lr=0.083066, time_each_step=1.28s, eta=6:49:18\n",
      "2022-01-20 11:49:33 [INFO]\t[TRAIN] Epoch=11/50, Step=170/478, loss=0.066658, lr=0.083059, time_each_step=1.28s, eta=6:49:35\n",
      "2022-01-20 11:49:36 [INFO]\t[TRAIN] Epoch=11/50, Step=172/478, loss=0.069291, lr=0.083052, time_each_step=1.29s, eta=6:50:54\n",
      "2022-01-20 11:49:38 [INFO]\t[TRAIN] Epoch=11/50, Step=174/478, loss=0.060976, lr=0.083045, time_each_step=1.28s, eta=6:49:12\n",
      "2022-01-20 11:49:41 [INFO]\t[TRAIN] Epoch=11/50, Step=176/478, loss=0.052445, lr=0.083038, time_each_step=1.29s, eta=6:50:35\n",
      "2022-01-20 11:49:43 [INFO]\t[TRAIN] Epoch=11/50, Step=178/478, loss=0.079113, lr=0.083031, time_each_step=1.29s, eta=6:50:48\n",
      "2022-01-20 11:49:46 [INFO]\t[TRAIN] Epoch=11/50, Step=180/478, loss=0.095048, lr=0.083024, time_each_step=1.28s, eta=6:49:33\n",
      "2022-01-20 11:49:49 [INFO]\t[TRAIN] Epoch=11/50, Step=182/478, loss=0.078080, lr=0.083017, time_each_step=1.29s, eta=6:50:8\n",
      "2022-01-20 11:49:51 [INFO]\t[TRAIN] Epoch=11/50, Step=184/478, loss=0.047561, lr=0.083010, time_each_step=1.29s, eta=6:50:12\n",
      "2022-01-20 11:49:54 [INFO]\t[TRAIN] Epoch=11/50, Step=186/478, loss=0.098392, lr=0.083003, time_each_step=1.28s, eta=6:49:26\n",
      "2022-01-20 11:49:56 [INFO]\t[TRAIN] Epoch=11/50, Step=188/478, loss=0.065073, lr=0.082996, time_each_step=1.29s, eta=6:50:3\n",
      "2022-01-20 11:49:59 [INFO]\t[TRAIN] Epoch=11/50, Step=190/478, loss=0.043162, lr=0.082989, time_each_step=1.29s, eta=6:49:56\n",
      "2022-01-20 11:50:01 [INFO]\t[TRAIN] Epoch=11/50, Step=192/478, loss=0.087644, lr=0.082982, time_each_step=1.28s, eta=6:49:12\n",
      "2022-01-20 11:50:04 [INFO]\t[TRAIN] Epoch=11/50, Step=194/478, loss=0.060689, lr=0.082975, time_each_step=1.29s, eta=6:50:56\n",
      "2022-01-20 11:50:07 [INFO]\t[TRAIN] Epoch=11/50, Step=196/478, loss=0.078384, lr=0.082968, time_each_step=1.29s, eta=6:49:50\n",
      "2022-01-20 11:50:09 [INFO]\t[TRAIN] Epoch=11/50, Step=198/478, loss=0.079988, lr=0.082961, time_each_step=1.28s, eta=6:48:50\n",
      "2022-01-20 11:50:12 [INFO]\t[TRAIN] Epoch=11/50, Step=200/478, loss=0.063902, lr=0.082954, time_each_step=1.29s, eta=6:49:25\n",
      "2022-01-20 11:50:14 [INFO]\t[TRAIN] Epoch=11/50, Step=202/478, loss=0.070877, lr=0.082947, time_each_step=1.29s, eta=6:50:22\n",
      "2022-01-20 11:50:17 [INFO]\t[TRAIN] Epoch=11/50, Step=204/478, loss=0.073329, lr=0.082940, time_each_step=1.28s, eta=6:48:58\n",
      "2022-01-20 11:50:19 [INFO]\t[TRAIN] Epoch=11/50, Step=206/478, loss=0.066067, lr=0.082933, time_each_step=1.29s, eta=6:49:23\n",
      "2022-01-20 11:50:22 [INFO]\t[TRAIN] Epoch=11/50, Step=208/478, loss=0.060485, lr=0.082926, time_each_step=1.29s, eta=6:50:21\n",
      "2022-01-20 11:50:25 [INFO]\t[TRAIN] Epoch=11/50, Step=210/478, loss=0.061910, lr=0.082919, time_each_step=1.28s, eta=6:48:25\n",
      "2022-01-20 11:50:27 [INFO]\t[TRAIN] Epoch=11/50, Step=212/478, loss=0.059562, lr=0.082912, time_each_step=1.29s, eta=6:49:52\n",
      "2022-01-20 11:50:30 [INFO]\t[TRAIN] Epoch=11/50, Step=214/478, loss=0.077537, lr=0.082905, time_each_step=1.29s, eta=6:50:49\n",
      "2022-01-20 11:50:32 [INFO]\t[TRAIN] Epoch=11/50, Step=216/478, loss=0.079405, lr=0.082898, time_each_step=1.28s, eta=6:48:12\n",
      "2022-01-20 11:50:35 [INFO]\t[TRAIN] Epoch=11/50, Step=218/478, loss=0.098313, lr=0.082891, time_each_step=1.29s, eta=6:49:14\n",
      "2022-01-20 11:50:37 [INFO]\t[TRAIN] Epoch=11/50, Step=220/478, loss=0.061890, lr=0.082884, time_each_step=1.29s, eta=6:49:39\n",
      "2022-01-20 11:50:40 [INFO]\t[TRAIN] Epoch=11/50, Step=222/478, loss=0.060759, lr=0.082877, time_each_step=1.28s, eta=6:47:43\n",
      "2022-01-20 11:50:43 [INFO]\t[TRAIN] Epoch=11/50, Step=224/478, loss=0.050468, lr=0.082870, time_each_step=1.29s, eta=6:48:52\n",
      "2022-01-20 11:50:45 [INFO]\t[TRAIN] Epoch=11/50, Step=226/478, loss=0.074393, lr=0.082863, time_each_step=1.29s, eta=6:49:16\n",
      "2022-01-20 11:50:48 [INFO]\t[TRAIN] Epoch=11/50, Step=228/478, loss=0.094180, lr=0.082856, time_each_step=1.28s, eta=6:48:30\n",
      "2022-01-20 11:50:50 [INFO]\t[TRAIN] Epoch=11/50, Step=230/478, loss=0.077002, lr=0.082849, time_each_step=1.29s, eta=6:48:57\n",
      "2022-01-20 11:50:53 [INFO]\t[TRAIN] Epoch=11/50, Step=232/478, loss=0.056233, lr=0.082842, time_each_step=1.29s, eta=6:51:16\n",
      "2022-01-20 11:50:55 [INFO]\t[TRAIN] Epoch=11/50, Step=234/478, loss=0.072764, lr=0.082835, time_each_step=1.29s, eta=6:49:27\n",
      "2022-01-20 11:50:58 [INFO]\t[TRAIN] Epoch=11/50, Step=236/478, loss=0.083870, lr=0.082828, time_each_step=1.29s, eta=6:49:51\n",
      "2022-01-20 11:51:01 [INFO]\t[TRAIN] Epoch=11/50, Step=238/478, loss=0.097160, lr=0.082821, time_each_step=1.29s, eta=6:49:13\n",
      "2022-01-20 11:51:03 [INFO]\t[TRAIN] Epoch=11/50, Step=240/478, loss=0.076606, lr=0.082814, time_each_step=1.28s, eta=6:48:13\n",
      "2022-01-20 11:51:06 [INFO]\t[TRAIN] Epoch=11/50, Step=242/478, loss=0.057363, lr=0.082807, time_each_step=1.29s, eta=6:49:9\n",
      "2022-01-20 11:51:08 [INFO]\t[TRAIN] Epoch=11/50, Step=244/478, loss=0.073563, lr=0.082800, time_each_step=1.28s, eta=6:47:30\n",
      "2022-01-20 11:51:11 [INFO]\t[TRAIN] Epoch=11/50, Step=246/478, loss=0.055455, lr=0.082793, time_each_step=1.28s, eta=6:47:54\n",
      "2022-01-20 11:51:13 [INFO]\t[TRAIN] Epoch=11/50, Step=248/478, loss=0.129241, lr=0.082786, time_each_step=1.29s, eta=6:48:57\n",
      "2022-01-20 11:51:16 [INFO]\t[TRAIN] Epoch=11/50, Step=250/478, loss=0.059860, lr=0.082779, time_each_step=1.29s, eta=6:48:38\n",
      "2022-01-20 11:51:19 [INFO]\t[TRAIN] Epoch=11/50, Step=252/478, loss=0.058313, lr=0.082771, time_each_step=1.29s, eta=6:48:53\n",
      "2022-01-20 11:51:21 [INFO]\t[TRAIN] Epoch=11/50, Step=254/478, loss=0.067340, lr=0.082764, time_each_step=1.29s, eta=6:49:23\n",
      "2022-01-20 11:51:24 [INFO]\t[TRAIN] Epoch=11/50, Step=256/478, loss=0.069501, lr=0.082757, time_each_step=1.29s, eta=6:49:0\n",
      "2022-01-20 11:51:26 [INFO]\t[TRAIN] Epoch=11/50, Step=258/478, loss=0.098904, lr=0.082750, time_each_step=1.29s, eta=6:48:28\n",
      "2022-01-20 11:51:29 [INFO]\t[TRAIN] Epoch=11/50, Step=260/478, loss=0.062671, lr=0.082743, time_each_step=1.29s, eta=6:48:47\n",
      "2022-01-20 11:51:32 [INFO]\t[TRAIN] Epoch=11/50, Step=262/478, loss=0.073255, lr=0.082736, time_each_step=1.29s, eta=6:48:18\n",
      "2022-01-20 11:51:34 [INFO]\t[TRAIN] Epoch=11/50, Step=264/478, loss=0.089216, lr=0.082729, time_each_step=1.29s, eta=6:48:3\n",
      "2022-01-20 11:51:37 [INFO]\t[TRAIN] Epoch=11/50, Step=266/478, loss=0.104016, lr=0.082722, time_each_step=1.29s, eta=6:48:59\n",
      "2022-01-20 11:51:39 [INFO]\t[TRAIN] Epoch=11/50, Step=268/478, loss=0.057627, lr=0.082715, time_each_step=1.29s, eta=6:48:38\n",
      "2022-01-20 11:51:42 [INFO]\t[TRAIN] Epoch=11/50, Step=270/478, loss=0.051380, lr=0.082708, time_each_step=1.29s, eta=6:48:22\n",
      "2022-01-20 11:51:44 [INFO]\t[TRAIN] Epoch=11/50, Step=272/478, loss=0.057615, lr=0.082701, time_each_step=1.29s, eta=6:48:23\n",
      "2022-01-20 11:51:47 [INFO]\t[TRAIN] Epoch=11/50, Step=274/478, loss=0.069527, lr=0.082694, time_each_step=1.28s, eta=6:47:20\n",
      "2022-01-20 11:51:50 [INFO]\t[TRAIN] Epoch=11/50, Step=276/478, loss=0.061038, lr=0.082687, time_each_step=1.28s, eta=6:47:27\n",
      "2022-01-20 11:51:52 [INFO]\t[TRAIN] Epoch=11/50, Step=278/478, loss=0.076709, lr=0.082680, time_each_step=1.29s, eta=6:48:3\n",
      "2022-01-20 11:51:55 [INFO]\t[TRAIN] Epoch=11/50, Step=280/478, loss=0.064067, lr=0.082673, time_each_step=1.29s, eta=6:47:47\n",
      "2022-01-20 11:51:57 [INFO]\t[TRAIN] Epoch=11/50, Step=282/478, loss=0.056926, lr=0.082666, time_each_step=1.28s, eta=6:47:32\n",
      "2022-01-20 11:52:00 [INFO]\t[TRAIN] Epoch=11/50, Step=284/478, loss=0.058843, lr=0.082659, time_each_step=1.29s, eta=6:48:24\n",
      "2022-01-20 11:52:02 [INFO]\t[TRAIN] Epoch=11/50, Step=286/478, loss=0.076954, lr=0.082652, time_each_step=1.29s, eta=6:47:32\n",
      "2022-01-20 11:52:05 [INFO]\t[TRAIN] Epoch=11/50, Step=288/478, loss=0.079011, lr=0.082645, time_each_step=1.28s, eta=6:47:17\n",
      "2022-01-20 11:52:08 [INFO]\t[TRAIN] Epoch=11/50, Step=290/478, loss=0.076186, lr=0.082638, time_each_step=1.29s, eta=6:48:38\n",
      "2022-01-20 11:52:10 [INFO]\t[TRAIN] Epoch=11/50, Step=292/478, loss=0.081651, lr=0.082631, time_each_step=1.28s, eta=6:47:3\n",
      "2022-01-20 11:52:13 [INFO]\t[TRAIN] Epoch=11/50, Step=294/478, loss=0.081351, lr=0.082624, time_each_step=1.28s, eta=6:47:1\n",
      "2022-01-20 11:52:15 [INFO]\t[TRAIN] Epoch=11/50, Step=296/478, loss=0.067375, lr=0.082617, time_each_step=1.29s, eta=6:48:37\n",
      "2022-01-20 11:52:18 [INFO]\t[TRAIN] Epoch=11/50, Step=298/478, loss=0.066284, lr=0.082610, time_each_step=1.28s, eta=6:46:59\n",
      "2022-01-20 11:52:20 [INFO]\t[TRAIN] Epoch=11/50, Step=300/478, loss=0.072542, lr=0.082603, time_each_step=1.29s, eta=6:47:16\n",
      "2022-01-20 11:52:23 [INFO]\t[TRAIN] Epoch=11/50, Step=302/478, loss=0.068177, lr=0.082596, time_each_step=1.29s, eta=6:49:2\n",
      "2022-01-20 11:52:26 [INFO]\t[TRAIN] Epoch=11/50, Step=304/478, loss=0.065133, lr=0.082589, time_each_step=1.28s, eta=6:46:34\n",
      "2022-01-20 11:52:28 [INFO]\t[TRAIN] Epoch=11/50, Step=306/478, loss=0.064749, lr=0.082582, time_each_step=1.29s, eta=6:47:17\n",
      "2022-01-20 11:52:31 [INFO]\t[TRAIN] Epoch=11/50, Step=308/478, loss=0.084869, lr=0.082575, time_each_step=1.29s, eta=6:48:41\n",
      "2022-01-20 11:52:33 [INFO]\t[TRAIN] Epoch=11/50, Step=310/478, loss=0.086244, lr=0.082568, time_each_step=1.28s, eta=6:46:42\n",
      "2022-01-20 11:52:36 [INFO]\t[TRAIN] Epoch=11/50, Step=312/478, loss=0.106565, lr=0.082561, time_each_step=1.28s, eta=6:46:48\n",
      "2022-01-20 11:52:38 [INFO]\t[TRAIN] Epoch=11/50, Step=314/478, loss=0.054471, lr=0.082554, time_each_step=1.29s, eta=6:47:50\n",
      "2022-01-20 11:52:41 [INFO]\t[TRAIN] Epoch=11/50, Step=316/478, loss=0.081732, lr=0.082547, time_each_step=1.28s, eta=6:46:5\n",
      "2022-01-20 11:52:44 [INFO]\t[TRAIN] Epoch=11/50, Step=318/478, loss=0.062040, lr=0.082540, time_each_step=1.29s, eta=6:46:51\n",
      "2022-01-20 11:52:46 [INFO]\t[TRAIN] Epoch=11/50, Step=320/478, loss=0.093419, lr=0.082533, time_each_step=1.29s, eta=6:47:29\n",
      "2022-01-20 11:52:49 [INFO]\t[TRAIN] Epoch=11/50, Step=322/478, loss=0.066776, lr=0.082526, time_each_step=1.29s, eta=6:47:37\n",
      "2022-01-20 11:52:51 [INFO]\t[TRAIN] Epoch=11/50, Step=324/478, loss=0.063577, lr=0.082519, time_each_step=1.29s, eta=6:47:10\n",
      "2022-01-20 11:52:54 [INFO]\t[TRAIN] Epoch=11/50, Step=326/478, loss=0.065899, lr=0.082512, time_each_step=1.29s, eta=6:47:57\n",
      "2022-01-20 11:52:56 [INFO]\t[TRAIN] Epoch=11/50, Step=328/478, loss=0.075031, lr=0.082505, time_each_step=1.29s, eta=6:47:6\n",
      "2022-01-20 11:52:59 [INFO]\t[TRAIN] Epoch=11/50, Step=330/478, loss=0.059514, lr=0.082498, time_each_step=1.29s, eta=6:46:54\n",
      "2022-01-20 11:53:02 [INFO]\t[TRAIN] Epoch=11/50, Step=332/478, loss=0.061851, lr=0.082491, time_each_step=1.28s, eta=6:46:16\n",
      "2022-01-20 11:53:04 [INFO]\t[TRAIN] Epoch=11/50, Step=334/478, loss=0.088393, lr=0.082484, time_each_step=1.28s, eta=6:46:21\n",
      "2022-01-20 11:53:07 [INFO]\t[TRAIN] Epoch=11/50, Step=336/478, loss=0.061814, lr=0.082477, time_each_step=1.29s, eta=6:46:34\n",
      "2022-01-20 11:53:09 [INFO]\t[TRAIN] Epoch=11/50, Step=338/478, loss=0.083754, lr=0.082470, time_each_step=1.29s, eta=6:46:22\n",
      "2022-01-20 11:53:12 [INFO]\t[TRAIN] Epoch=11/50, Step=340/478, loss=0.050340, lr=0.082463, time_each_step=1.29s, eta=6:46:45\n",
      "2022-01-20 11:53:14 [INFO]\t[TRAIN] Epoch=11/50, Step=342/478, loss=0.057155, lr=0.082456, time_each_step=1.29s, eta=6:46:38\n",
      "2022-01-20 11:53:17 [INFO]\t[TRAIN] Epoch=11/50, Step=344/478, loss=0.083173, lr=0.082448, time_each_step=1.29s, eta=6:47:20\n",
      "2022-01-20 11:53:20 [INFO]\t[TRAIN] Epoch=11/50, Step=346/478, loss=0.088257, lr=0.082441, time_each_step=1.29s, eta=6:47:6\n",
      "2022-01-20 11:53:22 [INFO]\t[TRAIN] Epoch=11/50, Step=348/478, loss=0.085526, lr=0.082434, time_each_step=1.28s, eta=6:46:8\n",
      "2022-01-20 11:53:25 [INFO]\t[TRAIN] Epoch=11/50, Step=350/478, loss=0.046037, lr=0.082427, time_each_step=1.29s, eta=6:46:18\n",
      "2022-01-20 11:53:27 [INFO]\t[TRAIN] Epoch=11/50, Step=352/478, loss=0.077987, lr=0.082420, time_each_step=1.29s, eta=6:46:12\n",
      "2022-01-20 11:53:30 [INFO]\t[TRAIN] Epoch=11/50, Step=354/478, loss=0.069567, lr=0.082413, time_each_step=1.29s, eta=6:46:7\n",
      "2022-01-20 11:53:32 [INFO]\t[TRAIN] Epoch=11/50, Step=356/478, loss=0.087153, lr=0.082406, time_each_step=1.29s, eta=6:46:22\n",
      "2022-01-20 11:53:35 [INFO]\t[TRAIN] Epoch=11/50, Step=358/478, loss=0.084683, lr=0.082399, time_each_step=1.28s, eta=6:45:45\n",
      "2022-01-20 11:53:38 [INFO]\t[TRAIN] Epoch=11/50, Step=360/478, loss=0.055850, lr=0.082392, time_each_step=1.29s, eta=6:46:14\n",
      "2022-01-20 11:53:40 [INFO]\t[TRAIN] Epoch=11/50, Step=362/478, loss=0.079772, lr=0.082385, time_each_step=1.29s, eta=6:46:18\n",
      "2022-01-20 11:53:43 [INFO]\t[TRAIN] Epoch=11/50, Step=364/478, loss=0.057941, lr=0.082378, time_each_step=1.29s, eta=6:45:49\n",
      "2022-01-20 11:53:45 [INFO]\t[TRAIN] Epoch=11/50, Step=366/478, loss=0.048610, lr=0.082371, time_each_step=1.28s, eta=6:45:27\n",
      "2022-01-20 11:53:48 [INFO]\t[TRAIN] Epoch=11/50, Step=368/478, loss=0.049740, lr=0.082364, time_each_step=1.29s, eta=6:46:58\n",
      "2022-01-20 11:53:50 [INFO]\t[TRAIN] Epoch=11/50, Step=370/478, loss=0.093167, lr=0.082357, time_each_step=1.29s, eta=6:45:56\n",
      "2022-01-20 11:53:53 [INFO]\t[TRAIN] Epoch=11/50, Step=372/478, loss=0.071396, lr=0.082350, time_each_step=1.29s, eta=6:45:49\n",
      "2022-01-20 11:53:56 [INFO]\t[TRAIN] Epoch=11/50, Step=374/478, loss=0.096035, lr=0.082343, time_each_step=1.29s, eta=6:46:7\n",
      "2022-01-20 11:53:58 [INFO]\t[TRAIN] Epoch=11/50, Step=376/478, loss=0.107569, lr=0.082336, time_each_step=1.29s, eta=6:45:46\n",
      "2022-01-20 11:54:01 [INFO]\t[TRAIN] Epoch=11/50, Step=378/478, loss=0.074175, lr=0.082329, time_each_step=1.28s, eta=6:45:18\n",
      "2022-01-20 11:54:03 [INFO]\t[TRAIN] Epoch=11/50, Step=380/478, loss=0.059555, lr=0.082322, time_each_step=1.29s, eta=6:46:21\n",
      "2022-01-20 11:54:06 [INFO]\t[TRAIN] Epoch=11/50, Step=382/478, loss=0.076827, lr=0.082315, time_each_step=1.28s, eta=6:44:46\n",
      "2022-01-20 11:54:08 [INFO]\t[TRAIN] Epoch=11/50, Step=384/478, loss=0.055719, lr=0.082308, time_each_step=1.29s, eta=6:46:3\n",
      "2022-01-20 11:54:11 [INFO]\t[TRAIN] Epoch=11/50, Step=386/478, loss=0.069329, lr=0.082301, time_each_step=1.29s, eta=6:46:2\n",
      "2022-01-20 11:54:14 [INFO]\t[TRAIN] Epoch=11/50, Step=388/478, loss=0.055296, lr=0.082294, time_each_step=1.29s, eta=6:45:39\n",
      "2022-01-20 11:54:16 [INFO]\t[TRAIN] Epoch=11/50, Step=390/478, loss=0.073505, lr=0.082287, time_each_step=1.29s, eta=6:45:49\n",
      "2022-01-20 11:54:19 [INFO]\t[TRAIN] Epoch=11/50, Step=392/478, loss=0.084345, lr=0.082280, time_each_step=1.29s, eta=6:45:23\n",
      "2022-01-20 11:54:21 [INFO]\t[TRAIN] Epoch=11/50, Step=394/478, loss=0.080769, lr=0.082273, time_each_step=1.29s, eta=6:45:40\n",
      "2022-01-20 11:54:24 [INFO]\t[TRAIN] Epoch=11/50, Step=396/478, loss=0.077546, lr=0.082266, time_each_step=1.29s, eta=6:45:15\n",
      "2022-01-20 11:54:26 [INFO]\t[TRAIN] Epoch=11/50, Step=398/478, loss=0.071899, lr=0.082259, time_each_step=1.29s, eta=6:45:41\n",
      "2022-01-20 11:54:29 [INFO]\t[TRAIN] Epoch=11/50, Step=400/478, loss=0.069663, lr=0.082252, time_each_step=1.29s, eta=6:45:20\n",
      "2022-01-20 11:54:32 [INFO]\t[TRAIN] Epoch=11/50, Step=402/478, loss=0.075067, lr=0.082245, time_each_step=1.29s, eta=6:45:34\n",
      "2022-01-20 11:54:34 [INFO]\t[TRAIN] Epoch=11/50, Step=404/478, loss=0.072760, lr=0.082238, time_each_step=1.29s, eta=6:45:39\n",
      "2022-01-20 11:54:37 [INFO]\t[TRAIN] Epoch=11/50, Step=406/478, loss=0.064233, lr=0.082231, time_each_step=1.29s, eta=6:45:6\n",
      "2022-01-20 11:54:39 [INFO]\t[TRAIN] Epoch=11/50, Step=408/478, loss=0.066147, lr=0.082224, time_each_step=1.29s, eta=6:45:3\n",
      "2022-01-20 11:54:42 [INFO]\t[TRAIN] Epoch=11/50, Step=410/478, loss=0.052911, lr=0.082217, time_each_step=1.29s, eta=6:45:54\n",
      "2022-01-20 11:54:44 [INFO]\t[TRAIN] Epoch=11/50, Step=412/478, loss=0.061207, lr=0.082210, time_each_step=1.29s, eta=6:44:53\n",
      "2022-01-20 11:54:47 [INFO]\t[TRAIN] Epoch=11/50, Step=414/478, loss=0.057254, lr=0.082202, time_each_step=1.29s, eta=6:45:20\n",
      "2022-01-20 11:54:50 [INFO]\t[TRAIN] Epoch=11/50, Step=416/478, loss=0.051278, lr=0.082195, time_each_step=1.29s, eta=6:45:53\n",
      "2022-01-20 11:54:52 [INFO]\t[TRAIN] Epoch=11/50, Step=418/478, loss=0.060917, lr=0.082188, time_each_step=1.28s, eta=6:44:23\n",
      "2022-01-20 11:54:55 [INFO]\t[TRAIN] Epoch=11/50, Step=420/478, loss=0.076324, lr=0.082181, time_each_step=1.28s, eta=6:44:32\n",
      "2022-01-20 11:54:57 [INFO]\t[TRAIN] Epoch=11/50, Step=422/478, loss=0.080850, lr=0.082174, time_each_step=1.29s, eta=6:45:20\n",
      "2022-01-20 11:55:00 [INFO]\t[TRAIN] Epoch=11/50, Step=424/478, loss=0.091430, lr=0.082167, time_each_step=1.29s, eta=6:44:43\n",
      "2022-01-20 11:55:02 [INFO]\t[TRAIN] Epoch=11/50, Step=426/478, loss=0.084431, lr=0.082160, time_each_step=1.28s, eta=6:44:9\n",
      "2022-01-20 11:55:05 [INFO]\t[TRAIN] Epoch=11/50, Step=428/478, loss=0.082580, lr=0.082153, time_each_step=1.29s, eta=6:45:18\n",
      "2022-01-20 11:55:08 [INFO]\t[TRAIN] Epoch=11/50, Step=430/478, loss=0.067730, lr=0.082146, time_each_step=1.29s, eta=6:45:58\n",
      "2022-01-20 11:55:10 [INFO]\t[TRAIN] Epoch=11/50, Step=432/478, loss=0.049630, lr=0.082139, time_each_step=1.28s, eta=6:43:54\n",
      "2022-01-20 11:55:13 [INFO]\t[TRAIN] Epoch=11/50, Step=434/478, loss=0.063871, lr=0.082132, time_each_step=1.29s, eta=6:45:59\n",
      "2022-01-20 11:55:15 [INFO]\t[TRAIN] Epoch=11/50, Step=436/478, loss=0.067493, lr=0.082125, time_each_step=1.29s, eta=6:45:7\n",
      "2022-01-20 11:55:18 [INFO]\t[TRAIN] Epoch=11/50, Step=438/478, loss=0.067120, lr=0.082118, time_each_step=1.28s, eta=6:44:3\n",
      "2022-01-20 11:55:20 [INFO]\t[TRAIN] Epoch=11/50, Step=440/478, loss=0.087348, lr=0.082111, time_each_step=1.29s, eta=6:46:5\n",
      "2022-01-20 11:55:23 [INFO]\t[TRAIN] Epoch=11/50, Step=442/478, loss=0.080712, lr=0.082104, time_each_step=1.29s, eta=6:44:24\n",
      "2022-01-20 11:55:26 [INFO]\t[TRAIN] Epoch=11/50, Step=444/478, loss=0.075976, lr=0.082097, time_each_step=1.28s, eta=6:43:42\n",
      "2022-01-20 11:55:28 [INFO]\t[TRAIN] Epoch=11/50, Step=446/478, loss=0.075981, lr=0.082090, time_each_step=1.29s, eta=6:44:49\n",
      "2022-01-20 11:55:31 [INFO]\t[TRAIN] Epoch=11/50, Step=448/478, loss=0.063942, lr=0.082083, time_each_step=1.28s, eta=6:43:41\n",
      "2022-01-20 11:55:33 [INFO]\t[TRAIN] Epoch=11/50, Step=450/478, loss=0.080721, lr=0.082076, time_each_step=1.29s, eta=6:44:17\n",
      "2022-01-20 11:55:36 [INFO]\t[TRAIN] Epoch=11/50, Step=452/478, loss=0.046345, lr=0.082069, time_each_step=1.29s, eta=6:44:44\n",
      "2022-01-20 11:55:38 [INFO]\t[TRAIN] Epoch=11/50, Step=454/478, loss=0.073322, lr=0.082062, time_each_step=1.28s, eta=6:43:41\n",
      "2022-01-20 11:55:41 [INFO]\t[TRAIN] Epoch=11/50, Step=456/478, loss=0.062489, lr=0.082055, time_each_step=1.28s, eta=6:43:26\n",
      "2022-01-20 11:55:44 [INFO]\t[TRAIN] Epoch=11/50, Step=458/478, loss=0.044451, lr=0.082048, time_each_step=1.29s, eta=6:44:55\n",
      "2022-01-20 11:55:46 [INFO]\t[TRAIN] Epoch=11/50, Step=460/478, loss=0.058047, lr=0.082041, time_each_step=1.29s, eta=6:44:3\n",
      "2022-01-20 11:55:49 [INFO]\t[TRAIN] Epoch=11/50, Step=462/478, loss=0.073422, lr=0.082034, time_each_step=1.29s, eta=6:44:0\n",
      "2022-01-20 11:55:51 [INFO]\t[TRAIN] Epoch=11/50, Step=464/478, loss=0.075684, lr=0.082027, time_each_step=1.29s, eta=6:45:15\n",
      "2022-01-20 11:55:54 [INFO]\t[TRAIN] Epoch=11/50, Step=466/478, loss=0.072723, lr=0.082020, time_each_step=1.28s, eta=6:43:3\n",
      "2022-01-20 11:55:56 [INFO]\t[TRAIN] Epoch=11/50, Step=468/478, loss=0.069109, lr=0.082013, time_each_step=1.28s, eta=6:43:4\n",
      "2022-01-20 11:55:59 [INFO]\t[TRAIN] Epoch=11/50, Step=470/478, loss=0.062987, lr=0.082006, time_each_step=1.29s, eta=6:44:33\n",
      "2022-01-20 11:56:02 [INFO]\t[TRAIN] Epoch=11/50, Step=472/478, loss=0.060239, lr=0.081999, time_each_step=1.29s, eta=6:43:47\n",
      "2022-01-20 11:56:04 [INFO]\t[TRAIN] Epoch=11/50, Step=474/478, loss=0.072853, lr=0.081992, time_each_step=1.29s, eta=6:43:53\n",
      "2022-01-20 11:56:07 [INFO]\t[TRAIN] Epoch=11/50, Step=476/478, loss=0.052754, lr=0.081984, time_each_step=1.28s, eta=6:42:40\n",
      "2022-01-20 11:56:09 [INFO]\t[TRAIN] Epoch=11/50, Step=478/478, loss=0.082708, lr=0.081977, time_each_step=1.29s, eta=6:44:20\n",
      "2022-01-20 11:56:09 [INFO]\t[TRAIN] Epoch 11 finished, loss=0.07074269 .\n",
      "2022-01-20 11:56:09 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-01-20 11:56:10 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-01-20 11:56:16 [INFO]\t[EVAL] Finished, Epoch=11, miou=0.822173, category_iou=[0.96898496 0.72076315 0.7767718 ], oacc=0.971072, category_acc=[0.98381585 0.8667158  0.8710197 ], kappa=0.858036, category_F1-score=[0.98424821 0.83772495 0.874363  ] .\n",
      "2022-01-20 11:56:16 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_6, miou=0.8331509232521057\n",
      "2022-01-20 11:56:16 [INFO]\tModel saved in model/deeplab_augument_alldata2/epoch_11.\n",
      "2022-01-20 11:56:20 [INFO]\t[TRAIN] Epoch=12/50, Step=2/478, loss=0.114329, lr=0.081970, time_each_step=1.85s, eta=9:38:8\n",
      "2022-01-20 11:56:23 [INFO]\t[TRAIN] Epoch=12/50, Step=4/478, loss=0.070139, lr=0.081963, time_each_step=1.29s, eta=6:43:47\n",
      "2022-01-20 11:56:25 [INFO]\t[TRAIN] Epoch=12/50, Step=6/478, loss=0.061345, lr=0.081956, time_each_step=1.28s, eta=6:42:40\n",
      "2022-01-20 11:56:28 [INFO]\t[TRAIN] Epoch=12/50, Step=8/478, loss=0.051870, lr=0.081949, time_each_step=1.29s, eta=6:43:57\n",
      "2022-01-20 11:56:30 [INFO]\t[TRAIN] Epoch=12/50, Step=10/478, loss=0.053400, lr=0.081942, time_each_step=1.29s, eta=6:43:18\n",
      "2022-01-20 11:56:33 [INFO]\t[TRAIN] Epoch=12/50, Step=12/478, loss=0.062644, lr=0.081935, time_each_step=1.28s, eta=6:42:20\n",
      "2022-01-20 11:56:35 [INFO]\t[TRAIN] Epoch=12/50, Step=14/478, loss=0.079043, lr=0.081928, time_each_step=1.29s, eta=6:43:44\n",
      "2022-01-20 11:56:38 [INFO]\t[TRAIN] Epoch=12/50, Step=16/478, loss=0.061140, lr=0.081921, time_each_step=1.29s, eta=6:43:6\n",
      "2022-01-20 11:56:41 [INFO]\t[TRAIN] Epoch=12/50, Step=18/478, loss=0.069575, lr=0.081914, time_each_step=1.29s, eta=6:43:14\n",
      "2022-01-20 11:56:43 [INFO]\t[TRAIN] Epoch=12/50, Step=20/478, loss=0.077101, lr=0.081907, time_each_step=1.29s, eta=6:43:45\n",
      "2022-01-20 11:56:46 [INFO]\t[TRAIN] Epoch=12/50, Step=22/478, loss=0.091501, lr=0.081900, time_each_step=1.29s, eta=6:42:51\n",
      "2022-01-20 11:56:48 [INFO]\t[TRAIN] Epoch=12/50, Step=24/478, loss=0.060534, lr=0.081893, time_each_step=1.29s, eta=6:42:56\n",
      "2022-01-20 11:56:51 [INFO]\t[TRAIN] Epoch=12/50, Step=26/478, loss=0.071875, lr=0.081886, time_each_step=1.29s, eta=6:43:45\n",
      "2022-01-20 11:56:53 [INFO]\t[TRAIN] Epoch=12/50, Step=28/478, loss=0.059493, lr=0.081879, time_each_step=1.28s, eta=6:42:19\n",
      "2022-01-20 11:56:56 [INFO]\t[TRAIN] Epoch=12/50, Step=30/478, loss=0.080083, lr=0.081872, time_each_step=1.29s, eta=6:42:49\n",
      "2022-01-20 11:56:59 [INFO]\t[TRAIN] Epoch=12/50, Step=32/478, loss=0.048448, lr=0.081865, time_each_step=1.29s, eta=6:43:17\n",
      "2022-01-20 11:57:01 [INFO]\t[TRAIN] Epoch=12/50, Step=34/478, loss=0.055171, lr=0.081858, time_each_step=1.28s, eta=6:41:33\n",
      "2022-01-20 11:57:04 [INFO]\t[TRAIN] Epoch=12/50, Step=36/478, loss=0.062344, lr=0.081851, time_each_step=1.29s, eta=6:42:37\n",
      "2022-01-20 11:57:06 [INFO]\t[TRAIN] Epoch=12/50, Step=38/478, loss=0.073429, lr=0.081844, time_each_step=1.29s, eta=6:43:34\n",
      "2022-01-20 11:57:09 [INFO]\t[TRAIN] Epoch=12/50, Step=40/478, loss=0.066711, lr=0.081837, time_each_step=1.29s, eta=6:43:6\n",
      "2022-01-20 11:57:11 [INFO]\t[TRAIN] Epoch=12/50, Step=42/478, loss=0.074055, lr=0.081830, time_each_step=1.29s, eta=6:42:44\n",
      "2022-01-20 11:57:14 [INFO]\t[TRAIN] Epoch=12/50, Step=44/478, loss=0.073666, lr=0.081823, time_each_step=1.29s, eta=6:43:33\n",
      "2022-01-20 11:57:17 [INFO]\t[TRAIN] Epoch=12/50, Step=46/478, loss=0.051386, lr=0.081816, time_each_step=1.29s, eta=6:42:37\n",
      "2022-01-20 11:57:19 [INFO]\t[TRAIN] Epoch=12/50, Step=48/478, loss=0.089134, lr=0.081809, time_each_step=1.29s, eta=6:44:6\n",
      "2022-01-20 11:57:22 [INFO]\t[TRAIN] Epoch=12/50, Step=50/478, loss=0.107848, lr=0.081801, time_each_step=1.29s, eta=6:43:8\n",
      "2022-01-20 11:57:24 [INFO]\t[TRAIN] Epoch=12/50, Step=52/478, loss=0.094955, lr=0.081794, time_each_step=1.28s, eta=6:41:45\n",
      "2022-01-20 11:57:27 [INFO]\t[TRAIN] Epoch=12/50, Step=54/478, loss=0.062541, lr=0.081787, time_each_step=1.29s, eta=6:42:55\n",
      "2022-01-20 11:57:30 [INFO]\t[TRAIN] Epoch=12/50, Step=56/478, loss=0.053159, lr=0.081780, time_each_step=1.29s, eta=6:42:32\n",
      "2022-01-20 11:57:32 [INFO]\t[TRAIN] Epoch=12/50, Step=58/478, loss=0.077276, lr=0.081773, time_each_step=1.28s, eta=6:41:48\n",
      "2022-01-20 11:57:35 [INFO]\t[TRAIN] Epoch=12/50, Step=60/478, loss=0.089270, lr=0.081766, time_each_step=1.29s, eta=6:42:22\n",
      "2022-01-20 11:57:37 [INFO]\t[TRAIN] Epoch=12/50, Step=62/478, loss=0.100520, lr=0.081759, time_each_step=1.29s, eta=6:42:55\n",
      "2022-01-20 11:57:40 [INFO]\t[TRAIN] Epoch=12/50, Step=64/478, loss=0.080751, lr=0.081752, time_each_step=1.28s, eta=6:41:42\n",
      "2022-01-20 11:57:42 [INFO]\t[TRAIN] Epoch=12/50, Step=66/478, loss=0.104336, lr=0.081745, time_each_step=1.28s, eta=6:41:29\n",
      "2022-01-20 11:57:45 [INFO]\t[TRAIN] Epoch=12/50, Step=68/478, loss=0.066441, lr=0.081738, time_each_step=1.29s, eta=6:42:2\n",
      "2022-01-20 11:57:47 [INFO]\t[TRAIN] Epoch=12/50, Step=70/478, loss=0.104240, lr=0.081731, time_each_step=1.29s, eta=6:41:49\n",
      "2022-01-20 11:57:50 [INFO]\t[TRAIN] Epoch=12/50, Step=72/478, loss=0.051829, lr=0.081724, time_each_step=1.29s, eta=6:42:19\n",
      "2022-01-20 11:57:53 [INFO]\t[TRAIN] Epoch=12/50, Step=74/478, loss=0.049832, lr=0.081717, time_each_step=1.29s, eta=6:42:11\n",
      "2022-01-20 11:57:55 [INFO]\t[TRAIN] Epoch=12/50, Step=76/478, loss=0.078535, lr=0.081710, time_each_step=1.29s, eta=6:42:28\n",
      "2022-01-20 11:57:58 [INFO]\t[TRAIN] Epoch=12/50, Step=78/478, loss=0.084147, lr=0.081703, time_each_step=1.29s, eta=6:41:36\n",
      "2022-01-20 11:58:00 [INFO]\t[TRAIN] Epoch=12/50, Step=80/478, loss=0.081408, lr=0.081696, time_each_step=1.29s, eta=6:42:24\n",
      "2022-01-20 11:58:03 [INFO]\t[TRAIN] Epoch=12/50, Step=82/478, loss=0.101246, lr=0.081689, time_each_step=1.29s, eta=6:41:38\n",
      "2022-01-20 11:58:06 [INFO]\t[TRAIN] Epoch=12/50, Step=84/478, loss=0.101185, lr=0.081682, time_each_step=1.29s, eta=6:41:35\n",
      "2022-01-20 11:58:08 [INFO]\t[TRAIN] Epoch=12/50, Step=86/478, loss=0.067754, lr=0.081675, time_each_step=1.29s, eta=6:42:3\n",
      "2022-01-20 11:58:11 [INFO]\t[TRAIN] Epoch=12/50, Step=88/478, loss=0.059528, lr=0.081668, time_each_step=1.29s, eta=6:41:24\n",
      "2022-01-20 11:58:13 [INFO]\t[TRAIN] Epoch=12/50, Step=90/478, loss=0.068529, lr=0.081661, time_each_step=1.28s, eta=6:41:10\n",
      "2022-01-20 11:58:16 [INFO]\t[TRAIN] Epoch=12/50, Step=92/478, loss=0.044793, lr=0.081654, time_each_step=1.29s, eta=6:42:23\n",
      "2022-01-20 11:58:18 [INFO]\t[TRAIN] Epoch=12/50, Step=94/478, loss=0.067572, lr=0.081647, time_each_step=1.28s, eta=6:40:59\n",
      "2022-01-20 11:58:21 [INFO]\t[TRAIN] Epoch=12/50, Step=96/478, loss=0.091411, lr=0.081640, time_each_step=1.29s, eta=6:41:49\n",
      "2022-01-20 11:58:24 [INFO]\t[TRAIN] Epoch=12/50, Step=98/478, loss=0.050707, lr=0.081633, time_each_step=1.29s, eta=6:42:58\n",
      "2022-01-20 11:58:26 [INFO]\t[TRAIN] Epoch=12/50, Step=100/478, loss=0.063474, lr=0.081625, time_each_step=1.29s, eta=6:41:24\n",
      "2022-01-20 11:58:29 [INFO]\t[TRAIN] Epoch=12/50, Step=102/478, loss=0.074778, lr=0.081618, time_each_step=1.28s, eta=6:40:42\n",
      "2022-01-20 11:58:31 [INFO]\t[TRAIN] Epoch=12/50, Step=104/478, loss=0.061276, lr=0.081611, time_each_step=1.29s, eta=6:41:56\n",
      "2022-01-20 11:58:34 [INFO]\t[TRAIN] Epoch=12/50, Step=106/478, loss=0.072616, lr=0.081604, time_each_step=1.28s, eta=6:40:35\n",
      "2022-01-20 11:58:36 [INFO]\t[TRAIN] Epoch=12/50, Step=108/478, loss=0.069689, lr=0.081597, time_each_step=1.29s, eta=6:41:15\n",
      "2022-01-20 11:58:39 [INFO]\t[TRAIN] Epoch=12/50, Step=110/478, loss=0.095622, lr=0.081590, time_each_step=1.29s, eta=6:42:25\n",
      "2022-01-20 11:58:42 [INFO]\t[TRAIN] Epoch=12/50, Step=112/478, loss=0.059232, lr=0.081583, time_each_step=1.28s, eta=6:40:49\n",
      "2022-01-20 11:58:44 [INFO]\t[TRAIN] Epoch=12/50, Step=114/478, loss=0.040209, lr=0.081576, time_each_step=1.29s, eta=6:41:16\n",
      "2022-01-20 11:58:47 [INFO]\t[TRAIN] Epoch=12/50, Step=116/478, loss=0.065243, lr=0.081569, time_each_step=1.29s, eta=6:41:48\n",
      "2022-01-20 11:58:49 [INFO]\t[TRAIN] Epoch=12/50, Step=118/478, loss=0.085226, lr=0.081562, time_each_step=1.28s, eta=6:40:9\n",
      "2022-01-20 11:58:52 [INFO]\t[TRAIN] Epoch=12/50, Step=120/478, loss=0.085347, lr=0.081555, time_each_step=1.28s, eta=6:40:31\n",
      "2022-01-20 11:58:54 [INFO]\t[TRAIN] Epoch=12/50, Step=122/478, loss=0.066862, lr=0.081548, time_each_step=1.29s, eta=6:41:42\n",
      "2022-01-20 11:58:57 [INFO]\t[TRAIN] Epoch=12/50, Step=124/478, loss=0.062025, lr=0.081541, time_each_step=1.28s, eta=6:40:24\n",
      "2022-01-20 11:59:00 [INFO]\t[TRAIN] Epoch=12/50, Step=126/478, loss=0.090270, lr=0.081534, time_each_step=1.29s, eta=6:41:4\n",
      "2022-01-20 11:59:02 [INFO]\t[TRAIN] Epoch=12/50, Step=128/478, loss=0.077393, lr=0.081527, time_each_step=1.29s, eta=6:41:23\n",
      "2022-01-20 11:59:05 [INFO]\t[TRAIN] Epoch=12/50, Step=130/478, loss=0.053271, lr=0.081520, time_each_step=1.28s, eta=6:40:11\n",
      "2022-01-20 11:59:07 [INFO]\t[TRAIN] Epoch=12/50, Step=132/478, loss=0.106141, lr=0.081513, time_each_step=1.29s, eta=6:40:50\n",
      "2022-01-20 11:59:10 [INFO]\t[TRAIN] Epoch=12/50, Step=134/478, loss=0.057202, lr=0.081506, time_each_step=1.29s, eta=6:41:15\n",
      "2022-01-20 11:59:12 [INFO]\t[TRAIN] Epoch=12/50, Step=136/478, loss=0.070956, lr=0.081499, time_each_step=1.28s, eta=6:39:34\n",
      "2022-01-20 11:59:15 [INFO]\t[TRAIN] Epoch=12/50, Step=138/478, loss=0.063005, lr=0.081492, time_each_step=1.28s, eta=6:40:3\n",
      "2022-01-20 11:59:18 [INFO]\t[TRAIN] Epoch=12/50, Step=140/478, loss=0.052440, lr=0.081485, time_each_step=1.29s, eta=6:42:59\n",
      "2022-01-20 11:59:20 [INFO]\t[TRAIN] Epoch=12/50, Step=142/478, loss=0.092557, lr=0.081478, time_each_step=1.29s, eta=6:40:58\n",
      "2022-01-20 11:59:23 [INFO]\t[TRAIN] Epoch=12/50, Step=144/478, loss=0.071928, lr=0.081470, time_each_step=1.28s, eta=6:40:4\n",
      "2022-01-20 11:59:25 [INFO]\t[TRAIN] Epoch=12/50, Step=146/478, loss=0.058911, lr=0.081463, time_each_step=1.29s, eta=6:41:50\n",
      "2022-01-20 11:59:28 [INFO]\t[TRAIN] Epoch=12/50, Step=148/478, loss=0.046189, lr=0.081456, time_each_step=1.28s, eta=6:39:31\n",
      "2022-01-20 11:59:30 [INFO]\t[TRAIN] Epoch=12/50, Step=150/478, loss=0.060055, lr=0.081449, time_each_step=1.28s, eta=6:39:34\n",
      "2022-01-20 11:59:33 [INFO]\t[TRAIN] Epoch=12/50, Step=152/478, loss=0.081938, lr=0.081442, time_each_step=1.29s, eta=6:40:22\n",
      "2022-01-20 11:59:36 [INFO]\t[TRAIN] Epoch=12/50, Step=154/478, loss=0.070495, lr=0.081435, time_each_step=1.29s, eta=6:40:27\n",
      "2022-01-20 11:59:38 [INFO]\t[TRAIN] Epoch=12/50, Step=156/478, loss=0.091286, lr=0.081428, time_each_step=1.29s, eta=6:40:17\n",
      "2022-01-20 11:59:41 [INFO]\t[TRAIN] Epoch=12/50, Step=158/478, loss=0.059936, lr=0.081421, time_each_step=1.29s, eta=6:40:38\n",
      "2022-01-20 11:59:43 [INFO]\t[TRAIN] Epoch=12/50, Step=160/478, loss=0.045150, lr=0.081414, time_each_step=1.29s, eta=6:41:4\n",
      "2022-01-20 11:59:46 [INFO]\t[TRAIN] Epoch=12/50, Step=162/478, loss=0.059666, lr=0.081407, time_each_step=1.29s, eta=6:40:1\n",
      "2022-01-20 11:59:48 [INFO]\t[TRAIN] Epoch=12/50, Step=164/478, loss=0.080613, lr=0.081400, time_each_step=1.29s, eta=6:40:39\n",
      "2022-01-20 11:59:51 [INFO]\t[TRAIN] Epoch=12/50, Step=166/478, loss=0.078190, lr=0.081393, time_each_step=1.29s, eta=6:40:26\n",
      "2022-01-20 11:59:54 [INFO]\t[TRAIN] Epoch=12/50, Step=168/478, loss=0.079478, lr=0.081386, time_each_step=1.29s, eta=6:40:5\n",
      "2022-01-20 11:59:56 [INFO]\t[TRAIN] Epoch=12/50, Step=170/478, loss=0.079489, lr=0.081379, time_each_step=1.29s, eta=6:41:4\n",
      "2022-01-20 11:59:59 [INFO]\t[TRAIN] Epoch=12/50, Step=172/478, loss=0.096536, lr=0.081372, time_each_step=1.29s, eta=6:41:11\n",
      "2022-01-20 12:00:01 [INFO]\t[TRAIN] Epoch=12/50, Step=174/478, loss=0.060059, lr=0.081365, time_each_step=1.29s, eta=6:42:35\n",
      "2022-01-20 12:00:04 [INFO]\t[TRAIN] Epoch=12/50, Step=176/478, loss=0.118537, lr=0.081358, time_each_step=1.29s, eta=6:42:7\n",
      "2022-01-20 12:00:06 [INFO]\t[TRAIN] Epoch=12/50, Step=178/478, loss=0.062759, lr=0.081351, time_each_step=1.29s, eta=6:41:15\n",
      "2022-01-20 12:00:09 [INFO]\t[TRAIN] Epoch=12/50, Step=180/478, loss=0.056130, lr=0.081344, time_each_step=1.29s, eta=6:42:17\n",
      "2022-01-20 12:00:12 [INFO]\t[TRAIN] Epoch=12/50, Step=182/478, loss=0.067951, lr=0.081337, time_each_step=1.29s, eta=6:40:34\n",
      "2022-01-20 12:00:14 [INFO]\t[TRAIN] Epoch=12/50, Step=184/478, loss=0.080281, lr=0.081330, time_each_step=1.3s, eta=6:42:33\n",
      "2022-01-20 12:00:17 [INFO]\t[TRAIN] Epoch=12/50, Step=186/478, loss=0.050563, lr=0.081322, time_each_step=1.29s, eta=6:40:51\n",
      "2022-01-20 12:00:19 [INFO]\t[TRAIN] Epoch=12/50, Step=188/478, loss=0.070114, lr=0.081315, time_each_step=1.29s, eta=6:41:58\n",
      "2022-01-20 12:00:22 [INFO]\t[TRAIN] Epoch=12/50, Step=190/478, loss=0.090006, lr=0.081308, time_each_step=1.3s, eta=6:43:58\n",
      "2022-01-20 12:00:25 [INFO]\t[TRAIN] Epoch=12/50, Step=192/478, loss=0.069934, lr=0.081301, time_each_step=1.29s, eta=6:41:40\n",
      "2022-01-20 12:00:27 [INFO]\t[TRAIN] Epoch=12/50, Step=194/478, loss=0.052547, lr=0.081294, time_each_step=1.29s, eta=6:41:54\n",
      "2022-01-20 12:00:30 [INFO]\t[TRAIN] Epoch=12/50, Step=196/478, loss=0.080472, lr=0.081287, time_each_step=1.29s, eta=6:41:10\n",
      "2022-01-20 12:00:32 [INFO]\t[TRAIN] Epoch=12/50, Step=198/478, loss=0.077354, lr=0.081280, time_each_step=1.3s, eta=6:43:21\n",
      "2022-01-20 12:00:35 [INFO]\t[TRAIN] Epoch=12/50, Step=200/478, loss=0.070833, lr=0.081273, time_each_step=1.3s, eta=6:42:6\n",
      "2022-01-20 12:00:38 [INFO]\t[TRAIN] Epoch=12/50, Step=202/478, loss=0.063693, lr=0.081266, time_each_step=1.31s, eta=6:47:55\n",
      "2022-01-20 12:00:40 [INFO]\t[TRAIN] Epoch=12/50, Step=204/478, loss=0.051618, lr=0.081259, time_each_step=1.3s, eta=6:41:58\n",
      "2022-01-20 12:00:43 [INFO]\t[TRAIN] Epoch=12/50, Step=206/478, loss=0.100001, lr=0.081252, time_each_step=1.29s, eta=6:41:33\n",
      "2022-01-20 12:00:45 [INFO]\t[TRAIN] Epoch=12/50, Step=208/478, loss=0.085018, lr=0.081245, time_each_step=1.29s, eta=6:41:26\n",
      "2022-01-20 12:00:48 [INFO]\t[TRAIN] Epoch=12/50, Step=210/478, loss=0.046626, lr=0.081238, time_each_step=1.29s, eta=6:41:25\n",
      "2022-01-20 12:00:51 [INFO]\t[TRAIN] Epoch=12/50, Step=212/478, loss=0.058604, lr=0.081231, time_each_step=1.3s, eta=6:42:22\n",
      "2022-01-20 12:00:53 [INFO]\t[TRAIN] Epoch=12/50, Step=214/478, loss=0.071890, lr=0.081224, time_each_step=1.29s, eta=6:41:15\n",
      "2022-01-20 12:00:56 [INFO]\t[TRAIN] Epoch=12/50, Step=216/478, loss=0.061869, lr=0.081217, time_each_step=1.3s, eta=6:42:16\n",
      "2022-01-20 12:00:58 [INFO]\t[TRAIN] Epoch=12/50, Step=218/478, loss=0.043739, lr=0.081210, time_each_step=1.29s, eta=6:40:30\n",
      "2022-01-20 12:01:01 [INFO]\t[TRAIN] Epoch=12/50, Step=220/478, loss=0.076288, lr=0.081203, time_each_step=1.3s, eta=6:41:55\n",
      "2022-01-20 12:01:03 [INFO]\t[TRAIN] Epoch=12/50, Step=222/478, loss=0.061186, lr=0.081196, time_each_step=1.29s, eta=6:41:11\n",
      "2022-01-20 12:01:06 [INFO]\t[TRAIN] Epoch=12/50, Step=224/478, loss=0.114530, lr=0.081188, time_each_step=1.29s, eta=6:40:42\n",
      "2022-01-20 12:01:09 [INFO]\t[TRAIN] Epoch=12/50, Step=226/478, loss=0.066711, lr=0.081181, time_each_step=1.3s, eta=6:42:4\n",
      "2022-01-20 12:01:11 [INFO]\t[TRAIN] Epoch=12/50, Step=228/478, loss=0.073478, lr=0.081174, time_each_step=1.29s, eta=6:40:41\n",
      "2022-01-20 12:01:14 [INFO]\t[TRAIN] Epoch=12/50, Step=230/478, loss=0.065952, lr=0.081167, time_each_step=1.3s, eta=6:41:51\n",
      "2022-01-20 12:01:16 [INFO]\t[TRAIN] Epoch=12/50, Step=232/478, loss=0.055439, lr=0.081160, time_each_step=1.29s, eta=6:39:49\n",
      "2022-01-20 12:01:19 [INFO]\t[TRAIN] Epoch=12/50, Step=234/478, loss=0.074736, lr=0.081153, time_each_step=1.3s, eta=6:42:52\n",
      "2022-01-20 12:01:22 [INFO]\t[TRAIN] Epoch=12/50, Step=236/478, loss=0.060294, lr=0.081146, time_each_step=1.29s, eta=6:39:56\n",
      "2022-01-20 12:01:24 [INFO]\t[TRAIN] Epoch=12/50, Step=238/478, loss=0.057432, lr=0.081139, time_each_step=1.3s, eta=6:41:30\n",
      "2022-01-20 12:01:27 [INFO]\t[TRAIN] Epoch=12/50, Step=240/478, loss=0.072217, lr=0.081132, time_each_step=1.29s, eta=6:41:8\n",
      "2022-01-20 12:01:29 [INFO]\t[TRAIN] Epoch=12/50, Step=242/478, loss=0.074438, lr=0.081125, time_each_step=1.29s, eta=6:40:8\n",
      "2022-01-20 12:01:32 [INFO]\t[TRAIN] Epoch=12/50, Step=244/478, loss=0.080864, lr=0.081118, time_each_step=1.3s, eta=6:41:40\n",
      "2022-01-20 12:01:35 [INFO]\t[TRAIN] Epoch=12/50, Step=246/478, loss=0.043993, lr=0.081111, time_each_step=1.29s, eta=6:39:2\n",
      "2022-01-20 12:01:37 [INFO]\t[TRAIN] Epoch=12/50, Step=248/478, loss=0.075322, lr=0.081104, time_each_step=1.29s, eta=6:40:57\n",
      "2022-01-20 12:01:40 [INFO]\t[TRAIN] Epoch=12/50, Step=250/478, loss=0.069883, lr=0.081097, time_each_step=1.29s, eta=6:39:44\n",
      "2022-01-20 12:01:42 [INFO]\t[TRAIN] Epoch=12/50, Step=252/478, loss=0.063244, lr=0.081090, time_each_step=1.29s, eta=6:40:11\n",
      "2022-01-20 12:01:45 [INFO]\t[TRAIN] Epoch=12/50, Step=254/478, loss=0.068104, lr=0.081083, time_each_step=1.29s, eta=6:40:25\n",
      "2022-01-20 12:01:47 [INFO]\t[TRAIN] Epoch=12/50, Step=256/478, loss=0.052721, lr=0.081076, time_each_step=1.29s, eta=6:38:55\n",
      "2022-01-20 12:01:50 [INFO]\t[TRAIN] Epoch=12/50, Step=258/478, loss=0.069578, lr=0.081069, time_each_step=1.29s, eta=6:39:31\n",
      "2022-01-20 12:01:53 [INFO]\t[TRAIN] Epoch=12/50, Step=260/478, loss=0.049876, lr=0.081062, time_each_step=1.29s, eta=6:40:26\n",
      "2022-01-20 12:01:55 [INFO]\t[TRAIN] Epoch=12/50, Step=262/478, loss=0.059566, lr=0.081054, time_each_step=1.29s, eta=6:38:52\n",
      "2022-01-20 12:01:58 [INFO]\t[TRAIN] Epoch=12/50, Step=264/478, loss=0.067070, lr=0.081047, time_each_step=1.29s, eta=6:39:50\n",
      "2022-01-20 12:02:00 [INFO]\t[TRAIN] Epoch=12/50, Step=266/478, loss=0.068141, lr=0.081040, time_each_step=1.29s, eta=6:38:42\n",
      "2022-01-20 12:02:03 [INFO]\t[TRAIN] Epoch=12/50, Step=268/478, loss=0.065054, lr=0.081033, time_each_step=1.3s, eta=6:40:51\n",
      "2022-01-20 12:02:06 [INFO]\t[TRAIN] Epoch=12/50, Step=270/478, loss=0.066245, lr=0.081026, time_each_step=1.3s, eta=6:40:44\n",
      "2022-01-20 12:02:08 [INFO]\t[TRAIN] Epoch=12/50, Step=272/478, loss=0.068614, lr=0.081019, time_each_step=1.29s, eta=6:38:52\n",
      "2022-01-20 12:02:11 [INFO]\t[TRAIN] Epoch=12/50, Step=274/478, loss=0.074509, lr=0.081012, time_each_step=1.29s, eta=6:40:2\n",
      "2022-01-20 12:02:13 [INFO]\t[TRAIN] Epoch=12/50, Step=276/478, loss=0.081376, lr=0.081005, time_each_step=1.29s, eta=6:38:42\n",
      "2022-01-20 12:02:16 [INFO]\t[TRAIN] Epoch=12/50, Step=278/478, loss=0.049371, lr=0.080998, time_each_step=1.29s, eta=6:39:56\n",
      "2022-01-20 12:02:18 [INFO]\t[TRAIN] Epoch=12/50, Step=280/478, loss=0.054250, lr=0.080991, time_each_step=1.29s, eta=6:38:44\n",
      "2022-01-20 12:02:21 [INFO]\t[TRAIN] Epoch=12/50, Step=282/478, loss=0.101314, lr=0.080984, time_each_step=1.29s, eta=6:38:35\n",
      "2022-01-20 12:02:24 [INFO]\t[TRAIN] Epoch=12/50, Step=284/478, loss=0.083828, lr=0.080977, time_each_step=1.29s, eta=6:39:52\n",
      "2022-01-20 12:02:26 [INFO]\t[TRAIN] Epoch=12/50, Step=286/478, loss=0.054588, lr=0.080970, time_each_step=1.29s, eta=6:38:3\n",
      "2022-01-20 12:02:29 [INFO]\t[TRAIN] Epoch=12/50, Step=288/478, loss=0.061602, lr=0.080963, time_each_step=1.29s, eta=6:39:16\n",
      "2022-01-20 12:02:31 [INFO]\t[TRAIN] Epoch=12/50, Step=290/478, loss=0.101644, lr=0.080956, time_each_step=1.29s, eta=6:38:48\n",
      "2022-01-20 12:02:34 [INFO]\t[TRAIN] Epoch=12/50, Step=292/478, loss=0.075051, lr=0.080949, time_each_step=1.29s, eta=6:38:27\n",
      "2022-01-20 12:02:37 [INFO]\t[TRAIN] Epoch=12/50, Step=294/478, loss=0.064255, lr=0.080942, time_each_step=1.29s, eta=6:39:4\n",
      "2022-01-20 12:02:39 [INFO]\t[TRAIN] Epoch=12/50, Step=296/478, loss=0.059354, lr=0.080935, time_each_step=1.29s, eta=6:37:51\n",
      "2022-01-20 12:02:42 [INFO]\t[TRAIN] Epoch=12/50, Step=298/478, loss=0.066417, lr=0.080927, time_each_step=1.29s, eta=6:37:19\n",
      "2022-01-20 12:02:44 [INFO]\t[TRAIN] Epoch=12/50, Step=300/478, loss=0.088040, lr=0.080920, time_each_step=1.29s, eta=6:37:54\n",
      "2022-01-20 12:02:47 [INFO]\t[TRAIN] Epoch=12/50, Step=302/478, loss=0.075671, lr=0.080913, time_each_step=1.29s, eta=6:37:24\n",
      "2022-01-20 12:02:49 [INFO]\t[TRAIN] Epoch=12/50, Step=304/478, loss=0.080537, lr=0.080906, time_each_step=1.29s, eta=6:37:25\n",
      "2022-01-20 12:02:52 [INFO]\t[TRAIN] Epoch=12/50, Step=306/478, loss=0.070289, lr=0.080899, time_each_step=1.29s, eta=6:37:51\n",
      "2022-01-20 12:02:55 [INFO]\t[TRAIN] Epoch=12/50, Step=308/478, loss=0.053019, lr=0.080892, time_each_step=1.29s, eta=6:36:53\n",
      "2022-01-20 12:02:57 [INFO]\t[TRAIN] Epoch=12/50, Step=310/478, loss=0.073332, lr=0.080885, time_each_step=1.29s, eta=6:36:59\n",
      "2022-01-20 12:03:00 [INFO]\t[TRAIN] Epoch=12/50, Step=312/478, loss=0.066939, lr=0.080878, time_each_step=1.29s, eta=6:38:20\n",
      "2022-01-20 12:03:02 [INFO]\t[TRAIN] Epoch=12/50, Step=314/478, loss=0.090087, lr=0.080871, time_each_step=1.28s, eta=6:36:4\n",
      "2022-01-20 12:03:05 [INFO]\t[TRAIN] Epoch=12/50, Step=316/478, loss=0.043646, lr=0.080864, time_each_step=1.29s, eta=6:37:43\n",
      "2022-01-20 12:03:07 [INFO]\t[TRAIN] Epoch=12/50, Step=318/478, loss=0.069767, lr=0.080857, time_each_step=1.29s, eta=6:38:54\n",
      "2022-01-20 12:03:10 [INFO]\t[TRAIN] Epoch=12/50, Step=320/478, loss=0.071548, lr=0.080850, time_each_step=1.29s, eta=6:38:15\n",
      "2022-01-20 12:03:13 [INFO]\t[TRAIN] Epoch=12/50, Step=322/478, loss=0.084691, lr=0.080843, time_each_step=1.29s, eta=6:38:22\n",
      "2022-01-20 12:03:15 [INFO]\t[TRAIN] Epoch=12/50, Step=324/478, loss=0.065039, lr=0.080836, time_each_step=1.29s, eta=6:39:19\n",
      "2022-01-20 12:03:18 [INFO]\t[TRAIN] Epoch=12/50, Step=326/478, loss=0.100704, lr=0.080829, time_each_step=1.29s, eta=6:37:40\n",
      "2022-01-20 12:03:20 [INFO]\t[TRAIN] Epoch=12/50, Step=328/478, loss=0.084646, lr=0.080822, time_each_step=1.29s, eta=6:38:48\n",
      "2022-01-20 12:03:23 [INFO]\t[TRAIN] Epoch=12/50, Step=330/478, loss=0.052852, lr=0.080814, time_each_step=1.29s, eta=6:37:22\n",
      "2022-01-20 12:03:26 [INFO]\t[TRAIN] Epoch=12/50, Step=332/478, loss=0.100544, lr=0.080807, time_each_step=1.29s, eta=6:37:48\n",
      "2022-01-20 12:03:28 [INFO]\t[TRAIN] Epoch=12/50, Step=334/478, loss=0.079094, lr=0.080800, time_each_step=1.29s, eta=6:37:25\n",
      "2022-01-20 12:03:31 [INFO]\t[TRAIN] Epoch=12/50, Step=336/478, loss=0.068324, lr=0.080793, time_each_step=1.29s, eta=6:38:12\n",
      "2022-01-20 12:03:33 [INFO]\t[TRAIN] Epoch=12/50, Step=338/478, loss=0.055559, lr=0.080786, time_each_step=1.3s, eta=6:39:18\n",
      "2022-01-20 12:03:36 [INFO]\t[TRAIN] Epoch=12/50, Step=340/478, loss=0.066039, lr=0.080779, time_each_step=1.29s, eta=6:37:57\n",
      "2022-01-20 12:03:38 [INFO]\t[TRAIN] Epoch=12/50, Step=342/478, loss=0.074068, lr=0.080772, time_each_step=1.29s, eta=6:37:29\n",
      "2022-01-20 12:03:41 [INFO]\t[TRAIN] Epoch=12/50, Step=344/478, loss=0.073075, lr=0.080765, time_each_step=1.29s, eta=6:37:22\n",
      "2022-01-20 12:03:44 [INFO]\t[TRAIN] Epoch=12/50, Step=346/478, loss=0.063296, lr=0.080758, time_each_step=1.29s, eta=6:36:24\n",
      "2022-01-20 12:03:46 [INFO]\t[TRAIN] Epoch=12/50, Step=348/478, loss=0.081414, lr=0.080751, time_each_step=1.3s, eta=6:38:57\n",
      "2022-01-20 12:03:49 [INFO]\t[TRAIN] Epoch=12/50, Step=350/478, loss=0.076482, lr=0.080744, time_each_step=1.29s, eta=6:37:59\n",
      "2022-01-20 12:03:51 [INFO]\t[TRAIN] Epoch=12/50, Step=352/478, loss=0.098795, lr=0.080737, time_each_step=1.29s, eta=6:37:6\n",
      "2022-01-20 12:03:54 [INFO]\t[TRAIN] Epoch=12/50, Step=354/478, loss=0.076257, lr=0.080730, time_each_step=1.29s, eta=6:36:39\n",
      "2022-01-20 12:03:57 [INFO]\t[TRAIN] Epoch=12/50, Step=356/478, loss=0.063573, lr=0.080723, time_each_step=1.29s, eta=6:37:37\n",
      "2022-01-20 12:03:59 [INFO]\t[TRAIN] Epoch=12/50, Step=358/478, loss=0.062182, lr=0.080716, time_each_step=1.29s, eta=6:37:23\n",
      "2022-01-20 12:04:02 [INFO]\t[TRAIN] Epoch=12/50, Step=360/478, loss=0.075705, lr=0.080709, time_each_step=1.29s, eta=6:35:50\n",
      "2022-01-20 12:04:04 [INFO]\t[TRAIN] Epoch=12/50, Step=362/478, loss=0.082064, lr=0.080702, time_each_step=1.29s, eta=6:36:42\n",
      "2022-01-20 12:04:07 [INFO]\t[TRAIN] Epoch=12/50, Step=364/478, loss=0.057940, lr=0.080694, time_each_step=1.29s, eta=6:37:0\n",
      "2022-01-20 12:04:09 [INFO]\t[TRAIN] Epoch=12/50, Step=366/478, loss=0.049283, lr=0.080687, time_each_step=1.28s, eta=6:35:22\n",
      "2022-01-20 12:04:12 [INFO]\t[TRAIN] Epoch=12/50, Step=368/478, loss=0.089330, lr=0.080680, time_each_step=1.29s, eta=6:36:25\n",
      "2022-01-20 12:04:15 [INFO]\t[TRAIN] Epoch=12/50, Step=370/478, loss=0.093000, lr=0.080673, time_each_step=1.29s, eta=6:37:39\n",
      "2022-01-20 12:04:17 [INFO]\t[TRAIN] Epoch=12/50, Step=372/478, loss=0.089273, lr=0.080666, time_each_step=1.29s, eta=6:35:54\n",
      "2022-01-20 12:04:20 [INFO]\t[TRAIN] Epoch=12/50, Step=374/478, loss=0.070316, lr=0.080659, time_each_step=1.3s, eta=6:40:21\n",
      "2022-01-20 12:04:22 [INFO]\t[TRAIN] Epoch=12/50, Step=376/478, loss=0.060185, lr=0.080652, time_each_step=1.29s, eta=6:35:58\n",
      "2022-01-20 12:04:25 [INFO]\t[TRAIN] Epoch=12/50, Step=378/478, loss=0.089358, lr=0.080645, time_each_step=1.29s, eta=6:35:32\n",
      "2022-01-20 12:04:27 [INFO]\t[TRAIN] Epoch=12/50, Step=380/478, loss=0.052060, lr=0.080638, time_each_step=1.29s, eta=6:36:5\n",
      "2022-01-20 12:04:30 [INFO]\t[TRAIN] Epoch=12/50, Step=382/478, loss=0.070370, lr=0.080631, time_each_step=1.29s, eta=6:35:17\n",
      "2022-01-20 12:04:33 [INFO]\t[TRAIN] Epoch=12/50, Step=384/478, loss=0.060921, lr=0.080624, time_each_step=1.28s, eta=6:34:55\n",
      "2022-01-20 12:04:35 [INFO]\t[TRAIN] Epoch=12/50, Step=386/478, loss=0.064586, lr=0.080617, time_each_step=1.29s, eta=6:36:19\n",
      "2022-01-20 12:04:38 [INFO]\t[TRAIN] Epoch=12/50, Step=388/478, loss=0.058923, lr=0.080610, time_each_step=1.29s, eta=6:36:2\n",
      "2022-01-20 12:04:40 [INFO]\t[TRAIN] Epoch=12/50, Step=390/478, loss=0.062636, lr=0.080603, time_each_step=1.29s, eta=6:37:46\n",
      "2022-01-20 12:04:43 [INFO]\t[TRAIN] Epoch=12/50, Step=392/478, loss=0.058476, lr=0.080596, time_each_step=1.29s, eta=6:36:21\n",
      "2022-01-20 12:04:46 [INFO]\t[TRAIN] Epoch=12/50, Step=394/478, loss=0.061208, lr=0.080588, time_each_step=1.29s, eta=6:36:18\n",
      "2022-01-20 12:04:48 [INFO]\t[TRAIN] Epoch=12/50, Step=396/478, loss=0.065659, lr=0.080581, time_each_step=1.29s, eta=6:36:6\n",
      "2022-01-20 12:04:51 [INFO]\t[TRAIN] Epoch=12/50, Step=398/478, loss=0.041700, lr=0.080574, time_each_step=1.29s, eta=6:35:56\n",
      "2022-01-20 12:04:53 [INFO]\t[TRAIN] Epoch=12/50, Step=400/478, loss=0.068848, lr=0.080567, time_each_step=1.29s, eta=6:35:28\n",
      "2022-01-20 12:04:56 [INFO]\t[TRAIN] Epoch=12/50, Step=402/478, loss=0.063175, lr=0.080560, time_each_step=1.29s, eta=6:36:24\n",
      "2022-01-20 12:04:58 [INFO]\t[TRAIN] Epoch=12/50, Step=404/478, loss=0.053392, lr=0.080553, time_each_step=1.29s, eta=6:35:12\n",
      "2022-01-20 12:05:01 [INFO]\t[TRAIN] Epoch=12/50, Step=406/478, loss=0.062875, lr=0.080546, time_each_step=1.29s, eta=6:35:7\n",
      "2022-01-20 12:05:04 [INFO]\t[TRAIN] Epoch=12/50, Step=408/478, loss=0.051415, lr=0.080539, time_each_step=1.29s, eta=6:35:41\n",
      "2022-01-20 12:05:06 [INFO]\t[TRAIN] Epoch=12/50, Step=410/478, loss=0.043451, lr=0.080532, time_each_step=1.29s, eta=6:35:4\n",
      "2022-01-20 12:05:09 [INFO]\t[TRAIN] Epoch=12/50, Step=412/478, loss=0.075979, lr=0.080525, time_each_step=1.29s, eta=6:35:11\n",
      "2022-01-20 12:05:11 [INFO]\t[TRAIN] Epoch=12/50, Step=414/478, loss=0.075020, lr=0.080518, time_each_step=1.29s, eta=6:35:55\n",
      "2022-01-20 12:05:14 [INFO]\t[TRAIN] Epoch=12/50, Step=416/478, loss=0.056435, lr=0.080511, time_each_step=1.29s, eta=6:34:45\n",
      "2022-01-20 12:05:16 [INFO]\t[TRAIN] Epoch=12/50, Step=418/478, loss=0.076886, lr=0.080504, time_each_step=1.29s, eta=6:35:16\n",
      "2022-01-20 12:05:19 [INFO]\t[TRAIN] Epoch=12/50, Step=420/478, loss=0.079699, lr=0.080497, time_each_step=1.29s, eta=6:36:22\n",
      "2022-01-20 12:05:22 [INFO]\t[TRAIN] Epoch=12/50, Step=422/478, loss=0.070670, lr=0.080490, time_each_step=1.29s, eta=6:35:5\n",
      "2022-01-20 12:05:24 [INFO]\t[TRAIN] Epoch=12/50, Step=424/478, loss=0.060664, lr=0.080482, time_each_step=1.29s, eta=6:36:44\n",
      "2022-01-20 12:05:27 [INFO]\t[TRAIN] Epoch=12/50, Step=426/478, loss=0.050836, lr=0.080475, time_each_step=1.29s, eta=6:35:2\n",
      "2022-01-20 12:05:29 [INFO]\t[TRAIN] Epoch=12/50, Step=428/478, loss=0.057784, lr=0.080468, time_each_step=1.29s, eta=6:35:7\n",
      "2022-01-20 12:05:32 [INFO]\t[TRAIN] Epoch=12/50, Step=430/478, loss=0.063496, lr=0.080461, time_each_step=1.29s, eta=6:35:33\n",
      "2022-01-20 12:05:34 [INFO]\t[TRAIN] Epoch=12/50, Step=432/478, loss=0.082152, lr=0.080454, time_each_step=1.29s, eta=6:34:45\n",
      "2022-01-20 12:05:37 [INFO]\t[TRAIN] Epoch=12/50, Step=434/478, loss=0.070632, lr=0.080447, time_each_step=1.29s, eta=6:36:35\n",
      "2022-01-20 12:05:40 [INFO]\t[TRAIN] Epoch=12/50, Step=436/478, loss=0.059349, lr=0.080440, time_each_step=1.29s, eta=6:35:43\n",
      "2022-01-20 12:05:42 [INFO]\t[TRAIN] Epoch=12/50, Step=438/478, loss=0.067553, lr=0.080433, time_each_step=1.29s, eta=6:34:26\n",
      "2022-01-20 12:05:45 [INFO]\t[TRAIN] Epoch=12/50, Step=440/478, loss=0.071402, lr=0.080426, time_each_step=1.29s, eta=6:35:54\n",
      "2022-01-20 12:05:47 [INFO]\t[TRAIN] Epoch=12/50, Step=442/478, loss=0.053892, lr=0.080419, time_each_step=1.29s, eta=6:34:23\n",
      "2022-01-20 12:05:50 [INFO]\t[TRAIN] Epoch=12/50, Step=444/478, loss=0.082624, lr=0.080412, time_each_step=1.29s, eta=6:34:22\n",
      "2022-01-20 12:05:53 [INFO]\t[TRAIN] Epoch=12/50, Step=446/478, loss=0.081450, lr=0.080405, time_each_step=1.29s, eta=6:34:58\n",
      "2022-01-20 12:05:55 [INFO]\t[TRAIN] Epoch=12/50, Step=448/478, loss=0.046613, lr=0.080398, time_each_step=1.29s, eta=6:33:59\n",
      "2022-01-20 12:05:58 [INFO]\t[TRAIN] Epoch=12/50, Step=450/478, loss=0.066977, lr=0.080391, time_each_step=1.29s, eta=6:34:15\n",
      "2022-01-20 12:06:00 [INFO]\t[TRAIN] Epoch=12/50, Step=452/478, loss=0.073694, lr=0.080384, time_each_step=1.29s, eta=6:35:17\n",
      "2022-01-20 12:06:03 [INFO]\t[TRAIN] Epoch=12/50, Step=454/478, loss=0.064119, lr=0.080376, time_each_step=1.29s, eta=6:33:46\n",
      "2022-01-20 12:06:05 [INFO]\t[TRAIN] Epoch=12/50, Step=456/478, loss=0.077561, lr=0.080369, time_each_step=1.29s, eta=6:35:52\n",
      "2022-01-20 12:06:08 [INFO]\t[TRAIN] Epoch=12/50, Step=458/478, loss=0.047969, lr=0.080362, time_each_step=1.29s, eta=6:34:57\n",
      "2022-01-20 12:06:11 [INFO]\t[TRAIN] Epoch=12/50, Step=460/478, loss=0.048842, lr=0.080355, time_each_step=1.29s, eta=6:34:57\n",
      "2022-01-20 12:06:13 [INFO]\t[TRAIN] Epoch=12/50, Step=462/478, loss=0.044862, lr=0.080348, time_each_step=1.29s, eta=6:34:40\n",
      "2022-01-20 12:06:16 [INFO]\t[TRAIN] Epoch=12/50, Step=464/478, loss=0.067908, lr=0.080341, time_each_step=1.29s, eta=6:34:7\n",
      "2022-01-20 12:06:18 [INFO]\t[TRAIN] Epoch=12/50, Step=466/478, loss=0.067483, lr=0.080334, time_each_step=1.29s, eta=6:34:6\n",
      "2022-01-20 12:06:21 [INFO]\t[TRAIN] Epoch=12/50, Step=468/478, loss=0.069456, lr=0.080327, time_each_step=1.29s, eta=6:33:58\n",
      "2022-01-20 12:06:23 [INFO]\t[TRAIN] Epoch=12/50, Step=470/478, loss=0.059108, lr=0.080320, time_each_step=1.29s, eta=6:33:48\n",
      "2022-01-20 12:06:26 [INFO]\t[TRAIN] Epoch=12/50, Step=472/478, loss=0.049990, lr=0.080313, time_each_step=1.29s, eta=6:33:51\n",
      "2022-01-20 12:06:29 [INFO]\t[TRAIN] Epoch=12/50, Step=474/478, loss=0.056858, lr=0.080306, time_each_step=1.29s, eta=6:34:13\n",
      "2022-01-20 12:06:31 [INFO]\t[TRAIN] Epoch=12/50, Step=476/478, loss=0.100826, lr=0.080299, time_each_step=1.28s, eta=6:32:38\n",
      "2022-01-20 12:06:34 [INFO]\t[TRAIN] Epoch=12/50, Step=478/478, loss=0.072751, lr=0.080292, time_each_step=1.29s, eta=6:33:26\n",
      "2022-01-20 12:06:34 [INFO]\t[TRAIN] Epoch 12 finished, loss=0.07013227 .\n",
      "2022-01-20 12:06:34 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-01-20 12:06:34 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-01-20 12:06:40 [INFO]\t[EVAL] Finished, Epoch=12, miou=0.830981, category_iou=[0.9696481  0.73882693 0.7844687 ], oacc=0.971807, category_acc=[0.98678   0.8452222 0.8619784], kappa=0.864224, category_F1-score=[0.98459015 0.84979927 0.87921823] .\n",
      "2022-01-20 12:06:40 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_6, miou=0.8331509232521057\n",
      "2022-01-20 12:06:41 [INFO]\tModel saved in model/deeplab_augument_alldata2/epoch_12.\n",
      "2022-01-20 12:06:45 [INFO]\t[TRAIN] Epoch=13/50, Step=2/478, loss=0.046327, lr=0.080285, time_each_step=1.95s, eta=9:55:37\n",
      "2022-01-20 12:06:47 [INFO]\t[TRAIN] Epoch=13/50, Step=4/478, loss=0.046368, lr=0.080277, time_each_step=1.29s, eta=6:33:47\n",
      "2022-01-20 12:06:50 [INFO]\t[TRAIN] Epoch=13/50, Step=6/478, loss=0.061687, lr=0.080270, time_each_step=1.29s, eta=6:33:35\n",
      "2022-01-20 12:06:53 [INFO]\t[TRAIN] Epoch=13/50, Step=8/478, loss=0.068632, lr=0.080263, time_each_step=1.29s, eta=6:34:21\n",
      "2022-01-20 12:06:55 [INFO]\t[TRAIN] Epoch=13/50, Step=10/478, loss=0.064780, lr=0.080256, time_each_step=1.29s, eta=6:33:18\n",
      "2022-01-20 12:06:58 [INFO]\t[TRAIN] Epoch=13/50, Step=12/478, loss=0.059144, lr=0.080249, time_each_step=1.29s, eta=6:33:24\n",
      "2022-01-20 12:07:00 [INFO]\t[TRAIN] Epoch=13/50, Step=14/478, loss=0.063586, lr=0.080242, time_each_step=1.29s, eta=6:34:19\n",
      "2022-01-20 12:07:03 [INFO]\t[TRAIN] Epoch=13/50, Step=16/478, loss=0.066025, lr=0.080235, time_each_step=1.29s, eta=6:33:7\n",
      "2022-01-20 12:07:05 [INFO]\t[TRAIN] Epoch=13/50, Step=18/478, loss=0.070171, lr=0.080228, time_each_step=1.29s, eta=6:32:51\n",
      "2022-01-20 12:07:08 [INFO]\t[TRAIN] Epoch=13/50, Step=20/478, loss=0.103727, lr=0.080221, time_each_step=1.29s, eta=6:33:28\n",
      "2022-01-20 12:07:11 [INFO]\t[TRAIN] Epoch=13/50, Step=22/478, loss=0.047661, lr=0.080214, time_each_step=1.29s, eta=6:33:6\n",
      "2022-01-20 12:07:13 [INFO]\t[TRAIN] Epoch=13/50, Step=24/478, loss=0.055833, lr=0.080207, time_each_step=1.28s, eta=6:32:13\n",
      "2022-01-20 12:07:16 [INFO]\t[TRAIN] Epoch=13/50, Step=26/478, loss=0.084308, lr=0.080200, time_each_step=1.29s, eta=6:33:4\n",
      "2022-01-20 12:07:18 [INFO]\t[TRAIN] Epoch=13/50, Step=28/478, loss=0.055114, lr=0.080193, time_each_step=1.29s, eta=6:34:14\n",
      "2022-01-20 12:07:21 [INFO]\t[TRAIN] Epoch=13/50, Step=30/478, loss=0.071033, lr=0.080185, time_each_step=1.29s, eta=6:32:54\n",
      "2022-01-20 12:07:23 [INFO]\t[TRAIN] Epoch=13/50, Step=32/478, loss=0.069634, lr=0.080178, time_each_step=1.29s, eta=6:33:20\n",
      "2022-01-20 12:07:26 [INFO]\t[TRAIN] Epoch=13/50, Step=34/478, loss=0.057828, lr=0.080171, time_each_step=1.29s, eta=6:32:31\n",
      "2022-01-20 12:07:29 [INFO]\t[TRAIN] Epoch=13/50, Step=36/478, loss=0.053129, lr=0.080164, time_each_step=1.29s, eta=6:32:39\n",
      "2022-01-20 12:07:31 [INFO]\t[TRAIN] Epoch=13/50, Step=38/478, loss=0.067474, lr=0.080157, time_each_step=1.29s, eta=6:32:59\n",
      "2022-01-20 12:07:34 [INFO]\t[TRAIN] Epoch=13/50, Step=40/478, loss=0.086708, lr=0.080150, time_each_step=1.28s, eta=6:31:31\n",
      "2022-01-20 12:07:36 [INFO]\t[TRAIN] Epoch=13/50, Step=42/478, loss=0.048319, lr=0.080143, time_each_step=1.29s, eta=6:32:11\n",
      "2022-01-20 12:07:39 [INFO]\t[TRAIN] Epoch=13/50, Step=44/478, loss=0.078495, lr=0.080136, time_each_step=1.29s, eta=6:32:29\n",
      "2022-01-20 12:07:41 [INFO]\t[TRAIN] Epoch=13/50, Step=46/478, loss=0.073275, lr=0.080129, time_each_step=1.29s, eta=6:32:15\n",
      "2022-01-20 12:07:44 [INFO]\t[TRAIN] Epoch=13/50, Step=48/478, loss=0.057604, lr=0.080122, time_each_step=1.28s, eta=6:31:45\n",
      "2022-01-20 12:07:47 [INFO]\t[TRAIN] Epoch=13/50, Step=50/478, loss=0.068866, lr=0.080115, time_each_step=1.29s, eta=6:33:3\n",
      "2022-01-20 12:07:49 [INFO]\t[TRAIN] Epoch=13/50, Step=52/478, loss=0.066934, lr=0.080108, time_each_step=1.29s, eta=6:32:10\n",
      "2022-01-20 12:07:52 [INFO]\t[TRAIN] Epoch=13/50, Step=54/478, loss=0.051226, lr=0.080101, time_each_step=1.29s, eta=6:32:9\n",
      "2022-01-20 12:07:54 [INFO]\t[TRAIN] Epoch=13/50, Step=56/478, loss=0.081929, lr=0.080093, time_each_step=1.29s, eta=6:32:50\n",
      "2022-01-20 12:07:57 [INFO]\t[TRAIN] Epoch=13/50, Step=58/478, loss=0.068318, lr=0.080086, time_each_step=1.29s, eta=6:31:59\n",
      "2022-01-20 12:07:59 [INFO]\t[TRAIN] Epoch=13/50, Step=60/478, loss=0.053177, lr=0.080079, time_each_step=1.29s, eta=6:32:10\n",
      "2022-01-20 12:08:02 [INFO]\t[TRAIN] Epoch=13/50, Step=62/478, loss=0.087588, lr=0.080072, time_each_step=1.29s, eta=6:32:16\n",
      "2022-01-20 12:08:05 [INFO]\t[TRAIN] Epoch=13/50, Step=64/478, loss=0.052300, lr=0.080065, time_each_step=1.29s, eta=6:31:39\n",
      "2022-01-20 12:08:07 [INFO]\t[TRAIN] Epoch=13/50, Step=66/478, loss=0.082542, lr=0.080058, time_each_step=1.28s, eta=6:31:25\n",
      "2022-01-20 12:08:10 [INFO]\t[TRAIN] Epoch=13/50, Step=68/478, loss=0.055906, lr=0.080051, time_each_step=1.29s, eta=6:31:44\n",
      "2022-01-20 12:08:12 [INFO]\t[TRAIN] Epoch=13/50, Step=70/478, loss=0.057903, lr=0.080044, time_each_step=1.29s, eta=6:31:37\n",
      "2022-01-20 12:08:15 [INFO]\t[TRAIN] Epoch=13/50, Step=72/478, loss=0.096697, lr=0.080037, time_each_step=1.28s, eta=6:31:8\n",
      "2022-01-20 12:08:17 [INFO]\t[TRAIN] Epoch=13/50, Step=74/478, loss=0.052746, lr=0.080030, time_each_step=1.29s, eta=6:32:29\n",
      "2022-01-20 12:08:20 [INFO]\t[TRAIN] Epoch=13/50, Step=76/478, loss=0.052858, lr=0.080023, time_each_step=1.29s, eta=6:31:44\n",
      "2022-01-20 12:08:23 [INFO]\t[TRAIN] Epoch=13/50, Step=78/478, loss=0.067673, lr=0.080016, time_each_step=1.29s, eta=6:31:57\n",
      "2022-01-20 12:08:25 [INFO]\t[TRAIN] Epoch=13/50, Step=80/478, loss=0.069389, lr=0.080009, time_each_step=1.29s, eta=6:31:38\n",
      "2022-01-20 12:08:28 [INFO]\t[TRAIN] Epoch=13/50, Step=82/478, loss=0.066940, lr=0.080001, time_each_step=1.29s, eta=6:31:18\n",
      "2022-01-20 12:08:30 [INFO]\t[TRAIN] Epoch=13/50, Step=84/478, loss=0.052511, lr=0.079994, time_each_step=1.28s, eta=6:30:44\n",
      "2022-01-20 12:08:33 [INFO]\t[TRAIN] Epoch=13/50, Step=86/478, loss=0.106599, lr=0.079987, time_each_step=1.29s, eta=6:31:43\n",
      "2022-01-20 12:08:36 [INFO]\t[TRAIN] Epoch=13/50, Step=88/478, loss=0.078456, lr=0.079980, time_each_step=1.29s, eta=6:31:52\n",
      "2022-01-20 12:08:38 [INFO]\t[TRAIN] Epoch=13/50, Step=90/478, loss=0.062183, lr=0.079973, time_each_step=1.29s, eta=6:31:38\n",
      "2022-01-20 12:08:41 [INFO]\t[TRAIN] Epoch=13/50, Step=92/478, loss=0.066430, lr=0.079966, time_each_step=1.29s, eta=6:32:27\n",
      "2022-01-20 12:08:43 [INFO]\t[TRAIN] Epoch=13/50, Step=94/478, loss=0.070205, lr=0.079959, time_each_step=1.28s, eta=6:30:27\n",
      "2022-01-20 12:08:46 [INFO]\t[TRAIN] Epoch=13/50, Step=96/478, loss=0.105354, lr=0.079952, time_each_step=1.29s, eta=6:31:39\n",
      "2022-01-20 12:08:48 [INFO]\t[TRAIN] Epoch=13/50, Step=98/478, loss=0.085531, lr=0.079945, time_each_step=1.29s, eta=6:31:6\n",
      "2022-01-20 12:08:51 [INFO]\t[TRAIN] Epoch=13/50, Step=100/478, loss=0.058917, lr=0.079938, time_each_step=1.29s, eta=6:31:23\n",
      "2022-01-20 12:08:54 [INFO]\t[TRAIN] Epoch=13/50, Step=102/478, loss=0.099631, lr=0.079931, time_each_step=1.28s, eta=6:30:44\n",
      "2022-01-20 12:08:56 [INFO]\t[TRAIN] Epoch=13/50, Step=104/478, loss=0.070503, lr=0.079924, time_each_step=1.29s, eta=6:31:36\n",
      "2022-01-20 12:08:59 [INFO]\t[TRAIN] Epoch=13/50, Step=106/478, loss=0.070448, lr=0.079917, time_each_step=1.29s, eta=6:31:8\n",
      "2022-01-20 12:09:01 [INFO]\t[TRAIN] Epoch=13/50, Step=108/478, loss=0.075923, lr=0.079909, time_each_step=1.29s, eta=6:30:55\n",
      "2022-01-20 12:09:04 [INFO]\t[TRAIN] Epoch=13/50, Step=110/478, loss=0.060185, lr=0.079902, time_each_step=1.29s, eta=6:31:23\n",
      "2022-01-20 12:09:06 [INFO]\t[TRAIN] Epoch=13/50, Step=112/478, loss=0.062969, lr=0.079895, time_each_step=1.28s, eta=6:30:32\n",
      "2022-01-20 12:09:09 [INFO]\t[TRAIN] Epoch=13/50, Step=114/478, loss=0.097174, lr=0.079888, time_each_step=1.29s, eta=6:31:2\n",
      "2022-01-20 12:09:12 [INFO]\t[TRAIN] Epoch=13/50, Step=116/478, loss=0.085290, lr=0.079881, time_each_step=1.29s, eta=6:31:21\n",
      "2022-01-20 12:09:14 [INFO]\t[TRAIN] Epoch=13/50, Step=118/478, loss=0.073828, lr=0.079874, time_each_step=1.29s, eta=6:30:46\n",
      "2022-01-20 12:09:17 [INFO]\t[TRAIN] Epoch=13/50, Step=120/478, loss=0.054982, lr=0.079867, time_each_step=1.29s, eta=6:30:39\n",
      "2022-01-20 12:09:19 [INFO]\t[TRAIN] Epoch=13/50, Step=122/478, loss=0.079148, lr=0.079860, time_each_step=1.29s, eta=6:31:18\n",
      "2022-01-20 12:09:22 [INFO]\t[TRAIN] Epoch=13/50, Step=124/478, loss=0.061089, lr=0.079853, time_each_step=1.28s, eta=6:30:3\n",
      "2022-01-20 12:09:24 [INFO]\t[TRAIN] Epoch=13/50, Step=126/478, loss=0.082323, lr=0.079846, time_each_step=1.29s, eta=6:30:44\n",
      "2022-01-20 12:09:27 [INFO]\t[TRAIN] Epoch=13/50, Step=128/478, loss=0.051970, lr=0.079839, time_each_step=1.29s, eta=6:30:17\n",
      "2022-01-20 12:09:30 [INFO]\t[TRAIN] Epoch=13/50, Step=130/478, loss=0.047405, lr=0.079832, time_each_step=1.28s, eta=6:30:3\n",
      "2022-01-20 12:09:32 [INFO]\t[TRAIN] Epoch=13/50, Step=132/478, loss=0.076237, lr=0.079824, time_each_step=1.29s, eta=6:30:57\n",
      "2022-01-20 12:09:35 [INFO]\t[TRAIN] Epoch=13/50, Step=134/478, loss=0.071140, lr=0.079817, time_each_step=1.29s, eta=6:31:30\n",
      "2022-01-20 12:09:37 [INFO]\t[TRAIN] Epoch=13/50, Step=136/478, loss=0.070853, lr=0.079810, time_each_step=1.29s, eta=6:30:25\n",
      "2022-01-20 12:09:40 [INFO]\t[TRAIN] Epoch=13/50, Step=138/478, loss=0.089107, lr=0.079803, time_each_step=1.29s, eta=6:30:50\n",
      "2022-01-20 12:09:42 [INFO]\t[TRAIN] Epoch=13/50, Step=140/478, loss=0.085642, lr=0.079796, time_each_step=1.29s, eta=6:30:53\n",
      "2022-01-20 12:09:45 [INFO]\t[TRAIN] Epoch=13/50, Step=142/478, loss=0.049087, lr=0.079789, time_each_step=1.29s, eta=6:30:19\n",
      "2022-01-20 12:09:48 [INFO]\t[TRAIN] Epoch=13/50, Step=144/478, loss=0.063509, lr=0.079782, time_each_step=1.29s, eta=6:30:13\n",
      "2022-01-20 12:09:50 [INFO]\t[TRAIN] Epoch=13/50, Step=146/478, loss=0.062699, lr=0.079775, time_each_step=1.29s, eta=6:30:24\n",
      "2022-01-20 12:09:53 [INFO]\t[TRAIN] Epoch=13/50, Step=148/478, loss=0.043338, lr=0.079768, time_each_step=1.29s, eta=6:30:17\n",
      "2022-01-20 12:09:55 [INFO]\t[TRAIN] Epoch=13/50, Step=150/478, loss=0.053937, lr=0.079761, time_each_step=1.28s, eta=6:29:16\n",
      "2022-01-20 12:09:58 [INFO]\t[TRAIN] Epoch=13/50, Step=152/478, loss=0.058025, lr=0.079754, time_each_step=1.29s, eta=6:29:52\n",
      "2022-01-20 12:10:00 [INFO]\t[TRAIN] Epoch=13/50, Step=154/478, loss=0.058148, lr=0.079747, time_each_step=1.28s, eta=6:29:21\n",
      "2022-01-20 12:10:03 [INFO]\t[TRAIN] Epoch=13/50, Step=156/478, loss=0.045126, lr=0.079739, time_each_step=1.28s, eta=6:29:15\n",
      "2022-01-20 12:10:06 [INFO]\t[TRAIN] Epoch=13/50, Step=158/478, loss=0.072800, lr=0.079732, time_each_step=1.29s, eta=6:30:7\n",
      "2022-01-20 12:10:08 [INFO]\t[TRAIN] Epoch=13/50, Step=160/478, loss=0.067075, lr=0.079725, time_each_step=1.29s, eta=6:29:47\n",
      "2022-01-20 12:10:11 [INFO]\t[TRAIN] Epoch=13/50, Step=162/478, loss=0.055653, lr=0.079718, time_each_step=1.29s, eta=6:29:32\n",
      "2022-01-20 12:10:13 [INFO]\t[TRAIN] Epoch=13/50, Step=164/478, loss=0.099057, lr=0.079711, time_each_step=1.29s, eta=6:30:25\n",
      "2022-01-20 12:10:16 [INFO]\t[TRAIN] Epoch=13/50, Step=166/478, loss=0.051076, lr=0.079704, time_each_step=1.28s, eta=6:29:9\n",
      "2022-01-20 12:10:18 [INFO]\t[TRAIN] Epoch=13/50, Step=168/478, loss=0.065679, lr=0.079697, time_each_step=1.28s, eta=6:29:6\n",
      "2022-01-20 12:10:21 [INFO]\t[TRAIN] Epoch=13/50, Step=170/478, loss=0.062581, lr=0.079690, time_each_step=1.29s, eta=6:30:40\n",
      "2022-01-20 12:10:24 [INFO]\t[TRAIN] Epoch=13/50, Step=172/478, loss=0.054707, lr=0.079683, time_each_step=1.29s, eta=6:29:58\n",
      "2022-01-20 12:10:26 [INFO]\t[TRAIN] Epoch=13/50, Step=174/478, loss=0.051126, lr=0.079676, time_each_step=1.29s, eta=6:29:52\n",
      "2022-01-20 12:10:29 [INFO]\t[TRAIN] Epoch=13/50, Step=176/478, loss=0.056280, lr=0.079669, time_each_step=1.29s, eta=6:30:20\n",
      "2022-01-20 12:10:31 [INFO]\t[TRAIN] Epoch=13/50, Step=178/478, loss=0.060747, lr=0.079662, time_each_step=1.28s, eta=6:28:16\n",
      "2022-01-20 12:10:34 [INFO]\t[TRAIN] Epoch=13/50, Step=180/478, loss=0.059831, lr=0.079654, time_each_step=1.28s, eta=6:28:33\n",
      "2022-01-20 12:10:36 [INFO]\t[TRAIN] Epoch=13/50, Step=182/478, loss=0.074338, lr=0.079647, time_each_step=1.29s, eta=6:30:25\n",
      "2022-01-20 12:10:39 [INFO]\t[TRAIN] Epoch=13/50, Step=184/478, loss=0.055018, lr=0.079640, time_each_step=1.28s, eta=6:29:2\n",
      "2022-01-20 12:10:42 [INFO]\t[TRAIN] Epoch=13/50, Step=186/478, loss=0.071369, lr=0.079633, time_each_step=1.28s, eta=6:28:48\n",
      "2022-01-20 12:10:44 [INFO]\t[TRAIN] Epoch=13/50, Step=188/478, loss=0.063067, lr=0.079626, time_each_step=1.29s, eta=6:29:27\n",
      "2022-01-20 12:10:47 [INFO]\t[TRAIN] Epoch=13/50, Step=190/478, loss=0.085249, lr=0.079619, time_each_step=1.29s, eta=6:29:29\n",
      "2022-01-20 12:10:49 [INFO]\t[TRAIN] Epoch=13/50, Step=192/478, loss=0.045650, lr=0.079612, time_each_step=1.28s, eta=6:28:39\n",
      "2022-01-20 12:10:52 [INFO]\t[TRAIN] Epoch=13/50, Step=194/478, loss=0.070770, lr=0.079605, time_each_step=1.29s, eta=6:29:41\n",
      "2022-01-20 12:10:54 [INFO]\t[TRAIN] Epoch=13/50, Step=196/478, loss=0.070641, lr=0.079598, time_each_step=1.28s, eta=6:28:17\n",
      "2022-01-20 12:10:57 [INFO]\t[TRAIN] Epoch=13/50, Step=198/478, loss=0.071759, lr=0.079591, time_each_step=1.29s, eta=6:29:0\n",
      "2022-01-20 12:11:00 [INFO]\t[TRAIN] Epoch=13/50, Step=200/478, loss=0.045404, lr=0.079584, time_each_step=1.29s, eta=6:29:39\n",
      "2022-01-20 12:11:02 [INFO]\t[TRAIN] Epoch=13/50, Step=202/478, loss=0.068868, lr=0.079576, time_each_step=1.28s, eta=6:28:27\n",
      "2022-01-20 12:11:05 [INFO]\t[TRAIN] Epoch=13/50, Step=204/478, loss=0.045729, lr=0.079569, time_each_step=1.29s, eta=6:28:53\n",
      "2022-01-20 12:11:07 [INFO]\t[TRAIN] Epoch=13/50, Step=206/478, loss=0.090855, lr=0.079562, time_each_step=1.29s, eta=6:29:25\n",
      "2022-01-20 12:11:10 [INFO]\t[TRAIN] Epoch=13/50, Step=208/478, loss=0.098936, lr=0.079555, time_each_step=1.29s, eta=6:28:36\n",
      "2022-01-20 12:11:12 [INFO]\t[TRAIN] Epoch=13/50, Step=210/478, loss=0.072165, lr=0.079548, time_each_step=1.28s, eta=6:28:5\n",
      "2022-01-20 12:11:15 [INFO]\t[TRAIN] Epoch=13/50, Step=212/478, loss=0.055673, lr=0.079541, time_each_step=1.29s, eta=6:28:42\n",
      "2022-01-20 12:11:18 [INFO]\t[TRAIN] Epoch=13/50, Step=214/478, loss=0.066743, lr=0.079534, time_each_step=1.29s, eta=6:28:41\n",
      "2022-01-20 12:11:20 [INFO]\t[TRAIN] Epoch=13/50, Step=216/478, loss=0.113219, lr=0.079527, time_each_step=1.28s, eta=6:27:53\n",
      "2022-01-20 12:11:23 [INFO]\t[TRAIN] Epoch=13/50, Step=218/478, loss=0.082422, lr=0.079520, time_each_step=1.29s, eta=6:28:56\n",
      "2022-01-20 12:11:25 [INFO]\t[TRAIN] Epoch=13/50, Step=220/478, loss=0.079065, lr=0.079513, time_each_step=1.29s, eta=6:28:28\n",
      "2022-01-20 12:11:28 [INFO]\t[TRAIN] Epoch=13/50, Step=222/478, loss=0.067172, lr=0.079506, time_each_step=1.29s, eta=6:29:9\n",
      "2022-01-20 12:11:30 [INFO]\t[TRAIN] Epoch=13/50, Step=224/478, loss=0.073157, lr=0.079499, time_each_step=1.28s, eta=6:27:45\n",
      "2022-01-20 12:11:33 [INFO]\t[TRAIN] Epoch=13/50, Step=226/478, loss=0.079281, lr=0.079491, time_each_step=1.29s, eta=6:29:51\n",
      "2022-01-20 12:11:36 [INFO]\t[TRAIN] Epoch=13/50, Step=228/478, loss=0.058012, lr=0.079484, time_each_step=1.29s, eta=6:29:14\n",
      "2022-01-20 12:11:38 [INFO]\t[TRAIN] Epoch=13/50, Step=230/478, loss=0.046538, lr=0.079477, time_each_step=1.29s, eta=6:28:56\n",
      "2022-01-20 12:11:41 [INFO]\t[TRAIN] Epoch=13/50, Step=232/478, loss=0.065143, lr=0.079470, time_each_step=1.29s, eta=6:28:44\n",
      "2022-01-20 12:11:43 [INFO]\t[TRAIN] Epoch=13/50, Step=234/478, loss=0.074031, lr=0.079463, time_each_step=1.29s, eta=6:28:10\n",
      "2022-01-20 12:11:46 [INFO]\t[TRAIN] Epoch=13/50, Step=236/478, loss=0.077351, lr=0.079456, time_each_step=1.29s, eta=6:29:30\n",
      "2022-01-20 12:11:48 [INFO]\t[TRAIN] Epoch=13/50, Step=238/478, loss=0.055627, lr=0.079449, time_each_step=1.28s, eta=6:27:26\n",
      "2022-01-20 12:11:51 [INFO]\t[TRAIN] Epoch=13/50, Step=240/478, loss=0.052637, lr=0.079442, time_each_step=1.29s, eta=6:28:25\n",
      "2022-01-20 12:11:54 [INFO]\t[TRAIN] Epoch=13/50, Step=242/478, loss=0.063301, lr=0.079435, time_each_step=1.29s, eta=6:28:43\n",
      "2022-01-20 12:11:56 [INFO]\t[TRAIN] Epoch=13/50, Step=244/478, loss=0.062243, lr=0.079428, time_each_step=1.28s, eta=6:27:29\n",
      "2022-01-20 12:11:59 [INFO]\t[TRAIN] Epoch=13/50, Step=246/478, loss=0.067778, lr=0.079421, time_each_step=1.28s, eta=6:27:17\n",
      "2022-01-20 12:12:01 [INFO]\t[TRAIN] Epoch=13/50, Step=248/478, loss=0.057913, lr=0.079413, time_each_step=1.29s, eta=6:28:48\n",
      "2022-01-20 12:12:04 [INFO]\t[TRAIN] Epoch=13/50, Step=250/478, loss=0.072944, lr=0.079406, time_each_step=1.28s, eta=6:27:31\n",
      "2022-01-20 12:12:06 [INFO]\t[TRAIN] Epoch=13/50, Step=252/478, loss=0.073715, lr=0.079399, time_each_step=1.28s, eta=6:27:10\n",
      "2022-01-20 12:12:09 [INFO]\t[TRAIN] Epoch=13/50, Step=254/478, loss=0.056892, lr=0.079392, time_each_step=1.29s, eta=6:28:56\n",
      "2022-01-20 12:12:12 [INFO]\t[TRAIN] Epoch=13/50, Step=256/478, loss=0.107582, lr=0.079385, time_each_step=1.29s, eta=6:27:41\n",
      "2022-01-20 12:12:14 [INFO]\t[TRAIN] Epoch=13/50, Step=258/478, loss=0.066186, lr=0.079378, time_each_step=1.29s, eta=6:27:34\n",
      "2022-01-20 12:12:17 [INFO]\t[TRAIN] Epoch=13/50, Step=260/478, loss=0.065995, lr=0.079371, time_each_step=1.29s, eta=6:28:5\n",
      "2022-01-20 12:12:19 [INFO]\t[TRAIN] Epoch=13/50, Step=262/478, loss=0.056518, lr=0.079364, time_each_step=1.28s, eta=6:26:54\n",
      "2022-01-20 12:12:22 [INFO]\t[TRAIN] Epoch=13/50, Step=264/478, loss=0.104602, lr=0.079357, time_each_step=1.29s, eta=6:28:1\n",
      "2022-01-20 12:12:24 [INFO]\t[TRAIN] Epoch=13/50, Step=266/478, loss=0.057881, lr=0.079350, time_each_step=1.29s, eta=6:28:33\n",
      "2022-01-20 12:12:27 [INFO]\t[TRAIN] Epoch=13/50, Step=268/478, loss=0.045599, lr=0.079342, time_each_step=1.29s, eta=6:27:22\n",
      "2022-01-20 12:12:30 [INFO]\t[TRAIN] Epoch=13/50, Step=270/478, loss=0.059365, lr=0.079335, time_each_step=1.29s, eta=6:27:23\n",
      "2022-01-20 12:12:32 [INFO]\t[TRAIN] Epoch=13/50, Step=272/478, loss=0.072505, lr=0.079328, time_each_step=1.29s, eta=6:28:17\n",
      "2022-01-20 12:12:35 [INFO]\t[TRAIN] Epoch=13/50, Step=274/478, loss=0.046621, lr=0.079321, time_each_step=1.28s, eta=6:26:58\n",
      "2022-01-20 12:12:37 [INFO]\t[TRAIN] Epoch=13/50, Step=276/478, loss=0.080020, lr=0.079314, time_each_step=1.29s, eta=6:27:6\n",
      "2022-01-20 12:12:40 [INFO]\t[TRAIN] Epoch=13/50, Step=278/478, loss=0.073138, lr=0.079307, time_each_step=1.29s, eta=6:28:15\n",
      "2022-01-20 12:12:42 [INFO]\t[TRAIN] Epoch=13/50, Step=280/478, loss=0.074067, lr=0.079300, time_each_step=1.29s, eta=6:27:18\n",
      "2022-01-20 12:12:45 [INFO]\t[TRAIN] Epoch=13/50, Step=282/478, loss=0.052979, lr=0.079293, time_each_step=1.29s, eta=6:27:0\n",
      "2022-01-20 12:12:48 [INFO]\t[TRAIN] Epoch=13/50, Step=284/478, loss=0.093877, lr=0.079286, time_each_step=1.29s, eta=6:28:8\n",
      "2022-01-20 12:12:50 [INFO]\t[TRAIN] Epoch=13/50, Step=286/478, loss=0.113690, lr=0.079279, time_each_step=1.28s, eta=6:26:20\n",
      "2022-01-20 12:12:53 [INFO]\t[TRAIN] Epoch=13/50, Step=288/478, loss=0.068766, lr=0.079272, time_each_step=1.28s, eta=6:26:43\n",
      "2022-01-20 12:12:55 [INFO]\t[TRAIN] Epoch=13/50, Step=290/478, loss=0.072961, lr=0.079264, time_each_step=1.29s, eta=6:27:44\n",
      "2022-01-20 12:12:58 [INFO]\t[TRAIN] Epoch=13/50, Step=292/478, loss=0.068048, lr=0.079257, time_each_step=1.29s, eta=6:27:22\n",
      "2022-01-20 12:13:00 [INFO]\t[TRAIN] Epoch=13/50, Step=294/478, loss=0.062939, lr=0.079250, time_each_step=1.29s, eta=6:27:24\n",
      "2022-01-20 12:13:03 [INFO]\t[TRAIN] Epoch=13/50, Step=296/478, loss=0.078323, lr=0.079243, time_each_step=1.29s, eta=6:27:13\n",
      "2022-01-20 12:13:06 [INFO]\t[TRAIN] Epoch=13/50, Step=298/478, loss=0.081261, lr=0.079236, time_each_step=1.28s, eta=6:26:29\n",
      "2022-01-20 12:13:08 [INFO]\t[TRAIN] Epoch=13/50, Step=300/478, loss=0.111692, lr=0.079229, time_each_step=1.29s, eta=6:26:36\n",
      "2022-01-20 12:13:11 [INFO]\t[TRAIN] Epoch=13/50, Step=302/478, loss=0.062570, lr=0.079222, time_each_step=1.29s, eta=6:26:57\n",
      "2022-01-20 12:13:13 [INFO]\t[TRAIN] Epoch=13/50, Step=304/478, loss=0.057413, lr=0.079215, time_each_step=1.28s, eta=6:26:14\n",
      "2022-01-20 12:13:16 [INFO]\t[TRAIN] Epoch=13/50, Step=306/478, loss=0.057882, lr=0.079208, time_each_step=1.28s, eta=6:26:9\n",
      "2022-01-20 12:13:18 [INFO]\t[TRAIN] Epoch=13/50, Step=308/478, loss=0.092482, lr=0.079201, time_each_step=1.29s, eta=6:27:15\n",
      "2022-01-20 12:13:21 [INFO]\t[TRAIN] Epoch=13/50, Step=310/478, loss=0.052537, lr=0.079194, time_each_step=1.29s, eta=6:26:54\n",
      "2022-01-20 12:13:24 [INFO]\t[TRAIN] Epoch=13/50, Step=312/478, loss=0.086317, lr=0.079186, time_each_step=1.28s, eta=6:26:12\n",
      "2022-01-20 12:13:26 [INFO]\t[TRAIN] Epoch=13/50, Step=314/478, loss=0.085043, lr=0.079179, time_each_step=1.29s, eta=6:27:22\n",
      "2022-01-20 12:13:29 [INFO]\t[TRAIN] Epoch=13/50, Step=316/478, loss=0.085403, lr=0.079172, time_each_step=1.29s, eta=6:26:40\n",
      "2022-01-20 12:13:31 [INFO]\t[TRAIN] Epoch=13/50, Step=318/478, loss=0.087931, lr=0.079165, time_each_step=1.28s, eta=6:25:55\n",
      "2022-01-20 12:13:34 [INFO]\t[TRAIN] Epoch=13/50, Step=320/478, loss=0.050534, lr=0.079158, time_each_step=1.29s, eta=6:26:20\n",
      "2022-01-20 12:13:36 [INFO]\t[TRAIN] Epoch=13/50, Step=322/478, loss=0.078034, lr=0.079151, time_each_step=1.29s, eta=6:26:23\n",
      "2022-01-20 12:13:39 [INFO]\t[TRAIN] Epoch=13/50, Step=324/478, loss=0.085791, lr=0.079144, time_each_step=1.28s, eta=6:25:56\n",
      "2022-01-20 12:13:42 [INFO]\t[TRAIN] Epoch=13/50, Step=326/478, loss=0.044057, lr=0.079137, time_each_step=1.29s, eta=6:26:20\n",
      "2022-01-20 12:13:44 [INFO]\t[TRAIN] Epoch=13/50, Step=328/478, loss=0.065779, lr=0.079130, time_each_step=1.29s, eta=6:26:8\n",
      "2022-01-20 12:13:47 [INFO]\t[TRAIN] Epoch=13/50, Step=330/478, loss=0.048485, lr=0.079123, time_each_step=1.28s, eta=6:25:34\n",
      "2022-01-20 12:13:49 [INFO]\t[TRAIN] Epoch=13/50, Step=332/478, loss=0.052239, lr=0.079115, time_each_step=1.29s, eta=6:26:27\n",
      "2022-01-20 12:13:52 [INFO]\t[TRAIN] Epoch=13/50, Step=334/478, loss=0.067726, lr=0.079108, time_each_step=1.29s, eta=6:25:56\n",
      "2022-01-20 12:13:54 [INFO]\t[TRAIN] Epoch=13/50, Step=336/478, loss=0.090224, lr=0.079101, time_each_step=1.29s, eta=6:25:53\n",
      "2022-01-20 12:13:57 [INFO]\t[TRAIN] Epoch=13/50, Step=338/478, loss=0.058144, lr=0.079094, time_each_step=1.29s, eta=6:26:42\n",
      "2022-01-20 12:14:00 [INFO]\t[TRAIN] Epoch=13/50, Step=340/478, loss=0.106781, lr=0.079087, time_each_step=1.29s, eta=6:25:44\n",
      "2022-01-20 12:14:02 [INFO]\t[TRAIN] Epoch=13/50, Step=342/478, loss=0.066557, lr=0.079080, time_each_step=1.28s, eta=6:25:10\n",
      "2022-01-20 12:14:05 [INFO]\t[TRAIN] Epoch=13/50, Step=344/478, loss=0.041676, lr=0.079073, time_each_step=1.29s, eta=6:26:32\n",
      "2022-01-20 12:14:07 [INFO]\t[TRAIN] Epoch=13/50, Step=346/478, loss=0.070452, lr=0.079066, time_each_step=1.29s, eta=6:25:56\n",
      "2022-01-20 12:14:10 [INFO]\t[TRAIN] Epoch=13/50, Step=348/478, loss=0.056535, lr=0.079059, time_each_step=1.29s, eta=6:25:41\n",
      "2022-01-20 12:14:12 [INFO]\t[TRAIN] Epoch=13/50, Step=350/478, loss=0.091076, lr=0.079052, time_each_step=1.29s, eta=6:26:9\n",
      "2022-01-20 12:14:15 [INFO]\t[TRAIN] Epoch=13/50, Step=352/478, loss=0.058990, lr=0.079044, time_each_step=1.29s, eta=6:25:35\n",
      "2022-01-20 12:14:18 [INFO]\t[TRAIN] Epoch=13/50, Step=354/478, loss=0.075090, lr=0.079037, time_each_step=1.29s, eta=6:25:30\n",
      "2022-01-20 12:14:20 [INFO]\t[TRAIN] Epoch=13/50, Step=356/478, loss=0.060589, lr=0.079030, time_each_step=1.29s, eta=6:25:52\n",
      "2022-01-20 12:14:23 [INFO]\t[TRAIN] Epoch=13/50, Step=358/478, loss=0.056428, lr=0.079023, time_each_step=1.29s, eta=6:25:45\n",
      "2022-01-20 12:14:25 [INFO]\t[TRAIN] Epoch=13/50, Step=360/478, loss=0.096791, lr=0.079016, time_each_step=1.28s, eta=6:25:3\n",
      "2022-01-20 12:14:28 [INFO]\t[TRAIN] Epoch=13/50, Step=362/478, loss=0.093534, lr=0.079009, time_each_step=1.29s, eta=6:26:23\n",
      "2022-01-20 12:14:30 [INFO]\t[TRAIN] Epoch=13/50, Step=364/478, loss=0.062171, lr=0.079002, time_each_step=1.28s, eta=6:24:31\n",
      "2022-01-20 12:14:33 [INFO]\t[TRAIN] Epoch=13/50, Step=366/478, loss=0.047366, lr=0.078995, time_each_step=1.29s, eta=6:25:54\n",
      "2022-01-20 12:14:36 [INFO]\t[TRAIN] Epoch=13/50, Step=368/478, loss=0.065530, lr=0.078988, time_each_step=1.29s, eta=6:26:2\n",
      "2022-01-20 12:14:38 [INFO]\t[TRAIN] Epoch=13/50, Step=370/478, loss=0.094076, lr=0.078981, time_each_step=1.29s, eta=6:25:27\n",
      "2022-01-20 12:14:41 [INFO]\t[TRAIN] Epoch=13/50, Step=372/478, loss=0.051888, lr=0.078973, time_each_step=1.28s, eta=6:24:59\n",
      "2022-01-20 12:14:43 [INFO]\t[TRAIN] Epoch=13/50, Step=374/478, loss=0.066497, lr=0.078966, time_each_step=1.29s, eta=6:25:35\n",
      "2022-01-20 12:14:46 [INFO]\t[TRAIN] Epoch=13/50, Step=376/478, loss=0.081260, lr=0.078959, time_each_step=1.29s, eta=6:25:15\n",
      "2022-01-20 12:14:48 [INFO]\t[TRAIN] Epoch=13/50, Step=378/478, loss=0.077719, lr=0.078952, time_each_step=1.29s, eta=6:25:6\n",
      "2022-01-20 12:14:51 [INFO]\t[TRAIN] Epoch=13/50, Step=380/478, loss=0.045946, lr=0.078945, time_each_step=1.29s, eta=6:25:29\n",
      "2022-01-20 12:14:54 [INFO]\t[TRAIN] Epoch=13/50, Step=382/478, loss=0.054236, lr=0.078938, time_each_step=1.29s, eta=6:25:27\n",
      "2022-01-20 12:14:56 [INFO]\t[TRAIN] Epoch=13/50, Step=384/478, loss=0.073956, lr=0.078931, time_each_step=1.29s, eta=6:24:53\n",
      "2022-01-20 12:14:59 [INFO]\t[TRAIN] Epoch=13/50, Step=386/478, loss=0.070258, lr=0.078924, time_each_step=1.29s, eta=6:25:49\n",
      "2022-01-20 12:15:01 [INFO]\t[TRAIN] Epoch=13/50, Step=388/478, loss=0.104695, lr=0.078917, time_each_step=1.29s, eta=6:24:48\n",
      "2022-01-20 12:15:04 [INFO]\t[TRAIN] Epoch=13/50, Step=390/478, loss=0.058196, lr=0.078910, time_each_step=1.29s, eta=6:24:38\n",
      "2022-01-20 12:15:07 [INFO]\t[TRAIN] Epoch=13/50, Step=392/478, loss=0.040304, lr=0.078902, time_each_step=1.28s, eta=6:23:59\n",
      "2022-01-20 12:15:09 [INFO]\t[TRAIN] Epoch=13/50, Step=394/478, loss=0.051133, lr=0.078895, time_each_step=1.29s, eta=6:25:55\n",
      "2022-01-20 12:15:12 [INFO]\t[TRAIN] Epoch=13/50, Step=396/478, loss=0.043577, lr=0.078888, time_each_step=1.28s, eta=6:24:10\n",
      "2022-01-20 12:15:14 [INFO]\t[TRAIN] Epoch=13/50, Step=398/478, loss=0.077698, lr=0.078881, time_each_step=1.29s, eta=6:26:23\n",
      "2022-01-20 12:15:17 [INFO]\t[TRAIN] Epoch=13/50, Step=400/478, loss=0.057291, lr=0.078874, time_each_step=1.29s, eta=6:25:7\n",
      "2022-01-20 12:15:19 [INFO]\t[TRAIN] Epoch=13/50, Step=402/478, loss=0.074249, lr=0.078867, time_each_step=1.29s, eta=6:24:29\n",
      "2022-01-20 12:15:22 [INFO]\t[TRAIN] Epoch=13/50, Step=404/478, loss=0.083343, lr=0.078860, time_each_step=1.29s, eta=6:25:4\n",
      "2022-01-20 12:15:25 [INFO]\t[TRAIN] Epoch=13/50, Step=406/478, loss=0.063879, lr=0.078853, time_each_step=1.29s, eta=6:24:26\n",
      "2022-01-20 12:15:27 [INFO]\t[TRAIN] Epoch=13/50, Step=408/478, loss=0.061336, lr=0.078846, time_each_step=1.28s, eta=6:23:51\n",
      "2022-01-20 12:15:30 [INFO]\t[TRAIN] Epoch=13/50, Step=410/478, loss=0.060129, lr=0.078838, time_each_step=1.29s, eta=6:25:31\n",
      "2022-01-20 12:15:32 [INFO]\t[TRAIN] Epoch=13/50, Step=412/478, loss=0.081129, lr=0.078831, time_each_step=1.28s, eta=6:23:36\n",
      "2022-01-20 12:15:35 [INFO]\t[TRAIN] Epoch=13/50, Step=414/478, loss=0.120459, lr=0.078824, time_each_step=1.29s, eta=6:24:21\n",
      "2022-01-20 12:15:37 [INFO]\t[TRAIN] Epoch=13/50, Step=416/478, loss=0.068844, lr=0.078817, time_each_step=1.29s, eta=6:24:19\n",
      "2022-01-20 12:15:40 [INFO]\t[TRAIN] Epoch=13/50, Step=418/478, loss=0.051034, lr=0.078810, time_each_step=1.29s, eta=6:24:5\n",
      "2022-01-20 12:15:43 [INFO]\t[TRAIN] Epoch=13/50, Step=420/478, loss=0.096232, lr=0.078803, time_each_step=1.28s, eta=6:23:23\n",
      "2022-01-20 12:15:45 [INFO]\t[TRAIN] Epoch=13/50, Step=422/478, loss=0.062139, lr=0.078796, time_each_step=1.29s, eta=6:24:35\n",
      "2022-01-20 12:15:48 [INFO]\t[TRAIN] Epoch=13/50, Step=424/478, loss=0.046805, lr=0.078789, time_each_step=1.29s, eta=6:24:0\n",
      "2022-01-20 12:15:50 [INFO]\t[TRAIN] Epoch=13/50, Step=426/478, loss=0.067599, lr=0.078782, time_each_step=1.28s, eta=6:23:40\n",
      "2022-01-20 12:15:53 [INFO]\t[TRAIN] Epoch=13/50, Step=428/478, loss=0.058040, lr=0.078775, time_each_step=1.29s, eta=6:24:48\n",
      "2022-01-20 12:15:55 [INFO]\t[TRAIN] Epoch=13/50, Step=430/478, loss=0.053676, lr=0.078767, time_each_step=1.28s, eta=6:23:31\n",
      "2022-01-20 12:15:58 [INFO]\t[TRAIN] Epoch=13/50, Step=432/478, loss=0.058953, lr=0.078760, time_each_step=1.29s, eta=6:24:18\n",
      "2022-01-20 12:16:01 [INFO]\t[TRAIN] Epoch=13/50, Step=434/478, loss=0.084949, lr=0.078753, time_each_step=1.29s, eta=6:25:14\n",
      "2022-01-20 12:16:03 [INFO]\t[TRAIN] Epoch=13/50, Step=436/478, loss=0.075177, lr=0.078746, time_each_step=1.29s, eta=6:23:50\n",
      "2022-01-20 12:16:06 [INFO]\t[TRAIN] Epoch=13/50, Step=438/478, loss=0.078019, lr=0.078739, time_each_step=1.29s, eta=6:23:39\n",
      "2022-01-20 12:16:08 [INFO]\t[TRAIN] Epoch=13/50, Step=440/478, loss=0.067357, lr=0.078732, time_each_step=1.29s, eta=6:25:12\n",
      "2022-01-20 12:16:11 [INFO]\t[TRAIN] Epoch=13/50, Step=442/478, loss=0.055860, lr=0.078725, time_each_step=1.29s, eta=6:23:52\n",
      "2022-01-20 12:16:13 [INFO]\t[TRAIN] Epoch=13/50, Step=444/478, loss=0.079487, lr=0.078718, time_each_step=1.29s, eta=6:24:3\n",
      "2022-01-20 12:16:16 [INFO]\t[TRAIN] Epoch=13/50, Step=446/478, loss=0.083473, lr=0.078711, time_each_step=1.29s, eta=6:23:59\n",
      "2022-01-20 12:16:19 [INFO]\t[TRAIN] Epoch=13/50, Step=448/478, loss=0.067148, lr=0.078703, time_each_step=1.29s, eta=6:23:33\n",
      "2022-01-20 12:16:21 [INFO]\t[TRAIN] Epoch=13/50, Step=450/478, loss=0.060736, lr=0.078696, time_each_step=1.29s, eta=6:23:34\n",
      "2022-01-20 12:16:24 [INFO]\t[TRAIN] Epoch=13/50, Step=452/478, loss=0.088455, lr=0.078689, time_each_step=1.29s, eta=6:23:44\n",
      "2022-01-20 12:16:26 [INFO]\t[TRAIN] Epoch=13/50, Step=454/478, loss=0.080770, lr=0.078682, time_each_step=1.29s, eta=6:23:56\n",
      "2022-01-20 12:16:29 [INFO]\t[TRAIN] Epoch=13/50, Step=456/478, loss=0.060673, lr=0.078675, time_each_step=1.29s, eta=6:23:20\n",
      "2022-01-20 12:16:31 [INFO]\t[TRAIN] Epoch=13/50, Step=458/478, loss=0.047919, lr=0.078668, time_each_step=1.29s, eta=6:24:8\n",
      "2022-01-20 12:16:34 [INFO]\t[TRAIN] Epoch=13/50, Step=460/478, loss=0.066789, lr=0.078661, time_each_step=1.29s, eta=6:23:50\n",
      "2022-01-20 12:16:37 [INFO]\t[TRAIN] Epoch=13/50, Step=462/478, loss=0.105535, lr=0.078654, time_each_step=1.28s, eta=6:23:1\n",
      "2022-01-20 12:16:39 [INFO]\t[TRAIN] Epoch=13/50, Step=464/478, loss=0.082215, lr=0.078647, time_each_step=1.29s, eta=6:23:37\n",
      "2022-01-20 12:16:42 [INFO]\t[TRAIN] Epoch=13/50, Step=466/478, loss=0.057593, lr=0.078639, time_each_step=1.29s, eta=6:23:17\n",
      "2022-01-20 12:16:44 [INFO]\t[TRAIN] Epoch=13/50, Step=468/478, loss=0.074758, lr=0.078632, time_each_step=1.28s, eta=6:22:55\n",
      "2022-01-20 12:16:47 [INFO]\t[TRAIN] Epoch=13/50, Step=470/478, loss=0.056605, lr=0.078625, time_each_step=1.29s, eta=6:23:48\n",
      "2022-01-20 12:16:49 [INFO]\t[TRAIN] Epoch=13/50, Step=472/478, loss=0.049889, lr=0.078618, time_each_step=1.29s, eta=6:23:0\n",
      "2022-01-20 12:16:52 [INFO]\t[TRAIN] Epoch=13/50, Step=474/478, loss=0.070534, lr=0.078611, time_each_step=1.28s, eta=6:22:21\n",
      "2022-01-20 12:16:55 [INFO]\t[TRAIN] Epoch=13/50, Step=476/478, loss=0.077633, lr=0.078604, time_each_step=1.28s, eta=6:22:36\n",
      "2022-01-20 12:16:57 [INFO]\t[TRAIN] Epoch=13/50, Step=478/478, loss=0.061486, lr=0.078597, time_each_step=1.28s, eta=6:22:37\n",
      "2022-01-20 12:16:57 [INFO]\t[TRAIN] Epoch 13 finished, loss=0.069121465 .\n",
      "2022-01-20 12:16:57 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-01-20 12:16:57 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-01-20 12:17:04 [INFO]\t[EVAL] Finished, Epoch=13, miou=0.840081, category_iou=[0.9717656  0.7483266  0.80015165], oacc=0.973727, category_acc=[0.9889085  0.85341346 0.86285573], kappa=0.874352, category_F1-score=[0.98568063 0.85604894 0.88898248] .\n",
      "2022-01-20 12:17:04 [INFO]\tModel saved in model/deeplab_augument_alldata2/best_model.\n",
      "2022-01-20 12:17:04 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_13, miou=0.8400812745094299\n",
      "2022-01-20 12:17:05 [INFO]\tModel saved in model/deeplab_augument_alldata2/epoch_13.\n",
      "2022-01-20 12:17:09 [INFO]\t[TRAIN] Epoch=14/50, Step=2/478, loss=0.062235, lr=0.078590, time_each_step=1.91s, eta=9:26:3\n",
      "2022-01-20 12:17:11 [INFO]\t[TRAIN] Epoch=14/50, Step=4/478, loss=0.088699, lr=0.078583, time_each_step=1.29s, eta=6:23:33\n",
      "2022-01-20 12:17:14 [INFO]\t[TRAIN] Epoch=14/50, Step=6/478, loss=0.064292, lr=0.078575, time_each_step=1.28s, eta=6:22:29\n",
      "2022-01-20 12:17:16 [INFO]\t[TRAIN] Epoch=14/50, Step=8/478, loss=0.072597, lr=0.078568, time_each_step=1.29s, eta=6:23:11\n",
      "2022-01-20 12:17:19 [INFO]\t[TRAIN] Epoch=14/50, Step=10/478, loss=0.110737, lr=0.078561, time_each_step=1.29s, eta=6:23:10\n",
      "2022-01-20 12:17:21 [INFO]\t[TRAIN] Epoch=14/50, Step=12/478, loss=0.060896, lr=0.078554, time_each_step=1.28s, eta=6:22:29\n",
      "2022-01-20 12:17:24 [INFO]\t[TRAIN] Epoch=14/50, Step=14/478, loss=0.064358, lr=0.078547, time_each_step=1.29s, eta=6:22:53\n",
      "2022-01-20 12:17:27 [INFO]\t[TRAIN] Epoch=14/50, Step=16/478, loss=0.046633, lr=0.078540, time_each_step=1.29s, eta=6:22:56\n",
      "2022-01-20 12:17:29 [INFO]\t[TRAIN] Epoch=14/50, Step=18/478, loss=0.060866, lr=0.078533, time_each_step=1.28s, eta=6:21:52\n",
      "2022-01-20 12:17:32 [INFO]\t[TRAIN] Epoch=14/50, Step=20/478, loss=0.074398, lr=0.078526, time_each_step=1.28s, eta=6:22:21\n",
      "2022-01-20 12:17:34 [INFO]\t[TRAIN] Epoch=14/50, Step=22/478, loss=0.078889, lr=0.078519, time_each_step=1.29s, eta=6:23:6\n",
      "2022-01-20 12:17:37 [INFO]\t[TRAIN] Epoch=14/50, Step=24/478, loss=0.071138, lr=0.078511, time_each_step=1.28s, eta=6:21:53\n",
      "2022-01-20 12:17:39 [INFO]\t[TRAIN] Epoch=14/50, Step=26/478, loss=0.064980, lr=0.078504, time_each_step=1.29s, eta=6:23:1\n",
      "2022-01-20 12:17:42 [INFO]\t[TRAIN] Epoch=14/50, Step=28/478, loss=0.051639, lr=0.078497, time_each_step=1.29s, eta=6:23:22\n",
      "2022-01-20 12:17:45 [INFO]\t[TRAIN] Epoch=14/50, Step=30/478, loss=0.075660, lr=0.078490, time_each_step=1.28s, eta=6:21:7\n",
      "2022-01-20 12:17:47 [INFO]\t[TRAIN] Epoch=14/50, Step=32/478, loss=0.060449, lr=0.078483, time_each_step=1.28s, eta=6:22:1\n",
      "2022-01-20 12:17:50 [INFO]\t[TRAIN] Epoch=14/50, Step=34/478, loss=0.058268, lr=0.078476, time_each_step=1.29s, eta=6:23:2\n",
      "2022-01-20 12:17:52 [INFO]\t[TRAIN] Epoch=14/50, Step=36/478, loss=0.081780, lr=0.078469, time_each_step=1.29s, eta=6:22:23\n",
      "2022-01-20 12:17:55 [INFO]\t[TRAIN] Epoch=14/50, Step=38/478, loss=0.060802, lr=0.078462, time_each_step=1.29s, eta=6:22:22\n",
      "2022-01-20 12:17:57 [INFO]\t[TRAIN] Epoch=14/50, Step=40/478, loss=0.098819, lr=0.078455, time_each_step=1.29s, eta=6:23:11\n",
      "2022-01-20 12:18:00 [INFO]\t[TRAIN] Epoch=14/50, Step=42/478, loss=0.042934, lr=0.078447, time_each_step=1.28s, eta=6:21:16\n",
      "2022-01-20 12:18:03 [INFO]\t[TRAIN] Epoch=14/50, Step=44/478, loss=0.092625, lr=0.078440, time_each_step=1.28s, eta=6:21:29\n",
      "2022-01-20 12:18:05 [INFO]\t[TRAIN] Epoch=14/50, Step=46/478, loss=0.054733, lr=0.078433, time_each_step=1.29s, eta=6:22:27\n",
      "2022-01-20 12:18:08 [INFO]\t[TRAIN] Epoch=14/50, Step=48/478, loss=0.051881, lr=0.078426, time_each_step=1.28s, eta=6:21:33\n",
      "2022-01-20 12:18:10 [INFO]\t[TRAIN] Epoch=14/50, Step=50/478, loss=0.060445, lr=0.078419, time_each_step=1.28s, eta=6:21:41\n",
      "2022-01-20 12:18:13 [INFO]\t[TRAIN] Epoch=14/50, Step=52/478, loss=0.065317, lr=0.078412, time_each_step=1.29s, eta=6:22:19\n",
      "2022-01-20 12:18:15 [INFO]\t[TRAIN] Epoch=14/50, Step=54/478, loss=0.064939, lr=0.078405, time_each_step=1.29s, eta=6:21:53\n",
      "2022-01-20 12:18:18 [INFO]\t[TRAIN] Epoch=14/50, Step=56/478, loss=0.045207, lr=0.078398, time_each_step=1.28s, eta=6:21:40\n",
      "2022-01-20 12:18:21 [INFO]\t[TRAIN] Epoch=14/50, Step=58/478, loss=0.036565, lr=0.078391, time_each_step=1.29s, eta=6:22:30\n",
      "2022-01-20 12:18:23 [INFO]\t[TRAIN] Epoch=14/50, Step=60/478, loss=0.066344, lr=0.078383, time_each_step=1.29s, eta=6:22:2\n",
      "2022-01-20 12:18:26 [INFO]\t[TRAIN] Epoch=14/50, Step=62/478, loss=0.067574, lr=0.078376, time_each_step=1.29s, eta=6:21:55\n",
      "2022-01-20 12:18:28 [INFO]\t[TRAIN] Epoch=14/50, Step=64/478, loss=0.054649, lr=0.078369, time_each_step=1.29s, eta=6:22:9\n",
      "2022-01-20 12:18:31 [INFO]\t[TRAIN] Epoch=14/50, Step=66/478, loss=0.052463, lr=0.078362, time_each_step=1.28s, eta=6:21:23\n",
      "2022-01-20 12:18:33 [INFO]\t[TRAIN] Epoch=14/50, Step=68/478, loss=0.063189, lr=0.078355, time_each_step=1.28s, eta=6:21:3\n",
      "2022-01-20 12:18:36 [INFO]\t[TRAIN] Epoch=14/50, Step=70/478, loss=0.064064, lr=0.078348, time_each_step=1.29s, eta=6:22:20\n",
      "2022-01-20 12:18:39 [INFO]\t[TRAIN] Epoch=14/50, Step=72/478, loss=0.064037, lr=0.078341, time_each_step=1.29s, eta=6:21:37\n",
      "2022-01-20 12:18:41 [INFO]\t[TRAIN] Epoch=14/50, Step=74/478, loss=0.059977, lr=0.078334, time_each_step=1.29s, eta=6:21:44\n",
      "2022-01-20 12:18:44 [INFO]\t[TRAIN] Epoch=14/50, Step=76/478, loss=0.068124, lr=0.078327, time_each_step=1.29s, eta=6:22:22\n",
      "2022-01-20 12:18:46 [INFO]\t[TRAIN] Epoch=14/50, Step=78/478, loss=0.068062, lr=0.078319, time_each_step=1.29s, eta=6:21:20\n",
      "2022-01-20 12:18:49 [INFO]\t[TRAIN] Epoch=14/50, Step=80/478, loss=0.051573, lr=0.078312, time_each_step=1.29s, eta=6:21:23\n",
      "2022-01-20 12:18:51 [INFO]\t[TRAIN] Epoch=14/50, Step=82/478, loss=0.095422, lr=0.078305, time_each_step=1.29s, eta=6:22:15\n",
      "2022-01-20 12:18:54 [INFO]\t[TRAIN] Epoch=14/50, Step=84/478, loss=0.080119, lr=0.078298, time_each_step=1.29s, eta=6:21:40\n",
      "2022-01-20 12:18:57 [INFO]\t[TRAIN] Epoch=14/50, Step=86/478, loss=0.061297, lr=0.078291, time_each_step=1.28s, eta=6:20:32\n",
      "2022-01-20 12:18:59 [INFO]\t[TRAIN] Epoch=14/50, Step=88/478, loss=0.066409, lr=0.078284, time_each_step=1.29s, eta=6:22:31\n",
      "2022-01-20 12:19:02 [INFO]\t[TRAIN] Epoch=14/50, Step=90/478, loss=0.085491, lr=0.078277, time_each_step=1.28s, eta=6:20:56\n",
      "2022-01-20 12:19:04 [INFO]\t[TRAIN] Epoch=14/50, Step=92/478, loss=0.051914, lr=0.078270, time_each_step=1.29s, eta=6:21:36\n",
      "2022-01-20 12:19:07 [INFO]\t[TRAIN] Epoch=14/50, Step=94/478, loss=0.073419, lr=0.078262, time_each_step=1.29s, eta=6:21:26\n",
      "2022-01-20 12:19:09 [INFO]\t[TRAIN] Epoch=14/50, Step=96/478, loss=0.070791, lr=0.078255, time_each_step=1.29s, eta=6:21:20\n",
      "2022-01-20 12:19:12 [INFO]\t[TRAIN] Epoch=14/50, Step=98/478, loss=0.080387, lr=0.078248, time_each_step=1.28s, eta=6:20:48\n",
      "2022-01-20 12:19:15 [INFO]\t[TRAIN] Epoch=14/50, Step=100/478, loss=0.064458, lr=0.078241, time_each_step=1.29s, eta=6:22:1\n",
      "2022-01-20 12:19:17 [INFO]\t[TRAIN] Epoch=14/50, Step=102/478, loss=0.082176, lr=0.078234, time_each_step=1.29s, eta=6:21:7\n",
      "2022-01-20 12:19:20 [INFO]\t[TRAIN] Epoch=14/50, Step=104/478, loss=0.050454, lr=0.078227, time_each_step=1.29s, eta=6:21:4\n",
      "2022-01-20 12:19:22 [INFO]\t[TRAIN] Epoch=14/50, Step=106/478, loss=0.059095, lr=0.078220, time_each_step=1.29s, eta=6:21:29\n",
      "2022-01-20 12:19:25 [INFO]\t[TRAIN] Epoch=14/50, Step=108/478, loss=0.050395, lr=0.078213, time_each_step=1.29s, eta=6:21:0\n",
      "2022-01-20 12:19:28 [INFO]\t[TRAIN] Epoch=14/50, Step=110/478, loss=0.105950, lr=0.078206, time_each_step=1.29s, eta=6:20:56\n",
      "2022-01-20 12:19:30 [INFO]\t[TRAIN] Epoch=14/50, Step=112/478, loss=0.065296, lr=0.078198, time_each_step=1.29s, eta=6:20:49\n",
      "2022-01-20 12:19:33 [INFO]\t[TRAIN] Epoch=14/50, Step=114/478, loss=0.071801, lr=0.078191, time_each_step=1.28s, eta=6:20:27\n",
      "2022-01-20 12:19:35 [INFO]\t[TRAIN] Epoch=14/50, Step=116/478, loss=0.076312, lr=0.078184, time_each_step=1.28s, eta=6:20:8\n",
      "2022-01-20 12:19:38 [INFO]\t[TRAIN] Epoch=14/50, Step=118/478, loss=0.040206, lr=0.078177, time_each_step=1.29s, eta=6:20:49\n",
      "2022-01-20 12:19:40 [INFO]\t[TRAIN] Epoch=14/50, Step=120/478, loss=0.054023, lr=0.078170, time_each_step=1.29s, eta=6:21:25\n",
      "2022-01-20 12:19:43 [INFO]\t[TRAIN] Epoch=14/50, Step=122/478, loss=0.080656, lr=0.078163, time_each_step=1.28s, eta=6:20:20\n",
      "2022-01-20 12:19:46 [INFO]\t[TRAIN] Epoch=14/50, Step=124/478, loss=0.061490, lr=0.078156, time_each_step=1.29s, eta=6:21:7\n",
      "2022-01-20 12:19:48 [INFO]\t[TRAIN] Epoch=14/50, Step=126/478, loss=0.055988, lr=0.078149, time_each_step=1.29s, eta=6:21:44\n",
      "2022-01-20 12:19:51 [INFO]\t[TRAIN] Epoch=14/50, Step=128/478, loss=0.067102, lr=0.078141, time_each_step=1.28s, eta=6:19:32\n",
      "2022-01-20 12:19:53 [INFO]\t[TRAIN] Epoch=14/50, Step=130/478, loss=0.047652, lr=0.078134, time_each_step=1.29s, eta=6:20:32\n",
      "2022-01-20 12:19:56 [INFO]\t[TRAIN] Epoch=14/50, Step=132/478, loss=0.086805, lr=0.078127, time_each_step=1.29s, eta=6:20:42\n",
      "2022-01-20 12:19:58 [INFO]\t[TRAIN] Epoch=14/50, Step=134/478, loss=0.065804, lr=0.078120, time_each_step=1.29s, eta=6:20:16\n",
      "2022-01-20 12:20:01 [INFO]\t[TRAIN] Epoch=14/50, Step=136/478, loss=0.059601, lr=0.078113, time_each_step=1.29s, eta=6:21:6\n",
      "2022-01-20 12:20:04 [INFO]\t[TRAIN] Epoch=14/50, Step=138/478, loss=0.076767, lr=0.078106, time_each_step=1.28s, eta=6:20:2\n",
      "2022-01-20 12:20:06 [INFO]\t[TRAIN] Epoch=14/50, Step=140/478, loss=0.076276, lr=0.078099, time_each_step=1.29s, eta=6:20:7\n",
      "2022-01-20 12:20:09 [INFO]\t[TRAIN] Epoch=14/50, Step=142/478, loss=0.061949, lr=0.078092, time_each_step=1.29s, eta=6:21:39\n",
      "2022-01-20 12:20:11 [INFO]\t[TRAIN] Epoch=14/50, Step=144/478, loss=0.094874, lr=0.078084, time_each_step=1.28s, eta=6:19:53\n",
      "2022-01-20 12:20:14 [INFO]\t[TRAIN] Epoch=14/50, Step=146/478, loss=0.052402, lr=0.078077, time_each_step=1.29s, eta=6:20:6\n",
      "2022-01-20 12:20:16 [INFO]\t[TRAIN] Epoch=14/50, Step=148/478, loss=0.051111, lr=0.078070, time_each_step=1.29s, eta=6:20:17\n",
      "2022-01-20 12:20:19 [INFO]\t[TRAIN] Epoch=14/50, Step=150/478, loss=0.083818, lr=0.078063, time_each_step=1.28s, eta=6:19:45\n",
      "2022-01-20 12:20:22 [INFO]\t[TRAIN] Epoch=14/50, Step=152/478, loss=0.081464, lr=0.078056, time_each_step=1.28s, eta=6:19:36\n",
      "2022-01-20 12:20:24 [INFO]\t[TRAIN] Epoch=14/50, Step=154/478, loss=0.060274, lr=0.078049, time_each_step=1.29s, eta=6:20:47\n",
      "2022-01-20 12:20:27 [INFO]\t[TRAIN] Epoch=14/50, Step=156/478, loss=0.084217, lr=0.078042, time_each_step=1.28s, eta=6:19:31\n",
      "2022-01-20 12:20:29 [INFO]\t[TRAIN] Epoch=14/50, Step=158/478, loss=0.080228, lr=0.078035, time_each_step=1.29s, eta=6:19:40\n",
      "2022-01-20 12:20:32 [INFO]\t[TRAIN] Epoch=14/50, Step=160/478, loss=0.075680, lr=0.078028, time_each_step=1.29s, eta=6:20:45\n",
      "2022-01-20 12:20:34 [INFO]\t[TRAIN] Epoch=14/50, Step=162/478, loss=0.061764, lr=0.078020, time_each_step=1.28s, eta=6:19:16\n",
      "2022-01-20 12:20:37 [INFO]\t[TRAIN] Epoch=14/50, Step=164/478, loss=0.075078, lr=0.078013, time_each_step=1.29s, eta=6:20:10\n",
      "2022-01-20 12:20:40 [INFO]\t[TRAIN] Epoch=14/50, Step=166/478, loss=0.098158, lr=0.078006, time_each_step=1.29s, eta=6:19:56\n",
      "2022-01-20 12:20:42 [INFO]\t[TRAIN] Epoch=14/50, Step=168/478, loss=0.066100, lr=0.077999, time_each_step=1.29s, eta=6:19:58\n",
      "2022-01-20 12:20:45 [INFO]\t[TRAIN] Epoch=14/50, Step=170/478, loss=0.061862, lr=0.077992, time_each_step=1.29s, eta=6:20:10\n",
      "2022-01-20 12:20:47 [INFO]\t[TRAIN] Epoch=14/50, Step=172/478, loss=0.051155, lr=0.077985, time_each_step=1.29s, eta=6:19:51\n",
      "2022-01-20 12:20:50 [INFO]\t[TRAIN] Epoch=14/50, Step=174/478, loss=0.060203, lr=0.077978, time_each_step=1.29s, eta=6:19:35\n",
      "2022-01-20 12:20:52 [INFO]\t[TRAIN] Epoch=14/50, Step=176/478, loss=0.053356, lr=0.077971, time_each_step=1.29s, eta=6:20:4\n",
      "2022-01-20 12:20:55 [INFO]\t[TRAIN] Epoch=14/50, Step=178/478, loss=0.056999, lr=0.077963, time_each_step=1.29s, eta=6:20:6\n",
      "2022-01-20 12:20:58 [INFO]\t[TRAIN] Epoch=14/50, Step=180/478, loss=0.067768, lr=0.077956, time_each_step=1.29s, eta=6:19:42\n",
      "2022-01-20 12:21:00 [INFO]\t[TRAIN] Epoch=14/50, Step=182/478, loss=0.071681, lr=0.077949, time_each_step=1.29s, eta=6:19:14\n",
      "2022-01-20 12:21:03 [INFO]\t[TRAIN] Epoch=14/50, Step=184/478, loss=0.079101, lr=0.077942, time_each_step=1.29s, eta=6:20:2\n",
      "2022-01-20 12:21:05 [INFO]\t[TRAIN] Epoch=14/50, Step=186/478, loss=0.047933, lr=0.077935, time_each_step=1.28s, eta=6:18:49\n",
      "2022-01-20 12:21:08 [INFO]\t[TRAIN] Epoch=14/50, Step=188/478, loss=0.052075, lr=0.077928, time_each_step=1.29s, eta=6:19:10\n",
      "2022-01-20 12:21:10 [INFO]\t[TRAIN] Epoch=14/50, Step=190/478, loss=0.046412, lr=0.077921, time_each_step=1.29s, eta=6:19:22\n",
      "2022-01-20 12:21:13 [INFO]\t[TRAIN] Epoch=14/50, Step=192/478, loss=0.057569, lr=0.077914, time_each_step=1.29s, eta=6:19:22\n",
      "2022-01-20 12:21:16 [INFO]\t[TRAIN] Epoch=14/50, Step=194/478, loss=0.051729, lr=0.077906, time_each_step=1.28s, eta=6:18:43\n",
      "2022-01-20 12:21:18 [INFO]\t[TRAIN] Epoch=14/50, Step=196/478, loss=0.056560, lr=0.077899, time_each_step=1.29s, eta=6:19:9\n",
      "2022-01-20 12:21:21 [INFO]\t[TRAIN] Epoch=14/50, Step=198/478, loss=0.064936, lr=0.077892, time_each_step=1.29s, eta=6:18:56\n",
      "2022-01-20 12:21:23 [INFO]\t[TRAIN] Epoch=14/50, Step=200/478, loss=0.072575, lr=0.077885, time_each_step=1.29s, eta=6:19:16\n",
      "2022-01-20 12:21:26 [INFO]\t[TRAIN] Epoch=14/50, Step=202/478, loss=0.075018, lr=0.077878, time_each_step=1.29s, eta=6:18:53\n",
      "2022-01-20 12:21:28 [INFO]\t[TRAIN] Epoch=14/50, Step=204/478, loss=0.067769, lr=0.077871, time_each_step=1.29s, eta=6:18:40\n",
      "2022-01-20 12:21:31 [INFO]\t[TRAIN] Epoch=14/50, Step=206/478, loss=0.067471, lr=0.077864, time_each_step=1.29s, eta=6:18:38\n",
      "2022-01-20 12:21:34 [INFO]\t[TRAIN] Epoch=14/50, Step=208/478, loss=0.071274, lr=0.077857, time_each_step=1.29s, eta=6:19:11\n",
      "2022-01-20 12:21:36 [INFO]\t[TRAIN] Epoch=14/50, Step=210/478, loss=0.051873, lr=0.077849, time_each_step=1.29s, eta=6:19:3\n",
      "2022-01-20 12:21:39 [INFO]\t[TRAIN] Epoch=14/50, Step=212/478, loss=0.112750, lr=0.077842, time_each_step=1.29s, eta=6:18:39\n",
      "2022-01-20 12:21:41 [INFO]\t[TRAIN] Epoch=14/50, Step=214/478, loss=0.084575, lr=0.077835, time_each_step=1.29s, eta=6:18:53\n",
      "2022-01-20 12:21:44 [INFO]\t[TRAIN] Epoch=14/50, Step=216/478, loss=0.056146, lr=0.077828, time_each_step=1.29s, eta=6:18:56\n",
      "2022-01-20 12:21:46 [INFO]\t[TRAIN] Epoch=14/50, Step=218/478, loss=0.052435, lr=0.077821, time_each_step=1.29s, eta=6:18:37\n",
      "2022-01-20 12:21:49 [INFO]\t[TRAIN] Epoch=14/50, Step=220/478, loss=0.057838, lr=0.077814, time_each_step=1.29s, eta=6:20:10\n",
      "2022-01-20 12:21:52 [INFO]\t[TRAIN] Epoch=14/50, Step=222/478, loss=0.067950, lr=0.077807, time_each_step=1.29s, eta=6:18:58\n",
      "2022-01-20 12:21:54 [INFO]\t[TRAIN] Epoch=14/50, Step=224/478, loss=0.063761, lr=0.077799, time_each_step=1.29s, eta=6:18:39\n",
      "2022-01-20 12:21:57 [INFO]\t[TRAIN] Epoch=14/50, Step=226/478, loss=0.075183, lr=0.077792, time_each_step=1.29s, eta=6:18:31\n",
      "2022-01-20 12:21:59 [INFO]\t[TRAIN] Epoch=14/50, Step=228/478, loss=0.055402, lr=0.077785, time_each_step=1.29s, eta=6:18:12\n",
      "2022-01-20 12:22:02 [INFO]\t[TRAIN] Epoch=14/50, Step=230/478, loss=0.086706, lr=0.077778, time_each_step=1.28s, eta=6:18:3\n",
      "2022-01-20 12:22:04 [INFO]\t[TRAIN] Epoch=14/50, Step=232/478, loss=0.068887, lr=0.077771, time_each_step=1.29s, eta=6:18:28\n",
      "2022-01-20 12:22:07 [INFO]\t[TRAIN] Epoch=14/50, Step=234/478, loss=0.057468, lr=0.077764, time_each_step=1.28s, eta=6:17:51\n",
      "2022-01-20 12:22:10 [INFO]\t[TRAIN] Epoch=14/50, Step=236/478, loss=0.070871, lr=0.077757, time_each_step=1.28s, eta=6:17:34\n",
      "2022-01-20 12:22:12 [INFO]\t[TRAIN] Epoch=14/50, Step=238/478, loss=0.064830, lr=0.077750, time_each_step=1.29s, eta=6:18:21\n",
      "2022-01-20 12:22:15 [INFO]\t[TRAIN] Epoch=14/50, Step=240/478, loss=0.074281, lr=0.077742, time_each_step=1.29s, eta=6:17:51\n",
      "2022-01-20 12:22:17 [INFO]\t[TRAIN] Epoch=14/50, Step=242/478, loss=0.084070, lr=0.077735, time_each_step=1.29s, eta=6:17:54\n",
      "2022-01-20 12:22:20 [INFO]\t[TRAIN] Epoch=14/50, Step=244/478, loss=0.062387, lr=0.077728, time_each_step=1.29s, eta=6:18:43\n",
      "2022-01-20 12:22:22 [INFO]\t[TRAIN] Epoch=14/50, Step=246/478, loss=0.127334, lr=0.077721, time_each_step=1.29s, eta=6:17:46\n",
      "2022-01-20 12:22:25 [INFO]\t[TRAIN] Epoch=14/50, Step=248/478, loss=0.070218, lr=0.077714, time_each_step=1.28s, eta=6:17:28\n",
      "2022-01-20 12:22:28 [INFO]\t[TRAIN] Epoch=14/50, Step=250/478, loss=0.067454, lr=0.077707, time_each_step=1.29s, eta=6:19:2\n",
      "2022-01-20 12:22:30 [INFO]\t[TRAIN] Epoch=14/50, Step=252/478, loss=0.087530, lr=0.077700, time_each_step=1.28s, eta=6:17:17\n",
      "2022-01-20 12:22:33 [INFO]\t[TRAIN] Epoch=14/50, Step=254/478, loss=0.098615, lr=0.077693, time_each_step=1.29s, eta=6:17:51\n",
      "2022-01-20 12:22:35 [INFO]\t[TRAIN] Epoch=14/50, Step=256/478, loss=0.074739, lr=0.077685, time_each_step=1.29s, eta=6:18:41\n",
      "2022-01-20 12:22:38 [INFO]\t[TRAIN] Epoch=14/50, Step=258/478, loss=0.047084, lr=0.077678, time_each_step=1.28s, eta=6:16:51\n",
      "2022-01-20 12:22:40 [INFO]\t[TRAIN] Epoch=14/50, Step=260/478, loss=0.063914, lr=0.077671, time_each_step=1.29s, eta=6:18:17\n",
      "2022-01-20 12:22:43 [INFO]\t[TRAIN] Epoch=14/50, Step=262/478, loss=0.062689, lr=0.077664, time_each_step=1.29s, eta=6:18:19\n",
      "2022-01-20 12:22:46 [INFO]\t[TRAIN] Epoch=14/50, Step=264/478, loss=0.104254, lr=0.077657, time_each_step=1.28s, eta=6:16:41\n",
      "2022-01-20 12:22:48 [INFO]\t[TRAIN] Epoch=14/50, Step=266/478, loss=0.056529, lr=0.077650, time_each_step=1.29s, eta=6:17:26\n",
      "2022-01-20 12:22:51 [INFO]\t[TRAIN] Epoch=14/50, Step=268/478, loss=0.110197, lr=0.077643, time_each_step=1.29s, eta=6:18:34\n",
      "2022-01-20 12:22:53 [INFO]\t[TRAIN] Epoch=14/50, Step=270/478, loss=0.059824, lr=0.077636, time_each_step=1.29s, eta=6:17:31\n",
      "2022-01-20 12:22:56 [INFO]\t[TRAIN] Epoch=14/50, Step=272/478, loss=0.044041, lr=0.077628, time_each_step=1.29s, eta=6:17:55\n",
      "2022-01-20 12:22:58 [INFO]\t[TRAIN] Epoch=14/50, Step=274/478, loss=0.055268, lr=0.077621, time_each_step=1.29s, eta=6:18:10\n",
      "2022-01-20 12:23:01 [INFO]\t[TRAIN] Epoch=14/50, Step=276/478, loss=0.071719, lr=0.077614, time_each_step=1.29s, eta=6:17:51\n",
      "2022-01-20 12:23:04 [INFO]\t[TRAIN] Epoch=14/50, Step=278/478, loss=0.081354, lr=0.077607, time_each_step=1.29s, eta=6:17:23\n",
      "2022-01-20 12:23:06 [INFO]\t[TRAIN] Epoch=14/50, Step=280/478, loss=0.059619, lr=0.077600, time_each_step=1.29s, eta=6:17:41\n",
      "2022-01-20 12:23:09 [INFO]\t[TRAIN] Epoch=14/50, Step=282/478, loss=0.062211, lr=0.077593, time_each_step=1.28s, eta=6:16:20\n",
      "2022-01-20 12:23:11 [INFO]\t[TRAIN] Epoch=14/50, Step=284/478, loss=0.066846, lr=0.077586, time_each_step=1.29s, eta=6:17:21\n",
      "2022-01-20 12:23:14 [INFO]\t[TRAIN] Epoch=14/50, Step=286/478, loss=0.064859, lr=0.077578, time_each_step=1.29s, eta=6:17:37\n",
      "2022-01-20 12:23:16 [INFO]\t[TRAIN] Epoch=14/50, Step=288/478, loss=0.060169, lr=0.077571, time_each_step=1.29s, eta=6:17:12\n",
      "2022-01-20 12:23:19 [INFO]\t[TRAIN] Epoch=14/50, Step=290/478, loss=0.079555, lr=0.077564, time_each_step=1.28s, eta=6:16:42\n",
      "2022-01-20 12:23:22 [INFO]\t[TRAIN] Epoch=14/50, Step=292/478, loss=0.083622, lr=0.077557, time_each_step=1.29s, eta=6:18:25\n",
      "2022-01-20 12:23:24 [INFO]\t[TRAIN] Epoch=14/50, Step=294/478, loss=0.072960, lr=0.077550, time_each_step=1.28s, eta=6:16:12\n",
      "2022-01-20 12:23:27 [INFO]\t[TRAIN] Epoch=14/50, Step=296/478, loss=0.069041, lr=0.077543, time_each_step=1.29s, eta=6:17:26\n",
      "2022-01-20 12:23:29 [INFO]\t[TRAIN] Epoch=14/50, Step=298/478, loss=0.058392, lr=0.077536, time_each_step=1.29s, eta=6:19:18\n",
      "2022-01-20 12:23:32 [INFO]\t[TRAIN] Epoch=14/50, Step=300/478, loss=0.082590, lr=0.077529, time_each_step=1.28s, eta=6:16:16\n",
      "2022-01-20 12:23:34 [INFO]\t[TRAIN] Epoch=14/50, Step=302/478, loss=0.049055, lr=0.077521, time_each_step=1.29s, eta=6:16:53\n",
      "2022-01-20 12:23:37 [INFO]\t[TRAIN] Epoch=14/50, Step=304/478, loss=0.100215, lr=0.077514, time_each_step=1.29s, eta=6:17:53\n",
      "2022-01-20 12:23:40 [INFO]\t[TRAIN] Epoch=14/50, Step=306/478, loss=0.057856, lr=0.077507, time_each_step=1.28s, eta=6:16:14\n",
      "2022-01-20 12:23:42 [INFO]\t[TRAIN] Epoch=14/50, Step=308/478, loss=0.090401, lr=0.077500, time_each_step=1.29s, eta=6:17:12\n",
      "2022-01-20 12:23:45 [INFO]\t[TRAIN] Epoch=14/50, Step=310/478, loss=0.042684, lr=0.077493, time_each_step=1.29s, eta=6:17:4\n",
      "2022-01-20 12:23:47 [INFO]\t[TRAIN] Epoch=14/50, Step=312/478, loss=0.064579, lr=0.077486, time_each_step=1.28s, eta=6:16:6\n",
      "2022-01-20 12:23:50 [INFO]\t[TRAIN] Epoch=14/50, Step=314/478, loss=0.059558, lr=0.077479, time_each_step=1.29s, eta=6:16:21\n",
      "2022-01-20 12:23:53 [INFO]\t[TRAIN] Epoch=14/50, Step=316/478, loss=0.094375, lr=0.077471, time_each_step=1.29s, eta=6:17:54\n",
      "2022-01-20 12:23:55 [INFO]\t[TRAIN] Epoch=14/50, Step=318/478, loss=0.088596, lr=0.077464, time_each_step=1.28s, eta=6:15:56\n",
      "2022-01-20 12:23:58 [INFO]\t[TRAIN] Epoch=14/50, Step=320/478, loss=0.061021, lr=0.077457, time_each_step=1.29s, eta=6:16:53\n",
      "2022-01-20 12:24:00 [INFO]\t[TRAIN] Epoch=14/50, Step=322/478, loss=0.049122, lr=0.077450, time_each_step=1.29s, eta=6:17:8\n",
      "2022-01-20 12:24:03 [INFO]\t[TRAIN] Epoch=14/50, Step=324/478, loss=0.084348, lr=0.077443, time_each_step=1.28s, eta=6:15:32\n",
      "2022-01-20 12:24:05 [INFO]\t[TRAIN] Epoch=14/50, Step=326/478, loss=0.049346, lr=0.077436, time_each_step=1.29s, eta=6:16:39\n",
      "2022-01-20 12:24:08 [INFO]\t[TRAIN] Epoch=14/50, Step=328/478, loss=0.112972, lr=0.077429, time_each_step=1.29s, eta=6:17:11\n",
      "2022-01-20 12:24:11 [INFO]\t[TRAIN] Epoch=14/50, Step=330/478, loss=0.111426, lr=0.077421, time_each_step=1.28s, eta=6:15:37\n",
      "2022-01-20 12:24:13 [INFO]\t[TRAIN] Epoch=14/50, Step=332/478, loss=0.062822, lr=0.077414, time_each_step=1.29s, eta=6:17:32\n",
      "2022-01-20 12:24:16 [INFO]\t[TRAIN] Epoch=14/50, Step=334/478, loss=0.083228, lr=0.077407, time_each_step=1.29s, eta=6:16:49\n",
      "2022-01-20 12:24:18 [INFO]\t[TRAIN] Epoch=14/50, Step=336/478, loss=0.102195, lr=0.077400, time_each_step=1.29s, eta=6:16:43\n",
      "2022-01-20 12:24:21 [INFO]\t[TRAIN] Epoch=14/50, Step=338/478, loss=0.080608, lr=0.077393, time_each_step=1.29s, eta=6:16:10\n",
      "2022-01-20 12:24:23 [INFO]\t[TRAIN] Epoch=14/50, Step=340/478, loss=0.083270, lr=0.077386, time_each_step=1.29s, eta=6:16:10\n",
      "2022-01-20 12:24:26 [INFO]\t[TRAIN] Epoch=14/50, Step=342/478, loss=0.064369, lr=0.077379, time_each_step=1.29s, eta=6:15:52\n",
      "2022-01-20 12:24:29 [INFO]\t[TRAIN] Epoch=14/50, Step=344/478, loss=0.068785, lr=0.077372, time_each_step=1.29s, eta=6:16:27\n",
      "2022-01-20 12:24:31 [INFO]\t[TRAIN] Epoch=14/50, Step=346/478, loss=0.061526, lr=0.077364, time_each_step=1.28s, eta=6:15:28\n",
      "2022-01-20 12:24:34 [INFO]\t[TRAIN] Epoch=14/50, Step=348/478, loss=0.076633, lr=0.077357, time_each_step=1.29s, eta=6:15:48\n",
      "2022-01-20 12:24:36 [INFO]\t[TRAIN] Epoch=14/50, Step=350/478, loss=0.080672, lr=0.077350, time_each_step=1.29s, eta=6:16:29\n",
      "2022-01-20 12:24:39 [INFO]\t[TRAIN] Epoch=14/50, Step=352/478, loss=0.078569, lr=0.077343, time_each_step=1.29s, eta=6:16:2\n",
      "2022-01-20 12:24:41 [INFO]\t[TRAIN] Epoch=14/50, Step=354/478, loss=0.049871, lr=0.077336, time_each_step=1.28s, eta=6:15:18\n",
      "2022-01-20 12:24:44 [INFO]\t[TRAIN] Epoch=14/50, Step=356/478, loss=0.078197, lr=0.077329, time_each_step=1.28s, eta=6:15:12\n",
      "2022-01-20 12:24:47 [INFO]\t[TRAIN] Epoch=14/50, Step=358/478, loss=0.067376, lr=0.077322, time_each_step=1.29s, eta=6:15:49\n",
      "2022-01-20 12:24:49 [INFO]\t[TRAIN] Epoch=14/50, Step=360/478, loss=0.069489, lr=0.077314, time_each_step=1.29s, eta=6:15:25\n",
      "2022-01-20 12:24:52 [INFO]\t[TRAIN] Epoch=14/50, Step=362/478, loss=0.075260, lr=0.077307, time_each_step=1.29s, eta=6:15:34\n",
      "2022-01-20 12:24:54 [INFO]\t[TRAIN] Epoch=14/50, Step=364/478, loss=0.093741, lr=0.077300, time_each_step=1.29s, eta=6:15:41\n",
      "2022-01-20 12:24:57 [INFO]\t[TRAIN] Epoch=14/50, Step=366/478, loss=0.057554, lr=0.077293, time_each_step=1.29s, eta=6:15:36\n",
      "2022-01-20 12:24:59 [INFO]\t[TRAIN] Epoch=14/50, Step=368/478, loss=0.057494, lr=0.077286, time_each_step=1.29s, eta=6:15:49\n",
      "2022-01-20 12:25:02 [INFO]\t[TRAIN] Epoch=14/50, Step=370/478, loss=0.102546, lr=0.077279, time_each_step=1.29s, eta=6:15:38\n",
      "2022-01-20 12:25:05 [INFO]\t[TRAIN] Epoch=14/50, Step=372/478, loss=0.051390, lr=0.077272, time_each_step=1.28s, eta=6:14:51\n",
      "2022-01-20 12:25:07 [INFO]\t[TRAIN] Epoch=14/50, Step=374/478, loss=0.062347, lr=0.077264, time_each_step=1.29s, eta=6:16:17\n",
      "2022-01-20 12:25:10 [INFO]\t[TRAIN] Epoch=14/50, Step=376/478, loss=0.071845, lr=0.077257, time_each_step=1.29s, eta=6:15:35\n",
      "2022-01-20 12:25:12 [INFO]\t[TRAIN] Epoch=14/50, Step=378/478, loss=0.061425, lr=0.077250, time_each_step=1.29s, eta=6:15:39\n",
      "2022-01-20 12:25:15 [INFO]\t[TRAIN] Epoch=14/50, Step=380/478, loss=0.078756, lr=0.077243, time_each_step=1.29s, eta=6:15:55\n",
      "2022-01-20 12:25:17 [INFO]\t[TRAIN] Epoch=14/50, Step=382/478, loss=0.051078, lr=0.077236, time_each_step=1.28s, eta=6:14:30\n",
      "2022-01-20 12:25:20 [INFO]\t[TRAIN] Epoch=14/50, Step=384/478, loss=0.079466, lr=0.077229, time_each_step=1.28s, eta=6:14:30\n",
      "2022-01-20 12:25:23 [INFO]\t[TRAIN] Epoch=14/50, Step=386/478, loss=0.055538, lr=0.077222, time_each_step=1.29s, eta=6:15:8\n",
      "2022-01-20 12:25:25 [INFO]\t[TRAIN] Epoch=14/50, Step=388/478, loss=0.040956, lr=0.077214, time_each_step=1.28s, eta=6:14:37\n",
      "2022-01-20 12:25:28 [INFO]\t[TRAIN] Epoch=14/50, Step=390/478, loss=0.066797, lr=0.077207, time_each_step=1.28s, eta=6:14:27\n",
      "2022-01-20 12:25:30 [INFO]\t[TRAIN] Epoch=14/50, Step=392/478, loss=0.105798, lr=0.077200, time_each_step=1.29s, eta=6:15:18\n",
      "2022-01-20 12:25:33 [INFO]\t[TRAIN] Epoch=14/50, Step=394/478, loss=0.052181, lr=0.077193, time_each_step=1.28s, eta=6:14:24\n",
      "2022-01-20 12:25:35 [INFO]\t[TRAIN] Epoch=14/50, Step=396/478, loss=0.078685, lr=0.077186, time_each_step=1.29s, eta=6:15:16\n",
      "2022-01-20 12:25:38 [INFO]\t[TRAIN] Epoch=14/50, Step=398/478, loss=0.066979, lr=0.077179, time_each_step=1.29s, eta=6:15:29\n",
      "2022-01-20 12:25:41 [INFO]\t[TRAIN] Epoch=14/50, Step=400/478, loss=0.070775, lr=0.077172, time_each_step=1.28s, eta=6:14:13\n",
      "2022-01-20 12:25:43 [INFO]\t[TRAIN] Epoch=14/50, Step=402/478, loss=0.056302, lr=0.077164, time_each_step=1.28s, eta=6:14:18\n",
      "2022-01-20 12:25:46 [INFO]\t[TRAIN] Epoch=14/50, Step=404/478, loss=0.067623, lr=0.077157, time_each_step=1.29s, eta=6:15:38\n",
      "2022-01-20 12:25:48 [INFO]\t[TRAIN] Epoch=14/50, Step=406/478, loss=0.068510, lr=0.077150, time_each_step=1.28s, eta=6:14:8\n",
      "2022-01-20 12:25:51 [INFO]\t[TRAIN] Epoch=14/50, Step=408/478, loss=0.097093, lr=0.077143, time_each_step=1.29s, eta=6:14:25\n",
      "2022-01-20 12:25:53 [INFO]\t[TRAIN] Epoch=14/50, Step=410/478, loss=0.084032, lr=0.077136, time_each_step=1.29s, eta=6:15:35\n",
      "2022-01-20 12:25:56 [INFO]\t[TRAIN] Epoch=14/50, Step=412/478, loss=0.096474, lr=0.077129, time_each_step=1.28s, eta=6:13:20\n",
      "2022-01-20 12:25:59 [INFO]\t[TRAIN] Epoch=14/50, Step=414/478, loss=0.068939, lr=0.077122, time_each_step=1.29s, eta=6:14:12\n",
      "2022-01-20 12:26:01 [INFO]\t[TRAIN] Epoch=14/50, Step=416/478, loss=0.070919, lr=0.077114, time_each_step=1.29s, eta=6:14:27\n",
      "2022-01-20 12:26:04 [INFO]\t[TRAIN] Epoch=14/50, Step=418/478, loss=0.047450, lr=0.077107, time_each_step=1.29s, eta=6:14:28\n",
      "2022-01-20 12:26:06 [INFO]\t[TRAIN] Epoch=14/50, Step=420/478, loss=0.089795, lr=0.077100, time_each_step=1.29s, eta=6:14:17\n",
      "2022-01-20 12:26:09 [INFO]\t[TRAIN] Epoch=14/50, Step=422/478, loss=0.085099, lr=0.077093, time_each_step=1.29s, eta=6:14:2\n",
      "2022-01-20 12:26:11 [INFO]\t[TRAIN] Epoch=14/50, Step=424/478, loss=0.102103, lr=0.077086, time_each_step=1.29s, eta=6:14:38\n",
      "2022-01-20 12:26:14 [INFO]\t[TRAIN] Epoch=14/50, Step=426/478, loss=0.048803, lr=0.077079, time_each_step=1.29s, eta=6:14:33\n",
      "2022-01-20 12:26:17 [INFO]\t[TRAIN] Epoch=14/50, Step=428/478, loss=0.052185, lr=0.077072, time_each_step=1.29s, eta=6:15:11\n",
      "2022-01-20 12:26:19 [INFO]\t[TRAIN] Epoch=14/50, Step=430/478, loss=0.064760, lr=0.077064, time_each_step=1.29s, eta=6:15:0\n",
      "2022-01-20 12:26:22 [INFO]\t[TRAIN] Epoch=14/50, Step=432/478, loss=0.059565, lr=0.077057, time_each_step=1.29s, eta=6:14:0\n",
      "2022-01-20 12:26:24 [INFO]\t[TRAIN] Epoch=14/50, Step=434/478, loss=0.092344, lr=0.077050, time_each_step=1.29s, eta=6:14:22\n",
      "2022-01-20 12:26:27 [INFO]\t[TRAIN] Epoch=14/50, Step=436/478, loss=0.119644, lr=0.077043, time_each_step=1.29s, eta=6:14:44\n",
      "2022-01-20 12:26:29 [INFO]\t[TRAIN] Epoch=14/50, Step=438/478, loss=0.067358, lr=0.077036, time_each_step=1.28s, eta=6:13:23\n",
      "2022-01-20 12:26:32 [INFO]\t[TRAIN] Epoch=14/50, Step=440/478, loss=0.056794, lr=0.077029, time_each_step=1.29s, eta=6:14:0\n",
      "2022-01-20 12:26:35 [INFO]\t[TRAIN] Epoch=14/50, Step=442/478, loss=0.055098, lr=0.077022, time_each_step=1.28s, eta=6:13:23\n",
      "2022-01-20 12:26:37 [INFO]\t[TRAIN] Epoch=14/50, Step=444/478, loss=0.068347, lr=0.077014, time_each_step=1.29s, eta=6:13:30\n",
      "2022-01-20 12:26:40 [INFO]\t[TRAIN] Epoch=14/50, Step=446/478, loss=0.090803, lr=0.077007, time_each_step=1.28s, eta=6:13:22\n",
      "2022-01-20 12:26:42 [INFO]\t[TRAIN] Epoch=14/50, Step=448/478, loss=0.079782, lr=0.077000, time_each_step=1.29s, eta=6:14:17\n",
      "2022-01-20 12:26:45 [INFO]\t[TRAIN] Epoch=14/50, Step=450/478, loss=0.060962, lr=0.076993, time_each_step=1.29s, eta=6:13:35\n",
      "2022-01-20 12:26:47 [INFO]\t[TRAIN] Epoch=14/50, Step=452/478, loss=0.050443, lr=0.076986, time_each_step=1.29s, eta=6:14:10\n",
      "2022-01-20 12:26:50 [INFO]\t[TRAIN] Epoch=14/50, Step=454/478, loss=0.088534, lr=0.076979, time_each_step=1.29s, eta=6:13:55\n",
      "2022-01-20 12:26:53 [INFO]\t[TRAIN] Epoch=14/50, Step=456/478, loss=0.082358, lr=0.076972, time_each_step=1.29s, eta=6:13:22\n",
      "2022-01-20 12:26:55 [INFO]\t[TRAIN] Epoch=14/50, Step=458/478, loss=0.080493, lr=0.076964, time_each_step=1.29s, eta=6:13:43\n",
      "2022-01-20 12:26:58 [INFO]\t[TRAIN] Epoch=14/50, Step=460/478, loss=0.079283, lr=0.076957, time_each_step=1.29s, eta=6:13:38\n",
      "2022-01-20 12:27:00 [INFO]\t[TRAIN] Epoch=14/50, Step=462/478, loss=0.046687, lr=0.076950, time_each_step=1.28s, eta=6:13:5\n",
      "2022-01-20 12:27:03 [INFO]\t[TRAIN] Epoch=14/50, Step=464/478, loss=0.053271, lr=0.076943, time_each_step=1.29s, eta=6:13:36\n",
      "2022-01-20 12:27:05 [INFO]\t[TRAIN] Epoch=14/50, Step=466/478, loss=0.070451, lr=0.076936, time_each_step=1.29s, eta=6:13:16\n",
      "2022-01-20 12:27:08 [INFO]\t[TRAIN] Epoch=14/50, Step=468/478, loss=0.064905, lr=0.076929, time_each_step=1.29s, eta=6:13:16\n",
      "2022-01-20 12:27:11 [INFO]\t[TRAIN] Epoch=14/50, Step=470/478, loss=0.060881, lr=0.076921, time_each_step=1.29s, eta=6:13:51\n",
      "2022-01-20 12:27:13 [INFO]\t[TRAIN] Epoch=14/50, Step=472/478, loss=0.078824, lr=0.076914, time_each_step=1.29s, eta=6:13:8\n",
      "2022-01-20 12:27:16 [INFO]\t[TRAIN] Epoch=14/50, Step=474/478, loss=0.047479, lr=0.076907, time_each_step=1.28s, eta=6:12:44\n",
      "2022-01-20 12:27:18 [INFO]\t[TRAIN] Epoch=14/50, Step=476/478, loss=0.061828, lr=0.076900, time_each_step=1.29s, eta=6:14:9\n",
      "2022-01-20 12:27:21 [INFO]\t[TRAIN] Epoch=14/50, Step=478/478, loss=0.074806, lr=0.076893, time_each_step=1.28s, eta=6:12:16\n",
      "2022-01-20 12:27:21 [INFO]\t[TRAIN] Epoch 14 finished, loss=0.068969086 .\n",
      "2022-01-20 12:27:21 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-01-20 12:27:21 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-01-20 12:27:27 [INFO]\t[EVAL] Finished, Epoch=14, miou=0.830626, category_iou=[0.9707767  0.7352376  0.78586274], oacc=0.972537, category_acc=[0.9853594  0.84306866 0.8795992 ], kappa=0.865889, category_F1-score=[0.9851717  0.84742011 0.88009312] .\n",
      "2022-01-20 12:27:27 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_13, miou=0.8400812745094299\n",
      "2022-01-20 12:27:28 [INFO]\tModel saved in model/deeplab_augument_alldata2/epoch_14.\n",
      "2022-01-20 12:27:32 [INFO]\t[TRAIN] Epoch=15/50, Step=2/478, loss=0.065440, lr=0.076886, time_each_step=2.04s, eta=9:48:8\n",
      "2022-01-20 12:27:35 [INFO]\t[TRAIN] Epoch=15/50, Step=4/478, loss=0.069223, lr=0.076879, time_each_step=1.29s, eta=6:13:21\n",
      "2022-01-20 12:27:37 [INFO]\t[TRAIN] Epoch=15/50, Step=6/478, loss=0.051675, lr=0.076871, time_each_step=1.28s, eta=6:11:51\n",
      "2022-01-20 12:27:40 [INFO]\t[TRAIN] Epoch=15/50, Step=8/478, loss=0.068073, lr=0.076864, time_each_step=1.28s, eta=6:11:10\n",
      "2022-01-20 12:27:42 [INFO]\t[TRAIN] Epoch=15/50, Step=10/478, loss=0.050219, lr=0.076857, time_each_step=1.29s, eta=6:12:9\n",
      "2022-01-20 12:27:45 [INFO]\t[TRAIN] Epoch=15/50, Step=12/478, loss=0.059895, lr=0.076850, time_each_step=1.28s, eta=6:11:48\n",
      "2022-01-20 12:27:47 [INFO]\t[TRAIN] Epoch=15/50, Step=14/478, loss=0.050842, lr=0.076843, time_each_step=1.29s, eta=6:12:22\n",
      "2022-01-20 12:27:50 [INFO]\t[TRAIN] Epoch=15/50, Step=16/478, loss=0.094502, lr=0.076836, time_each_step=1.29s, eta=6:12:33\n",
      "2022-01-20 12:27:53 [INFO]\t[TRAIN] Epoch=15/50, Step=18/478, loss=0.093638, lr=0.076829, time_each_step=1.29s, eta=6:12:9\n",
      "2022-01-20 12:27:55 [INFO]\t[TRAIN] Epoch=15/50, Step=20/478, loss=0.049140, lr=0.076821, time_each_step=1.28s, eta=6:11:26\n",
      "2022-01-20 12:27:58 [INFO]\t[TRAIN] Epoch=15/50, Step=22/478, loss=0.049959, lr=0.076814, time_each_step=1.29s, eta=6:12:0\n",
      "2022-01-20 12:28:00 [INFO]\t[TRAIN] Epoch=15/50, Step=24/478, loss=0.088643, lr=0.076807, time_each_step=1.29s, eta=6:12:9\n",
      "2022-01-20 12:28:03 [INFO]\t[TRAIN] Epoch=15/50, Step=26/478, loss=0.066122, lr=0.076800, time_each_step=1.29s, eta=6:12:1\n",
      "2022-01-20 12:28:05 [INFO]\t[TRAIN] Epoch=15/50, Step=28/478, loss=0.058861, lr=0.076793, time_each_step=1.29s, eta=6:11:47\n",
      "2022-01-20 12:28:08 [INFO]\t[TRAIN] Epoch=15/50, Step=30/478, loss=0.051609, lr=0.076786, time_each_step=1.29s, eta=6:12:4\n",
      "2022-01-20 12:28:11 [INFO]\t[TRAIN] Epoch=15/50, Step=32/478, loss=0.087759, lr=0.076778, time_each_step=1.29s, eta=6:11:44\n",
      "2022-01-20 12:28:13 [INFO]\t[TRAIN] Epoch=15/50, Step=34/478, loss=0.055614, lr=0.076771, time_each_step=1.28s, eta=6:11:15\n",
      "2022-01-20 12:28:16 [INFO]\t[TRAIN] Epoch=15/50, Step=36/478, loss=0.095794, lr=0.076764, time_each_step=1.29s, eta=6:11:54\n",
      "2022-01-20 12:28:18 [INFO]\t[TRAIN] Epoch=15/50, Step=38/478, loss=0.077815, lr=0.076757, time_each_step=1.28s, eta=6:10:54\n",
      "2022-01-20 12:28:21 [INFO]\t[TRAIN] Epoch=15/50, Step=40/478, loss=0.051916, lr=0.076750, time_each_step=1.28s, eta=6:11:15\n",
      "2022-01-20 12:28:23 [INFO]\t[TRAIN] Epoch=15/50, Step=42/478, loss=0.059573, lr=0.076743, time_each_step=1.29s, eta=6:12:2\n",
      "2022-01-20 12:28:26 [INFO]\t[TRAIN] Epoch=15/50, Step=44/478, loss=0.070467, lr=0.076736, time_each_step=1.28s, eta=6:10:3\n",
      "2022-01-20 12:28:29 [INFO]\t[TRAIN] Epoch=15/50, Step=46/478, loss=0.060217, lr=0.076728, time_each_step=1.29s, eta=6:11:56\n",
      "2022-01-20 12:28:31 [INFO]\t[TRAIN] Epoch=15/50, Step=48/478, loss=0.094691, lr=0.076721, time_each_step=1.29s, eta=6:12:59\n",
      "2022-01-20 12:28:34 [INFO]\t[TRAIN] Epoch=15/50, Step=50/478, loss=0.048745, lr=0.076714, time_each_step=1.28s, eta=6:10:57\n",
      "2022-01-20 12:28:36 [INFO]\t[TRAIN] Epoch=15/50, Step=52/478, loss=0.056768, lr=0.076707, time_each_step=1.29s, eta=6:11:16\n",
      "2022-01-20 12:28:39 [INFO]\t[TRAIN] Epoch=15/50, Step=54/478, loss=0.056564, lr=0.076700, time_each_step=1.28s, eta=6:11:4\n",
      "2022-01-20 12:28:41 [INFO]\t[TRAIN] Epoch=15/50, Step=56/478, loss=0.071848, lr=0.076693, time_each_step=1.28s, eta=6:10:49\n",
      "2022-01-20 12:28:44 [INFO]\t[TRAIN] Epoch=15/50, Step=58/478, loss=0.042359, lr=0.076685, time_each_step=1.29s, eta=6:11:34\n",
      "2022-01-20 12:28:47 [INFO]\t[TRAIN] Epoch=15/50, Step=60/478, loss=0.079764, lr=0.076678, time_each_step=1.29s, eta=6:11:26\n",
      "2022-01-20 12:28:49 [INFO]\t[TRAIN] Epoch=15/50, Step=62/478, loss=0.051815, lr=0.076671, time_each_step=1.28s, eta=6:10:54\n",
      "2022-01-20 12:28:52 [INFO]\t[TRAIN] Epoch=15/50, Step=64/478, loss=0.061115, lr=0.076664, time_each_step=1.28s, eta=6:10:38\n",
      "2022-01-20 12:28:54 [INFO]\t[TRAIN] Epoch=15/50, Step=66/478, loss=0.086427, lr=0.076657, time_each_step=1.29s, eta=6:11:44\n",
      "2022-01-20 12:28:57 [INFO]\t[TRAIN] Epoch=15/50, Step=68/478, loss=0.062289, lr=0.076650, time_each_step=1.28s, eta=6:10:34\n",
      "2022-01-20 12:28:59 [INFO]\t[TRAIN] Epoch=15/50, Step=70/478, loss=0.052693, lr=0.076643, time_each_step=1.28s, eta=6:10:39\n",
      "2022-01-20 12:29:02 [INFO]\t[TRAIN] Epoch=15/50, Step=72/478, loss=0.103890, lr=0.076635, time_each_step=1.29s, eta=6:11:26\n",
      "2022-01-20 12:29:05 [INFO]\t[TRAIN] Epoch=15/50, Step=74/478, loss=0.076535, lr=0.076628, time_each_step=1.28s, eta=6:10:19\n",
      "2022-01-20 12:29:07 [INFO]\t[TRAIN] Epoch=15/50, Step=76/478, loss=0.098741, lr=0.076621, time_each_step=1.29s, eta=6:10:54\n",
      "2022-01-20 12:29:10 [INFO]\t[TRAIN] Epoch=15/50, Step=78/478, loss=0.067241, lr=0.076614, time_each_step=1.29s, eta=6:11:47\n",
      "2022-01-20 12:29:12 [INFO]\t[TRAIN] Epoch=15/50, Step=80/478, loss=0.063012, lr=0.076607, time_each_step=1.28s, eta=6:10:17\n",
      "2022-01-20 12:29:15 [INFO]\t[TRAIN] Epoch=15/50, Step=82/478, loss=0.096522, lr=0.076600, time_each_step=1.29s, eta=6:10:58\n",
      "2022-01-20 12:29:17 [INFO]\t[TRAIN] Epoch=15/50, Step=84/478, loss=0.060948, lr=0.076592, time_each_step=1.29s, eta=6:10:40\n",
      "2022-01-20 12:29:20 [INFO]\t[TRAIN] Epoch=15/50, Step=86/478, loss=0.077554, lr=0.076585, time_each_step=1.29s, eta=6:10:45\n",
      "2022-01-20 12:29:23 [INFO]\t[TRAIN] Epoch=15/50, Step=88/478, loss=0.079606, lr=0.076578, time_each_step=1.29s, eta=6:10:28\n",
      "2022-01-20 12:29:25 [INFO]\t[TRAIN] Epoch=15/50, Step=90/478, loss=0.084676, lr=0.076571, time_each_step=1.29s, eta=6:11:37\n",
      "2022-01-20 12:29:28 [INFO]\t[TRAIN] Epoch=15/50, Step=92/478, loss=0.069922, lr=0.076564, time_each_step=1.28s, eta=6:10:8\n",
      "2022-01-20 12:29:30 [INFO]\t[TRAIN] Epoch=15/50, Step=94/478, loss=0.086928, lr=0.076557, time_each_step=1.29s, eta=6:10:50\n",
      "2022-01-20 12:29:33 [INFO]\t[TRAIN] Epoch=15/50, Step=96/478, loss=0.073734, lr=0.076550, time_each_step=1.29s, eta=6:11:41\n",
      "2022-01-20 12:29:36 [INFO]\t[TRAIN] Epoch=15/50, Step=98/478, loss=0.081573, lr=0.076542, time_each_step=1.28s, eta=6:10:0\n",
      "2022-01-20 12:29:38 [INFO]\t[TRAIN] Epoch=15/50, Step=100/478, loss=0.055029, lr=0.076535, time_each_step=1.29s, eta=6:10:29\n",
      "2022-01-20 12:29:41 [INFO]\t[TRAIN] Epoch=15/50, Step=102/478, loss=0.067423, lr=0.076528, time_each_step=1.29s, eta=6:10:53\n",
      "2022-01-20 12:29:43 [INFO]\t[TRAIN] Epoch=15/50, Step=104/478, loss=0.038297, lr=0.076521, time_each_step=1.29s, eta=6:10:31\n",
      "2022-01-20 12:29:46 [INFO]\t[TRAIN] Epoch=15/50, Step=106/478, loss=0.068135, lr=0.076514, time_each_step=1.29s, eta=6:10:19\n",
      "2022-01-20 12:29:48 [INFO]\t[TRAIN] Epoch=15/50, Step=108/478, loss=0.064784, lr=0.076507, time_each_step=1.29s, eta=6:10:46\n",
      "2022-01-20 12:29:51 [INFO]\t[TRAIN] Epoch=15/50, Step=110/478, loss=0.064554, lr=0.076499, time_each_step=1.29s, eta=6:10:17\n",
      "2022-01-20 12:29:54 [INFO]\t[TRAIN] Epoch=15/50, Step=112/478, loss=0.092880, lr=0.076492, time_each_step=1.28s, eta=6:9:47\n",
      "2022-01-20 12:29:56 [INFO]\t[TRAIN] Epoch=15/50, Step=114/478, loss=0.055120, lr=0.076485, time_each_step=1.29s, eta=6:10:50\n",
      "2022-01-20 12:29:59 [INFO]\t[TRAIN] Epoch=15/50, Step=116/478, loss=0.057899, lr=0.076478, time_each_step=1.28s, eta=6:9:24\n",
      "2022-01-20 12:30:01 [INFO]\t[TRAIN] Epoch=15/50, Step=118/478, loss=0.048007, lr=0.076471, time_each_step=1.29s, eta=6:10:23\n",
      "2022-01-20 12:30:04 [INFO]\t[TRAIN] Epoch=15/50, Step=120/478, loss=0.057719, lr=0.076464, time_each_step=1.29s, eta=6:10:41\n",
      "2022-01-20 12:30:06 [INFO]\t[TRAIN] Epoch=15/50, Step=122/478, loss=0.060656, lr=0.076456, time_each_step=1.28s, eta=6:9:4\n",
      "2022-01-20 12:30:09 [INFO]\t[TRAIN] Epoch=15/50, Step=124/478, loss=0.055465, lr=0.076449, time_each_step=1.29s, eta=6:9:51\n",
      "2022-01-20 12:30:12 [INFO]\t[TRAIN] Epoch=15/50, Step=126/478, loss=0.064105, lr=0.076442, time_each_step=1.29s, eta=6:10:15\n",
      "2022-01-20 12:30:14 [INFO]\t[TRAIN] Epoch=15/50, Step=128/478, loss=0.070109, lr=0.076435, time_each_step=1.29s, eta=6:9:39\n",
      "2022-01-20 12:30:17 [INFO]\t[TRAIN] Epoch=15/50, Step=130/478, loss=0.049095, lr=0.076428, time_each_step=1.29s, eta=6:9:51\n",
      "2022-01-20 12:30:19 [INFO]\t[TRAIN] Epoch=15/50, Step=132/478, loss=0.084991, lr=0.076421, time_each_step=1.29s, eta=6:9:28\n",
      "2022-01-20 12:30:22 [INFO]\t[TRAIN] Epoch=15/50, Step=134/478, loss=0.059747, lr=0.076414, time_each_step=1.28s, eta=6:8:36\n",
      "2022-01-20 12:30:24 [INFO]\t[TRAIN] Epoch=15/50, Step=136/478, loss=0.089697, lr=0.076406, time_each_step=1.29s, eta=6:9:44\n",
      "2022-01-20 12:30:27 [INFO]\t[TRAIN] Epoch=15/50, Step=138/478, loss=0.081856, lr=0.076399, time_each_step=1.29s, eta=6:9:54\n",
      "2022-01-20 12:30:30 [INFO]\t[TRAIN] Epoch=15/50, Step=140/478, loss=0.068001, lr=0.076392, time_each_step=1.29s, eta=6:9:55\n",
      "2022-01-20 12:30:32 [INFO]\t[TRAIN] Epoch=15/50, Step=142/478, loss=0.041906, lr=0.076385, time_each_step=1.29s, eta=6:9:24\n",
      "2022-01-20 12:30:35 [INFO]\t[TRAIN] Epoch=15/50, Step=144/478, loss=0.077563, lr=0.076378, time_each_step=1.29s, eta=6:9:57\n",
      "2022-01-20 12:30:37 [INFO]\t[TRAIN] Epoch=15/50, Step=146/478, loss=0.064724, lr=0.076371, time_each_step=1.29s, eta=6:9:55\n",
      "2022-01-20 12:30:40 [INFO]\t[TRAIN] Epoch=15/50, Step=148/478, loss=0.062721, lr=0.076363, time_each_step=1.29s, eta=6:10:1\n",
      "2022-01-20 12:30:42 [INFO]\t[TRAIN] Epoch=15/50, Step=150/478, loss=0.055916, lr=0.076356, time_each_step=1.29s, eta=6:9:14\n",
      "2022-01-20 12:30:45 [INFO]\t[TRAIN] Epoch=15/50, Step=152/478, loss=0.070711, lr=0.076349, time_each_step=1.29s, eta=6:9:21\n",
      "2022-01-20 12:30:48 [INFO]\t[TRAIN] Epoch=15/50, Step=154/478, loss=0.095584, lr=0.076342, time_each_step=1.29s, eta=6:9:57\n",
      "2022-01-20 12:30:50 [INFO]\t[TRAIN] Epoch=15/50, Step=156/478, loss=0.056190, lr=0.076335, time_each_step=1.29s, eta=6:9:18\n",
      "2022-01-20 12:30:53 [INFO]\t[TRAIN] Epoch=15/50, Step=158/478, loss=0.064941, lr=0.076328, time_each_step=1.29s, eta=6:8:52\n",
      "2022-01-20 12:30:55 [INFO]\t[TRAIN] Epoch=15/50, Step=160/478, loss=0.060219, lr=0.076320, time_each_step=1.29s, eta=6:9:3\n",
      "2022-01-20 12:30:58 [INFO]\t[TRAIN] Epoch=15/50, Step=162/478, loss=0.088197, lr=0.076313, time_each_step=1.29s, eta=6:9:20\n",
      "2022-01-20 12:31:00 [INFO]\t[TRAIN] Epoch=15/50, Step=164/478, loss=0.072862, lr=0.076306, time_each_step=1.28s, eta=6:8:38\n",
      "2022-01-20 12:31:03 [INFO]\t[TRAIN] Epoch=15/50, Step=166/478, loss=0.087124, lr=0.076299, time_each_step=1.28s, eta=6:8:35\n",
      "2022-01-20 12:31:06 [INFO]\t[TRAIN] Epoch=15/50, Step=168/478, loss=0.086171, lr=0.076292, time_each_step=1.29s, eta=6:9:11\n",
      "2022-01-20 12:31:08 [INFO]\t[TRAIN] Epoch=15/50, Step=170/478, loss=0.073132, lr=0.076285, time_each_step=1.29s, eta=6:9:6\n",
      "2022-01-20 12:31:11 [INFO]\t[TRAIN] Epoch=15/50, Step=172/478, loss=0.061870, lr=0.076277, time_each_step=1.28s, eta=6:8:28\n",
      "2022-01-20 12:31:13 [INFO]\t[TRAIN] Epoch=15/50, Step=174/478, loss=0.068754, lr=0.076270, time_each_step=1.29s, eta=6:9:34\n",
      "2022-01-20 12:31:16 [INFO]\t[TRAIN] Epoch=15/50, Step=176/478, loss=0.046743, lr=0.076263, time_each_step=1.29s, eta=6:8:35\n",
      "2022-01-20 12:31:18 [INFO]\t[TRAIN] Epoch=15/50, Step=178/478, loss=0.066509, lr=0.076256, time_each_step=1.28s, eta=6:8:9\n",
      "2022-01-20 12:31:21 [INFO]\t[TRAIN] Epoch=15/50, Step=180/478, loss=0.060207, lr=0.076249, time_each_step=1.29s, eta=6:9:28\n",
      "2022-01-20 12:31:24 [INFO]\t[TRAIN] Epoch=15/50, Step=182/478, loss=0.060358, lr=0.076242, time_each_step=1.28s, eta=6:7:55\n",
      "2022-01-20 12:31:26 [INFO]\t[TRAIN] Epoch=15/50, Step=184/478, loss=0.096117, lr=0.076234, time_each_step=1.29s, eta=6:8:55\n",
      "2022-01-20 12:31:29 [INFO]\t[TRAIN] Epoch=15/50, Step=186/478, loss=0.076342, lr=0.076227, time_each_step=1.29s, eta=6:10:2\n",
      "2022-01-20 12:31:31 [INFO]\t[TRAIN] Epoch=15/50, Step=188/478, loss=0.059747, lr=0.076220, time_each_step=1.29s, eta=6:8:19\n",
      "2022-01-20 12:31:34 [INFO]\t[TRAIN] Epoch=15/50, Step=190/478, loss=0.066071, lr=0.076213, time_each_step=1.29s, eta=6:8:27\n",
      "2022-01-20 12:31:36 [INFO]\t[TRAIN] Epoch=15/50, Step=192/478, loss=0.086084, lr=0.076206, time_each_step=1.29s, eta=6:8:52\n",
      "2022-01-20 12:31:39 [INFO]\t[TRAIN] Epoch=15/50, Step=194/478, loss=0.058556, lr=0.076199, time_each_step=1.28s, eta=6:7:43\n",
      "2022-01-20 12:31:42 [INFO]\t[TRAIN] Epoch=15/50, Step=196/478, loss=0.057038, lr=0.076191, time_each_step=1.29s, eta=6:8:9\n",
      "2022-01-20 12:31:44 [INFO]\t[TRAIN] Epoch=15/50, Step=198/478, loss=0.053469, lr=0.076184, time_each_step=1.29s, eta=6:9:2\n",
      "2022-01-20 12:31:47 [INFO]\t[TRAIN] Epoch=15/50, Step=200/478, loss=0.115017, lr=0.076177, time_each_step=1.29s, eta=6:8:24\n",
      "2022-01-20 12:31:49 [INFO]\t[TRAIN] Epoch=15/50, Step=202/478, loss=0.073169, lr=0.076170, time_each_step=1.29s, eta=6:8:47\n",
      "2022-01-20 12:31:52 [INFO]\t[TRAIN] Epoch=15/50, Step=204/478, loss=0.056058, lr=0.076163, time_each_step=1.29s, eta=6:9:45\n",
      "2022-01-20 12:31:54 [INFO]\t[TRAIN] Epoch=15/50, Step=206/478, loss=0.053184, lr=0.076156, time_each_step=1.29s, eta=6:7:54\n",
      "2022-01-20 12:31:57 [INFO]\t[TRAIN] Epoch=15/50, Step=208/478, loss=0.069245, lr=0.076148, time_each_step=1.28s, eta=6:7:35\n",
      "2022-01-20 12:32:00 [INFO]\t[TRAIN] Epoch=15/50, Step=210/478, loss=0.079446, lr=0.076141, time_each_step=1.29s, eta=6:9:19\n",
      "2022-01-20 12:32:02 [INFO]\t[TRAIN] Epoch=15/50, Step=212/478, loss=0.068739, lr=0.076134, time_each_step=1.28s, eta=6:7:18\n",
      "2022-01-20 12:32:05 [INFO]\t[TRAIN] Epoch=15/50, Step=214/478, loss=0.090288, lr=0.076127, time_each_step=1.29s, eta=6:8:31\n",
      "2022-01-20 12:32:07 [INFO]\t[TRAIN] Epoch=15/50, Step=216/478, loss=0.055743, lr=0.076120, time_each_step=1.29s, eta=6:9:5\n",
      "2022-01-20 12:32:10 [INFO]\t[TRAIN] Epoch=15/50, Step=218/478, loss=0.054203, lr=0.076113, time_each_step=1.28s, eta=6:6:48\n",
      "2022-01-20 12:32:12 [INFO]\t[TRAIN] Epoch=15/50, Step=220/478, loss=0.070467, lr=0.076105, time_each_step=1.29s, eta=6:7:50\n",
      "2022-01-20 12:32:15 [INFO]\t[TRAIN] Epoch=15/50, Step=222/478, loss=0.040639, lr=0.076098, time_each_step=1.29s, eta=6:8:3\n",
      "2022-01-20 12:32:18 [INFO]\t[TRAIN] Epoch=15/50, Step=224/478, loss=0.054646, lr=0.076091, time_each_step=1.28s, eta=6:7:18\n",
      "2022-01-20 12:32:20 [INFO]\t[TRAIN] Epoch=15/50, Step=226/478, loss=0.072277, lr=0.076084, time_each_step=1.29s, eta=6:8:24\n",
      "2022-01-20 12:32:23 [INFO]\t[TRAIN] Epoch=15/50, Step=228/478, loss=0.059608, lr=0.076077, time_each_step=1.29s, eta=6:8:35\n",
      "2022-01-20 12:32:25 [INFO]\t[TRAIN] Epoch=15/50, Step=230/478, loss=0.054682, lr=0.076070, time_each_step=1.28s, eta=6:6:51\n",
      "2022-01-20 12:32:28 [INFO]\t[TRAIN] Epoch=15/50, Step=232/478, loss=0.042260, lr=0.076062, time_each_step=1.29s, eta=6:8:37\n",
      "2022-01-20 12:32:30 [INFO]\t[TRAIN] Epoch=15/50, Step=234/478, loss=0.083917, lr=0.076055, time_each_step=1.29s, eta=6:8:22\n",
      "2022-01-20 12:32:33 [INFO]\t[TRAIN] Epoch=15/50, Step=236/478, loss=0.062367, lr=0.076048, time_each_step=1.29s, eta=6:7:18\n",
      "2022-01-20 12:32:36 [INFO]\t[TRAIN] Epoch=15/50, Step=238/478, loss=0.060714, lr=0.076041, time_each_step=1.29s, eta=6:7:59\n",
      "2022-01-20 12:32:38 [INFO]\t[TRAIN] Epoch=15/50, Step=240/478, loss=0.068008, lr=0.076034, time_each_step=1.28s, eta=6:7:3\n",
      "2022-01-20 12:32:41 [INFO]\t[TRAIN] Epoch=15/50, Step=242/478, loss=0.073932, lr=0.076027, time_each_step=1.29s, eta=6:7:27\n",
      "2022-01-20 12:32:43 [INFO]\t[TRAIN] Epoch=15/50, Step=244/478, loss=0.073783, lr=0.076019, time_each_step=1.29s, eta=6:7:44\n",
      "2022-01-20 12:32:46 [INFO]\t[TRAIN] Epoch=15/50, Step=246/478, loss=0.060022, lr=0.076012, time_each_step=1.29s, eta=6:7:27\n",
      "2022-01-20 12:32:48 [INFO]\t[TRAIN] Epoch=15/50, Step=248/478, loss=0.060906, lr=0.076005, time_each_step=1.29s, eta=6:7:8\n",
      "2022-01-20 12:32:51 [INFO]\t[TRAIN] Epoch=15/50, Step=250/478, loss=0.080069, lr=0.075998, time_each_step=1.29s, eta=6:8:27\n",
      "2022-01-20 12:32:54 [INFO]\t[TRAIN] Epoch=15/50, Step=252/478, loss=0.065679, lr=0.075991, time_each_step=1.29s, eta=6:7:28\n",
      "2022-01-20 12:32:56 [INFO]\t[TRAIN] Epoch=15/50, Step=254/478, loss=0.066781, lr=0.075984, time_each_step=1.29s, eta=6:7:6\n",
      "2022-01-20 12:32:59 [INFO]\t[TRAIN] Epoch=15/50, Step=256/478, loss=0.044314, lr=0.075976, time_each_step=1.29s, eta=6:8:27\n",
      "2022-01-20 12:33:01 [INFO]\t[TRAIN] Epoch=15/50, Step=258/478, loss=0.050116, lr=0.075969, time_each_step=1.29s, eta=6:7:14\n",
      "2022-01-20 12:33:04 [INFO]\t[TRAIN] Epoch=15/50, Step=260/478, loss=0.079671, lr=0.075962, time_each_step=1.29s, eta=6:7:9\n",
      "2022-01-20 12:33:07 [INFO]\t[TRAIN] Epoch=15/50, Step=262/478, loss=0.060276, lr=0.075955, time_each_step=1.29s, eta=6:8:20\n",
      "2022-01-20 12:33:09 [INFO]\t[TRAIN] Epoch=15/50, Step=264/478, loss=0.051086, lr=0.075948, time_each_step=1.28s, eta=6:6:28\n",
      "2022-01-20 12:33:12 [INFO]\t[TRAIN] Epoch=15/50, Step=266/478, loss=0.075320, lr=0.075941, time_each_step=1.28s, eta=6:6:32\n",
      "2022-01-20 12:33:14 [INFO]\t[TRAIN] Epoch=15/50, Step=268/478, loss=0.069992, lr=0.075933, time_each_step=1.29s, eta=6:7:25\n",
      "2022-01-20 12:33:17 [INFO]\t[TRAIN] Epoch=15/50, Step=270/478, loss=0.051700, lr=0.075926, time_each_step=1.28s, eta=6:6:11\n",
      "2022-01-20 12:33:19 [INFO]\t[TRAIN] Epoch=15/50, Step=272/478, loss=0.078557, lr=0.075919, time_each_step=1.29s, eta=6:6:31\n",
      "2022-01-20 12:33:22 [INFO]\t[TRAIN] Epoch=15/50, Step=274/478, loss=0.071244, lr=0.075912, time_each_step=1.29s, eta=6:8:21\n",
      "2022-01-20 12:33:25 [INFO]\t[TRAIN] Epoch=15/50, Step=276/478, loss=0.059113, lr=0.075905, time_each_step=1.29s, eta=6:6:28\n",
      "2022-01-20 12:33:27 [INFO]\t[TRAIN] Epoch=15/50, Step=278/478, loss=0.083242, lr=0.075898, time_each_step=1.29s, eta=6:6:47\n",
      "2022-01-20 12:33:30 [INFO]\t[TRAIN] Epoch=15/50, Step=280/478, loss=0.056189, lr=0.075890, time_each_step=1.29s, eta=6:7:36\n",
      "2022-01-20 12:33:32 [INFO]\t[TRAIN] Epoch=15/50, Step=282/478, loss=0.061500, lr=0.075883, time_each_step=1.28s, eta=6:6:2\n",
      "2022-01-20 12:33:35 [INFO]\t[TRAIN] Epoch=15/50, Step=284/478, loss=0.045411, lr=0.075876, time_each_step=1.29s, eta=6:7:23\n",
      "2022-01-20 12:33:37 [INFO]\t[TRAIN] Epoch=15/50, Step=286/478, loss=0.075945, lr=0.075869, time_each_step=1.29s, eta=6:7:41\n",
      "2022-01-20 12:33:40 [INFO]\t[TRAIN] Epoch=15/50, Step=288/478, loss=0.064607, lr=0.075862, time_each_step=1.29s, eta=6:7:1\n",
      "2022-01-20 12:33:43 [INFO]\t[TRAIN] Epoch=15/50, Step=290/478, loss=0.065692, lr=0.075855, time_each_step=1.29s, eta=6:6:49\n",
      "2022-01-20 12:33:45 [INFO]\t[TRAIN] Epoch=15/50, Step=292/478, loss=0.104684, lr=0.075847, time_each_step=1.29s, eta=6:6:11\n",
      "2022-01-20 12:33:48 [INFO]\t[TRAIN] Epoch=15/50, Step=294/478, loss=0.048800, lr=0.075840, time_each_step=1.28s, eta=6:5:37\n",
      "2022-01-20 12:33:50 [INFO]\t[TRAIN] Epoch=15/50, Step=296/478, loss=0.102744, lr=0.075833, time_each_step=1.29s, eta=6:6:39\n",
      "2022-01-20 12:33:53 [INFO]\t[TRAIN] Epoch=15/50, Step=298/478, loss=0.081262, lr=0.075826, time_each_step=1.29s, eta=6:6:20\n",
      "2022-01-20 12:33:55 [INFO]\t[TRAIN] Epoch=15/50, Step=300/478, loss=0.088840, lr=0.075819, time_each_step=1.29s, eta=6:5:57\n",
      "2022-01-20 12:33:58 [INFO]\t[TRAIN] Epoch=15/50, Step=302/478, loss=0.055851, lr=0.075811, time_each_step=1.29s, eta=6:6:16\n",
      "2022-01-20 12:34:01 [INFO]\t[TRAIN] Epoch=15/50, Step=304/478, loss=0.083753, lr=0.075804, time_each_step=1.29s, eta=6:6:15\n",
      "2022-01-20 12:34:03 [INFO]\t[TRAIN] Epoch=15/50, Step=306/478, loss=0.081828, lr=0.075797, time_each_step=1.29s, eta=6:6:36\n",
      "2022-01-20 12:34:06 [INFO]\t[TRAIN] Epoch=15/50, Step=308/478, loss=0.059850, lr=0.075790, time_each_step=1.29s, eta=6:7:0\n",
      "2022-01-20 12:34:08 [INFO]\t[TRAIN] Epoch=15/50, Step=310/478, loss=0.104452, lr=0.075783, time_each_step=1.29s, eta=6:6:12\n",
      "2022-01-20 12:34:11 [INFO]\t[TRAIN] Epoch=15/50, Step=312/478, loss=0.054123, lr=0.075776, time_each_step=1.28s, eta=6:5:24\n",
      "2022-01-20 12:34:13 [INFO]\t[TRAIN] Epoch=15/50, Step=314/478, loss=0.062887, lr=0.075768, time_each_step=1.29s, eta=6:6:41\n",
      "2022-01-20 12:34:16 [INFO]\t[TRAIN] Epoch=15/50, Step=316/478, loss=0.052177, lr=0.075761, time_each_step=1.29s, eta=6:5:41\n",
      "2022-01-20 12:34:19 [INFO]\t[TRAIN] Epoch=15/50, Step=318/478, loss=0.047264, lr=0.075754, time_each_step=1.29s, eta=6:5:41\n",
      "2022-01-20 12:34:21 [INFO]\t[TRAIN] Epoch=15/50, Step=320/478, loss=0.049808, lr=0.075747, time_each_step=1.29s, eta=6:6:17\n",
      "2022-01-20 12:34:24 [INFO]\t[TRAIN] Epoch=15/50, Step=322/478, loss=0.045625, lr=0.075740, time_each_step=1.28s, eta=6:4:37\n",
      "2022-01-20 12:34:26 [INFO]\t[TRAIN] Epoch=15/50, Step=324/478, loss=0.080466, lr=0.075733, time_each_step=1.29s, eta=6:5:31\n",
      "2022-01-20 12:34:29 [INFO]\t[TRAIN] Epoch=15/50, Step=326/478, loss=0.070627, lr=0.075725, time_each_step=1.29s, eta=6:5:57\n",
      "2022-01-20 12:34:31 [INFO]\t[TRAIN] Epoch=15/50, Step=328/478, loss=0.073036, lr=0.075718, time_each_step=1.29s, eta=6:5:40\n",
      "2022-01-20 12:34:34 [INFO]\t[TRAIN] Epoch=15/50, Step=330/478, loss=0.053722, lr=0.075711, time_each_step=1.29s, eta=6:5:54\n",
      "2022-01-20 12:34:37 [INFO]\t[TRAIN] Epoch=15/50, Step=332/478, loss=0.047963, lr=0.075704, time_each_step=1.29s, eta=6:5:24\n",
      "2022-01-20 12:34:39 [INFO]\t[TRAIN] Epoch=15/50, Step=334/478, loss=0.095117, lr=0.075697, time_each_step=1.29s, eta=6:5:19\n",
      "2022-01-20 12:34:42 [INFO]\t[TRAIN] Epoch=15/50, Step=336/478, loss=0.060246, lr=0.075689, time_each_step=1.29s, eta=6:5:10\n",
      "2022-01-20 12:34:44 [INFO]\t[TRAIN] Epoch=15/50, Step=338/478, loss=0.090747, lr=0.075682, time_each_step=1.29s, eta=6:5:26\n",
      "2022-01-20 12:34:47 [INFO]\t[TRAIN] Epoch=15/50, Step=340/478, loss=0.065876, lr=0.075675, time_each_step=1.28s, eta=6:4:47\n",
      "2022-01-20 12:34:49 [INFO]\t[TRAIN] Epoch=15/50, Step=342/478, loss=0.069500, lr=0.075668, time_each_step=1.29s, eta=6:5:17\n",
      "2022-01-20 12:34:52 [INFO]\t[TRAIN] Epoch=15/50, Step=344/478, loss=0.076344, lr=0.075661, time_each_step=1.29s, eta=6:6:2\n",
      "2022-01-20 12:34:55 [INFO]\t[TRAIN] Epoch=15/50, Step=346/478, loss=0.060070, lr=0.075654, time_each_step=1.29s, eta=6:4:55\n",
      "2022-01-20 12:34:57 [INFO]\t[TRAIN] Epoch=15/50, Step=348/478, loss=0.065516, lr=0.075646, time_each_step=1.28s, eta=6:4:36\n",
      "2022-01-20 12:35:00 [INFO]\t[TRAIN] Epoch=15/50, Step=350/478, loss=0.069818, lr=0.075639, time_each_step=1.29s, eta=6:4:49\n",
      "2022-01-20 12:35:02 [INFO]\t[TRAIN] Epoch=15/50, Step=352/478, loss=0.064752, lr=0.075632, time_each_step=1.28s, eta=6:4:40\n",
      "2022-01-20 12:35:05 [INFO]\t[TRAIN] Epoch=15/50, Step=354/478, loss=0.056320, lr=0.075625, time_each_step=1.29s, eta=6:5:1\n",
      "2022-01-20 12:35:07 [INFO]\t[TRAIN] Epoch=15/50, Step=356/478, loss=0.069244, lr=0.075618, time_each_step=1.29s, eta=6:5:19\n",
      "2022-01-20 12:35:10 [INFO]\t[TRAIN] Epoch=15/50, Step=358/478, loss=0.069789, lr=0.075611, time_each_step=1.29s, eta=6:5:15\n",
      "2022-01-20 12:35:13 [INFO]\t[TRAIN] Epoch=15/50, Step=360/478, loss=0.059433, lr=0.075603, time_each_step=1.29s, eta=6:5:17\n",
      "2022-01-20 12:35:15 [INFO]\t[TRAIN] Epoch=15/50, Step=362/478, loss=0.043673, lr=0.075596, time_each_step=1.29s, eta=6:5:46\n",
      "2022-01-20 12:35:18 [INFO]\t[TRAIN] Epoch=15/50, Step=364/478, loss=0.074154, lr=0.075589, time_each_step=1.29s, eta=6:4:35\n",
      "2022-01-20 12:35:20 [INFO]\t[TRAIN] Epoch=15/50, Step=366/478, loss=0.066876, lr=0.075582, time_each_step=1.29s, eta=6:5:38\n",
      "2022-01-20 12:35:23 [INFO]\t[TRAIN] Epoch=15/50, Step=368/478, loss=0.079881, lr=0.075575, time_each_step=1.29s, eta=6:5:7\n",
      "2022-01-20 12:35:25 [INFO]\t[TRAIN] Epoch=15/50, Step=370/478, loss=0.076782, lr=0.075567, time_each_step=1.29s, eta=6:4:42\n",
      "2022-01-20 12:35:28 [INFO]\t[TRAIN] Epoch=15/50, Step=372/478, loss=0.075950, lr=0.075560, time_each_step=1.29s, eta=6:4:26\n",
      "2022-01-20 12:35:31 [INFO]\t[TRAIN] Epoch=15/50, Step=374/478, loss=0.076507, lr=0.075553, time_each_step=1.29s, eta=6:4:51\n",
      "2022-01-20 12:35:33 [INFO]\t[TRAIN] Epoch=15/50, Step=376/478, loss=0.065213, lr=0.075546, time_each_step=1.29s, eta=6:4:14\n",
      "2022-01-20 12:35:36 [INFO]\t[TRAIN] Epoch=15/50, Step=378/478, loss=0.099043, lr=0.075539, time_each_step=1.28s, eta=6:3:28\n",
      "2022-01-20 12:35:38 [INFO]\t[TRAIN] Epoch=15/50, Step=380/478, loss=0.090538, lr=0.075532, time_each_step=1.29s, eta=6:4:44\n",
      "2022-01-20 12:35:41 [INFO]\t[TRAIN] Epoch=15/50, Step=382/478, loss=0.071376, lr=0.075524, time_each_step=1.28s, eta=6:3:51\n",
      "2022-01-20 12:35:43 [INFO]\t[TRAIN] Epoch=15/50, Step=384/478, loss=0.081740, lr=0.075517, time_each_step=1.29s, eta=6:4:10\n",
      "2022-01-20 12:35:46 [INFO]\t[TRAIN] Epoch=15/50, Step=386/478, loss=0.044433, lr=0.075510, time_each_step=1.29s, eta=6:4:19\n",
      "2022-01-20 12:35:49 [INFO]\t[TRAIN] Epoch=15/50, Step=388/478, loss=0.083787, lr=0.075503, time_each_step=1.29s, eta=6:4:9\n",
      "2022-01-20 12:35:51 [INFO]\t[TRAIN] Epoch=15/50, Step=390/478, loss=0.051045, lr=0.075496, time_each_step=1.29s, eta=6:4:5\n",
      "2022-01-20 12:35:54 [INFO]\t[TRAIN] Epoch=15/50, Step=392/478, loss=0.090659, lr=0.075488, time_each_step=1.29s, eta=6:4:48\n",
      "2022-01-20 12:35:56 [INFO]\t[TRAIN] Epoch=15/50, Step=394/478, loss=0.054362, lr=0.075481, time_each_step=1.28s, eta=6:3:40\n",
      "2022-01-20 12:35:59 [INFO]\t[TRAIN] Epoch=15/50, Step=396/478, loss=0.060850, lr=0.075474, time_each_step=1.28s, eta=6:3:35\n",
      "2022-01-20 12:36:01 [INFO]\t[TRAIN] Epoch=15/50, Step=398/478, loss=0.061263, lr=0.075467, time_each_step=1.29s, eta=6:5:0\n",
      "2022-01-20 12:36:04 [INFO]\t[TRAIN] Epoch=15/50, Step=400/478, loss=0.054688, lr=0.075460, time_each_step=1.29s, eta=6:3:42\n",
      "2022-01-20 12:36:07 [INFO]\t[TRAIN] Epoch=15/50, Step=402/478, loss=0.052496, lr=0.075453, time_each_step=1.29s, eta=6:4:1\n",
      "2022-01-20 12:36:09 [INFO]\t[TRAIN] Epoch=15/50, Step=404/478, loss=0.065834, lr=0.075445, time_each_step=1.29s, eta=6:5:1\n",
      "2022-01-20 12:36:12 [INFO]\t[TRAIN] Epoch=15/50, Step=406/478, loss=0.072945, lr=0.075438, time_each_step=1.29s, eta=6:3:52\n",
      "2022-01-20 12:36:14 [INFO]\t[TRAIN] Epoch=15/50, Step=408/478, loss=0.062646, lr=0.075431, time_each_step=1.29s, eta=6:4:2\n",
      "2022-01-20 12:36:17 [INFO]\t[TRAIN] Epoch=15/50, Step=410/478, loss=0.066761, lr=0.075424, time_each_step=1.29s, eta=6:4:47\n",
      "2022-01-20 12:36:20 [INFO]\t[TRAIN] Epoch=15/50, Step=412/478, loss=0.049658, lr=0.075417, time_each_step=1.29s, eta=6:4:36\n",
      "2022-01-20 12:36:22 [INFO]\t[TRAIN] Epoch=15/50, Step=414/478, loss=0.050030, lr=0.075409, time_each_step=1.29s, eta=6:4:7\n",
      "2022-01-20 12:36:25 [INFO]\t[TRAIN] Epoch=15/50, Step=416/478, loss=0.057921, lr=0.075402, time_each_step=1.29s, eta=6:4:14\n",
      "2022-01-20 12:36:27 [INFO]\t[TRAIN] Epoch=15/50, Step=418/478, loss=0.093531, lr=0.075395, time_each_step=1.28s, eta=6:3:6\n",
      "2022-01-20 12:36:30 [INFO]\t[TRAIN] Epoch=15/50, Step=420/478, loss=0.048005, lr=0.075388, time_each_step=1.28s, eta=6:3:3\n",
      "2022-01-20 12:36:32 [INFO]\t[TRAIN] Epoch=15/50, Step=422/478, loss=0.056982, lr=0.075381, time_each_step=1.29s, eta=6:3:44\n",
      "2022-01-20 12:36:35 [INFO]\t[TRAIN] Epoch=15/50, Step=424/478, loss=0.066105, lr=0.075374, time_each_step=1.29s, eta=6:3:37\n",
      "2022-01-20 12:36:38 [INFO]\t[TRAIN] Epoch=15/50, Step=426/478, loss=0.058868, lr=0.075366, time_each_step=1.29s, eta=6:3:21\n",
      "2022-01-20 12:36:40 [INFO]\t[TRAIN] Epoch=15/50, Step=428/478, loss=0.053013, lr=0.075359, time_each_step=1.29s, eta=6:4:9\n",
      "2022-01-20 12:36:43 [INFO]\t[TRAIN] Epoch=15/50, Step=430/478, loss=0.060756, lr=0.075352, time_each_step=1.29s, eta=6:3:45\n",
      "2022-01-20 12:36:45 [INFO]\t[TRAIN] Epoch=15/50, Step=432/478, loss=0.085214, lr=0.075345, time_each_step=1.29s, eta=6:3:13\n",
      "2022-01-20 12:36:48 [INFO]\t[TRAIN] Epoch=15/50, Step=434/478, loss=0.084833, lr=0.075338, time_each_step=1.29s, eta=6:4:20\n",
      "2022-01-20 12:36:50 [INFO]\t[TRAIN] Epoch=15/50, Step=436/478, loss=0.061760, lr=0.075330, time_each_step=1.28s, eta=6:2:29\n",
      "2022-01-20 12:36:53 [INFO]\t[TRAIN] Epoch=15/50, Step=438/478, loss=0.057545, lr=0.075323, time_each_step=1.29s, eta=6:3:40\n",
      "2022-01-20 12:36:56 [INFO]\t[TRAIN] Epoch=15/50, Step=440/478, loss=0.068521, lr=0.075316, time_each_step=1.29s, eta=6:4:41\n",
      "2022-01-20 12:36:58 [INFO]\t[TRAIN] Epoch=15/50, Step=442/478, loss=0.060608, lr=0.075309, time_each_step=1.29s, eta=6:3:32\n",
      "2022-01-20 12:37:01 [INFO]\t[TRAIN] Epoch=15/50, Step=444/478, loss=0.107312, lr=0.075302, time_each_step=1.29s, eta=6:4:22\n",
      "2022-01-20 12:37:03 [INFO]\t[TRAIN] Epoch=15/50, Step=446/478, loss=0.046923, lr=0.075294, time_each_step=1.29s, eta=6:3:1\n",
      "2022-01-20 12:37:06 [INFO]\t[TRAIN] Epoch=15/50, Step=448/478, loss=0.055413, lr=0.075287, time_each_step=1.29s, eta=6:3:10\n",
      "2022-01-20 12:37:08 [INFO]\t[TRAIN] Epoch=15/50, Step=450/478, loss=0.053850, lr=0.075280, time_each_step=1.29s, eta=6:2:52\n",
      "2022-01-20 12:37:11 [INFO]\t[TRAIN] Epoch=15/50, Step=452/478, loss=0.038164, lr=0.075273, time_each_step=1.29s, eta=6:2:47\n",
      "2022-01-20 12:37:14 [INFO]\t[TRAIN] Epoch=15/50, Step=454/478, loss=0.071949, lr=0.075266, time_each_step=1.28s, eta=6:2:15\n",
      "2022-01-20 12:37:16 [INFO]\t[TRAIN] Epoch=15/50, Step=456/478, loss=0.074874, lr=0.075259, time_each_step=1.29s, eta=6:3:34\n",
      "2022-01-20 12:37:19 [INFO]\t[TRAIN] Epoch=15/50, Step=458/478, loss=0.076881, lr=0.075251, time_each_step=1.28s, eta=6:2:16\n",
      "2022-01-20 12:37:21 [INFO]\t[TRAIN] Epoch=15/50, Step=460/478, loss=0.052638, lr=0.075244, time_each_step=1.29s, eta=6:3:12\n",
      "2022-01-20 12:37:24 [INFO]\t[TRAIN] Epoch=15/50, Step=462/478, loss=0.060071, lr=0.075237, time_each_step=1.29s, eta=6:3:22\n",
      "2022-01-20 12:37:26 [INFO]\t[TRAIN] Epoch=15/50, Step=464/478, loss=0.086854, lr=0.075230, time_each_step=1.29s, eta=6:2:23\n",
      "2022-01-20 12:37:29 [INFO]\t[TRAIN] Epoch=15/50, Step=466/478, loss=0.066703, lr=0.075223, time_each_step=1.29s, eta=6:2:55\n",
      "2022-01-20 12:37:32 [INFO]\t[TRAIN] Epoch=15/50, Step=468/478, loss=0.058850, lr=0.075215, time_each_step=1.29s, eta=6:3:11\n",
      "2022-01-20 12:37:34 [INFO]\t[TRAIN] Epoch=15/50, Step=470/478, loss=0.058402, lr=0.075208, time_each_step=1.29s, eta=6:2:11\n",
      "2022-01-20 12:37:37 [INFO]\t[TRAIN] Epoch=15/50, Step=472/478, loss=0.078303, lr=0.075201, time_each_step=1.29s, eta=6:2:58\n",
      "2022-01-20 12:37:39 [INFO]\t[TRAIN] Epoch=15/50, Step=474/478, loss=0.052715, lr=0.075194, time_each_step=1.29s, eta=6:3:32\n",
      "2022-01-20 12:37:42 [INFO]\t[TRAIN] Epoch=15/50, Step=476/478, loss=0.095084, lr=0.075187, time_each_step=1.28s, eta=6:1:43\n",
      "2022-01-20 12:37:44 [INFO]\t[TRAIN] Epoch=15/50, Step=478/478, loss=0.048446, lr=0.075179, time_each_step=1.28s, eta=6:1:52\n",
      "2022-01-20 12:37:45 [INFO]\t[TRAIN] Epoch 15 finished, loss=0.067562446 .\n",
      "2022-01-20 12:37:45 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-01-20 12:37:45 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-01-20 12:37:51 [INFO]\t[EVAL] Finished, Epoch=15, miou=0.836762, category_iou=[0.97083265 0.74447864 0.7949742 ], oacc=0.972903, category_acc=[0.9888933 0.8475414 0.8569557], kappa=0.870825, category_F1-score=[0.98520049 0.85352564 0.88577792] .\n",
      "2022-01-20 12:37:51 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_13, miou=0.8400812745094299\n",
      "2022-01-20 12:37:51 [INFO]\tModel saved in model/deeplab_augument_alldata2/epoch_15.\n",
      "2022-01-20 12:37:55 [INFO]\t[TRAIN] Epoch=16/50, Step=2/478, loss=0.040261, lr=0.075172, time_each_step=1.88s, eta=8:47:52\n",
      "2022-01-20 12:37:58 [INFO]\t[TRAIN] Epoch=16/50, Step=4/478, loss=0.063837, lr=0.075165, time_each_step=1.29s, eta=6:2:10\n",
      "2022-01-20 12:38:00 [INFO]\t[TRAIN] Epoch=16/50, Step=6/478, loss=0.071762, lr=0.075158, time_each_step=1.29s, eta=6:1:55\n",
      "2022-01-20 12:38:03 [INFO]\t[TRAIN] Epoch=16/50, Step=8/478, loss=0.091314, lr=0.075151, time_each_step=1.29s, eta=6:2:9\n",
      "2022-01-20 12:38:06 [INFO]\t[TRAIN] Epoch=16/50, Step=10/478, loss=0.068158, lr=0.075144, time_each_step=1.29s, eta=6:2:1\n",
      "2022-01-20 12:38:08 [INFO]\t[TRAIN] Epoch=16/50, Step=12/478, loss=0.043596, lr=0.075136, time_each_step=1.28s, eta=6:1:35\n",
      "2022-01-20 12:38:11 [INFO]\t[TRAIN] Epoch=16/50, Step=14/478, loss=0.066599, lr=0.075129, time_each_step=1.29s, eta=6:2:1\n",
      "2022-01-20 12:38:13 [INFO]\t[TRAIN] Epoch=16/50, Step=16/478, loss=0.077218, lr=0.075122, time_each_step=1.29s, eta=6:2:14\n",
      "2022-01-20 12:38:16 [INFO]\t[TRAIN] Epoch=16/50, Step=18/478, loss=0.081043, lr=0.075115, time_each_step=1.29s, eta=6:1:29\n",
      "2022-01-20 12:38:18 [INFO]\t[TRAIN] Epoch=16/50, Step=20/478, loss=0.058981, lr=0.075108, time_each_step=1.29s, eta=6:1:32\n",
      "2022-01-20 12:38:21 [INFO]\t[TRAIN] Epoch=16/50, Step=22/478, loss=0.064057, lr=0.075100, time_each_step=1.29s, eta=6:1:48\n",
      "2022-01-20 12:38:24 [INFO]\t[TRAIN] Epoch=16/50, Step=24/478, loss=0.056451, lr=0.075093, time_each_step=1.29s, eta=6:1:52\n",
      "2022-01-20 12:38:26 [INFO]\t[TRAIN] Epoch=16/50, Step=26/478, loss=0.098092, lr=0.075086, time_each_step=1.29s, eta=6:1:42\n",
      "2022-01-20 12:38:29 [INFO]\t[TRAIN] Epoch=16/50, Step=28/478, loss=0.071841, lr=0.075079, time_each_step=1.29s, eta=6:1:45\n",
      "2022-01-20 12:38:31 [INFO]\t[TRAIN] Epoch=16/50, Step=30/478, loss=0.065994, lr=0.075072, time_each_step=1.29s, eta=6:1:33\n",
      "2022-01-20 12:38:34 [INFO]\t[TRAIN] Epoch=16/50, Step=32/478, loss=0.049080, lr=0.075064, time_each_step=1.29s, eta=6:1:25\n",
      "2022-01-20 12:38:36 [INFO]\t[TRAIN] Epoch=16/50, Step=34/478, loss=0.067080, lr=0.075057, time_each_step=1.29s, eta=6:2:16\n",
      "2022-01-20 12:38:39 [INFO]\t[TRAIN] Epoch=16/50, Step=36/478, loss=0.069770, lr=0.075050, time_each_step=1.28s, eta=6:0:44\n",
      "2022-01-20 12:38:42 [INFO]\t[TRAIN] Epoch=16/50, Step=38/478, loss=0.071384, lr=0.075043, time_each_step=1.29s, eta=6:2:11\n",
      "2022-01-20 12:38:44 [INFO]\t[TRAIN] Epoch=16/50, Step=40/478, loss=0.048101, lr=0.075036, time_each_step=1.29s, eta=6:1:55\n",
      "2022-01-20 12:38:47 [INFO]\t[TRAIN] Epoch=16/50, Step=42/478, loss=0.055369, lr=0.075028, time_each_step=1.28s, eta=6:0:55\n",
      "2022-01-20 12:38:49 [INFO]\t[TRAIN] Epoch=16/50, Step=44/478, loss=0.059253, lr=0.075021, time_each_step=1.29s, eta=6:1:57\n",
      "2022-01-20 12:38:52 [INFO]\t[TRAIN] Epoch=16/50, Step=46/478, loss=0.061869, lr=0.075014, time_each_step=1.29s, eta=6:1:38\n",
      "2022-01-20 12:38:54 [INFO]\t[TRAIN] Epoch=16/50, Step=48/478, loss=0.072574, lr=0.075007, time_each_step=1.28s, eta=6:0:6\n",
      "2022-01-20 12:38:57 [INFO]\t[TRAIN] Epoch=16/50, Step=50/478, loss=0.049717, lr=0.075000, time_each_step=1.29s, eta=6:1:29\n",
      "2022-01-20 12:39:00 [INFO]\t[TRAIN] Epoch=16/50, Step=52/478, loss=0.042900, lr=0.074992, time_each_step=1.29s, eta=6:1:17\n",
      "2022-01-20 12:39:02 [INFO]\t[TRAIN] Epoch=16/50, Step=54/478, loss=0.076261, lr=0.074985, time_each_step=1.29s, eta=6:1:55\n",
      "2022-01-20 12:39:05 [INFO]\t[TRAIN] Epoch=16/50, Step=56/478, loss=0.082681, lr=0.074978, time_each_step=1.29s, eta=6:1:36\n",
      "2022-01-20 12:39:07 [INFO]\t[TRAIN] Epoch=16/50, Step=58/478, loss=0.041984, lr=0.074971, time_each_step=1.29s, eta=6:0:38\n",
      "2022-01-20 12:39:10 [INFO]\t[TRAIN] Epoch=16/50, Step=60/478, loss=0.051391, lr=0.074964, time_each_step=1.28s, eta=6:0:12\n",
      "2022-01-20 12:39:12 [INFO]\t[TRAIN] Epoch=16/50, Step=62/478, loss=0.065551, lr=0.074957, time_each_step=1.29s, eta=6:1:45\n",
      "2022-01-20 12:39:15 [INFO]\t[TRAIN] Epoch=16/50, Step=64/478, loss=0.065570, lr=0.074949, time_each_step=1.29s, eta=6:0:33\n",
      "2022-01-20 12:39:18 [INFO]\t[TRAIN] Epoch=16/50, Step=66/478, loss=0.075654, lr=0.074942, time_each_step=1.29s, eta=6:0:43\n",
      "2022-01-20 12:39:20 [INFO]\t[TRAIN] Epoch=16/50, Step=68/478, loss=0.061729, lr=0.074935, time_each_step=1.29s, eta=6:1:18\n",
      "2022-01-20 12:39:23 [INFO]\t[TRAIN] Epoch=16/50, Step=70/478, loss=0.069160, lr=0.074928, time_each_step=1.28s, eta=6:0:7\n",
      "2022-01-20 12:39:25 [INFO]\t[TRAIN] Epoch=16/50, Step=72/478, loss=0.066394, lr=0.074921, time_each_step=1.29s, eta=6:0:29\n",
      "2022-01-20 12:39:28 [INFO]\t[TRAIN] Epoch=16/50, Step=74/478, loss=0.059273, lr=0.074913, time_each_step=1.29s, eta=6:1:40\n",
      "2022-01-20 12:39:30 [INFO]\t[TRAIN] Epoch=16/50, Step=76/478, loss=0.060673, lr=0.074906, time_each_step=1.28s, eta=5:59:34\n",
      "2022-01-20 12:39:33 [INFO]\t[TRAIN] Epoch=16/50, Step=78/478, loss=0.061709, lr=0.074899, time_each_step=1.29s, eta=6:0:56\n",
      "2022-01-20 12:39:36 [INFO]\t[TRAIN] Epoch=16/50, Step=80/478, loss=0.081292, lr=0.074892, time_each_step=1.29s, eta=6:1:29\n",
      "2022-01-20 12:39:38 [INFO]\t[TRAIN] Epoch=16/50, Step=82/478, loss=0.074039, lr=0.074885, time_each_step=1.29s, eta=6:0:35\n",
      "2022-01-20 12:39:41 [INFO]\t[TRAIN] Epoch=16/50, Step=84/478, loss=0.077796, lr=0.074877, time_each_step=1.29s, eta=6:0:42\n",
      "2022-01-20 12:39:43 [INFO]\t[TRAIN] Epoch=16/50, Step=86/478, loss=0.080221, lr=0.074870, time_each_step=1.29s, eta=6:0:44\n",
      "2022-01-20 12:39:46 [INFO]\t[TRAIN] Epoch=16/50, Step=88/478, loss=0.078824, lr=0.074863, time_each_step=1.29s, eta=6:0:31\n",
      "2022-01-20 12:39:48 [INFO]\t[TRAIN] Epoch=16/50, Step=90/478, loss=0.095156, lr=0.074856, time_each_step=1.28s, eta=5:59:43\n",
      "2022-01-20 12:39:51 [INFO]\t[TRAIN] Epoch=16/50, Step=92/478, loss=0.076647, lr=0.074849, time_each_step=1.29s, eta=6:0:42\n",
      "2022-01-20 12:39:54 [INFO]\t[TRAIN] Epoch=16/50, Step=94/478, loss=0.070204, lr=0.074841, time_each_step=1.29s, eta=6:0:16\n",
      "2022-01-20 12:39:56 [INFO]\t[TRAIN] Epoch=16/50, Step=96/478, loss=0.086237, lr=0.074834, time_each_step=1.28s, eta=5:59:49\n",
      "2022-01-20 12:39:59 [INFO]\t[TRAIN] Epoch=16/50, Step=98/478, loss=0.097150, lr=0.074827, time_each_step=1.29s, eta=6:0:59\n",
      "2022-01-20 12:40:01 [INFO]\t[TRAIN] Epoch=16/50, Step=100/478, loss=0.060640, lr=0.074820, time_each_step=1.28s, eta=5:59:40\n",
      "2022-01-20 12:40:04 [INFO]\t[TRAIN] Epoch=16/50, Step=102/478, loss=0.069190, lr=0.074813, time_each_step=1.29s, eta=5:59:52\n",
      "2022-01-20 12:40:06 [INFO]\t[TRAIN] Epoch=16/50, Step=104/478, loss=0.082788, lr=0.074805, time_each_step=1.29s, eta=6:0:18\n",
      "2022-01-20 12:40:09 [INFO]\t[TRAIN] Epoch=16/50, Step=106/478, loss=0.070556, lr=0.074798, time_each_step=1.28s, eta=5:59:30\n",
      "2022-01-20 12:40:12 [INFO]\t[TRAIN] Epoch=16/50, Step=108/478, loss=0.070077, lr=0.074791, time_each_step=1.29s, eta=5:59:36\n",
      "2022-01-20 12:40:14 [INFO]\t[TRAIN] Epoch=16/50, Step=110/478, loss=0.047010, lr=0.074784, time_each_step=1.29s, eta=6:0:16\n",
      "2022-01-20 12:40:17 [INFO]\t[TRAIN] Epoch=16/50, Step=112/478, loss=0.075239, lr=0.074777, time_each_step=1.28s, eta=5:59:26\n",
      "2022-01-20 12:40:19 [INFO]\t[TRAIN] Epoch=16/50, Step=114/478, loss=0.070443, lr=0.074769, time_each_step=1.28s, eta=5:59:22\n",
      "2022-01-20 12:40:22 [INFO]\t[TRAIN] Epoch=16/50, Step=116/478, loss=0.079152, lr=0.074762, time_each_step=1.29s, eta=6:0:2\n",
      "2022-01-20 12:40:24 [INFO]\t[TRAIN] Epoch=16/50, Step=118/478, loss=0.064717, lr=0.074755, time_each_step=1.28s, eta=5:59:0\n",
      "2022-01-20 12:40:27 [INFO]\t[TRAIN] Epoch=16/50, Step=120/478, loss=0.057659, lr=0.074748, time_each_step=1.29s, eta=5:59:53\n",
      "2022-01-20 12:40:30 [INFO]\t[TRAIN] Epoch=16/50, Step=122/478, loss=0.068672, lr=0.074741, time_each_step=1.29s, eta=6:0:2\n",
      "2022-01-20 12:40:32 [INFO]\t[TRAIN] Epoch=16/50, Step=124/478, loss=0.079175, lr=0.074733, time_each_step=1.29s, eta=5:59:17\n",
      "2022-01-20 12:40:35 [INFO]\t[TRAIN] Epoch=16/50, Step=126/478, loss=0.066626, lr=0.074726, time_each_step=1.29s, eta=5:59:28\n",
      "2022-01-20 12:40:37 [INFO]\t[TRAIN] Epoch=16/50, Step=128/478, loss=0.058886, lr=0.074719, time_each_step=1.29s, eta=5:59:44\n",
      "2022-01-20 12:40:40 [INFO]\t[TRAIN] Epoch=16/50, Step=130/478, loss=0.066208, lr=0.074712, time_each_step=1.29s, eta=5:59:41\n",
      "2022-01-20 12:40:42 [INFO]\t[TRAIN] Epoch=16/50, Step=132/478, loss=0.089512, lr=0.074705, time_each_step=1.29s, eta=5:59:28\n",
      "2022-01-20 12:40:45 [INFO]\t[TRAIN] Epoch=16/50, Step=134/478, loss=0.071685, lr=0.074697, time_each_step=1.29s, eta=5:59:49\n",
      "2022-01-20 12:40:48 [INFO]\t[TRAIN] Epoch=16/50, Step=136/478, loss=0.078971, lr=0.074690, time_each_step=1.29s, eta=5:59:25\n",
      "2022-01-20 12:40:50 [INFO]\t[TRAIN] Epoch=16/50, Step=138/478, loss=0.042690, lr=0.074683, time_each_step=1.29s, eta=5:59:18\n",
      "2022-01-20 12:40:53 [INFO]\t[TRAIN] Epoch=16/50, Step=140/478, loss=0.061211, lr=0.074676, time_each_step=1.29s, eta=5:59:52\n",
      "2022-01-20 12:40:55 [INFO]\t[TRAIN] Epoch=16/50, Step=142/478, loss=0.064790, lr=0.074669, time_each_step=1.29s, eta=5:59:3\n",
      "2022-01-20 12:40:58 [INFO]\t[TRAIN] Epoch=16/50, Step=144/478, loss=0.069745, lr=0.074661, time_each_step=1.28s, eta=5:58:41\n",
      "2022-01-20 12:41:00 [INFO]\t[TRAIN] Epoch=16/50, Step=146/478, loss=0.071006, lr=0.074654, time_each_step=1.29s, eta=5:59:30\n",
      "2022-01-20 12:41:03 [INFO]\t[TRAIN] Epoch=16/50, Step=148/478, loss=0.064625, lr=0.074647, time_each_step=1.29s, eta=5:58:54\n",
      "2022-01-20 12:41:06 [INFO]\t[TRAIN] Epoch=16/50, Step=150/478, loss=0.062337, lr=0.074640, time_each_step=1.28s, eta=5:58:3\n",
      "2022-01-20 12:41:08 [INFO]\t[TRAIN] Epoch=16/50, Step=152/478, loss=0.053359, lr=0.074633, time_each_step=1.29s, eta=6:0:3\n",
      "2022-01-20 12:41:11 [INFO]\t[TRAIN] Epoch=16/50, Step=154/478, loss=0.049000, lr=0.074625, time_each_step=1.29s, eta=5:58:40\n",
      "2022-01-20 12:41:13 [INFO]\t[TRAIN] Epoch=16/50, Step=156/478, loss=0.081614, lr=0.074618, time_each_step=1.29s, eta=5:59:0\n",
      "2022-01-20 12:41:16 [INFO]\t[TRAIN] Epoch=16/50, Step=158/478, loss=0.053720, lr=0.074611, time_each_step=1.29s, eta=5:59:1\n",
      "2022-01-20 12:41:18 [INFO]\t[TRAIN] Epoch=16/50, Step=160/478, loss=0.063552, lr=0.074604, time_each_step=1.29s, eta=5:58:35\n",
      "2022-01-20 12:41:21 [INFO]\t[TRAIN] Epoch=16/50, Step=162/478, loss=0.074666, lr=0.074597, time_each_step=1.29s, eta=5:58:27\n",
      "2022-01-20 12:41:24 [INFO]\t[TRAIN] Epoch=16/50, Step=164/478, loss=0.053945, lr=0.074589, time_each_step=1.29s, eta=5:59:19\n",
      "2022-01-20 12:41:26 [INFO]\t[TRAIN] Epoch=16/50, Step=166/478, loss=0.073393, lr=0.074582, time_each_step=1.28s, eta=5:58:1\n",
      "2022-01-20 12:41:29 [INFO]\t[TRAIN] Epoch=16/50, Step=168/478, loss=0.057360, lr=0.074575, time_each_step=1.29s, eta=5:58:57\n",
      "2022-01-20 12:41:31 [INFO]\t[TRAIN] Epoch=16/50, Step=170/478, loss=0.068898, lr=0.074568, time_each_step=1.29s, eta=5:59:17\n",
      "2022-01-20 12:41:34 [INFO]\t[TRAIN] Epoch=16/50, Step=172/478, loss=0.081262, lr=0.074561, time_each_step=1.29s, eta=5:58:35\n",
      "2022-01-20 12:41:37 [INFO]\t[TRAIN] Epoch=16/50, Step=174/478, loss=0.081714, lr=0.074553, time_each_step=1.29s, eta=5:58:33\n",
      "2022-01-20 12:41:39 [INFO]\t[TRAIN] Epoch=16/50, Step=176/478, loss=0.065488, lr=0.074546, time_each_step=1.29s, eta=5:59:9\n",
      "2022-01-20 12:41:42 [INFO]\t[TRAIN] Epoch=16/50, Step=178/478, loss=0.070875, lr=0.074539, time_each_step=1.28s, eta=5:57:47\n",
      "2022-01-20 12:41:44 [INFO]\t[TRAIN] Epoch=16/50, Step=180/478, loss=0.067729, lr=0.074532, time_each_step=1.29s, eta=5:58:15\n",
      "2022-01-20 12:41:47 [INFO]\t[TRAIN] Epoch=16/50, Step=182/478, loss=0.057102, lr=0.074525, time_each_step=1.29s, eta=5:58:53\n",
      "2022-01-20 12:41:49 [INFO]\t[TRAIN] Epoch=16/50, Step=184/478, loss=0.070226, lr=0.074517, time_each_step=1.28s, eta=5:57:53\n",
      "2022-01-20 12:41:52 [INFO]\t[TRAIN] Epoch=16/50, Step=186/478, loss=0.059512, lr=0.074510, time_each_step=1.29s, eta=5:58:5\n",
      "2022-01-20 12:41:55 [INFO]\t[TRAIN] Epoch=16/50, Step=188/478, loss=0.065385, lr=0.074503, time_each_step=1.29s, eta=6:0:33\n",
      "2022-01-20 12:41:57 [INFO]\t[TRAIN] Epoch=16/50, Step=190/478, loss=0.052064, lr=0.074496, time_each_step=1.29s, eta=5:58:46\n",
      "2022-01-20 12:42:00 [INFO]\t[TRAIN] Epoch=16/50, Step=192/478, loss=0.098592, lr=0.074488, time_each_step=1.29s, eta=5:58:20\n",
      "2022-01-20 12:42:02 [INFO]\t[TRAIN] Epoch=16/50, Step=194/478, loss=0.077551, lr=0.074481, time_each_step=1.29s, eta=5:59:53\n",
      "2022-01-20 12:42:05 [INFO]\t[TRAIN] Epoch=16/50, Step=196/478, loss=0.042090, lr=0.074474, time_each_step=1.29s, eta=5:58:8\n",
      "2022-01-20 12:42:07 [INFO]\t[TRAIN] Epoch=16/50, Step=198/478, loss=0.047573, lr=0.074467, time_each_step=1.29s, eta=5:59:54\n",
      "2022-01-20 12:42:10 [INFO]\t[TRAIN] Epoch=16/50, Step=200/478, loss=0.052167, lr=0.074460, time_each_step=1.29s, eta=5:59:13\n",
      "2022-01-20 12:42:13 [INFO]\t[TRAIN] Epoch=16/50, Step=202/478, loss=0.095458, lr=0.074452, time_each_step=1.29s, eta=5:58:26\n",
      "2022-01-20 12:42:15 [INFO]\t[TRAIN] Epoch=16/50, Step=204/478, loss=0.070751, lr=0.074445, time_each_step=1.29s, eta=5:59:24\n",
      "2022-01-20 12:42:18 [INFO]\t[TRAIN] Epoch=16/50, Step=206/478, loss=0.040943, lr=0.074438, time_each_step=1.29s, eta=5:59:11\n",
      "2022-01-20 12:42:20 [INFO]\t[TRAIN] Epoch=16/50, Step=208/478, loss=0.059521, lr=0.074431, time_each_step=1.3s, eta=6:0:42\n",
      "2022-01-20 12:42:23 [INFO]\t[TRAIN] Epoch=16/50, Step=210/478, loss=0.049777, lr=0.074424, time_each_step=1.29s, eta=5:59:45\n",
      "2022-01-20 12:42:26 [INFO]\t[TRAIN] Epoch=16/50, Step=212/478, loss=0.056966, lr=0.074416, time_each_step=1.29s, eta=5:59:23\n",
      "2022-01-20 12:42:28 [INFO]\t[TRAIN] Epoch=16/50, Step=214/478, loss=0.051344, lr=0.074409, time_each_step=1.3s, eta=6:0:28\n",
      "2022-01-20 12:42:31 [INFO]\t[TRAIN] Epoch=16/50, Step=216/478, loss=0.076707, lr=0.074402, time_each_step=1.29s, eta=5:59:26\n",
      "2022-01-20 12:42:33 [INFO]\t[TRAIN] Epoch=16/50, Step=218/478, loss=0.098482, lr=0.074395, time_each_step=1.3s, eta=6:0:14\n",
      "2022-01-20 12:42:36 [INFO]\t[TRAIN] Epoch=16/50, Step=220/478, loss=0.071844, lr=0.074388, time_each_step=1.29s, eta=5:59:17\n",
      "2022-01-20 12:42:38 [INFO]\t[TRAIN] Epoch=16/50, Step=222/478, loss=0.052323, lr=0.074380, time_each_step=1.3s, eta=6:1:23\n",
      "2022-01-20 12:42:41 [INFO]\t[TRAIN] Epoch=16/50, Step=224/478, loss=0.062528, lr=0.074373, time_each_step=1.29s, eta=5:58:51\n",
      "2022-01-20 12:42:44 [INFO]\t[TRAIN] Epoch=16/50, Step=226/478, loss=0.106432, lr=0.074366, time_each_step=1.3s, eta=6:2:9\n",
      "2022-01-20 12:42:46 [INFO]\t[TRAIN] Epoch=16/50, Step=228/478, loss=0.052925, lr=0.074359, time_each_step=1.3s, eta=6:0:15\n",
      "2022-01-20 12:42:49 [INFO]\t[TRAIN] Epoch=16/50, Step=230/478, loss=0.081223, lr=0.074352, time_each_step=1.3s, eta=6:1:15\n",
      "2022-01-20 12:42:51 [INFO]\t[TRAIN] Epoch=16/50, Step=232/478, loss=0.057009, lr=0.074344, time_each_step=1.29s, eta=5:59:23\n",
      "2022-01-20 12:42:54 [INFO]\t[TRAIN] Epoch=16/50, Step=234/478, loss=0.061074, lr=0.074337, time_each_step=1.29s, eta=5:59:1\n",
      "2022-01-20 12:42:57 [INFO]\t[TRAIN] Epoch=16/50, Step=236/478, loss=0.079257, lr=0.074330, time_each_step=1.3s, eta=6:0:10\n",
      "2022-01-20 12:42:59 [INFO]\t[TRAIN] Epoch=16/50, Step=238/478, loss=0.081208, lr=0.074323, time_each_step=1.3s, eta=5:59:56\n",
      "2022-01-20 12:43:02 [INFO]\t[TRAIN] Epoch=16/50, Step=240/478, loss=0.056787, lr=0.074315, time_each_step=1.3s, eta=5:59:57\n",
      "2022-01-20 12:43:04 [INFO]\t[TRAIN] Epoch=16/50, Step=242/478, loss=0.071674, lr=0.074308, time_each_step=1.29s, eta=5:58:10\n",
      "2022-01-20 12:43:07 [INFO]\t[TRAIN] Epoch=16/50, Step=244/478, loss=0.065056, lr=0.074301, time_each_step=1.3s, eta=6:0:12\n",
      "2022-01-20 12:43:10 [INFO]\t[TRAIN] Epoch=16/50, Step=246/478, loss=0.053236, lr=0.074294, time_each_step=1.29s, eta=5:58:56\n",
      "2022-01-20 12:43:12 [INFO]\t[TRAIN] Epoch=16/50, Step=248/478, loss=0.067443, lr=0.074287, time_each_step=1.29s, eta=5:58:18\n",
      "2022-01-20 12:43:15 [INFO]\t[TRAIN] Epoch=16/50, Step=250/478, loss=0.083559, lr=0.074279, time_each_step=1.3s, eta=5:59:45\n",
      "2022-01-20 12:43:17 [INFO]\t[TRAIN] Epoch=16/50, Step=252/478, loss=0.053943, lr=0.074272, time_each_step=1.3s, eta=5:59:34\n",
      "2022-01-20 12:43:20 [INFO]\t[TRAIN] Epoch=16/50, Step=254/478, loss=0.059078, lr=0.074265, time_each_step=1.3s, eta=5:59:32\n",
      "2022-01-20 12:43:23 [INFO]\t[TRAIN] Epoch=16/50, Step=256/478, loss=0.098696, lr=0.074258, time_each_step=1.29s, eta=5:58:23\n",
      "2022-01-20 12:43:25 [INFO]\t[TRAIN] Epoch=16/50, Step=258/478, loss=0.067966, lr=0.074251, time_each_step=1.3s, eta=5:59:51\n",
      "2022-01-20 12:43:28 [INFO]\t[TRAIN] Epoch=16/50, Step=260/478, loss=0.054088, lr=0.074243, time_each_step=1.29s, eta=5:58:0\n",
      "2022-01-20 12:43:30 [INFO]\t[TRAIN] Epoch=16/50, Step=262/478, loss=0.059158, lr=0.074236, time_each_step=1.29s, eta=5:57:50\n",
      "2022-01-20 12:43:33 [INFO]\t[TRAIN] Epoch=16/50, Step=264/478, loss=0.049258, lr=0.074229, time_each_step=1.29s, eta=5:58:54\n",
      "2022-01-20 12:43:35 [INFO]\t[TRAIN] Epoch=16/50, Step=266/478, loss=0.079973, lr=0.074222, time_each_step=1.29s, eta=5:57:23\n",
      "2022-01-20 12:43:38 [INFO]\t[TRAIN] Epoch=16/50, Step=268/478, loss=0.049476, lr=0.074215, time_each_step=1.3s, eta=5:59:9\n",
      "2022-01-20 12:43:41 [INFO]\t[TRAIN] Epoch=16/50, Step=270/478, loss=0.059525, lr=0.074207, time_each_step=1.29s, eta=5:57:9\n",
      "2022-01-20 12:43:43 [INFO]\t[TRAIN] Epoch=16/50, Step=272/478, loss=0.058973, lr=0.074200, time_each_step=1.29s, eta=5:57:50\n",
      "2022-01-20 12:43:46 [INFO]\t[TRAIN] Epoch=16/50, Step=274/478, loss=0.083418, lr=0.074193, time_each_step=1.29s, eta=5:58:28\n",
      "2022-01-20 12:43:48 [INFO]\t[TRAIN] Epoch=16/50, Step=276/478, loss=0.040940, lr=0.074186, time_each_step=1.29s, eta=5:57:50\n",
      "2022-01-20 12:43:51 [INFO]\t[TRAIN] Epoch=16/50, Step=278/478, loss=0.066295, lr=0.074178, time_each_step=1.3s, eta=5:59:8\n",
      "2022-01-20 12:43:54 [INFO]\t[TRAIN] Epoch=16/50, Step=280/478, loss=0.059532, lr=0.074171, time_each_step=1.29s, eta=5:56:48\n",
      "2022-01-20 12:43:56 [INFO]\t[TRAIN] Epoch=16/50, Step=282/478, loss=0.080710, lr=0.074164, time_each_step=1.3s, eta=5:59:21\n",
      "2022-01-20 12:43:59 [INFO]\t[TRAIN] Epoch=16/50, Step=284/478, loss=0.089033, lr=0.074157, time_each_step=1.29s, eta=5:57:34\n",
      "2022-01-20 12:44:01 [INFO]\t[TRAIN] Epoch=16/50, Step=286/478, loss=0.049559, lr=0.074150, time_each_step=1.29s, eta=5:57:31\n",
      "2022-01-20 12:44:04 [INFO]\t[TRAIN] Epoch=16/50, Step=288/478, loss=0.075409, lr=0.074142, time_each_step=1.29s, eta=5:58:25\n",
      "2022-01-20 12:44:06 [INFO]\t[TRAIN] Epoch=16/50, Step=290/478, loss=0.047327, lr=0.074135, time_each_step=1.29s, eta=5:57:11\n",
      "2022-01-20 12:44:09 [INFO]\t[TRAIN] Epoch=16/50, Step=292/478, loss=0.059240, lr=0.074128, time_each_step=1.29s, eta=5:57:10\n",
      "2022-01-20 12:44:12 [INFO]\t[TRAIN] Epoch=16/50, Step=294/478, loss=0.070135, lr=0.074121, time_each_step=1.3s, eta=5:58:40\n",
      "2022-01-20 12:44:14 [INFO]\t[TRAIN] Epoch=16/50, Step=296/478, loss=0.068473, lr=0.074114, time_each_step=1.29s, eta=5:57:19\n",
      "2022-01-20 12:44:17 [INFO]\t[TRAIN] Epoch=16/50, Step=298/478, loss=0.064691, lr=0.074106, time_each_step=1.29s, eta=5:57:11\n",
      "2022-01-20 12:44:19 [INFO]\t[TRAIN] Epoch=16/50, Step=300/478, loss=0.058081, lr=0.074099, time_each_step=1.29s, eta=5:56:22\n",
      "2022-01-20 12:44:22 [INFO]\t[TRAIN] Epoch=16/50, Step=302/478, loss=0.061804, lr=0.074092, time_each_step=1.3s, eta=5:58:14\n",
      "2022-01-20 12:44:25 [INFO]\t[TRAIN] Epoch=16/50, Step=304/478, loss=0.076383, lr=0.074085, time_each_step=1.29s, eta=5:56:35\n",
      "2022-01-20 12:44:27 [INFO]\t[TRAIN] Epoch=16/50, Step=306/478, loss=0.056889, lr=0.074077, time_each_step=1.29s, eta=5:56:55\n",
      "2022-01-20 12:44:30 [INFO]\t[TRAIN] Epoch=16/50, Step=308/478, loss=0.063856, lr=0.074070, time_each_step=1.29s, eta=5:57:23\n",
      "2022-01-20 12:44:32 [INFO]\t[TRAIN] Epoch=16/50, Step=310/478, loss=0.076220, lr=0.074063, time_each_step=1.29s, eta=5:55:57\n",
      "2022-01-20 12:44:35 [INFO]\t[TRAIN] Epoch=16/50, Step=312/478, loss=0.050875, lr=0.074056, time_each_step=1.3s, eta=5:58:11\n",
      "2022-01-20 12:44:37 [INFO]\t[TRAIN] Epoch=16/50, Step=314/478, loss=0.065871, lr=0.074049, time_each_step=1.29s, eta=5:56:23\n",
      "2022-01-20 12:44:40 [INFO]\t[TRAIN] Epoch=16/50, Step=316/478, loss=0.073727, lr=0.074041, time_each_step=1.29s, eta=5:56:19\n",
      "2022-01-20 12:44:43 [INFO]\t[TRAIN] Epoch=16/50, Step=318/478, loss=0.083579, lr=0.074034, time_each_step=1.29s, eta=5:57:40\n",
      "2022-01-20 12:44:45 [INFO]\t[TRAIN] Epoch=16/50, Step=320/478, loss=0.075003, lr=0.074027, time_each_step=1.29s, eta=5:56:10\n",
      "2022-01-20 12:44:48 [INFO]\t[TRAIN] Epoch=16/50, Step=322/478, loss=0.070490, lr=0.074020, time_each_step=1.29s, eta=5:57:4\n",
      "2022-01-20 12:44:50 [INFO]\t[TRAIN] Epoch=16/50, Step=324/478, loss=0.066233, lr=0.074012, time_each_step=1.29s, eta=5:56:20\n",
      "2022-01-20 12:44:53 [INFO]\t[TRAIN] Epoch=16/50, Step=326/478, loss=0.067853, lr=0.074005, time_each_step=1.29s, eta=5:56:11\n",
      "2022-01-20 12:44:56 [INFO]\t[TRAIN] Epoch=16/50, Step=328/478, loss=0.057389, lr=0.073998, time_each_step=1.29s, eta=5:56:26\n",
      "2022-01-20 12:44:58 [INFO]\t[TRAIN] Epoch=16/50, Step=330/478, loss=0.058418, lr=0.073991, time_each_step=1.29s, eta=5:55:38\n",
      "2022-01-20 12:45:01 [INFO]\t[TRAIN] Epoch=16/50, Step=332/478, loss=0.053467, lr=0.073984, time_each_step=1.29s, eta=5:55:35\n",
      "2022-01-20 12:45:03 [INFO]\t[TRAIN] Epoch=16/50, Step=334/478, loss=0.072513, lr=0.073976, time_each_step=1.29s, eta=5:57:13\n",
      "2022-01-20 12:45:06 [INFO]\t[TRAIN] Epoch=16/50, Step=336/478, loss=0.065595, lr=0.073969, time_each_step=1.29s, eta=5:55:52\n",
      "2022-01-20 12:45:08 [INFO]\t[TRAIN] Epoch=16/50, Step=338/478, loss=0.066912, lr=0.073962, time_each_step=1.29s, eta=5:56:0\n",
      "2022-01-20 12:45:11 [INFO]\t[TRAIN] Epoch=16/50, Step=340/478, loss=0.057407, lr=0.073955, time_each_step=1.29s, eta=5:56:1\n",
      "2022-01-20 12:45:14 [INFO]\t[TRAIN] Epoch=16/50, Step=342/478, loss=0.071065, lr=0.073948, time_each_step=1.29s, eta=5:55:53\n",
      "2022-01-20 12:45:16 [INFO]\t[TRAIN] Epoch=16/50, Step=344/478, loss=0.069376, lr=0.073940, time_each_step=1.29s, eta=5:55:59\n",
      "2022-01-20 12:45:19 [INFO]\t[TRAIN] Epoch=16/50, Step=346/478, loss=0.059936, lr=0.073933, time_each_step=1.29s, eta=5:54:56\n",
      "2022-01-20 12:45:21 [INFO]\t[TRAIN] Epoch=16/50, Step=348/478, loss=0.047210, lr=0.073926, time_each_step=1.29s, eta=5:54:52\n",
      "2022-01-20 12:45:24 [INFO]\t[TRAIN] Epoch=16/50, Step=350/478, loss=0.070450, lr=0.073919, time_each_step=1.29s, eta=5:56:30\n",
      "2022-01-20 12:45:27 [INFO]\t[TRAIN] Epoch=16/50, Step=352/478, loss=0.096526, lr=0.073911, time_each_step=1.29s, eta=5:55:16\n",
      "2022-01-20 12:45:29 [INFO]\t[TRAIN] Epoch=16/50, Step=354/478, loss=0.051585, lr=0.073904, time_each_step=1.29s, eta=5:56:59\n",
      "2022-01-20 12:45:32 [INFO]\t[TRAIN] Epoch=16/50, Step=356/478, loss=0.058876, lr=0.073897, time_each_step=1.29s, eta=5:55:36\n",
      "2022-01-20 12:45:34 [INFO]\t[TRAIN] Epoch=16/50, Step=358/478, loss=0.061085, lr=0.073890, time_each_step=1.29s, eta=5:54:34\n",
      "2022-01-20 12:45:37 [INFO]\t[TRAIN] Epoch=16/50, Step=360/478, loss=0.060929, lr=0.073883, time_each_step=1.29s, eta=5:54:49\n",
      "2022-01-20 12:45:39 [INFO]\t[TRAIN] Epoch=16/50, Step=362/478, loss=0.068971, lr=0.073875, time_each_step=1.29s, eta=5:54:11\n",
      "2022-01-20 12:45:42 [INFO]\t[TRAIN] Epoch=16/50, Step=364/478, loss=0.070669, lr=0.073868, time_each_step=1.29s, eta=5:54:46\n",
      "2022-01-20 12:45:45 [INFO]\t[TRAIN] Epoch=16/50, Step=366/478, loss=0.068359, lr=0.073861, time_each_step=1.29s, eta=5:56:15\n",
      "2022-01-20 12:45:47 [INFO]\t[TRAIN] Epoch=16/50, Step=368/478, loss=0.069080, lr=0.073854, time_each_step=1.29s, eta=5:54:3\n",
      "2022-01-20 12:45:50 [INFO]\t[TRAIN] Epoch=16/50, Step=370/478, loss=0.059727, lr=0.073846, time_each_step=1.29s, eta=5:55:35\n",
      "2022-01-20 12:45:52 [INFO]\t[TRAIN] Epoch=16/50, Step=372/478, loss=0.090089, lr=0.073839, time_each_step=1.29s, eta=5:55:39\n",
      "2022-01-20 12:45:55 [INFO]\t[TRAIN] Epoch=16/50, Step=374/478, loss=0.072533, lr=0.073832, time_each_step=1.29s, eta=5:55:12\n",
      "2022-01-20 12:45:57 [INFO]\t[TRAIN] Epoch=16/50, Step=376/478, loss=0.047136, lr=0.073825, time_each_step=1.29s, eta=5:55:10\n",
      "2022-01-20 12:46:00 [INFO]\t[TRAIN] Epoch=16/50, Step=378/478, loss=0.074931, lr=0.073818, time_each_step=1.29s, eta=5:54:25\n",
      "2022-01-20 12:46:03 [INFO]\t[TRAIN] Epoch=16/50, Step=380/478, loss=0.084220, lr=0.073810, time_each_step=1.29s, eta=5:54:27\n",
      "2022-01-20 12:46:05 [INFO]\t[TRAIN] Epoch=16/50, Step=382/478, loss=0.062531, lr=0.073803, time_each_step=1.3s, eta=5:56:31\n",
      "2022-01-20 12:46:08 [INFO]\t[TRAIN] Epoch=16/50, Step=384/478, loss=0.081679, lr=0.073796, time_each_step=1.29s, eta=5:55:15\n",
      "2022-01-20 12:46:10 [INFO]\t[TRAIN] Epoch=16/50, Step=386/478, loss=0.078461, lr=0.073789, time_each_step=1.29s, eta=5:55:7\n",
      "2022-01-20 12:46:13 [INFO]\t[TRAIN] Epoch=16/50, Step=388/478, loss=0.087636, lr=0.073781, time_each_step=1.29s, eta=5:54:13\n",
      "2022-01-20 12:46:15 [INFO]\t[TRAIN] Epoch=16/50, Step=390/478, loss=0.082292, lr=0.073774, time_each_step=1.29s, eta=5:54:6\n",
      "2022-01-20 12:46:18 [INFO]\t[TRAIN] Epoch=16/50, Step=392/478, loss=0.055017, lr=0.073767, time_each_step=1.29s, eta=5:54:39\n",
      "2022-01-20 12:46:21 [INFO]\t[TRAIN] Epoch=16/50, Step=394/478, loss=0.077528, lr=0.073760, time_each_step=1.29s, eta=5:54:23\n",
      "2022-01-20 12:46:23 [INFO]\t[TRAIN] Epoch=16/50, Step=396/478, loss=0.075964, lr=0.073753, time_each_step=1.29s, eta=5:54:12\n",
      "2022-01-20 12:46:26 [INFO]\t[TRAIN] Epoch=16/50, Step=398/478, loss=0.053102, lr=0.073745, time_each_step=1.29s, eta=5:54:43\n",
      "2022-01-20 12:46:28 [INFO]\t[TRAIN] Epoch=16/50, Step=400/478, loss=0.072458, lr=0.073738, time_each_step=1.29s, eta=5:53:46\n",
      "2022-01-20 12:46:31 [INFO]\t[TRAIN] Epoch=16/50, Step=402/478, loss=0.064954, lr=0.073731, time_each_step=1.29s, eta=5:53:53\n",
      "2022-01-20 12:46:34 [INFO]\t[TRAIN] Epoch=16/50, Step=404/478, loss=0.055255, lr=0.073724, time_each_step=1.29s, eta=5:53:47\n",
      "2022-01-20 12:46:36 [INFO]\t[TRAIN] Epoch=16/50, Step=406/478, loss=0.059585, lr=0.073716, time_each_step=1.29s, eta=5:53:13\n",
      "2022-01-20 12:46:39 [INFO]\t[TRAIN] Epoch=16/50, Step=408/478, loss=0.057191, lr=0.073709, time_each_step=1.29s, eta=5:53:18\n",
      "2022-01-20 12:46:41 [INFO]\t[TRAIN] Epoch=16/50, Step=410/478, loss=0.050023, lr=0.073702, time_each_step=1.29s, eta=5:53:21\n",
      "2022-01-20 12:46:44 [INFO]\t[TRAIN] Epoch=16/50, Step=412/478, loss=0.053220, lr=0.073695, time_each_step=1.29s, eta=5:53:12\n",
      "2022-01-20 12:46:46 [INFO]\t[TRAIN] Epoch=16/50, Step=414/478, loss=0.051205, lr=0.073688, time_each_step=1.29s, eta=5:53:43\n",
      "2022-01-20 12:46:49 [INFO]\t[TRAIN] Epoch=16/50, Step=416/478, loss=0.060396, lr=0.073680, time_each_step=1.29s, eta=5:54:53\n",
      "2022-01-20 12:46:52 [INFO]\t[TRAIN] Epoch=16/50, Step=418/478, loss=0.076557, lr=0.073673, time_each_step=1.29s, eta=5:53:36\n",
      "2022-01-20 12:46:54 [INFO]\t[TRAIN] Epoch=16/50, Step=420/478, loss=0.053523, lr=0.073666, time_each_step=1.29s, eta=5:55:1\n",
      "2022-01-20 12:46:57 [INFO]\t[TRAIN] Epoch=16/50, Step=422/478, loss=0.060696, lr=0.073659, time_each_step=1.29s, eta=5:53:19\n",
      "2022-01-20 12:46:59 [INFO]\t[TRAIN] Epoch=16/50, Step=424/478, loss=0.072609, lr=0.073651, time_each_step=1.29s, eta=5:54:19\n",
      "2022-01-20 12:47:02 [INFO]\t[TRAIN] Epoch=16/50, Step=426/478, loss=0.056547, lr=0.073644, time_each_step=1.29s, eta=5:53:43\n",
      "2022-01-20 12:47:04 [INFO]\t[TRAIN] Epoch=16/50, Step=428/478, loss=0.077205, lr=0.073637, time_each_step=1.29s, eta=5:53:22\n",
      "2022-01-20 12:47:07 [INFO]\t[TRAIN] Epoch=16/50, Step=430/478, loss=0.071805, lr=0.073630, time_each_step=1.29s, eta=5:53:35\n",
      "2022-01-20 12:47:10 [INFO]\t[TRAIN] Epoch=16/50, Step=432/478, loss=0.044074, lr=0.073622, time_each_step=1.29s, eta=5:54:20\n",
      "2022-01-20 12:47:12 [INFO]\t[TRAIN] Epoch=16/50, Step=434/478, loss=0.069864, lr=0.073615, time_each_step=1.29s, eta=5:52:59\n",
      "2022-01-20 12:47:15 [INFO]\t[TRAIN] Epoch=16/50, Step=436/478, loss=0.039710, lr=0.073608, time_each_step=1.29s, eta=5:53:55\n",
      "2022-01-20 12:47:17 [INFO]\t[TRAIN] Epoch=16/50, Step=438/478, loss=0.044060, lr=0.073601, time_each_step=1.29s, eta=5:53:25\n",
      "2022-01-20 12:47:20 [INFO]\t[TRAIN] Epoch=16/50, Step=440/478, loss=0.071707, lr=0.073594, time_each_step=1.29s, eta=5:54:1\n",
      "2022-01-20 12:47:22 [INFO]\t[TRAIN] Epoch=16/50, Step=442/478, loss=0.081618, lr=0.073586, time_each_step=1.29s, eta=5:53:52\n",
      "2022-01-20 12:47:25 [INFO]\t[TRAIN] Epoch=16/50, Step=444/478, loss=0.061142, lr=0.073579, time_each_step=1.29s, eta=5:52:43\n",
      "2022-01-20 12:47:28 [INFO]\t[TRAIN] Epoch=16/50, Step=446/478, loss=0.044506, lr=0.073572, time_each_step=1.29s, eta=5:52:51\n",
      "2022-01-20 12:47:30 [INFO]\t[TRAIN] Epoch=16/50, Step=448/478, loss=0.060092, lr=0.073565, time_each_step=1.29s, eta=5:53:5\n",
      "2022-01-20 12:47:33 [INFO]\t[TRAIN] Epoch=16/50, Step=450/478, loss=0.070087, lr=0.073557, time_each_step=1.29s, eta=5:54:9\n",
      "2022-01-20 12:47:35 [INFO]\t[TRAIN] Epoch=16/50, Step=452/478, loss=0.050993, lr=0.073550, time_each_step=1.29s, eta=5:52:26\n",
      "2022-01-20 12:47:38 [INFO]\t[TRAIN] Epoch=16/50, Step=454/478, loss=0.094058, lr=0.073543, time_each_step=1.29s, eta=5:52:36\n",
      "2022-01-20 12:47:41 [INFO]\t[TRAIN] Epoch=16/50, Step=456/478, loss=0.062278, lr=0.073536, time_each_step=1.29s, eta=5:52:24\n",
      "2022-01-20 12:47:43 [INFO]\t[TRAIN] Epoch=16/50, Step=458/478, loss=0.073732, lr=0.073529, time_each_step=1.29s, eta=5:52:37\n",
      "2022-01-20 12:47:46 [INFO]\t[TRAIN] Epoch=16/50, Step=460/478, loss=0.050936, lr=0.073521, time_each_step=1.29s, eta=5:52:16\n",
      "2022-01-20 12:47:48 [INFO]\t[TRAIN] Epoch=16/50, Step=462/478, loss=0.062618, lr=0.073514, time_each_step=1.28s, eta=5:51:56\n",
      "2022-01-20 12:47:51 [INFO]\t[TRAIN] Epoch=16/50, Step=464/478, loss=0.085449, lr=0.073507, time_each_step=1.29s, eta=5:51:58\n",
      "2022-01-20 12:47:53 [INFO]\t[TRAIN] Epoch=16/50, Step=466/478, loss=0.050320, lr=0.073500, time_each_step=1.29s, eta=5:52:38\n",
      "2022-01-20 12:47:56 [INFO]\t[TRAIN] Epoch=16/50, Step=468/478, loss=0.093687, lr=0.073492, time_each_step=1.29s, eta=5:52:13\n",
      "2022-01-20 12:47:59 [INFO]\t[TRAIN] Epoch=16/50, Step=470/478, loss=0.078689, lr=0.073485, time_each_step=1.29s, eta=5:52:18\n",
      "2022-01-20 12:48:01 [INFO]\t[TRAIN] Epoch=16/50, Step=472/478, loss=0.070039, lr=0.073478, time_each_step=1.29s, eta=5:52:41\n",
      "2022-01-20 12:48:04 [INFO]\t[TRAIN] Epoch=16/50, Step=474/478, loss=0.053596, lr=0.073471, time_each_step=1.29s, eta=5:52:29\n",
      "2022-01-20 12:48:06 [INFO]\t[TRAIN] Epoch=16/50, Step=476/478, loss=0.063059, lr=0.073463, time_each_step=1.29s, eta=5:51:47\n",
      "2022-01-20 12:48:09 [INFO]\t[TRAIN] Epoch=16/50, Step=478/478, loss=0.068512, lr=0.073456, time_each_step=1.29s, eta=5:53:13\n",
      "2022-01-20 12:48:09 [INFO]\t[TRAIN] Epoch 16 finished, loss=0.06684504 .\n",
      "2022-01-20 12:48:09 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-01-20 12:48:09 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-01-20 12:48:15 [INFO]\t[EVAL] Finished, Epoch=16, miou=0.831062, category_iou=[0.97004783 0.7382487  0.78488874], oacc=0.972162, category_acc=[0.9854123 0.8547449 0.8728012], kappa=0.864440, category_F1-score=[0.9847962  0.84941668 0.87948194] .\n",
      "2022-01-20 12:48:15 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_13, miou=0.8400812745094299\n",
      "2022-01-20 12:48:16 [INFO]\tModel saved in model/deeplab_augument_alldata2/epoch_16.\n",
      "2022-01-20 12:48:20 [INFO]\t[TRAIN] Epoch=17/50, Step=2/478, loss=0.056088, lr=0.073449, time_each_step=1.94s, eta=8:48:18\n",
      "2022-01-20 12:48:22 [INFO]\t[TRAIN] Epoch=17/50, Step=4/478, loss=0.071569, lr=0.073442, time_each_step=1.29s, eta=5:51:34\n",
      "2022-01-20 12:48:25 [INFO]\t[TRAIN] Epoch=17/50, Step=6/478, loss=0.034637, lr=0.073435, time_each_step=1.29s, eta=5:51:57\n",
      "2022-01-20 12:48:27 [INFO]\t[TRAIN] Epoch=17/50, Step=8/478, loss=0.053875, lr=0.073427, time_each_step=1.28s, eta=5:50:46\n",
      "2022-01-20 12:48:30 [INFO]\t[TRAIN] Epoch=17/50, Step=10/478, loss=0.057151, lr=0.073420, time_each_step=1.28s, eta=5:51:7\n",
      "2022-01-20 12:48:33 [INFO]\t[TRAIN] Epoch=17/50, Step=12/478, loss=0.069044, lr=0.073413, time_each_step=1.29s, eta=5:52:0\n",
      "2022-01-20 12:48:35 [INFO]\t[TRAIN] Epoch=17/50, Step=14/478, loss=0.061009, lr=0.073406, time_each_step=1.29s, eta=5:51:31\n",
      "2022-01-20 12:48:38 [INFO]\t[TRAIN] Epoch=17/50, Step=16/478, loss=0.070563, lr=0.073398, time_each_step=1.28s, eta=5:51:5\n",
      "2022-01-20 12:48:40 [INFO]\t[TRAIN] Epoch=17/50, Step=18/478, loss=0.079050, lr=0.073391, time_each_step=1.28s, eta=5:51:4\n",
      "2022-01-20 12:48:43 [INFO]\t[TRAIN] Epoch=17/50, Step=20/478, loss=0.058947, lr=0.073384, time_each_step=1.29s, eta=5:52:3\n",
      "2022-01-20 12:48:45 [INFO]\t[TRAIN] Epoch=17/50, Step=22/478, loss=0.079363, lr=0.073377, time_each_step=1.28s, eta=5:50:35\n",
      "2022-01-20 12:48:48 [INFO]\t[TRAIN] Epoch=17/50, Step=24/478, loss=0.061405, lr=0.073369, time_each_step=1.29s, eta=5:51:21\n",
      "2022-01-20 12:48:51 [INFO]\t[TRAIN] Epoch=17/50, Step=26/478, loss=0.044777, lr=0.073362, time_each_step=1.29s, eta=5:52:58\n",
      "2022-01-20 12:48:53 [INFO]\t[TRAIN] Epoch=17/50, Step=28/478, loss=0.099948, lr=0.073355, time_each_step=1.28s, eta=5:50:54\n",
      "2022-01-20 12:48:56 [INFO]\t[TRAIN] Epoch=17/50, Step=30/478, loss=0.055992, lr=0.073348, time_each_step=1.28s, eta=5:50:37\n",
      "2022-01-20 12:48:58 [INFO]\t[TRAIN] Epoch=17/50, Step=32/478, loss=0.077306, lr=0.073340, time_each_step=1.29s, eta=5:51:34\n",
      "2022-01-20 12:49:01 [INFO]\t[TRAIN] Epoch=17/50, Step=34/478, loss=0.086642, lr=0.073333, time_each_step=1.29s, eta=5:51:9\n",
      "2022-01-20 12:49:03 [INFO]\t[TRAIN] Epoch=17/50, Step=36/478, loss=0.074517, lr=0.073326, time_each_step=1.29s, eta=5:51:16\n",
      "2022-01-20 12:49:06 [INFO]\t[TRAIN] Epoch=17/50, Step=38/478, loss=0.078996, lr=0.073319, time_each_step=1.29s, eta=5:51:59\n",
      "2022-01-20 12:49:09 [INFO]\t[TRAIN] Epoch=17/50, Step=40/478, loss=0.047284, lr=0.073312, time_each_step=1.29s, eta=5:51:9\n",
      "2022-01-20 12:49:11 [INFO]\t[TRAIN] Epoch=17/50, Step=42/478, loss=0.053774, lr=0.073304, time_each_step=1.29s, eta=5:52:23\n",
      "2022-01-20 12:49:14 [INFO]\t[TRAIN] Epoch=17/50, Step=44/478, loss=0.076525, lr=0.073297, time_each_step=1.29s, eta=5:51:5\n",
      "2022-01-20 12:49:16 [INFO]\t[TRAIN] Epoch=17/50, Step=46/478, loss=0.050604, lr=0.073290, time_each_step=1.28s, eta=5:50:31\n",
      "2022-01-20 12:49:19 [INFO]\t[TRAIN] Epoch=17/50, Step=48/478, loss=0.065152, lr=0.073283, time_each_step=1.29s, eta=5:51:18\n",
      "2022-01-20 12:49:22 [INFO]\t[TRAIN] Epoch=17/50, Step=50/478, loss=0.075263, lr=0.073275, time_each_step=1.29s, eta=5:50:59\n",
      "2022-01-20 12:49:24 [INFO]\t[TRAIN] Epoch=17/50, Step=52/478, loss=0.050472, lr=0.073268, time_each_step=1.29s, eta=5:50:54\n",
      "2022-01-20 12:49:27 [INFO]\t[TRAIN] Epoch=17/50, Step=54/478, loss=0.066400, lr=0.073261, time_each_step=1.29s, eta=5:51:42\n",
      "2022-01-20 12:49:29 [INFO]\t[TRAIN] Epoch=17/50, Step=56/478, loss=0.055209, lr=0.073254, time_each_step=1.29s, eta=5:50:31\n",
      "2022-01-20 12:49:32 [INFO]\t[TRAIN] Epoch=17/50, Step=58/478, loss=0.055912, lr=0.073246, time_each_step=1.29s, eta=5:50:36\n",
      "2022-01-20 12:49:34 [INFO]\t[TRAIN] Epoch=17/50, Step=60/478, loss=0.079167, lr=0.073239, time_each_step=1.29s, eta=5:51:37\n",
      "2022-01-20 12:49:37 [INFO]\t[TRAIN] Epoch=17/50, Step=62/478, loss=0.067278, lr=0.073232, time_each_step=1.29s, eta=5:50:57\n",
      "2022-01-20 12:49:40 [INFO]\t[TRAIN] Epoch=17/50, Step=64/478, loss=0.074885, lr=0.073225, time_each_step=1.29s, eta=5:50:40\n",
      "2022-01-20 12:49:42 [INFO]\t[TRAIN] Epoch=17/50, Step=66/478, loss=0.077720, lr=0.073217, time_each_step=1.29s, eta=5:51:8\n",
      "2022-01-20 12:49:45 [INFO]\t[TRAIN] Epoch=17/50, Step=68/478, loss=0.082940, lr=0.073210, time_each_step=1.28s, eta=5:49:29\n",
      "2022-01-20 12:49:47 [INFO]\t[TRAIN] Epoch=17/50, Step=70/478, loss=0.052405, lr=0.073203, time_each_step=1.29s, eta=5:51:2\n",
      "2022-01-20 12:49:50 [INFO]\t[TRAIN] Epoch=17/50, Step=72/478, loss=0.063183, lr=0.073196, time_each_step=1.29s, eta=5:51:23\n",
      "2022-01-20 12:49:52 [INFO]\t[TRAIN] Epoch=17/50, Step=74/478, loss=0.084799, lr=0.073189, time_each_step=1.28s, eta=5:49:39\n",
      "2022-01-20 12:49:55 [INFO]\t[TRAIN] Epoch=17/50, Step=76/478, loss=0.069353, lr=0.073181, time_each_step=1.29s, eta=5:50:7\n",
      "2022-01-20 12:49:58 [INFO]\t[TRAIN] Epoch=17/50, Step=78/478, loss=0.068731, lr=0.073174, time_each_step=1.29s, eta=5:50:45\n",
      "2022-01-20 12:50:00 [INFO]\t[TRAIN] Epoch=17/50, Step=80/478, loss=0.057188, lr=0.073167, time_each_step=1.29s, eta=5:50:15\n",
      "2022-01-20 12:50:03 [INFO]\t[TRAIN] Epoch=17/50, Step=82/478, loss=0.049000, lr=0.073160, time_each_step=1.29s, eta=5:49:48\n",
      "2022-01-20 12:50:05 [INFO]\t[TRAIN] Epoch=17/50, Step=84/478, loss=0.057270, lr=0.073152, time_each_step=1.29s, eta=5:51:0\n",
      "2022-01-20 12:50:08 [INFO]\t[TRAIN] Epoch=17/50, Step=86/478, loss=0.048939, lr=0.073145, time_each_step=1.28s, eta=5:49:36\n",
      "2022-01-20 12:50:10 [INFO]\t[TRAIN] Epoch=17/50, Step=88/478, loss=0.060408, lr=0.073138, time_each_step=1.29s, eta=5:50:41\n",
      "2022-01-20 12:50:13 [INFO]\t[TRAIN] Epoch=17/50, Step=90/478, loss=0.073647, lr=0.073131, time_each_step=1.29s, eta=5:50:46\n",
      "2022-01-20 12:50:16 [INFO]\t[TRAIN] Epoch=17/50, Step=92/478, loss=0.073829, lr=0.073123, time_each_step=1.28s, eta=5:48:59\n",
      "2022-01-20 12:50:18 [INFO]\t[TRAIN] Epoch=17/50, Step=94/478, loss=0.081780, lr=0.073116, time_each_step=1.29s, eta=5:50:43\n",
      "2022-01-20 12:50:21 [INFO]\t[TRAIN] Epoch=17/50, Step=96/478, loss=0.057116, lr=0.073109, time_each_step=1.29s, eta=5:51:12\n",
      "2022-01-20 12:50:23 [INFO]\t[TRAIN] Epoch=17/50, Step=98/478, loss=0.065709, lr=0.073102, time_each_step=1.29s, eta=5:49:42\n",
      "2022-01-20 12:50:26 [INFO]\t[TRAIN] Epoch=17/50, Step=100/478, loss=0.076218, lr=0.073094, time_each_step=1.29s, eta=5:51:15\n",
      "2022-01-20 12:50:28 [INFO]\t[TRAIN] Epoch=17/50, Step=102/478, loss=0.052082, lr=0.073087, time_each_step=1.29s, eta=5:49:36\n",
      "2022-01-20 12:50:31 [INFO]\t[TRAIN] Epoch=17/50, Step=104/478, loss=0.050295, lr=0.073080, time_each_step=1.29s, eta=5:49:35\n",
      "2022-01-20 12:50:34 [INFO]\t[TRAIN] Epoch=17/50, Step=106/478, loss=0.052589, lr=0.073073, time_each_step=1.29s, eta=5:49:33\n",
      "2022-01-20 12:50:36 [INFO]\t[TRAIN] Epoch=17/50, Step=108/478, loss=0.059335, lr=0.073065, time_each_step=1.28s, eta=5:49:10\n",
      "2022-01-20 12:50:39 [INFO]\t[TRAIN] Epoch=17/50, Step=110/478, loss=0.071529, lr=0.073058, time_each_step=1.29s, eta=5:49:28\n",
      "2022-01-20 12:50:41 [INFO]\t[TRAIN] Epoch=17/50, Step=112/478, loss=0.060485, lr=0.073051, time_each_step=1.29s, eta=5:49:56\n",
      "2022-01-20 12:50:44 [INFO]\t[TRAIN] Epoch=17/50, Step=114/478, loss=0.068824, lr=0.073044, time_each_step=1.29s, eta=5:49:45\n",
      "2022-01-20 12:50:46 [INFO]\t[TRAIN] Epoch=17/50, Step=116/478, loss=0.059242, lr=0.073036, time_each_step=1.29s, eta=5:50:1\n",
      "2022-01-20 12:50:49 [INFO]\t[TRAIN] Epoch=17/50, Step=118/478, loss=0.064761, lr=0.073029, time_each_step=1.29s, eta=5:50:32\n",
      "2022-01-20 12:50:52 [INFO]\t[TRAIN] Epoch=17/50, Step=120/478, loss=0.058618, lr=0.073022, time_each_step=1.29s, eta=5:49:31\n",
      "2022-01-20 12:50:54 [INFO]\t[TRAIN] Epoch=17/50, Step=122/478, loss=0.108539, lr=0.073015, time_each_step=1.29s, eta=5:49:37\n",
      "2022-01-20 12:50:57 [INFO]\t[TRAIN] Epoch=17/50, Step=124/478, loss=0.066610, lr=0.073008, time_each_step=1.29s, eta=5:49:54\n",
      "2022-01-20 12:50:59 [INFO]\t[TRAIN] Epoch=17/50, Step=126/478, loss=0.057017, lr=0.073000, time_each_step=1.28s, eta=5:48:23\n",
      "2022-01-20 12:51:02 [INFO]\t[TRAIN] Epoch=17/50, Step=128/478, loss=0.076367, lr=0.072993, time_each_step=1.29s, eta=5:49:7\n",
      "2022-01-20 12:51:04 [INFO]\t[TRAIN] Epoch=17/50, Step=130/478, loss=0.074720, lr=0.072986, time_each_step=1.29s, eta=5:50:44\n",
      "2022-01-20 12:51:07 [INFO]\t[TRAIN] Epoch=17/50, Step=132/478, loss=0.080573, lr=0.072979, time_each_step=1.29s, eta=5:48:44\n",
      "2022-01-20 12:51:10 [INFO]\t[TRAIN] Epoch=17/50, Step=134/478, loss=0.069028, lr=0.072971, time_each_step=1.29s, eta=5:50:48\n",
      "2022-01-20 12:51:12 [INFO]\t[TRAIN] Epoch=17/50, Step=136/478, loss=0.068562, lr=0.072964, time_each_step=1.29s, eta=5:48:59\n",
      "2022-01-20 12:51:15 [INFO]\t[TRAIN] Epoch=17/50, Step=138/478, loss=0.067499, lr=0.072957, time_each_step=1.29s, eta=5:49:21\n",
      "2022-01-20 12:51:17 [INFO]\t[TRAIN] Epoch=17/50, Step=140/478, loss=0.068227, lr=0.072950, time_each_step=1.29s, eta=5:49:33\n",
      "2022-01-20 12:51:20 [INFO]\t[TRAIN] Epoch=17/50, Step=142/478, loss=0.069731, lr=0.072942, time_each_step=1.29s, eta=5:48:54\n",
      "2022-01-20 12:51:23 [INFO]\t[TRAIN] Epoch=17/50, Step=144/478, loss=0.052961, lr=0.072935, time_each_step=1.29s, eta=5:48:35\n",
      "2022-01-20 12:51:25 [INFO]\t[TRAIN] Epoch=17/50, Step=146/478, loss=0.076374, lr=0.072928, time_each_step=1.29s, eta=5:48:56\n",
      "2022-01-20 12:51:28 [INFO]\t[TRAIN] Epoch=17/50, Step=148/478, loss=0.073584, lr=0.072921, time_each_step=1.28s, eta=5:48:22\n",
      "2022-01-20 12:51:30 [INFO]\t[TRAIN] Epoch=17/50, Step=150/478, loss=0.058728, lr=0.072913, time_each_step=1.29s, eta=5:48:33\n",
      "2022-01-20 12:51:33 [INFO]\t[TRAIN] Epoch=17/50, Step=152/478, loss=0.046124, lr=0.072906, time_each_step=1.29s, eta=5:48:31\n",
      "2022-01-20 12:51:35 [INFO]\t[TRAIN] Epoch=17/50, Step=154/478, loss=0.080364, lr=0.072899, time_each_step=1.29s, eta=5:48:27\n",
      "2022-01-20 12:51:38 [INFO]\t[TRAIN] Epoch=17/50, Step=156/478, loss=0.090193, lr=0.072892, time_each_step=1.29s, eta=5:48:28\n",
      "2022-01-20 12:51:41 [INFO]\t[TRAIN] Epoch=17/50, Step=158/478, loss=0.049919, lr=0.072884, time_each_step=1.29s, eta=5:49:14\n",
      "2022-01-20 12:51:43 [INFO]\t[TRAIN] Epoch=17/50, Step=160/478, loss=0.075459, lr=0.072877, time_each_step=1.29s, eta=5:48:52\n",
      "2022-01-20 12:51:46 [INFO]\t[TRAIN] Epoch=17/50, Step=162/478, loss=0.071129, lr=0.072870, time_each_step=1.29s, eta=5:48:5\n",
      "2022-01-20 12:51:48 [INFO]\t[TRAIN] Epoch=17/50, Step=164/478, loss=0.073351, lr=0.072863, time_each_step=1.29s, eta=5:48:34\n",
      "2022-01-20 12:51:51 [INFO]\t[TRAIN] Epoch=17/50, Step=166/478, loss=0.053178, lr=0.072855, time_each_step=1.29s, eta=5:48:29\n",
      "2022-01-20 12:51:53 [INFO]\t[TRAIN] Epoch=17/50, Step=168/478, loss=0.093899, lr=0.072848, time_each_step=1.28s, eta=5:47:36\n",
      "2022-01-20 12:51:56 [INFO]\t[TRAIN] Epoch=17/50, Step=170/478, loss=0.079384, lr=0.072841, time_each_step=1.29s, eta=5:48:45\n",
      "2022-01-20 12:51:59 [INFO]\t[TRAIN] Epoch=17/50, Step=172/478, loss=0.066764, lr=0.072834, time_each_step=1.29s, eta=5:49:0\n",
      "2022-01-20 12:52:01 [INFO]\t[TRAIN] Epoch=17/50, Step=174/478, loss=0.061654, lr=0.072826, time_each_step=1.29s, eta=5:48:45\n",
      "2022-01-20 12:52:04 [INFO]\t[TRAIN] Epoch=17/50, Step=176/478, loss=0.082611, lr=0.072819, time_each_step=1.29s, eta=5:48:36\n",
      "2022-01-20 12:52:06 [INFO]\t[TRAIN] Epoch=17/50, Step=178/478, loss=0.062911, lr=0.072812, time_each_step=1.29s, eta=5:47:49\n",
      "2022-01-20 12:52:09 [INFO]\t[TRAIN] Epoch=17/50, Step=180/478, loss=0.060238, lr=0.072805, time_each_step=1.29s, eta=5:47:44\n",
      "2022-01-20 12:52:11 [INFO]\t[TRAIN] Epoch=17/50, Step=182/478, loss=0.062353, lr=0.072797, time_each_step=1.29s, eta=5:48:28\n",
      "2022-01-20 12:52:14 [INFO]\t[TRAIN] Epoch=17/50, Step=184/478, loss=0.064971, lr=0.072790, time_each_step=1.29s, eta=5:47:43\n",
      "2022-01-20 12:52:17 [INFO]\t[TRAIN] Epoch=17/50, Step=186/478, loss=0.063380, lr=0.072783, time_each_step=1.29s, eta=5:48:9\n",
      "2022-01-20 12:52:19 [INFO]\t[TRAIN] Epoch=17/50, Step=188/478, loss=0.072959, lr=0.072776, time_each_step=1.29s, eta=5:48:33\n",
      "2022-01-20 12:52:22 [INFO]\t[TRAIN] Epoch=17/50, Step=190/478, loss=0.079380, lr=0.072768, time_each_step=1.29s, eta=5:47:31\n",
      "2022-01-20 12:52:24 [INFO]\t[TRAIN] Epoch=17/50, Step=192/478, loss=0.058434, lr=0.072761, time_each_step=1.28s, eta=5:47:25\n",
      "2022-01-20 12:52:27 [INFO]\t[TRAIN] Epoch=17/50, Step=194/478, loss=0.081628, lr=0.072754, time_each_step=1.29s, eta=5:48:48\n",
      "2022-01-20 12:52:29 [INFO]\t[TRAIN] Epoch=17/50, Step=196/478, loss=0.086697, lr=0.072747, time_each_step=1.28s, eta=5:47:5\n",
      "2022-01-20 12:52:32 [INFO]\t[TRAIN] Epoch=17/50, Step=198/478, loss=0.070559, lr=0.072739, time_each_step=1.28s, eta=5:47:10\n",
      "2022-01-20 12:52:35 [INFO]\t[TRAIN] Epoch=17/50, Step=200/478, loss=0.054638, lr=0.072732, time_each_step=1.29s, eta=5:48:2\n",
      "2022-01-20 12:52:37 [INFO]\t[TRAIN] Epoch=17/50, Step=202/478, loss=0.087103, lr=0.072725, time_each_step=1.28s, eta=5:46:40\n",
      "2022-01-20 12:52:40 [INFO]\t[TRAIN] Epoch=17/50, Step=204/478, loss=0.096099, lr=0.072718, time_each_step=1.28s, eta=5:47:4\n",
      "2022-01-20 12:52:42 [INFO]\t[TRAIN] Epoch=17/50, Step=206/478, loss=0.055294, lr=0.072710, time_each_step=1.29s, eta=5:47:59\n",
      "2022-01-20 12:52:45 [INFO]\t[TRAIN] Epoch=17/50, Step=208/478, loss=0.073397, lr=0.072703, time_each_step=1.28s, eta=5:46:45\n",
      "2022-01-20 12:52:47 [INFO]\t[TRAIN] Epoch=17/50, Step=210/478, loss=0.050953, lr=0.072696, time_each_step=1.28s, eta=5:46:50\n",
      "2022-01-20 12:52:50 [INFO]\t[TRAIN] Epoch=17/50, Step=212/478, loss=0.047906, lr=0.072689, time_each_step=1.29s, eta=5:47:52\n",
      "2022-01-20 12:52:53 [INFO]\t[TRAIN] Epoch=17/50, Step=214/478, loss=0.068796, lr=0.072681, time_each_step=1.28s, eta=5:46:45\n",
      "2022-01-20 12:52:55 [INFO]\t[TRAIN] Epoch=17/50, Step=216/478, loss=0.047808, lr=0.072674, time_each_step=1.29s, eta=5:47:22\n",
      "2022-01-20 12:52:58 [INFO]\t[TRAIN] Epoch=17/50, Step=218/478, loss=0.065781, lr=0.072667, time_each_step=1.29s, eta=5:48:16\n",
      "2022-01-20 12:53:00 [INFO]\t[TRAIN] Epoch=17/50, Step=220/478, loss=0.048500, lr=0.072660, time_each_step=1.28s, eta=5:46:41\n",
      "2022-01-20 12:53:03 [INFO]\t[TRAIN] Epoch=17/50, Step=222/478, loss=0.089163, lr=0.072652, time_each_step=1.29s, eta=5:47:14\n",
      "2022-01-20 12:53:05 [INFO]\t[TRAIN] Epoch=17/50, Step=224/478, loss=0.091627, lr=0.072645, time_each_step=1.29s, eta=5:47:27\n",
      "2022-01-20 12:53:08 [INFO]\t[TRAIN] Epoch=17/50, Step=226/478, loss=0.054456, lr=0.072638, time_each_step=1.28s, eta=5:46:3\n",
      "2022-01-20 12:53:11 [INFO]\t[TRAIN] Epoch=17/50, Step=228/478, loss=0.066318, lr=0.072631, time_each_step=1.28s, eta=5:46:27\n",
      "2022-01-20 12:53:13 [INFO]\t[TRAIN] Epoch=17/50, Step=230/478, loss=0.076087, lr=0.072623, time_each_step=1.29s, eta=5:47:31\n",
      "2022-01-20 12:53:16 [INFO]\t[TRAIN] Epoch=17/50, Step=232/478, loss=0.067974, lr=0.072616, time_each_step=1.28s, eta=5:46:18\n",
      "2022-01-20 12:53:18 [INFO]\t[TRAIN] Epoch=17/50, Step=234/478, loss=0.053700, lr=0.072609, time_each_step=1.29s, eta=5:46:51\n",
      "2022-01-20 12:53:21 [INFO]\t[TRAIN] Epoch=17/50, Step=236/478, loss=0.065363, lr=0.072602, time_each_step=1.29s, eta=5:46:43\n",
      "2022-01-20 12:53:23 [INFO]\t[TRAIN] Epoch=17/50, Step=238/478, loss=0.076883, lr=0.072594, time_each_step=1.28s, eta=5:46:17\n",
      "2022-01-20 12:53:26 [INFO]\t[TRAIN] Epoch=17/50, Step=240/478, loss=0.079797, lr=0.072587, time_each_step=1.28s, eta=5:46:3\n",
      "2022-01-20 12:53:29 [INFO]\t[TRAIN] Epoch=17/50, Step=242/478, loss=0.064272, lr=0.072580, time_each_step=1.29s, eta=5:47:0\n",
      "2022-01-20 12:53:31 [INFO]\t[TRAIN] Epoch=17/50, Step=244/478, loss=0.076188, lr=0.072573, time_each_step=1.29s, eta=5:46:45\n",
      "2022-01-20 12:53:34 [INFO]\t[TRAIN] Epoch=17/50, Step=246/478, loss=0.073849, lr=0.072565, time_each_step=1.28s, eta=5:46:3\n",
      "2022-01-20 12:53:36 [INFO]\t[TRAIN] Epoch=17/50, Step=248/478, loss=0.052635, lr=0.072558, time_each_step=1.29s, eta=5:47:15\n",
      "2022-01-20 12:53:39 [INFO]\t[TRAIN] Epoch=17/50, Step=250/478, loss=0.070908, lr=0.072551, time_each_step=1.29s, eta=5:46:14\n",
      "2022-01-20 12:53:41 [INFO]\t[TRAIN] Epoch=17/50, Step=252/478, loss=0.075464, lr=0.072544, time_each_step=1.28s, eta=5:45:53\n",
      "2022-01-20 12:53:44 [INFO]\t[TRAIN] Epoch=17/50, Step=254/478, loss=0.074086, lr=0.072536, time_each_step=1.29s, eta=5:47:15\n",
      "2022-01-20 12:53:47 [INFO]\t[TRAIN] Epoch=17/50, Step=256/478, loss=0.107002, lr=0.072529, time_each_step=1.28s, eta=5:46:3\n",
      "2022-01-20 12:53:49 [INFO]\t[TRAIN] Epoch=17/50, Step=258/478, loss=0.087844, lr=0.072522, time_each_step=1.28s, eta=5:45:47\n",
      "2022-01-20 12:53:52 [INFO]\t[TRAIN] Epoch=17/50, Step=260/478, loss=0.088331, lr=0.072515, time_each_step=1.29s, eta=5:46:29\n",
      "2022-01-20 12:53:54 [INFO]\t[TRAIN] Epoch=17/50, Step=262/478, loss=0.043151, lr=0.072507, time_each_step=1.28s, eta=5:45:48\n",
      "2022-01-20 12:53:57 [INFO]\t[TRAIN] Epoch=17/50, Step=264/478, loss=0.067814, lr=0.072500, time_each_step=1.29s, eta=5:46:19\n",
      "2022-01-20 12:53:59 [INFO]\t[TRAIN] Epoch=17/50, Step=266/478, loss=0.081831, lr=0.072493, time_each_step=1.29s, eta=5:46:16\n",
      "2022-01-20 12:54:02 [INFO]\t[TRAIN] Epoch=17/50, Step=268/478, loss=0.052573, lr=0.072486, time_each_step=1.29s, eta=5:46:26\n",
      "2022-01-20 12:54:05 [INFO]\t[TRAIN] Epoch=17/50, Step=270/478, loss=0.055907, lr=0.072478, time_each_step=1.29s, eta=5:46:2\n",
      "2022-01-20 12:54:07 [INFO]\t[TRAIN] Epoch=17/50, Step=272/478, loss=0.075493, lr=0.072471, time_each_step=1.29s, eta=5:46:58\n",
      "2022-01-20 12:54:10 [INFO]\t[TRAIN] Epoch=17/50, Step=274/478, loss=0.085226, lr=0.072464, time_each_step=1.29s, eta=5:45:58\n",
      "2022-01-20 12:54:12 [INFO]\t[TRAIN] Epoch=17/50, Step=276/478, loss=0.061913, lr=0.072457, time_each_step=1.29s, eta=5:46:20\n",
      "2022-01-20 12:54:15 [INFO]\t[TRAIN] Epoch=17/50, Step=278/478, loss=0.073595, lr=0.072449, time_each_step=1.29s, eta=5:46:8\n",
      "2022-01-20 12:54:17 [INFO]\t[TRAIN] Epoch=17/50, Step=280/478, loss=0.059908, lr=0.072442, time_each_step=1.28s, eta=5:45:6\n",
      "2022-01-20 12:54:20 [INFO]\t[TRAIN] Epoch=17/50, Step=282/478, loss=0.060752, lr=0.072435, time_each_step=1.29s, eta=5:46:1\n",
      "2022-01-20 12:54:23 [INFO]\t[TRAIN] Epoch=17/50, Step=284/478, loss=0.066407, lr=0.072428, time_each_step=1.29s, eta=5:48:0\n",
      "2022-01-20 12:54:25 [INFO]\t[TRAIN] Epoch=17/50, Step=286/478, loss=0.043467, lr=0.072420, time_each_step=1.29s, eta=5:45:26\n",
      "2022-01-20 12:54:28 [INFO]\t[TRAIN] Epoch=17/50, Step=288/478, loss=0.079178, lr=0.072413, time_each_step=1.29s, eta=5:47:6\n",
      "2022-01-20 12:54:30 [INFO]\t[TRAIN] Epoch=17/50, Step=290/478, loss=0.073835, lr=0.072406, time_each_step=1.29s, eta=5:45:44\n",
      "2022-01-20 12:54:33 [INFO]\t[TRAIN] Epoch=17/50, Step=292/478, loss=0.066026, lr=0.072399, time_each_step=1.29s, eta=5:45:52\n",
      "2022-01-20 12:54:35 [INFO]\t[TRAIN] Epoch=17/50, Step=294/478, loss=0.094422, lr=0.072391, time_each_step=1.29s, eta=5:45:31\n",
      "2022-01-20 12:54:38 [INFO]\t[TRAIN] Epoch=17/50, Step=296/478, loss=0.064039, lr=0.072384, time_each_step=1.29s, eta=5:46:3\n",
      "2022-01-20 12:54:41 [INFO]\t[TRAIN] Epoch=17/50, Step=298/478, loss=0.060039, lr=0.072377, time_each_step=1.29s, eta=5:45:15\n",
      "2022-01-20 12:54:43 [INFO]\t[TRAIN] Epoch=17/50, Step=300/478, loss=0.064275, lr=0.072369, time_each_step=1.29s, eta=5:45:21\n",
      "2022-01-20 12:54:46 [INFO]\t[TRAIN] Epoch=17/50, Step=302/478, loss=0.053726, lr=0.072362, time_each_step=1.28s, eta=5:44:58\n",
      "2022-01-20 12:54:48 [INFO]\t[TRAIN] Epoch=17/50, Step=304/478, loss=0.059767, lr=0.072355, time_each_step=1.28s, eta=5:44:59\n",
      "2022-01-20 12:54:51 [INFO]\t[TRAIN] Epoch=17/50, Step=306/478, loss=0.041092, lr=0.072348, time_each_step=1.29s, eta=5:45:12\n",
      "2022-01-20 12:54:53 [INFO]\t[TRAIN] Epoch=17/50, Step=308/478, loss=0.052320, lr=0.072340, time_each_step=1.29s, eta=5:45:11\n",
      "2022-01-20 12:54:56 [INFO]\t[TRAIN] Epoch=17/50, Step=310/478, loss=0.064315, lr=0.072333, time_each_step=1.29s, eta=5:45:21\n",
      "2022-01-20 12:54:59 [INFO]\t[TRAIN] Epoch=17/50, Step=312/478, loss=0.068031, lr=0.072326, time_each_step=1.29s, eta=5:45:49\n",
      "2022-01-20 12:55:01 [INFO]\t[TRAIN] Epoch=17/50, Step=314/478, loss=0.081842, lr=0.072319, time_each_step=1.29s, eta=5:44:55\n",
      "2022-01-20 12:55:04 [INFO]\t[TRAIN] Epoch=17/50, Step=316/478, loss=0.059199, lr=0.072311, time_each_step=1.29s, eta=5:45:9\n",
      "2022-01-20 12:55:06 [INFO]\t[TRAIN] Epoch=17/50, Step=318/478, loss=0.070380, lr=0.072304, time_each_step=1.29s, eta=5:45:9\n",
      "2022-01-20 12:55:09 [INFO]\t[TRAIN] Epoch=17/50, Step=320/478, loss=0.085370, lr=0.072297, time_each_step=1.29s, eta=5:45:12\n",
      "2022-01-20 12:55:11 [INFO]\t[TRAIN] Epoch=17/50, Step=322/478, loss=0.061697, lr=0.072290, time_each_step=1.28s, eta=5:44:28\n",
      "2022-01-20 12:55:14 [INFO]\t[TRAIN] Epoch=17/50, Step=324/478, loss=0.051319, lr=0.072282, time_each_step=1.29s, eta=5:45:41\n",
      "2022-01-20 12:55:17 [INFO]\t[TRAIN] Epoch=17/50, Step=326/478, loss=0.065162, lr=0.072275, time_each_step=1.29s, eta=5:44:47\n",
      "2022-01-20 12:55:19 [INFO]\t[TRAIN] Epoch=17/50, Step=328/478, loss=0.052965, lr=0.072268, time_each_step=1.29s, eta=5:46:11\n",
      "2022-01-20 12:55:22 [INFO]\t[TRAIN] Epoch=17/50, Step=330/478, loss=0.068194, lr=0.072261, time_each_step=1.29s, eta=5:44:41\n",
      "2022-01-20 12:55:24 [INFO]\t[TRAIN] Epoch=17/50, Step=332/478, loss=0.049900, lr=0.072253, time_each_step=1.29s, eta=5:44:32\n",
      "2022-01-20 12:55:27 [INFO]\t[TRAIN] Epoch=17/50, Step=334/478, loss=0.069079, lr=0.072246, time_each_step=1.29s, eta=5:45:9\n",
      "2022-01-20 12:55:30 [INFO]\t[TRAIN] Epoch=17/50, Step=336/478, loss=0.084872, lr=0.072239, time_each_step=1.29s, eta=5:44:39\n",
      "2022-01-20 12:55:32 [INFO]\t[TRAIN] Epoch=17/50, Step=338/478, loss=0.068029, lr=0.072232, time_each_step=1.29s, eta=5:44:24\n",
      "2022-01-20 12:55:35 [INFO]\t[TRAIN] Epoch=17/50, Step=340/478, loss=0.065463, lr=0.072224, time_each_step=1.29s, eta=5:44:18\n",
      "2022-01-20 12:55:37 [INFO]\t[TRAIN] Epoch=17/50, Step=342/478, loss=0.050112, lr=0.072217, time_each_step=1.29s, eta=5:45:20\n",
      "2022-01-20 12:55:40 [INFO]\t[TRAIN] Epoch=17/50, Step=344/478, loss=0.056989, lr=0.072210, time_each_step=1.29s, eta=5:44:28\n",
      "2022-01-20 12:55:42 [INFO]\t[TRAIN] Epoch=17/50, Step=346/478, loss=0.062867, lr=0.072203, time_each_step=1.28s, eta=5:43:55\n",
      "2022-01-20 12:55:45 [INFO]\t[TRAIN] Epoch=17/50, Step=348/478, loss=0.081972, lr=0.072195, time_each_step=1.29s, eta=5:45:7\n",
      "2022-01-20 12:55:48 [INFO]\t[TRAIN] Epoch=17/50, Step=350/478, loss=0.046497, lr=0.072188, time_each_step=1.28s, eta=5:43:58\n",
      "2022-01-20 12:55:50 [INFO]\t[TRAIN] Epoch=17/50, Step=352/478, loss=0.052349, lr=0.072181, time_each_step=1.29s, eta=5:44:26\n",
      "2022-01-20 12:55:53 [INFO]\t[TRAIN] Epoch=17/50, Step=354/478, loss=0.068865, lr=0.072173, time_each_step=1.29s, eta=5:45:2\n",
      "2022-01-20 12:55:55 [INFO]\t[TRAIN] Epoch=17/50, Step=356/478, loss=0.060801, lr=0.072166, time_each_step=1.28s, eta=5:43:50\n",
      "2022-01-20 12:55:58 [INFO]\t[TRAIN] Epoch=17/50, Step=358/478, loss=0.097186, lr=0.072159, time_each_step=1.29s, eta=5:44:4\n",
      "2022-01-20 12:56:00 [INFO]\t[TRAIN] Epoch=17/50, Step=360/478, loss=0.054915, lr=0.072152, time_each_step=1.29s, eta=5:44:56\n",
      "2022-01-20 12:56:03 [INFO]\t[TRAIN] Epoch=17/50, Step=362/478, loss=0.059286, lr=0.072144, time_each_step=1.28s, eta=5:43:36\n",
      "2022-01-20 12:56:06 [INFO]\t[TRAIN] Epoch=17/50, Step=364/478, loss=0.066228, lr=0.072137, time_each_step=1.29s, eta=5:44:22\n",
      "2022-01-20 12:56:08 [INFO]\t[TRAIN] Epoch=17/50, Step=366/478, loss=0.088782, lr=0.072130, time_each_step=1.29s, eta=5:45:9\n",
      "2022-01-20 12:56:11 [INFO]\t[TRAIN] Epoch=17/50, Step=368/478, loss=0.054621, lr=0.072123, time_each_step=1.28s, eta=5:43:37\n",
      "2022-01-20 12:56:13 [INFO]\t[TRAIN] Epoch=17/50, Step=370/478, loss=0.030626, lr=0.072115, time_each_step=1.29s, eta=5:43:40\n",
      "2022-01-20 12:56:16 [INFO]\t[TRAIN] Epoch=17/50, Step=372/478, loss=0.043084, lr=0.072108, time_each_step=1.29s, eta=5:45:12\n",
      "2022-01-20 12:56:18 [INFO]\t[TRAIN] Epoch=17/50, Step=374/478, loss=0.048275, lr=0.072101, time_each_step=1.29s, eta=5:43:32\n",
      "2022-01-20 12:56:21 [INFO]\t[TRAIN] Epoch=17/50, Step=376/478, loss=0.064926, lr=0.072094, time_each_step=1.29s, eta=5:43:34\n",
      "2022-01-20 12:56:24 [INFO]\t[TRAIN] Epoch=17/50, Step=378/478, loss=0.064507, lr=0.072086, time_each_step=1.29s, eta=5:45:2\n",
      "2022-01-20 12:56:26 [INFO]\t[TRAIN] Epoch=17/50, Step=380/478, loss=0.063664, lr=0.072079, time_each_step=1.28s, eta=5:43:22\n",
      "2022-01-20 12:56:29 [INFO]\t[TRAIN] Epoch=17/50, Step=382/478, loss=0.057597, lr=0.072072, time_each_step=1.29s, eta=5:43:56\n",
      "2022-01-20 12:56:31 [INFO]\t[TRAIN] Epoch=17/50, Step=384/478, loss=0.046265, lr=0.072064, time_each_step=1.29s, eta=5:44:41\n",
      "2022-01-20 12:56:34 [INFO]\t[TRAIN] Epoch=17/50, Step=386/478, loss=0.056075, lr=0.072057, time_each_step=1.29s, eta=5:43:23\n",
      "2022-01-20 12:56:36 [INFO]\t[TRAIN] Epoch=17/50, Step=388/478, loss=0.063739, lr=0.072050, time_each_step=1.29s, eta=5:43:36\n",
      "2022-01-20 12:56:39 [INFO]\t[TRAIN] Epoch=17/50, Step=390/478, loss=0.064630, lr=0.072043, time_each_step=1.29s, eta=5:43:54\n",
      "2022-01-20 12:56:42 [INFO]\t[TRAIN] Epoch=17/50, Step=392/478, loss=0.071207, lr=0.072035, time_each_step=1.28s, eta=5:43:3\n",
      "2022-01-20 12:56:44 [INFO]\t[TRAIN] Epoch=17/50, Step=394/478, loss=0.066237, lr=0.072028, time_each_step=1.29s, eta=5:43:55\n",
      "2022-01-20 12:56:47 [INFO]\t[TRAIN] Epoch=17/50, Step=396/478, loss=0.077430, lr=0.072021, time_each_step=1.29s, eta=5:43:56\n",
      "2022-01-20 12:56:49 [INFO]\t[TRAIN] Epoch=17/50, Step=398/478, loss=0.068650, lr=0.072014, time_each_step=1.29s, eta=5:43:11\n",
      "2022-01-20 12:56:52 [INFO]\t[TRAIN] Epoch=17/50, Step=400/478, loss=0.062428, lr=0.072006, time_each_step=1.29s, eta=5:43:41\n",
      "2022-01-20 12:56:54 [INFO]\t[TRAIN] Epoch=17/50, Step=402/478, loss=0.062385, lr=0.071999, time_each_step=1.29s, eta=5:44:3\n",
      "2022-01-20 12:56:57 [INFO]\t[TRAIN] Epoch=17/50, Step=404/478, loss=0.067339, lr=0.071992, time_each_step=1.29s, eta=5:43:31\n",
      "2022-01-20 12:57:00 [INFO]\t[TRAIN] Epoch=17/50, Step=406/478, loss=0.067296, lr=0.071985, time_each_step=1.29s, eta=5:44:8\n",
      "2022-01-20 12:57:02 [INFO]\t[TRAIN] Epoch=17/50, Step=408/478, loss=0.050094, lr=0.071977, time_each_step=1.29s, eta=5:43:8\n",
      "2022-01-20 12:57:05 [INFO]\t[TRAIN] Epoch=17/50, Step=410/478, loss=0.055328, lr=0.071970, time_each_step=1.29s, eta=5:43:6\n",
      "2022-01-20 12:57:07 [INFO]\t[TRAIN] Epoch=17/50, Step=412/478, loss=0.091025, lr=0.071963, time_each_step=1.29s, eta=5:44:16\n",
      "2022-01-20 12:57:10 [INFO]\t[TRAIN] Epoch=17/50, Step=414/478, loss=0.095576, lr=0.071955, time_each_step=1.29s, eta=5:42:45\n",
      "2022-01-20 12:57:12 [INFO]\t[TRAIN] Epoch=17/50, Step=416/478, loss=0.059639, lr=0.071948, time_each_step=1.29s, eta=5:42:54\n",
      "2022-01-20 12:57:15 [INFO]\t[TRAIN] Epoch=17/50, Step=418/478, loss=0.051843, lr=0.071941, time_each_step=1.29s, eta=5:43:43\n",
      "2022-01-20 12:57:18 [INFO]\t[TRAIN] Epoch=17/50, Step=420/478, loss=0.060352, lr=0.071934, time_each_step=1.28s, eta=5:42:16\n",
      "2022-01-20 12:57:20 [INFO]\t[TRAIN] Epoch=17/50, Step=422/478, loss=0.107090, lr=0.071926, time_each_step=1.28s, eta=5:42:12\n",
      "2022-01-20 12:57:23 [INFO]\t[TRAIN] Epoch=17/50, Step=424/478, loss=0.051337, lr=0.071919, time_each_step=1.29s, eta=5:44:5\n",
      "2022-01-20 12:57:25 [INFO]\t[TRAIN] Epoch=17/50, Step=426/478, loss=0.062578, lr=0.071912, time_each_step=1.28s, eta=5:42:1\n",
      "2022-01-20 12:57:28 [INFO]\t[TRAIN] Epoch=17/50, Step=428/478, loss=0.051697, lr=0.071905, time_each_step=1.29s, eta=5:42:41\n",
      "2022-01-20 12:57:30 [INFO]\t[TRAIN] Epoch=17/50, Step=430/478, loss=0.083453, lr=0.071897, time_each_step=1.29s, eta=5:43:37\n",
      "2022-01-20 12:57:33 [INFO]\t[TRAIN] Epoch=17/50, Step=432/478, loss=0.075612, lr=0.071890, time_each_step=1.29s, eta=5:42:19\n",
      "2022-01-20 12:57:36 [INFO]\t[TRAIN] Epoch=17/50, Step=434/478, loss=0.073615, lr=0.071883, time_each_step=1.28s, eta=5:42:3\n",
      "2022-01-20 12:57:38 [INFO]\t[TRAIN] Epoch=17/50, Step=436/478, loss=0.051879, lr=0.071876, time_each_step=1.29s, eta=5:43:17\n",
      "2022-01-20 12:57:41 [INFO]\t[TRAIN] Epoch=17/50, Step=438/478, loss=0.053474, lr=0.071868, time_each_step=1.29s, eta=5:42:27\n",
      "2022-01-20 12:57:43 [INFO]\t[TRAIN] Epoch=17/50, Step=440/478, loss=0.050176, lr=0.071861, time_each_step=1.28s, eta=5:42:5\n",
      "2022-01-20 12:57:46 [INFO]\t[TRAIN] Epoch=17/50, Step=442/478, loss=0.059486, lr=0.071854, time_each_step=1.29s, eta=5:42:45\n",
      "2022-01-20 12:57:49 [INFO]\t[TRAIN] Epoch=17/50, Step=444/478, loss=0.066985, lr=0.071846, time_each_step=1.29s, eta=5:42:12\n",
      "2022-01-20 12:57:51 [INFO]\t[TRAIN] Epoch=17/50, Step=446/478, loss=0.048387, lr=0.071839, time_each_step=1.28s, eta=5:41:35\n",
      "2022-01-20 12:57:54 [INFO]\t[TRAIN] Epoch=17/50, Step=448/478, loss=0.053114, lr=0.071832, time_each_step=1.29s, eta=5:43:2\n",
      "2022-01-20 12:57:56 [INFO]\t[TRAIN] Epoch=17/50, Step=450/478, loss=0.086754, lr=0.071825, time_each_step=1.28s, eta=5:41:29\n",
      "2022-01-20 12:57:59 [INFO]\t[TRAIN] Epoch=17/50, Step=452/478, loss=0.071968, lr=0.071817, time_each_step=1.29s, eta=5:42:9\n",
      "2022-01-20 12:58:01 [INFO]\t[TRAIN] Epoch=17/50, Step=454/478, loss=0.058371, lr=0.071810, time_each_step=1.29s, eta=5:42:55\n",
      "2022-01-20 12:58:04 [INFO]\t[TRAIN] Epoch=17/50, Step=456/478, loss=0.058742, lr=0.071803, time_each_step=1.28s, eta=5:41:25\n",
      "2022-01-20 12:58:07 [INFO]\t[TRAIN] Epoch=17/50, Step=458/478, loss=0.049737, lr=0.071796, time_each_step=1.29s, eta=5:42:7\n",
      "2022-01-20 12:58:09 [INFO]\t[TRAIN] Epoch=17/50, Step=460/478, loss=0.039347, lr=0.071788, time_each_step=1.3s, eta=5:46:16\n",
      "2022-01-20 12:58:12 [INFO]\t[TRAIN] Epoch=17/50, Step=462/478, loss=0.064753, lr=0.071781, time_each_step=1.29s, eta=5:42:12\n",
      "2022-01-20 12:58:14 [INFO]\t[TRAIN] Epoch=17/50, Step=464/478, loss=0.064965, lr=0.071774, time_each_step=1.29s, eta=5:42:26\n",
      "2022-01-20 12:58:17 [INFO]\t[TRAIN] Epoch=17/50, Step=466/478, loss=0.070142, lr=0.071766, time_each_step=1.29s, eta=5:41:56\n",
      "2022-01-20 12:58:19 [INFO]\t[TRAIN] Epoch=17/50, Step=468/478, loss=0.073945, lr=0.071759, time_each_step=1.28s, eta=5:41:15\n",
      "2022-01-20 12:58:22 [INFO]\t[TRAIN] Epoch=17/50, Step=470/478, loss=0.051089, lr=0.071752, time_each_step=1.29s, eta=5:42:11\n",
      "2022-01-20 12:58:25 [INFO]\t[TRAIN] Epoch=17/50, Step=472/478, loss=0.046242, lr=0.071745, time_each_step=1.29s, eta=5:41:32\n",
      "2022-01-20 12:58:27 [INFO]\t[TRAIN] Epoch=17/50, Step=474/478, loss=0.093058, lr=0.071737, time_each_step=1.29s, eta=5:41:56\n",
      "2022-01-20 12:58:30 [INFO]\t[TRAIN] Epoch=17/50, Step=476/478, loss=0.049621, lr=0.071730, time_each_step=1.29s, eta=5:41:57\n",
      "2022-01-20 12:58:32 [INFO]\t[TRAIN] Epoch=17/50, Step=478/478, loss=0.077877, lr=0.071723, time_each_step=1.28s, eta=5:41:11\n",
      "2022-01-20 12:58:32 [INFO]\t[TRAIN] Epoch 17 finished, loss=0.06628705 .\n",
      "2022-01-20 12:58:32 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-01-20 12:58:33 [INFO]\tStart to evaluate(total_samples=50, total_steps=50)...\n",
      "2022-01-20 12:58:39 [INFO]\t[EVAL] Finished, Epoch=17, miou=0.831559, category_iou=[0.96988684 0.7408223  0.78396755], oacc=0.972051, category_acc=[0.98561424 0.8615653  0.8685933 ], kappa=0.864158, category_F1-score=[0.98471327 0.85111767 0.87890334] .\n",
      "2022-01-20 12:58:39 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_13, miou=0.8400812745094299\n",
      "2022-01-20 12:58:39 [INFO]\tModel saved in model/deeplab_augument_alldata2/epoch_17.\n",
      "2022-01-20 12:58:43 [INFO]\t[TRAIN] Epoch=18/50, Step=2/478, loss=0.041251, lr=0.071716, time_each_step=1.89s, eta=8:21:9\n",
      "2022-01-20 12:58:46 [INFO]\t[TRAIN] Epoch=18/50, Step=4/478, loss=0.073245, lr=0.071708, time_each_step=1.28s, eta=5:40:52\n",
      "2022-01-20 12:58:48 [INFO]\t[TRAIN] Epoch=18/50, Step=6/478, loss=0.046858, lr=0.071701, time_each_step=1.28s, eta=5:40:59\n",
      "2022-01-20 12:58:51 [INFO]\t[TRAIN] Epoch=18/50, Step=8/478, loss=0.075104, lr=0.071694, time_each_step=1.29s, eta=5:41:26\n",
      "2022-01-20 12:58:53 [INFO]\t[TRAIN] Epoch=18/50, Step=10/478, loss=0.052008, lr=0.071686, time_each_step=1.28s, eta=5:40:11\n",
      "2022-01-20 12:58:56 [INFO]\t[TRAIN] Epoch=18/50, Step=12/478, loss=0.082157, lr=0.071679, time_each_step=1.28s, eta=5:40:25\n",
      "2022-01-20 12:58:59 [INFO]\t[TRAIN] Epoch=18/50, Step=14/478, loss=0.079507, lr=0.071672, time_each_step=1.29s, eta=5:42:0\n",
      "2022-01-20 12:59:01 [INFO]\t[TRAIN] Epoch=18/50, Step=16/478, loss=0.074882, lr=0.071665, time_each_step=1.28s, eta=5:40:21\n",
      "2022-01-20 12:59:04 [INFO]\t[TRAIN] Epoch=18/50, Step=18/478, loss=0.051602, lr=0.071657, time_each_step=1.28s, eta=5:40:47\n",
      "2022-01-20 12:59:06 [INFO]\t[TRAIN] Epoch=18/50, Step=20/478, loss=0.067588, lr=0.071650, time_each_step=1.29s, eta=5:41:33\n",
      "2022-01-20 12:59:09 [INFO]\t[TRAIN] Epoch=18/50, Step=22/478, loss=0.040067, lr=0.071643, time_each_step=1.28s, eta=5:40:24\n",
      "2022-01-20 12:59:11 [INFO]\t[TRAIN] Epoch=18/50, Step=24/478, loss=0.074199, lr=0.071635, time_each_step=1.29s, eta=5:40:57\n",
      "2022-01-20 12:59:14 [INFO]\t[TRAIN] Epoch=18/50, Step=26/478, loss=0.054752, lr=0.071628, time_each_step=1.29s, eta=5:42:10\n",
      "2022-01-20 12:59:17 [INFO]\t[TRAIN] Epoch=18/50, Step=28/478, loss=0.054308, lr=0.071621, time_each_step=1.28s, eta=5:40:15\n",
      "2022-01-20 12:59:19 [INFO]\t[TRAIN] Epoch=18/50, Step=30/478, loss=0.063995, lr=0.071614, time_each_step=1.28s, eta=5:40:17\n",
      "2022-01-20 12:59:22 [INFO]\t[TRAIN] Epoch=18/50, Step=32/478, loss=0.051712, lr=0.071606, time_each_step=1.29s, eta=5:41:54\n",
      "2022-01-20 12:59:24 [INFO]\t[TRAIN] Epoch=18/50, Step=34/478, loss=0.054996, lr=0.071599, time_each_step=1.28s, eta=5:40:17\n",
      "2022-01-20 12:59:27 [INFO]\t[TRAIN] Epoch=18/50, Step=36/478, loss=0.067148, lr=0.071592, time_each_step=1.28s, eta=5:40:20\n",
      "2022-01-20 12:59:29 [INFO]\t[TRAIN] Epoch=18/50, Step=38/478, loss=0.039574, lr=0.071585, time_each_step=1.29s, eta=5:41:35\n",
      "2022-01-20 12:59:32 [INFO]\t[TRAIN] Epoch=18/50, Step=40/478, loss=0.055640, lr=0.071577, time_each_step=1.28s, eta=5:40:10\n",
      "2022-01-20 12:59:35 [INFO]\t[TRAIN] Epoch=18/50, Step=42/478, loss=0.046587, lr=0.071570, time_each_step=1.29s, eta=5:40:52\n",
      "2022-01-20 12:59:37 [INFO]\t[TRAIN] Epoch=18/50, Step=44/478, loss=0.071647, lr=0.071563, time_each_step=1.29s, eta=5:41:21\n",
      "2022-01-20 12:59:40 [INFO]\t[TRAIN] Epoch=18/50, Step=46/478, loss=0.054401, lr=0.071555, time_each_step=1.28s, eta=5:40:14\n",
      "2022-01-20 12:59:42 [INFO]\t[TRAIN] Epoch=18/50, Step=48/478, loss=0.066180, lr=0.071548, time_each_step=1.29s, eta=5:40:39\n",
      "2022-01-20 12:59:45 [INFO]\t[TRAIN] Epoch=18/50, Step=50/478, loss=0.051023, lr=0.071541, time_each_step=1.29s, eta=5:41:0\n",
      "2022-01-20 12:59:47 [INFO]\t[TRAIN] Epoch=18/50, Step=52/478, loss=0.059557, lr=0.071534, time_each_step=1.28s, eta=5:39:6\n",
      "2022-01-20 12:59:50 [INFO]\t[TRAIN] Epoch=18/50, Step=54/478, loss=0.048367, lr=0.071526, time_each_step=1.28s, eta=5:39:23\n",
      "2022-01-20 12:59:53 [INFO]\t[TRAIN] Epoch=18/50, Step=56/478, loss=0.062914, lr=0.071519, time_each_step=1.29s, eta=5:40:19\n",
      "2022-01-20 12:59:55 [INFO]\t[TRAIN] Epoch=18/50, Step=58/478, loss=0.054080, lr=0.071512, time_each_step=1.29s, eta=5:40:23\n",
      "2022-01-20 12:59:58 [INFO]\t[TRAIN] Epoch=18/50, Step=60/478, loss=0.068016, lr=0.071504, time_each_step=1.28s, eta=5:39:31\n",
      "2022-01-20 13:00:00 [INFO]\t[TRAIN] Epoch=18/50, Step=62/478, loss=0.067562, lr=0.071497, time_each_step=1.29s, eta=5:41:35\n",
      "2022-01-20 13:00:03 [INFO]\t[TRAIN] Epoch=18/50, Step=64/478, loss=0.070424, lr=0.071490, time_each_step=1.28s, eta=5:39:21\n",
      "2022-01-20 13:00:05 [INFO]\t[TRAIN] Epoch=18/50, Step=66/478, loss=0.078981, lr=0.071483, time_each_step=1.28s, eta=5:39:42\n",
      "2022-01-20 13:00:08 [INFO]\t[TRAIN] Epoch=18/50, Step=68/478, loss=0.068579, lr=0.071475, time_each_step=1.29s, eta=5:40:10\n",
      "2022-01-20 13:00:11 [INFO]\t[TRAIN] Epoch=18/50, Step=70/478, loss=0.061328, lr=0.071468, time_each_step=1.29s, eta=5:40:15\n",
      "2022-01-20 13:00:13 [INFO]\t[TRAIN] Epoch=18/50, Step=72/478, loss=0.070439, lr=0.071461, time_each_step=1.29s, eta=5:39:51\n",
      "2022-01-20 13:00:16 [INFO]\t[TRAIN] Epoch=18/50, Step=74/478, loss=0.064216, lr=0.071454, time_each_step=1.29s, eta=5:40:51\n",
      "2022-01-20 13:00:18 [INFO]\t[TRAIN] Epoch=18/50, Step=76/478, loss=0.048457, lr=0.071446, time_each_step=1.28s, eta=5:39:31\n",
      "2022-01-20 13:00:21 [INFO]\t[TRAIN] Epoch=18/50, Step=78/478, loss=0.056008, lr=0.071439, time_each_step=1.29s, eta=5:39:49\n",
      "2022-01-20 13:00:23 [INFO]\t[TRAIN] Epoch=18/50, Step=80/478, loss=0.094610, lr=0.071432, time_each_step=1.29s, eta=5:40:37\n",
      "2022-01-20 13:00:26 [INFO]\t[TRAIN] Epoch=18/50, Step=82/478, loss=0.060515, lr=0.071424, time_each_step=1.29s, eta=5:39:44\n",
      "2022-01-20 13:00:29 [INFO]\t[TRAIN] Epoch=18/50, Step=84/478, loss=0.080925, lr=0.071417, time_each_step=1.29s, eta=5:39:50\n",
      "2022-01-20 13:00:31 [INFO]\t[TRAIN] Epoch=18/50, Step=86/478, loss=0.053890, lr=0.071410, time_each_step=1.29s, eta=5:40:24\n",
      "2022-01-20 13:00:34 [INFO]\t[TRAIN] Epoch=18/50, Step=88/478, loss=0.082512, lr=0.071403, time_each_step=1.28s, eta=5:39:8\n",
      "2022-01-20 13:00:36 [INFO]\t[TRAIN] Epoch=18/50, Step=90/478, loss=0.065118, lr=0.071395, time_each_step=1.28s, eta=5:39:15\n",
      "2022-01-20 13:00:39 [INFO]\t[TRAIN] Epoch=18/50, Step=92/478, loss=0.069307, lr=0.071388, time_each_step=1.29s, eta=5:40:17\n",
      "2022-01-20 13:00:41 [INFO]\t[TRAIN] Epoch=18/50, Step=94/478, loss=0.076322, lr=0.071381, time_each_step=1.29s, eta=5:39:17\n",
      "2022-01-20 13:00:44 [INFO]\t[TRAIN] Epoch=18/50, Step=96/478, loss=0.078640, lr=0.071373, time_each_step=1.29s, eta=5:39:21\n",
      "2022-01-20 13:00:47 [INFO]\t[TRAIN] Epoch=18/50, Step=98/478, loss=0.060563, lr=0.071366, time_each_step=1.29s, eta=5:40:17\n",
      "2022-01-20 13:00:49 [INFO]\t[TRAIN] Epoch=18/50, Step=100/478, loss=0.065859, lr=0.071359, time_each_step=1.28s, eta=5:38:30\n",
      "2022-01-20 13:00:52 [INFO]\t[TRAIN] Epoch=18/50, Step=102/478, loss=0.064463, lr=0.071352, time_each_step=1.28s, eta=5:38:58\n",
      "2022-01-20 13:00:54 [INFO]\t[TRAIN] Epoch=18/50, Step=104/478, loss=0.049800, lr=0.071344, time_each_step=1.29s, eta=5:39:55\n",
      "2022-01-20 13:00:57 [INFO]\t[TRAIN] Epoch=18/50, Step=106/478, loss=0.089500, lr=0.071337, time_each_step=1.29s, eta=5:39:50\n",
      "2022-01-20 13:00:59 [INFO]\t[TRAIN] Epoch=18/50, Step=108/478, loss=0.078258, lr=0.071330, time_each_step=1.29s, eta=5:39:10\n",
      "2022-01-20 13:01:02 [INFO]\t[TRAIN] Epoch=18/50, Step=110/478, loss=0.085118, lr=0.071322, time_each_step=1.29s, eta=5:39:45\n",
      "2022-01-20 13:01:05 [INFO]\t[TRAIN] Epoch=18/50, Step=112/478, loss=0.041237, lr=0.071315, time_each_step=1.28s, eta=5:38:24\n",
      "2022-01-20 13:01:07 [INFO]\t[TRAIN] Epoch=18/50, Step=114/478, loss=0.062307, lr=0.071308, time_each_step=1.28s, eta=5:38:43\n",
      "2022-01-20 13:01:10 [INFO]\t[TRAIN] Epoch=18/50, Step=116/478, loss=0.057140, lr=0.071301, time_each_step=1.29s, eta=5:39:4\n",
      "2022-01-20 13:01:12 [INFO]\t[TRAIN] Epoch=18/50, Step=118/478, loss=0.065873, lr=0.071293, time_each_step=1.29s, eta=5:38:58\n",
      "2022-01-20 13:01:15 [INFO]\t[TRAIN] Epoch=18/50, Step=120/478, loss=0.063572, lr=0.071286, time_each_step=1.29s, eta=5:38:51\n",
      "2022-01-20 13:01:17 [INFO]\t[TRAIN] Epoch=18/50, Step=122/478, loss=0.068573, lr=0.071279, time_each_step=1.29s, eta=5:39:33\n",
      "2022-01-20 13:01:20 [INFO]\t[TRAIN] Epoch=18/50, Step=124/478, loss=0.052332, lr=0.071271, time_each_step=1.29s, eta=5:38:46\n",
      "2022-01-20 13:01:23 [INFO]\t[TRAIN] Epoch=18/50, Step=126/478, loss=0.051379, lr=0.071264, time_each_step=1.28s, eta=5:38:32\n",
      "2022-01-20 13:01:25 [INFO]\t[TRAIN] Epoch=18/50, Step=128/478, loss=0.040485, lr=0.071257, time_each_step=1.29s, eta=5:39:34\n",
      "2022-01-20 13:01:28 [INFO]\t[TRAIN] Epoch=18/50, Step=130/478, loss=0.039870, lr=0.071250, time_each_step=1.29s, eta=5:38:30\n",
      "2022-01-20 13:01:30 [INFO]\t[TRAIN] Epoch=18/50, Step=132/478, loss=0.072754, lr=0.071242, time_each_step=1.28s, eta=5:38:7\n",
      "2022-01-20 13:01:33 [INFO]\t[TRAIN] Epoch=18/50, Step=134/478, loss=0.087899, lr=0.071235, time_each_step=1.29s, eta=5:39:2\n",
      "2022-01-20 13:01:35 [INFO]\t[TRAIN] Epoch=18/50, Step=136/478, loss=0.057170, lr=0.071228, time_each_step=1.28s, eta=5:38:10\n",
      "2022-01-20 13:01:38 [INFO]\t[TRAIN] Epoch=18/50, Step=138/478, loss=0.044175, lr=0.071220, time_each_step=1.28s, eta=5:38:0\n",
      "2022-01-20 13:01:41 [INFO]\t[TRAIN] Epoch=18/50, Step=140/478, loss=0.046838, lr=0.071213, time_each_step=1.29s, eta=5:38:49\n",
      "2022-01-20 13:01:43 [INFO]\t[TRAIN] Epoch=18/50, Step=142/478, loss=0.084666, lr=0.071206, time_each_step=1.28s, eta=5:38:3\n",
      "2022-01-20 13:01:46 [INFO]\t[TRAIN] Epoch=18/50, Step=144/478, loss=0.071645, lr=0.071199, time_each_step=1.29s, eta=5:38:23\n",
      "2022-01-20 13:01:48 [INFO]\t[TRAIN] Epoch=18/50, Step=146/478, loss=0.072100, lr=0.071191, time_each_step=1.29s, eta=5:38:45\n",
      "2022-01-20 13:01:51 [INFO]\t[TRAIN] Epoch=18/50, Step=148/478, loss=0.052034, lr=0.071184, time_each_step=1.28s, eta=5:37:53\n",
      "2022-01-20 13:01:53 [INFO]\t[TRAIN] Epoch=18/50, Step=150/478, loss=0.056724, lr=0.071177, time_each_step=1.29s, eta=5:38:38\n",
      "2022-01-20 13:01:56 [INFO]\t[TRAIN] Epoch=18/50, Step=152/478, loss=0.070012, lr=0.071169, time_each_step=1.29s, eta=5:39:1\n",
      "2022-01-20 13:01:59 [INFO]\t[TRAIN] Epoch=18/50, Step=154/478, loss=0.076387, lr=0.071162, time_each_step=1.29s, eta=5:38:9\n",
      "2022-01-20 13:02:01 [INFO]\t[TRAIN] Epoch=18/50, Step=156/478, loss=0.052167, lr=0.071155, time_each_step=1.29s, eta=5:38:39\n",
      "2022-01-20 13:02:04 [INFO]\t[TRAIN] Epoch=18/50, Step=158/478, loss=0.038690, lr=0.071148, time_each_step=1.29s, eta=5:38:18\n",
      "2022-01-20 13:02:06 [INFO]\t[TRAIN] Epoch=18/50, Step=160/478, loss=0.070749, lr=0.071140, time_each_step=1.28s, eta=5:37:43\n",
      "2022-01-20 13:02:09 [INFO]\t[TRAIN] Epoch=18/50, Step=162/478, loss=0.089552, lr=0.071133, time_each_step=1.28s, eta=5:37:29\n",
      "2022-01-20 13:02:11 [INFO]\t[TRAIN] Epoch=18/50, Step=164/478, loss=0.064215, lr=0.071126, time_each_step=1.29s, eta=5:38:36\n",
      "2022-01-20 13:02:14 [INFO]\t[TRAIN] Epoch=18/50, Step=166/478, loss=0.086147, lr=0.071118, time_each_step=1.29s, eta=5:38:24\n",
      "2022-01-20 13:02:17 [INFO]\t[TRAIN] Epoch=18/50, Step=168/478, loss=0.065100, lr=0.071111, time_each_step=1.29s, eta=5:37:57\n",
      "2022-01-20 13:02:19 [INFO]\t[TRAIN] Epoch=18/50, Step=170/478, loss=0.052996, lr=0.071104, time_each_step=1.29s, eta=5:38:29\n",
      "2022-01-20 13:02:22 [INFO]\t[TRAIN] Epoch=18/50, Step=172/478, loss=0.066171, lr=0.071096, time_each_step=1.29s, eta=5:37:38\n",
      "2022-01-20 13:02:24 [INFO]\t[TRAIN] Epoch=18/50, Step=174/478, loss=0.075195, lr=0.071089, time_each_step=1.29s, eta=5:38:8\n",
      "2022-01-20 13:02:27 [INFO]\t[TRAIN] Epoch=18/50, Step=176/478, loss=0.095909, lr=0.071082, time_each_step=1.29s, eta=5:37:39\n",
      "2022-01-20 13:02:29 [INFO]\t[TRAIN] Epoch=18/50, Step=178/478, loss=0.083767, lr=0.071075, time_each_step=1.28s, eta=5:37:24\n",
      "2022-01-20 13:02:32 [INFO]\t[TRAIN] Epoch=18/50, Step=180/478, loss=0.061363, lr=0.071067, time_each_step=1.29s, eta=5:37:39\n",
      "2022-01-20 13:02:35 [INFO]\t[TRAIN] Epoch=18/50, Step=182/478, loss=0.067882, lr=0.071060, time_each_step=1.29s, eta=5:38:6\n",
      "2022-01-20 13:02:37 [INFO]\t[TRAIN] Epoch=18/50, Step=184/478, loss=0.046647, lr=0.071053, time_each_step=1.29s, eta=5:37:31\n",
      "2022-01-20 13:02:40 [INFO]\t[TRAIN] Epoch=18/50, Step=186/478, loss=0.066401, lr=0.071045, time_each_step=1.28s, eta=5:37:10\n",
      "2022-01-20 13:02:42 [INFO]\t[TRAIN] Epoch=18/50, Step=188/478, loss=0.090029, lr=0.071038, time_each_step=1.29s, eta=5:37:56\n",
      "2022-01-20 13:02:45 [INFO]\t[TRAIN] Epoch=18/50, Step=190/478, loss=0.082106, lr=0.071031, time_each_step=1.29s, eta=5:37:38\n",
      "2022-01-20 13:02:47 [INFO]\t[TRAIN] Epoch=18/50, Step=192/478, loss=0.099864, lr=0.071024, time_each_step=1.28s, eta=5:36:59\n",
      "2022-01-20 13:02:50 [INFO]\t[TRAIN] Epoch=18/50, Step=194/478, loss=0.072454, lr=0.071016, time_each_step=1.29s, eta=5:37:40\n",
      "2022-01-20 13:02:53 [INFO]\t[TRAIN] Epoch=18/50, Step=196/478, loss=0.096845, lr=0.071009, time_each_step=1.28s, eta=5:37:0\n",
      "2022-01-20 13:02:55 [INFO]\t[TRAIN] Epoch=18/50, Step=198/478, loss=0.048145, lr=0.071002, time_each_step=1.29s, eta=5:37:7\n",
      "2022-01-20 13:02:58 [INFO]\t[TRAIN] Epoch=18/50, Step=200/478, loss=0.077199, lr=0.070994, time_each_step=1.29s, eta=5:37:11\n",
      "2022-01-20 13:03:00 [INFO]\t[TRAIN] Epoch=18/50, Step=202/478, loss=0.063586, lr=0.070987, time_each_step=1.29s, eta=5:37:8\n",
      "2022-01-20 13:03:03 [INFO]\t[TRAIN] Epoch=18/50, Step=204/478, loss=0.083191, lr=0.070980, time_each_step=1.29s, eta=5:37:12\n",
      "2022-01-20 13:03:06 [INFO]\t[TRAIN] Epoch=18/50, Step=206/478, loss=0.075297, lr=0.070973, time_each_step=1.29s, eta=5:37:10\n",
      "2022-01-20 13:03:08 [INFO]\t[TRAIN] Epoch=18/50, Step=208/478, loss=0.055557, lr=0.070965, time_each_step=1.28s, eta=5:36:46\n",
      "2022-01-20 13:03:11 [INFO]\t[TRAIN] Epoch=18/50, Step=210/478, loss=0.085461, lr=0.070958, time_each_step=1.28s, eta=5:36:42\n",
      "2022-01-20 13:03:13 [INFO]\t[TRAIN] Epoch=18/50, Step=212/478, loss=0.092016, lr=0.070951, time_each_step=1.29s, eta=5:38:23\n",
      "2022-01-20 13:03:16 [INFO]\t[TRAIN] Epoch=18/50, Step=214/478, loss=0.069597, lr=0.070943, time_each_step=1.29s, eta=5:36:50\n",
      "2022-01-20 13:03:18 [INFO]\t[TRAIN] Epoch=18/50, Step=216/478, loss=0.059366, lr=0.070936, time_each_step=1.29s, eta=5:37:35\n",
      "2022-01-20 13:03:21 [INFO]\t[TRAIN] Epoch=18/50, Step=218/478, loss=0.104425, lr=0.070929, time_each_step=1.29s, eta=5:37:14\n",
      "2022-01-20 13:03:24 [INFO]\t[TRAIN] Epoch=18/50, Step=220/478, loss=0.054774, lr=0.070921, time_each_step=1.28s, eta=5:36:23\n",
      "2022-01-20 13:03:26 [INFO]\t[TRAIN] Epoch=18/50, Step=222/478, loss=0.077571, lr=0.070914, time_each_step=1.29s, eta=5:36:50\n",
      "2022-01-20 13:03:29 [INFO]\t[TRAIN] Epoch=18/50, Step=224/478, loss=0.071806, lr=0.070907, time_each_step=1.29s, eta=5:36:52\n",
      "2022-01-20 13:03:31 [INFO]\t[TRAIN] Epoch=18/50, Step=226/478, loss=0.059316, lr=0.070900, time_each_step=1.29s, eta=5:36:42\n",
      "2022-01-20 13:03:34 [INFO]\t[TRAIN] Epoch=18/50, Step=228/478, loss=0.101132, lr=0.070892, time_each_step=1.29s, eta=5:36:31\n",
      "2022-01-20 13:03:36 [INFO]\t[TRAIN] Epoch=18/50, Step=230/478, loss=0.089703, lr=0.070885, time_each_step=1.29s, eta=5:36:43\n",
      "2022-01-20 13:03:39 [INFO]\t[TRAIN] Epoch=18/50, Step=232/478, loss=0.046867, lr=0.070878, time_each_step=1.28s, eta=5:36:10\n",
      "2022-01-20 13:03:42 [INFO]\t[TRAIN] Epoch=18/50, Step=234/478, loss=0.081360, lr=0.070870, time_each_step=1.28s, eta=5:35:53\n",
      "2022-01-20 13:03:44 [INFO]\t[TRAIN] Epoch=18/50, Step=236/478, loss=0.052782, lr=0.070863, time_each_step=1.29s, eta=5:38:0\n",
      "2022-01-20 13:03:47 [INFO]\t[TRAIN] Epoch=18/50, Step=238/478, loss=0.046888, lr=0.070856, time_each_step=1.28s, eta=5:36:3\n",
      "2022-01-20 13:03:49 [INFO]\t[TRAIN] Epoch=18/50, Step=240/478, loss=0.079827, lr=0.070849, time_each_step=1.28s, eta=5:36:1\n",
      "2022-01-20 13:03:52 [INFO]\t[TRAIN] Epoch=18/50, Step=242/478, loss=0.060795, lr=0.070841, time_each_step=1.29s, eta=5:36:50\n",
      "2022-01-20 13:03:54 [INFO]\t[TRAIN] Epoch=18/50, Step=244/478, loss=0.063343, lr=0.070834, time_each_step=1.28s, eta=5:35:48\n",
      "2022-01-20 13:03:57 [INFO]\t[TRAIN] Epoch=18/50, Step=246/478, loss=0.066409, lr=0.070827, time_each_step=1.28s, eta=5:35:46\n",
      "2022-01-20 13:04:00 [INFO]\t[TRAIN] Epoch=18/50, Step=248/478, loss=0.094829, lr=0.070819, time_each_step=1.29s, eta=5:37:8\n",
      "2022-01-20 13:04:02 [INFO]\t[TRAIN] Epoch=18/50, Step=250/478, loss=0.059012, lr=0.070812, time_each_step=1.29s, eta=5:36:11\n",
      "2022-01-20 13:04:05 [INFO]\t[TRAIN] Epoch=18/50, Step=252/478, loss=0.068818, lr=0.070805, time_each_step=1.29s, eta=5:36:5\n",
      "2022-01-20 13:04:07 [INFO]\t[TRAIN] Epoch=18/50, Step=254/478, loss=0.065780, lr=0.070797, time_each_step=1.29s, eta=5:37:5\n",
      "2022-01-20 13:04:10 [INFO]\t[TRAIN] Epoch=18/50, Step=256/478, loss=0.072173, lr=0.070790, time_each_step=1.29s, eta=5:36:1\n",
      "2022-01-20 13:04:12 [INFO]\t[TRAIN] Epoch=18/50, Step=258/478, loss=0.069533, lr=0.070783, time_each_step=1.29s, eta=5:36:5\n",
      "2022-01-20 13:04:15 [INFO]\t[TRAIN] Epoch=18/50, Step=260/478, loss=0.075902, lr=0.070776, time_each_step=1.29s, eta=5:35:54\n",
      "2022-01-20 13:04:18 [INFO]\t[TRAIN] Epoch=18/50, Step=262/478, loss=0.060876, lr=0.070768, time_each_step=1.29s, eta=5:36:50\n",
      "2022-01-20 13:04:20 [INFO]\t[TRAIN] Epoch=18/50, Step=264/478, loss=0.080077, lr=0.070761, time_each_step=1.29s, eta=5:35:36\n",
      "2022-01-20 13:04:23 [INFO]\t[TRAIN] Epoch=18/50, Step=266/478, loss=0.095649, lr=0.070754, time_each_step=1.29s, eta=5:36:38\n",
      "2022-01-20 13:04:25 [INFO]\t[TRAIN] Epoch=18/50, Step=268/478, loss=0.052217, lr=0.070746, time_each_step=1.29s, eta=5:35:47\n",
      "2022-01-20 13:04:28 [INFO]\t[TRAIN] Epoch=18/50, Step=270/478, loss=0.073567, lr=0.070739, time_each_step=1.29s, eta=5:35:43\n",
      "2022-01-20 13:04:30 [INFO]\t[TRAIN] Epoch=18/50, Step=272/478, loss=0.054614, lr=0.070732, time_each_step=1.29s, eta=5:36:2\n",
      "2022-01-20 13:04:33 [INFO]\t[TRAIN] Epoch=18/50, Step=274/478, loss=0.050847, lr=0.070724, time_each_step=1.29s, eta=5:35:36\n",
      "2022-01-20 13:04:36 [INFO]\t[TRAIN] Epoch=18/50, Step=276/478, loss=0.047226, lr=0.070717, time_each_step=1.29s, eta=5:35:31\n",
      "2022-01-20 13:04:38 [INFO]\t[TRAIN] Epoch=18/50, Step=278/478, loss=0.074090, lr=0.070710, time_each_step=1.29s, eta=5:36:15\n",
      "2022-01-20 13:04:41 [INFO]\t[TRAIN] Epoch=18/50, Step=280/478, loss=0.050383, lr=0.070703, time_each_step=1.28s, eta=5:35:14\n",
      "2022-01-20 13:04:43 [INFO]\t[TRAIN] Epoch=18/50, Step=282/478, loss=0.063240, lr=0.070695, time_each_step=1.29s, eta=5:35:28\n",
      "2022-01-20 13:04:46 [INFO]\t[TRAIN] Epoch=18/50, Step=284/478, loss=0.053753, lr=0.070688, time_each_step=1.29s, eta=5:35:32\n",
      "2022-01-20 13:04:48 [INFO]\t[TRAIN] Epoch=18/50, Step=286/478, loss=0.060962, lr=0.070681, time_each_step=1.28s, eta=5:35:2\n"
     ]
    }
   ],
   "source": [
    "\"\"\"训练模型并保存，可视化训练过程\"\"\"\n",
    "# 使用随机增强不要固定种子\n",
    "# random.seed(2048)\n",
    "# np.random.seed(2048)\n",
    "# paddle.seed(2048)\n",
    "\n",
    "num_classes = len(train_dataset.labels)\n",
    "model = pdx.seg.DeepLabV3P(num_classes=num_classes, use_mixed_loss=True)\n",
    "model.train(\n",
    "    num_epochs=50,\n",
    "    train_dataset=train_dataset,\n",
    "    train_batch_size=4,\n",
    "    eval_dataset=eval_dataset,\n",
    "    learning_rate=0.1,\n",
    "    lr_decay_power=0.8,\n",
    "    save_interval_epochs=1,\n",
    "    save_dir='model/deeplab_augument_alldata3',\n",
    "    use_vdl=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
